Debug doesn't need to be i18n.
Keeping the semi-colon outside the T() is deliberate so as to reduce the amount of duplicate work for the translators

ok, these strings could usefully be made i18n, as you do, however the exact trap which is first on the issue list to resolve has been fallen into: the word order is forced:
Don't break sentences up into fragments - please review the wiki to see how to address this.

I like the overall loook here, thanks.
However, a couple of implementation tweaks would be useful:
(1) Take a look at other deployment_settings and you'll see that read requests go through functions defined in modules/s3cfg.py.
This allows us to change the way in which this data is stored without changing code outside of this 1 module.
(2) JS shouldn't be added inline like this - instead it should be added to response.s3.js_global or response.s3.jquery_ready so that it loads at the bottom of the page after the layout has finished rendering
(3) I'm not sure that (m)any live deployments will want to refer to @sahanafoss when tweeting - they'll rather want to talk about this specific branded deployment.

(1) Would this be adding to modules/s3cfg.py:
    def get_share_social_media(self):
        return self.share.get("social_media", False)
, having a deployment_settings.share.social_media = True; in models/000_config.py which can be commented out
, and {{if deployment_settings.share.social_media:}} at layout.html?
I get an internal error for 'NoneType' object has no attribute 'social_media'
I don't understand what read requests are, or what the 1 module we are currently talking about is.
(2) Where can I find response.s3.js_global or response.s3.jquery_ready?

Look in layout.html for response.s3.*

If you create a new level of hierarchy in s3cfg (which is almost certainly unnecessary) then you need to initialise it in init.

Generally with Git, the idea is to make efforts to reduce the number of commits in the published branches.
Interim commits should ideally be hidden inside local feature branches. Suggest trying to get into this habit?

Removed numpy as a dependency

Yeah, have this one already, thanks

The S3XML fix is not correct. The actual mistake is that the branches of the "if" are mixed up - it should be the other way around. I have already fixed it in my local development branch, unsurprisingly exactly the same way Graeme did here:
https://github.com/graeme-f/eden/commit/ee197ce4d115f66ef6d4c89b28219e8054d405d3#L2L398

Sorry, see comment: http://ssf.sahanafoundation.org/eden/project/task/66

As discussed on IRC - try/except should be reduced to just the cPickle.loads and return a meaningful error representation if it fails, the function lacks a docstring and has a stealth name (should be renamed into search_vars_represent) as does the parameter "id" (should better be "search_vars"). import re and type cast is the right fix, although there maybe a (separate) problem with the search_vars field being a "string" instead of "text" (it could get truncated due to the default max length), so the field type should change into a "text".

Maybe later thinking about moving from cPickle to JSON to store the vars - this would be readable at the CLI and in the DB, it is unicode-compatible, and it can be read by JS directly without need for special back-end handling (hence we could Ajax' the search vars to populate forms).

Okay.I have made the suggested changes and am sending another pull request with updates.

Better not to read settings direct from the deployment_settings dict - instead create an API function in modules/s3cfg & call that. This allows the back-end storage to be changed more easily.
000_config.py template should be as empty as possible, so the API defaults to the default setting (True would give backward compatiblity), so the example should be commented-out.
I suggest 'milestones' for the title of the setting.
I don't understand the variable name 'listo' - could this not be 'list_fields'?
I am very wary of setting staff = milestones...I'd rather have the milestones check be 'staff & milestones'
(The staff check is based on membership of a group in branches)

Also, please rebase your commits where possible before publishing on GitHub to keep the revision history cleaner.

Okay.I have done the suggested changes and sent a new pull request.  https://github.com/flavour/eden/pull/35

Thanks :)
Pls remember to format with PEP8 (mainly spaces between tokens) - I'll fixup this time np, but pls don't make me always have to do that ;)

Okay,sure.I will keep it in mind:-)

On 27-Mar-2012 6:36 PM, "Fran Boon" <
reply@reply.github.com>
wrote:

Pls remember to format with PEP8 (mainly spaces between tokens) - I'll
fixup this time np, but pls don't make me always have to do that ;)

---

Reply to this email directly or view it on GitHub:
https://github.com/flavour/eden/pull/35#issuecomment-4715727

Thanks for catching and fixing this, Ashwyn!  -- Pat

No problem at all :)

I think the 'import inv' is wrong.
There seem to be a couple of indent issues too & the db=current.db should have PEP-8 spaces.

Thanks,
Fran.

Also would be great to remove the non-std CamelCase in the function name whilst there (pls grep code for any other refs to it)

Thanks!

I have made the necessary changes. Please have a look.

Thanks.

Can you rebase to make this appear as a single commit?
- this both helps to keep trunk cleaner & also makes it easier to review...

Thanks :)
F

Hi flavour, the pull request is ready now. Please have a look at it

Thanks,
Vivek

Can this be rebased?
13 commits is a lot to weigh trunk down with & also makes it much harder to review...

Thanks :)

If I could work out how to do it I'd be happy to try. But I can't get it to work. I thought that some of these you'd already merged they are over a week old so I don't really know what is happening.

probly my rebase.

A rebase is basically as simple as:
cd eden
git rebase -i

There may be merge conflicts in which case you can identify them via:
git rebase -- continue
& once fixed:
git add .
git rebase -- continue

Obviously these get a lot easier when done sooner rather than letting them accumulate...

F

Hi Pratyush, could this be rebased?
git rebase -i

We're trying to keep the trunk history as clean as possible & it makes it easier to review patches.
Thanks :)
Fran.

rebase doesn't work after pushing to GitHub - really needs to be done _before_ Pushing.
The best option now may be to make a patch to apply to a clean clone & then use rebase before pushing for future work...

Thanks, some suggested improvements:

Avoid XPath expressions like this as they're fragile: driver.find_element_by_xpath("//div[@id='facility_box']/a[4]/div").click()
Instead, edit the actual code to put an unambiguous ID where you want (or at least closer)

Avoid repeated lookups like this: driver.find_element_by_id
Instead create a shortcut:
find_element_by_id = driver.find_element_by_id
find_element_by_id(
find_element_by_id(
find_element_by_id(

It would be good to move the test data out of the main code - a simple set of variables within the function is an adequate start.

Please can you squash the commits into a single one using 'git rebase':
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#OngoingCoding

Thanks :)
Fran.

2 more little tweaks (sorry!):
- Docstring in the s3cfg.py function
- this will be used by WebSetup to proivde online help
- PEP8 spacing around the format==None

Thanks!
Fran.

Sorry Fran, I've been having problems with the Internet, over the last few
days. It is now back and hopefully it is stable.

You want me to make a patch of the code changes. Not certain how I would do
that. Would making a backup of all the changed files, getting a clean clone
and then restoring the backup work?

Graeme

There are a number of possible options outlined on the Wiki:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git

One way is indeed the .git folder from a clean clone with the rest of the files from your current branch & then doing a fresh:
git add .
git commit -a

A demo of the patch can be seen at http://106.187.91.158:8000/eden/irs/ireport login using blah@blah.com and blah as password. :)

Thanks - could you resubmit with more care on the PEP8 whitespace between tokens?
Whilst there, you could align the # in the commented zzz_1st_run.py as per the other functions.

Thanks :)

Can you give me a clean pull request please?
- this has 7 commits, whereas I'd like just 1...

Thanks!

Extremely sorry , i think i pushed an earlier commit :(. I have sent a new pull request.

This fixes some ADAT and inv bugs whilst also adding some functionality to the dataTable tests. The whole merge is one mess mixed up with changes is trunk. For the third time in a row this has taken me more than 2 hours to achieve. I need a simple guide to tell me how to push my changes without all this mess.

Files that I have changes
controllers/inv.py
modules/eden/inv.py
modules/eden/survey.py
modules/s3/s3survey.py
modules/tests/core/dataTable.py
modules/tests/inv/logistics.py

Moved to a new pull request:  https://github.com/flavour/eden/pull/61

Thanks - can these 5 be squashed to 1?

Note, I still need to do the CLA. but this is possibly not beyond the "threshold of originality"? anyway, I'll do it today.

I assume that you gave a correct Lat/Lon for these facilities?
Can you see them correctly via 'Show on Map' when looking at the facility details?
Are there any error tickets being logged? (look in Admin menu)

PS Git Issues isn't currently a recommended support channel. Suggest IRC &/or the mailing list.

I found the issue - a regression from merged code attempting to fix something else. I have reverted that & all should now work properly if you do a 'git pull'

Dear Flavour,
    Thank you very much. After git pull this version , it works fine now... :D http://3wa.tw:8000/eden/gis/index

```
Yesterday, I spend all the day trace and survey the code like controller/inv.py controller/gis.py... 
I increase lots of my dirty-codes to implement what I want...
I modified controller/inv.py open a new way for warehouse..and do select from gis_location and org_office...
Add lots codes, complete destruction of MVC structure ... XD

http://140.134.48.117/eden/gis/index

At last I can show these icons by myself, but poor performance and didn't know how to use the openlayers api .. lol

Thanks again for your help. You're so awesome. 
```

These menu changes have not been discussed, so I am reluctant to merge them.

The use of 'New XXX' here comes from maintaining the familiar paradigm from the desktop:
http://eden.sahanafoundation.org/wiki/BluePrint/Menu/Application#Description
I see no reason to arbitrarily change this to 'Add XXX'

The experiment to change to breaking menus up by type not resource should be done as a demo URL for discussion on the mailing list - not pushed as a pull request to trunk.

Also I see a test.xml artifact in the root, which should be removed...I'd prefer tests not to write output there, but if this is essential then add to .gitignore

On 15/06/12 7:14 PM, Fran Boon wrote:

> These menu changes have not been discussed, so I am reluctant to merge them.
> Fair enough - should I flick an email to the mailing list? Do you have 
> any big concerns - so I can try and present a balanced argument on the 
> list?
> The use of 'New XXX' here comes from maintaining the familiar paradigm from the desktop:
> http://eden.sahanafoundation.org/wiki/BluePrint/Menu/Application#Description
> I see no reason to arbitrarily change this to 'Add XXX'
> Eero requested this. I'm less concerned about the choice (Add XXX vs. 
> Add New XXX) than I am about being consistent with this choice.
> The experiment to change to breaking menus up by type not resource should be done as a demo URL for discussion on the mailing list - not pushed as a pull request to trunk.
> Are you refering to the splitting of reports into a report menus - which 
> I thought we had discussed - admittedly not on the list.
> Or what I've done with just the Asset menu? I thought that this would be 
> something that we could use for a example.
> Setting up a demo URL would be a huge overhead for me - although I can 
> easily share a mockup.

Cheers

## 

Michael Howden
skype: michael.howden
twitter:@michaelhowden
Managing Director, AidIQ
Director, Sahana Software Foundation
Sahana Eden Project Management Committee
Sahana Community Development Committee

On 16 June 2012 07:07, Michael Howden michael@sahanafoundation.org wrote:

> On 15/06/12 7:14 PM, Fran Boon wrote:
> 
> > These menu changes have not been discussed, so I am reluctant to merge
> > them.
> > Fair enough - should I flick an email to the mailing list? Do you have any
> > big concerns - so I can try and present a balanced argument on the list?

Other than just forcing undiscussed changes on trunk, the main thing
for me is the use of the term 'New' & not 'Add XXX'
'Add XXX' is really cluttered & I find it hard to see what's going on
- really contributes to the "too many menu items, I can't see what's
  going on"
  This simple approach is clean/uncluttered:
  Resource
- New
- Search

& the term 'New', specially in this menu position resonates nicely
with the default desktop UI of File | New

> > The use of 'New XXX' here comes from maintaining the familiar paradigm
> > from the desktop:
> > http://eden.sahanafoundation.org/wiki/BluePrint/Menu/Application#Description
> > I see no reason to arbitrarily change this to 'Add XXX'
> > Eero requested this. I'm less concerned about the choice (Add XXX vs. Add
> > New XXX) than I am about being consistent with this choice.

+1 to consistency.
I believe we are reasonably consistent already, however the commit you
are pushing makes us more inconsistent

> > The experiment to change to breaking menus up by type not resource should
> > be done as a demo URL for discussion on the mailing list - not pushed as a
> > pull request to trunk.
> > Are you refering to the splitting of reports into a report menus - which I
> > thought we had discussed - admittedly not on the list.
> > Or what I've done with just the Asset menu? I thought that this would be
> > something that we could use for a example.

Asset menu.
Trunk shouldn't really be used for examples like this

> Setting up a demo URL would be a huge overhead for me - although I can
> easily share a mockup.

A demo URL is obviously better as people can interact with it, but a
mockup is at least a significant step forward :)

F

(Not sure why the previous comment went under Michael's name!)

3W in the OCHA standard has neither Activities nor Communities.
I think we should therefore make their presence separate deployment_settings
- I had deliberately pushed this back to DRR as I have a 3W project which definitely doesn't want Communities, but I can appreciate you might not want this lumped within 'DRR'

Objectives doesn't seem generic either - again if you don't want this within 'DRR' then simply make another deployment_setting - I thought we'd agreed that the default option should be fewer fields rather than more.

Thinking about this more, perhaps making the generic table project_location with an optional label of 'Community' works best for all 3W cases & this should deprecate the countries_id field (which can instead be calculated virtually from the project locations)
This allows us to have projects stored just at the country level of granularity (as many are for both DRRPP & Oxfam) and allow going down to L1 or lower where we can (such as some Oxfam & the majority of OCHA 3W where the location focus is definitely within a single country...albeit many projects have national scale).
The label 'Community' is perfectly appropriate when we get down to the L3/L4 level but most data we have for DRRPP/Oxfam is L0, L1 or L2 at best...

On 16/06/12 10:23 PM, Fran Boon wrote:

> (Not sure why the previous comment went under Michael's name!)
> 
> 3W in the OCHA standard has neither Activities nor Communities.
> Do you have a link for this?
> I think we should therefore make their presence separate deployment_settings
> +1
> - I had deliberately pushed this back to DRR as I have a 3W project which definitely doesn't want Communities, but I can appreciate you might not want this lumped within 'DRR'
>   No - it should be a separate setting
> 
> Objectives doesn't seem generic either - again if you don't want this within 'DRR' then simply make another deployment_setting - I thought we'd agreed that the default option should be fewer fields rather than more.
> -1 Objectives seem a pretty generic thing for projects IMHO
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/112#issuecomment-6372192

## 

Michael Howden
skype: michael.howden
twitter:@michaelhowden
Managing Director, AidIQ
Director, Sahana Software Foundation
Sahana Eden Project Management Committee
Sahana Community Development Committee

On 16/06/12 11:41 PM, Fran Boon wrote:

> Thinking about this more, perhaps making the generic table project_location with an optional label of 'Community' works best for all 3W cases
> Perhaps - but wary of changing the data model again...
> & this should deprecate the countries_id field (which can instead be calculated virtually from the project locations)
> -1
> The user interface wouldn't be as good.
> This allows us to have projects stored just at the country level of granularity (as many are for both DRRPP & Oxfam) and allow going down to L1 or lower where we can (such as some Oxfam & the majority of OCHA 3W where the location focus is definitely within a single country...albeit many projects have national scale).
> The label 'Community' is perfectly appropriate when we get down to the L3/L4 level but most data we have for DRRPP/Oxfam is L0, L1 or L2 at best...
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/112#issuecomment-6372590

## 

Michael Howden
skype: michael.howden
twitter:@michaelhowden
Managing Director, AidIQ
Director, Sahana Software Foundation
Sahana Eden Project Management Committee
Sahana Community Development Committee

Why restrict expandability to "count" aggregation? We want to be able to expand _any_ aggregated value that is not a "list".
Where the fact field is a foreign key, we want to show the representation of the foreign records, while when the fact field is a value in the current resource, we want to show the representation of that record plus the value. The list items should be linked to the underlying records if the user is permitted to open this URL (may use S3NavigationItem to auto-deactivate).

What if the record representation is already being shown in the row or 
column header?

On 26/06/12 18:10, Dominic König wrote:

> Why restrict expandability to "count" aggregation? We want to be able to expand _any_ aggregated value that is not a "list".
> Where the fact field is a foreign key, we want to show the representation of the foreign records, while when the fact field is a value in the current resource, we want to show the representation of that record plus the value. The list items should be linked to the underlying records if the user is permitted to open this URL (may use S3NavigationItem to auto-deactivate).
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/124#issuecomment-6567900

Thanks, I've merged.

I guess the S3Parsing() class being loaded from default isn't
implemented yet, right?
I would completely swap around the functions in default.py & s3parser.py
- the introspection should be in the core & the examples in the template
  The examples need more refactoring:
- there should be a first level parser 'search' which decides whether
  we're looking for People, Orgs or Hospitals, directing to the relevant
  2nd-level parsers
- the code which is common between the 3 searches should be moved to
  core utility functions
  I am very wary about using soundex as the default search method - I
  think that should be configurable (default to off)

Please note the following issues for next time please (although I'm
aware some was in inherited code):
- (table.deleted == False) is generally more appropriate than
  (table.id> 0) [Although even better is to use resource to handle
  security but that can wait atm]
- no need to import everything - just what is needed (too much
  copy/paste is bad!)
- limitby=(0, 1) to optimise queries which you .first() anyway
- do modifications outside loops where possible (e.g. soundex(str(name)))
- please be careful to avoid tons of trailing white space everywhere
  (& the double indents in some functions)
- try to stick within the 80 character column limit (use \ )
- docstring formatting
- no need for current in controllers
- no need to db.commit() in interactive controllers (happens at the
  end of the page) [& if not being run interactively then don't
  redirect!]
- the membership check within the controller was redundant as the
  decorator did that anyway, however easier to modify the other form, so
  I removed the decorators instead [Although modified to use the more
  efficient s3_has_role(ADMIN)]
- request.args(0) won't crash if arg not present, unlike
  request.args[0](although maybe a try/except around the crashing form
  provides safety for bad args without slowing down the common case of
  args being present)
- if you have a docstring in a function (good!) then don't duplicate
  this with another # comment saying the same thing

Please let me know if this all makes sense to you :)

F

Note that I also changed the name of the deployment_setting & moved
s3parser out of s3base as we want to minimise the amount that we load
every request & there is minimal dependency on this
- the modules/eden/msg.py import needs changing to suit still, sorry I
  didn't fix that...

F

Thanks Fran!
*Yes,  S3Parsing() class being loaded from default isn't implemented yet but it will be there in the next commit.
*And, I also believe that s3parser should have the introspection code and examples in the template.(Will be changed next time.)
*I did not tweak the examples as of yet considering them only to be illustrative of different workflows.But, sure I will put up a 2-level ladder for the parsers and move the common code to the core utility.
*Yes, whether to use soundex or the core difflib module will be a deployment_setting as discussed with you and Praneeth.  
*Again, I am sorry that you had to bear the burden of fixing these issues for me.But surely I will keep these things in mind and ensure that I don't repeat them in future :)
*And I will fix the eden/modules/msg.py  import as well, no problem.

Regards,
-Ashwyn

Thanks - some good work here :)
I did my usual cleanups, whilst reading the code, such as consistency of " vs ', fewer intermediate variables unless they are used multiple times,do more of the model definition in-line, less use of caching (which can give unexpected effects) & various formatting, such as reducing to 80 chars.
I have left you a few @ToDos:
- Deal with msg_report table (move to msg.py or rename as can't be loaded from here)
- Move Incident Categories to a common table
- i18n all the field labels
- move the comments to a prep in the controller
- add missing CRUD strings

Only the 1st 2 are important before mid-terms...

I deliberately kept the tablename as project_community_contact as this both makes more sense & sounds nicer than project_location_contact - we don't really have a contact when this is an L0/L1 location...only when we are going down to the L4 Community level does this make sense.

Generally best to keep running in 'en' (override language in 000_config) so that we don't fill the en-gb
Also check your source data:
+'Catalogues': 'Catalogues',

I merged the Inv/Req stuff.
Not sure about exposing facilities in Inv? Should we not be encouraging use of other facility types?

Hi Fran,
I have not created the 2 level flow for parser examples as of now as they are just illustrative of independent workflow tasks.Eventually however there will be more refined examples put in.
Regards,
-Ashwyn

Why should we represent blank comments as NONE?
I prefer blank fields here - less confusing for the eye...

In a read page this means that the comment label will appear directly on
top of the label of the field below it.

On Tuesday, July 3, 2012, Fran Boon <
reply@reply.github.com>
wrote:

> Why should we represent blank comments as NONE?
> I prefer blank fields here - less confusing for the eye...
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/139#issuecomment-6730000

On 3 July 2012 10:51, Michael Howden
reply@reply.github.com
wrote:

> In a read page this means that the comment label will appear directly on
> top of the label of the field below it.

Generally comments field is lowest on the form..?

F

On 3/07/12 9:52 PM, Fran Boon wrote:

> On 3 July 2012 10:51, Michael Howden
> reply@reply.github.com
> wrote:
> 
> > In a read page this means that the comment label will appear directly on
> > top of the label of the field below it.
> > Generally comments field is lowest on the form..?
> > Generally - but we cannot guarantee that this will always be true. Still 
> > it looks like a error not to display anything - more consistent to use 
> > current.messages.NONE (Which can be configured globally)

Merged.
Could the 2 queries in source_represent() not be made into a single join?

Thanks.
Sure I will see if I can put a single join there :)

Please rebase pull requests - this one has 5 commits which is hard to wade through.
There are several errors where my work has been reverted.
There is a lot of hard-coding of roles directly within the model, which is inappropriate - most deployments won't use these roles.
That kind of security should ideally be done within the s3_permission table or else within a deployment branch (or at least protected by deployment_settings).
I am still wading through

Smoke test fails:

> python web2py.py -S eden -M -R applications/eden/modules/tests/suite.py -A --suite smoke
> web2py Web Framework
> Created by Massimo Di Pierro, Copyright 2007-2011
> Version 2.00.0 (2012-07-01 22:43:58) dev
> Database drivers available: SQLite3, pymysql, psycopg2, pg8000, IMAP
> runTest (applications.eden.modules.tests.smoke.broken_links.BrokenLinkTest) ... ERROR

# 

## ERROR: runTest (applications.eden.modules.tests.smoke.broken_links.BrokenLinkTest)

Traceback (most recent call last):
  File "applications\eden\modules\tests\smoke\broken_links.py", line 90, in runTest
    if self.login(user):
  File "applications\eden\modules\tests\smoke\broken_links.py", line 77, in login
    if form["_formname"] == "login":
  File "C:\bin\Python27\lib\site-packages\twill-0.9-py2.7.egg\twill\other_packages_mechanize_dist\ClientForm.py", line 2863, in __getitem__
    return self.find_control(name).value
  File "C:\bin\Python27\lib\site-packages\twill-0.9-py2.7.egg\twill\other_packages_mechanize_dist\ClientForm.py", line 3194, in find_control
    return self._find_control(name, type, kind, id, label, predicate, nr)
  File "C:\bin\Python27\lib\site-packages\twill-0.9-py2.7.egg\twill\other_packages_mechanize_dist\ClientForm.py", line 3278, in _find_control
    raise ControlNotFoundError("no control matching "+description)
ControlNotFoundError: no control matching name '_formname'

---

Ran 1 test in 2.826s

FAILED (errors=1)

ok, rebased, so the good stuff is in

This should be ok, yet I would have to test it.

Can you rebase on my branch and then re-send this pull request to me? That would be most helpful.

Can this be rebased please?

I think I picked out the few new changes which were buried amidst a heap of mine (I don't think the rebase went quite right!)

Could this be rebased into a single commit to make it easier to review & keep trunk revision history cleaner?
Thanks :)

Can this be rebased to 1 commit instead of 4?
Also I'm not sure why you move sys out of the rarely-used context into the commonly-used one?
Sure it'll likely be loaded by core web2py anyway (although Eden doesn't, other than in debug mode), but still no point in making the system check it's presence every request when we only need it for those very rare occasions when lxml isn't installed...

Why store Resilience values in the vulnerability_data table?
This means a lot of ugly code with a hardcoded 'magic' value of "Resilience" as one of the prepopped vulnerability_indicators.
I have removed some of the code to simplify it (we should minimise calls to s3.\* - these are primarily for caching, which wasn't being done here)

update_super should be done via the API not via a custom hack

I don't see why a JSON blob is put inside an item-container in the view....I moved that to js_global.

Why use stats_data not vulnerability_data when this is a custom function? (will have less rows to scan when we use stats for other things)

Graeme and I discussed the location of the Resilience Index and agreed that it's best to store this in vulnerability_data. What would you propose for the "Resilience" indicator? I would prefer the term "Index". Do you see this as a Deployment Setting?
Graeme: It's worth reading http://eden.sahanafoundation.org/wiki/S3XRC/ModelExtensions/SuperEntities if you haven't already.

The term 'Resilience' is fine.
What I object to is including this as a hardcoded name within the vulnerability_data table - it means that we have to do 2 lookups in this table - 1 to get all indicators (excluding this) & 1 to get this one - all very ugly.
Since this is something different (another type of aggregate) then it should be in a different table (even if all the fields are identical) -0 We never need to see/manage these together - always want them separate & currently we always need to filter for either case.

I'd say that it would be better to try and get both the indicators and the Resilience index in one lookup.
-1 to adding another table

-1 to this bastardized mixing of different resources within a single table with consequenty difficulties of coding.

Another table make it so simple.

What reason other than 'too many tables' is there for munging into a single table?

F

If at any point in the future there's the desire to switch between the indicators vs. the index - say in the map or a graph

And that's how it is now.

I don't see it as any harder to do either of these in 2 tables vs 1.

It is easy to make the change now, but will become increasingly hard as we layer all these myriad exceptions on top...

Why bother making a list of indicators flexible if 1 of the names is a magical one which is hardcoded to mean something _completely_ different?

What is the purpose of these functions, which I had removed previously & have come back in?
vulnerability_index_id()
vulnerability_ids()

These are too simple a lookup to benefit from an abstraction to hide the implementation details, which I just find unnecessarily confusing & prevents the ability to do the lookup as part of a single-request join when-possible.

I see that the results are now cached within each request, but I am unaware of any request which reads these more than once. If we think that this simple DAL request is so heavy that we should cache the result, then it should be cached in the session which would be cross-request, but I don't think even that would help the async requests which update the aggregates.

I would prefer to remove this level of abstraction again as it provides unnecessary complication for no added value.

Also these 3 commits should be rebased.

I was in the process of merging the 3 commits when you made your comment, I believe that they have now been merged.

If the results are not async then the cache will help. If the vulnerability indicator is to have an enabled field introduced then that will need to be checked the same of other features such as position. Then having the test in a single location makes it easier to implement those changes. Same idea for the index_id at the moment the table assumes to have a single record if that changes then having the look up in a single place makes it easier to fix.

commit have indeed been compressed now, thanks.

results will only be non-async on developer machines & we shouldn't be optimising code for that usecase.

An enabled field for indicators is very hypothetical  at this point - I personally very much doubt it will ever happen:
Not enabled == deleted.
What would be more likely is a more complex thing such as different Organisations wanting different indicators....I don't believe we should be adding complexity now which /might/ help that, but might also hinder it as it makes the current code a more complex starting point.

I would rather not assume a single record anyway in the aggregated indicators.
I would rather have the aggregation that we're interested in have a UUID & query for that (UUID means that the user-visible label can still be changed if-required).

Can you rebase this to squash to a single commit?
Thanks

Patch to the dispatch message is very heavy - remember the default for these messages is SMS, not email.
The help text should be massively shortened - maybe to something like "send help to see how to respond"

Why do we need the IS_IN_SET on msg_sessions? This table is never going to have users added manually is it?
We should avoid DB queries within the model if at all possible - if there were an interface to add sessions manually, the DB queries should be in that controller only (we don't want to slow down normal session lookups).
- this same principle applies to msg_log.source_task_id

Likewise I'm not sure it needs T() labels if this is just a back-end resource.

The tablename should be msg_session (singular) for consistency

s3msg could use some minor optimisations in the loop by moving the lookups outside the loop:
S3Parsing.parser
ltable.insert
otable.insert
ctable.contact_method
ctable.value
ltable.id

Likewise in s3parser.py, why instantiate Auth_Parse() twice?
request.utcnow lookup could be moved out of the loop
More importantly, why is the check for record.sender==sender not part of the DB query?
Do we need to check for deleted==False here? What process will ever delete these records? (Again this is pure back-end functionality)

parse_login shouldn't need to touch auth any more it seems - no need to define_tables() etc?

I see some formatting issues, especially that you use Tabs in some places instead of Spaces (these are very obvious in the GitHub .diff as the indent looks all wrong - the file itself appears OK at first glance but the tabs can be seen with as little checking)

templates/default/parser.py
No need for the query = query & s3_accessible: just add that part of the query directly.

Just picked the 1-line change to avoid having to revert the en-gb.,py

Consolidated into a single commit;
The stats_aggregate data model, with unit tests for the onaccept
Rename some files used in the test framework to avoid a name conflict
Initial ground work for the filter for vulnerability reports

I have made the suggested changes and refactored the parser into 2-step flow.Resent the request ;)

Is this the 1st-step parser?:
https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/modules/s3/s3parser.py#L43

(1) This needs to be in the template as needs to be editable per-deployment
(2) It doesn't seem to be a 2-step as it branches based on workflow rather than deciding the workflow
(3) The first part assumes ireport - loading all those models which will slow things down at best & barf completely if the irs module is disabled.
(4) Unlike what the docstring says, it doesn't appear to be called by parse_ireport

Seem to have lost a few cleanups I made
- tabs have come back into the templates/default/parser.py (obvious as the indentation looks all wrong on this page)
- the definition of accessible_query before multiple uses
- the adding of this direct in the main query rather than separately.

For the import of soundex, try this:
from s3.s3utils import soundex
(Sorry what I put in didn't work)

The else clause here should be done as a single Join rather than 3 sequential queries:
https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/private/templates/default/parser.py#L311

This doc line is incorrect:
https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/private/templates/default/parser.py#L7

I won't merge as-is.

F

> Is this the 1st-step parser?:
> 
> https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/modules/s3/s3parser.py#L43
> 
> Yes.
> 
> (1) This needs to be in the template as needs to be editable per-deployment
> (2) It doesn't seem to be a 2-step as it branches based on workflow rather
> than deciding the workflow
> 
> Well, I thought we agreed on this to start with.Though these three parsers
> should be a part of a single workflow; I used them as three different
> workflows to illustrate the concept of linking of a message source with a
> workflow.So, having a single step-1 parser the way you are saying is
> completely redundant since the user already made a choice of having all the
> messages going through a particular workflow no matter what.But, yes if
> they were to exist as a single workflow , which they ultimately will,then
> having a step-1 parser makes complete sense.

Here, the step-1 parser is only taking care of a situation when a message
source is linked to multiple workflows and then only the workflow for which
the message is intended is used.

> (3) The first part assumes ireport - loading all those models which will
> slow things down at best & barf completely if the irs module is disabled.

I will correct it.

> (4) Unlike what the docstring says, it doesn't appear to be called by
> parse_ireport
> 
> Which docstring? If you are talking about the one here at
> https://github.com/ashwyn/eden/blob/master/modules/s3/s3parser.py#L48 , it
> says called by parse_import(). Its the polling function in s3msg.py.
> 
> Seem to have lost a few cleanups I made
> - tabs have come back into the templates/default/parser.py (obvious as
>   the indentation looks all wrong on this page)
> 
> I am a little confused with this.This time I only used spaces as you had
> suggested, I seem to be misunderstanding this a bit :( . Can you explain
> why is this happening?
> - the definition of accessible_query before multiple uses
> - the adding of this direct in the main query rather than separately.
> 
> For the import of soundex, try this:
> from s3.s3utils import soundex
> (Sorry what I put in didn't work)
> 
> The else clause here should be done as a single Join rather than 3
> sequential queries:
> 
> https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/private/templates/default/parser.py#L311
> 
> This doc line is incorrect:
> 
> https://github.com/ashwyn/eden/blob/34efa90d6e8f4393621febb7bccafc3a3b42cf69/private/templates/default/parser.py#L7
> 
> I won't merge as-is.
> 
> F
> 
> —
> 
> Noted.I will make the corrections.

Regards,
-Ashwyn

On 16 August 2012 12:05, Ashwyn notifications@github.com wrote:

> > (1) This needs to be in the template as needs to be editable
> > per-deployment
> > (2) It doesn't seem to be a 2-step as it branches based on workflow
> > rather
> > than deciding the workflow
> > Well, I thought we agreed on this to start with.Though these three parsers
> > should be a part of a single workflow; I used them as three different
> > workflows to illustrate the concept of linking of a message source with a
> > workflow.

This was a very temporary allowance.

> So, having a single step-1 parser the way you are saying is
> completely redundant since the user already made a choice of having all
> the
> messages going through a particular workflow no matter what.But, yes if
> they were to exist as a single workflow , which they ultimately will,then
> having a step-1 parser makes complete sense.

I think we have 2 1st-phase parsers here:
- The Org/Person/Hospital one
- The ireport one

This is a good demo for showing both aspects.

> Here, the step-1 parser is only taking care of a situation when a message
> source is linked to multiple workflows

This should only be possible via chaining right?
Source links to 1st-pass & then that passes on to the appropriate 2nd-pass

> > (4) Unlike what the docstring says, it doesn't appear to be called by
> > parse_ireport
> > Which docstring? If you are talking about the one here at
> > https://github.com/ashwyn/eden/blob/master/modules/s3/s3parser.py#L48 ,
> > it
> > says called by parse_import(). Its the polling function in s3msg.py.

This URL is currently failing for me (GitHub appears to be having troubles,
so am replying here by email)
Maybe I misread it.

> > Seem to have lost a few cleanups I made
> > - tabs have come back into the templates/default/parser.py (obvious as
> >   the indentation looks all wrong on this page)
> >   I am a little confused with this.This time I only used spaces as you had
> >   suggested, I seem to be misunderstanding this a bit :( . Can you explain
> >   why is this happening?

Only way it can happen is if the text editor puts them there.
I guess my changes got lost as you took your version not mine - clone each
into separate folders to confirm the difference.

Thanks,
Fran.

Hi,

> I think we have 2 1st-phase parsers here:
> - The Org/Person/Hospital one
> - The ireport one
> 
> This is a good demo for showing both aspects.

Yea seems like the right choice. So we would have two workflows to choose
from . One would be parse_ireport . What would you like to name the other
one ?

Regards,
-Ashwyn

Sorry forgot to clarify previously .... And both stage parsers should stay
in the parser.py template ?
Also do you think nesting the two step functions into a single method would
be the correct approach ? Or having them as separate functions is the right
choice ?
- Ashwyn
  On Aug 18, 2012 10:05 AM, "ashwyn sharma" ashwyn1092@gmail.com wrote:

> Hi,
> 
> > I think we have 2 1st-phase parsers here:
> > - The Org/Person/Hospital one
> > - The ireport one
> > 
> > This is a good demo for showing both aspects.
> 
> Yea seems like the right choice. So we would have two workflows to choose
> from . One would be parse_ireport . What would you like to name the other
> one ?
> 
> Regards,
> -Ashwyn

On 17 August 2012 23:35, Ashwyn notifications@github.com wrote:

> > I think we have 2 1st-phase parsers here:
> > - The Org/Person/Hospital one
> > - The ireport one
> >   This is a good demo for showing both aspects.
> >   Yea seems like the right choice. So we would have two workflows to choose
> >   from . One would be parse_ireport . What would you like to name the other
> >   one ?

keyword_search?

F

On 17 August 2012 23:59, Ashwyn notifications@github.com wrote:

> Sorry forgot to clarify previously .... And both stage parsers should stay
> in the parser.py template?

Yes

> Also do you think nesting the two step functions into a single method would
> be the correct approach ? Or having them as separate functions is the right
> choice ?

Separate functions makes it more modular

F

Okay thanks :)
On Aug 18, 2012 10:30 AM, "Fran Boon" notifications@github.com wrote:

> On 17 August 2012 23:59, Ashwyn notifications@github.com wrote:
> 
> > Sorry forgot to clarify previously .... And both stage parsers should
> > stay
> > in the parser.py template?
> 
> Yes
> 
> > Also do you think nesting the two step functions into a single method
> > would
> > be the correct approach ? Or having them as separate functions is the
> > right
> > choice ?
> 
> Separate functions makes it more modular
> 
> F
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/170#issuecomment-7841815.

Can this be rebased to squash to a single commit?
Thanks

Can this be rebased to squash to a single commit?

Thanks - merged :)

Please fix the above issues before merging this.

In some places, whitespace gets added, in other places it gets removed - should be consistent, if at all. Some of the changes don't seem to have to do with the search subscription functionality at all - but affect other cases in a way that is not intended.

Rewriting master branch to discard old changes.

> This may need a left join, and a meaningful default for the project code. Also avoid repeated dict lookups - use s3db.tablename to load the tables and store the tables in a local variable.

Have changed. Project code is populated in project onvalidation.

> r.component_id?

changed

> You should use the scheduler here, not cron. And "admin@example.com" is not necessarily a user in the system (this is a test account).

I have removed the impersonate line but left as a cron script as that is what was requested.

> Still can't understand why you are removing show_link here. It may be True by default, but it is made explicit here to have it visible.

It prevented me from specifying a different value, and it was suggested that I remove it.

> Why does pr_saved_search use pe_id, not person_id? Isn't it always a person to save a search?

to facilitate group/organisation notifications in a future revision.

> You may want to use current.manager.represent instead

latest commit changes it to current.manager.represent

> never convert payload data into str

I will have used str() because unicode() and s3_unicode() choke on T<> objects and sometimes HTML helper objects. Uses of str() have been removed.

> Just wondering whether it is wise to only send HTML as notification email.

The task was to only support HTML emails for now.

> left as a cron script as that is what was requested.

I'm sure that was an error. Scheduler is the new cron.

Are there any other issues to be fixed before this can be merged?

I don't see any now.

Note that resource.select() does always return an iterable, so the extra count() isn't necessary unless you need an exact number.

ok, so can we get this rebased pls, ready to merge? Thanks :)

<Fran__> from gluon.languages import translator as T
<Fran__> Why?
<Fran__> we should use current.T
<Fran__> Am not sure why you don't follow the std of before functions putting:
<Fran__> # ---------------------------------------------------------------------
<Fran__> S3.i18n["Show full text"] = "{{=T("Show full text")}}";
<Fran__>    24 
<Fran__> +S3.i18n["Truncate text"] = "{{=T("Truncate text")}}";
<Fran__>    25 
<Fran__> +S3.i18n["View saved search."] = "{{=T("View saved search.")}}";
<Fran__> Do we really see these used so frqwuently that we want to parse them every HTML request?
<Fran__> Not better to inject them only when the widget is used?
<Fran__> static/scripts/S3/s3.search.js
<Fran__> JS should be ' not "
<Fran__> T("'My Page' is a private space which allows you to "),
<Fran__>    7 
<Fran__> +  STRONG(
<Fran__>    8 
<Fran__> +    T("save your favourite searches, graphs, matrix reports and maps"),
<Fran__>    9 
<Fran__> +  ),
<Fran__>    10 
<Fran__> +  T(" for later viewing. It is also where you can "),
<Fran__>    11 
<Fran__> +  STRONG(
<Fran__>    12 
<Fran__> +    T("manage the projects you are authorised to edit"),
<Fran__>    13 
<Fran__> +  ),
<Fran__>    14 
<Fran__> +  T("."),
<Fran__> Not very i18n
<Fran__> Word orders can be different in diff languages
<Fran__> Should be:
<Fran__> T("'My Page' is a private space which allows you to %(save)s for later viewing.") % dict(save=STRONG(T("save your favourite searches, graphs, matrix reports and maps")))
<Fran__> Even that isn't great, but it's better
<Fran__> In general I like view templates to have less whitespace in them
<Fran__> Since these files are downloaded to browsers
<Fran__> I like to save every little bit of bandwidth as users may be on crappy 3rd-world connections or expensive Satellite links
<Fran__> class mypage():
<Fran__> def **call**(self):
<Fran__> response = current.response
<Fran__>    703 
<Fran__> +        request = current.request
<Fran__>    705 
<Fran__> +        T = current.T
<Fran__> Why bring these into scope when one of the 2 branches doesn't use them?
<Fran__> I'd move that into the one branch which does use them
<Fran__> def project_activity_represent(row):
<Fran__> Since this is a method of the class which has just loaded project_project & project_activity, no need to use s3db, db is fine
<Fran__> I'm also not happy with all the style changes
<Fran__> Not just in new code but also modified code

Please remove the test result artifact (add folder to .gitignore) and also pls don't update en-gb.py unless there are actual translations in there.

Thanks!

Why remove this?
-                   onaccept = lambda form: auth.s3_approve_user(form.vars),

It was added to fix an issue with prepopped users not having an organisation set unless their email domain is in auth_organisation.

s3rest.py Fix is already in trunk

Can this be compressed with the move of this function to default so that there's less churn

Thanks

Update of:
flavour/eden#218

I don't see the mother/father names fields as being a generic requirement,
but rather specific to a very few use cases.
In general we prefer to hide fields (ideally in optional components) when
they are used in only a few cases as otherwise these forms look really
complicated to people doing data entry.

On 11 October 2012 10:52, Michael Howden notifications@github.com wrote:

> ---
> 
> You can merge this Pull Request by running:
> 
>   git pull https://github.com/michaelhowden/eden master
> 
> Or view, comment on, or merge it at:
> 
>   https://github.com/flavour/eden/pull/237
> Commit Summary
> - \* hrm_human_resource deletable by default (duplicate/error records
>   wi…
> - Merge branch 'master' of git://github.com/flavour/eden
> 
> File Changes
> - _M_ modules/eden/pr.py (8)
> - _M_ modules/s3cfg.py (2)
> 
> Patch Links
> - https://github.com/flavour/eden/pull/237.patch
> - https://github.com/flavour/eden/pull/237.diff
>   
>   —
>   Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/237.

Got a suggestion for the component name?

extra? optional?

pr_person_extra?
pr_person_optional?
yeah - either could work

The bug is still there with that line uncommented, which isn't surprising.
Open the Vulnerability app & select 'Approve Reports (seems like a common workflow)
With the lines uncommented then we get 'no results found'.
With the lines commented, we see 8 unapproved records in need of actioning.
This shouldn't make any difference to the usecase where a specific location is chosen first to approve records for as that branch should never be taken.
I also fixed a u() issue in the loc_represent & stopped accidental leaking of 2 JS vars into the global scope.

Dominic likes dashed lines so try that too. I thought dashed looked a little busy, perhaps.

I'll try both, thanks.

I absolutely want test users in the template as I prepop several times/day when doing dev & I really don't want to have to re-register every time, so reverting that one.

Refactoring with s3_represent_id and s3_represent_multi_id functions has passed both smoke and functional tests

Dominic --

Let me be clear that I am not saying there's anything wrong with the code being tested -- all I'm saying is that the removed test fails, and the failure seems reasonable. A ticket would be appropriate if this is not a correct fix. Since I've taken a fair amount of time to be sure I'm not mistaken in what the test is doing, let me first describe what happens when I run the test, and then suggest some reasons why your test runs may behave differently.

The unit tests fail reproducibly at this point:

FAIL: testExportTreeWithMSince (applications.eden_trunk.modules.unit_tests.s3.s3resource.ResourceExportTests)

## Test automatic ordering of export items by mtime if msince is given

Traceback (most recent call last):
  File "applications\eden_trunk\modules\unit_tests\s3\s3resource.py", line 1281,
 in testExportTreeWithMSince
    self.assertEqual(uuid, first)
AssertionError: 'ORDERTESTHOSPITAL2' != 'ORDERTESTHOSPITAL1'

In the test preparation here...
            resource.import_xml(xmltree)
...the elements do not get inserted in the database in the order in which they appear in the xml text. That's not a problem as far as I know -- the order of elements in the xml isn't supposed to be counted on, no? So here's what happens (as actually observed during single-stepping, on multiple runs):

The elements in the xml _text_ are in the order:
ORDERTESTHOSPITAL1
ORDERTESTHOSPITAL2

S3Resource.import_xml makes an S3ImportJob and calls S3ImportJob.add_item to add the elements to the S3ImportJob instance's items (which is a Storage):

```
    self.items[item_id] = item
```

Then S3ImportJob.commit is called.  It gets the keys out of items like this:

```
    import_list = []
    for item_id in self.items:
        self.resolve(item_id, import_list)
        if item_id not in import_list:
            import_list.append(item_id)
```

The Storage iterator does not deliver the items in a guaranteed order, and the order in which they appear.  They are inserted in import_list in the order in which they're delivered by the iterator.  That was reliably the opposite order from that in which they were inserted in the Storage.  That is, import_list pointed to the items in this order:
ORDERTESTHOSPITAL2
ORDERTESTHOSPITAL1

They're inserted in the table in the order in which they appear in import_list:

```
    for item_id in import_list:
        item = items[item_id]
        error = None
        success = item.commit(ignore_errors=ignore_errors)
```

So at this point, the table contains:

id = 1, uuid = ORDERTESTHOSPITAL2
id = 2, uuid = ORDERTESTHOSPITAL1

Now, back in the test, the records are loaded in a specified order:

```
        resource = current.s3db.resource(resource,
                                        uid=["ORDERTESTHOSPITAL1",
                                            "ORDERTESTHOSPITAL2"])
        resource.load()
        self.assertEqual(len(resource), 2)
        first = resource._rows[0]["uuid"]
        last = resource._rows[1]["uuid"]
```

That respects the order in the uid list, so:
first = ORDERTESTHOSPITAL1
last = ORDERTESTHOSPITAL2

The test without msince extracts a record like this:

```
        tree = resource.export_tree(start=0,
                                    limit=1,
                                    dereference=False)
```

S3Resource.export_tree, given no other ordering criteria, gets records in the order in which the database provides them, which is id order.  With the limit of 1, this gets id 1, which has uuid ORDERTESTHOSPITAL2.  The test expects the extracted record to have uuid ORDERTESTHOSPITAL1, and thus fails.

Since the test name and docstring both indicate it is a test for exporting _with_ msince, so the test _without_ msince was likely not important, and since the test _without_ msince fails reproducibly, it seemed reasonable to remove it.

Ok, now, why might your tests not fail?

Unlikely reasons:
1) Sqlite behaves differently on Windows (which I'm running) from the systems on which you're testing.
2) I have a different version of Sqlite, and that version behaves differently.
3) You're not using Sqlite for tests, and whatever you are using behaves differently.
4) Your code in modules/s3/s3resource.py or modules/s3/s3import.py differs from what's in Fran's Github repo.

Less unlikely:
5) You're using a different version of Web2py, and in your version, Storage behaves differently.
c:\web2py>cat VERSION
Version 2.0.9 (2012-09-15 15:42:37) stable
c:\web2py>git log | head
commit 2ba88b8951181e92571577ec753bd9a478a08126

I still don't see why there's any expectation of a guaranteed order in the import -- seems that it should be perfectly legal to import in arbitrary order.  I'm fairly sure you told me yourself, at RELIEF, when I was fussing with loading hospital addresses and phone numbers from OSM data, that I shouldn't expect the children of an xml element to be delivered in any particular order.

I just looked at the current gluon/storage.py, and Storage is still a subclass of dict there, and doesn't seem to have any OrderedDict-like mechanism. I recall seeing some posts about Storage being changed, and comments that it no longer supported dict methods, but wasn't the modified Storage reverted?  In fact, it was Dominic's complaint that got it reverted:
http://code.google.com/p/web2py/issues/detail?id=942

I'm sorry, but it does really not matter for this test in which order the items get written to the database. The test does not expect a particular order:

The test imports the items:

```
        resource = current.s3db.resource("hms_hospital")
        resource.import_xml(xmltree)
```

and then _loads them to see which one is first and which one is second_:

```
        resource.load()
        self.assertEqual(len(resource), 2)
        first = resource._rows[0]["uuid"]
        last = resource._rows[1]["uuid"]
```

then updates the mtime of the first in the DB:

```
        resource._rows[0].update_record(name="OrderTestHospital1")
```

and then checks that the records in export without msince appear in the same order as before:

```
        tree = resource.export_tree(start=0,
                                    limit=1,
                                    dereference=False)
        root = tree.getroot()
        self.assertEqual(len(root), 1)
        child = root[0]
        uuid = child.get("uuid", None)
        self.assertEqual(uuid, first)
```

whilst export with msince must reverse that order:

```
        tree = resource.export_tree(start=0,
                                    limit=1,
                                    msince=msince,
                                    dereference=False)
        root = tree.getroot()
        self.assertEqual(len(root), 1)

        child = root[0]
        uuid = child.get("uuid", None)
        self.assertEqual(uuid, last)
```

The first assertion about the order is important: if the first assertion fails, then the second assertion is always wrong (i.e. it will succeed if the order isn't reversed, and fail if the order is reversed). Therefore, both assertions have to remain in place - sorry if you've invested a lot of time into it.

However, that means, regardless in which order the records get written to the DB, the test should always give the same result. The only thing I can imagine why it fails for you is indeed an SQLite-specific issue. To overcome it, you may try and change (in the test function):

```
resource.load()
```

into

```
resource.load(start=0, limit=2)
```

Generally, if a unit test fails for you then you can very well file a bug report (regardless whether the cause is in the tested code or in the unit test itself) - and you can keep it short by just reporting which assertion fails. If you do not understand the test, then this is certainly the best thing to do (although unit tests should always come with a comment to explain the purpose of the test).

This is where your analysis goes wrong:

> That respects the order in the uid list, so:
> first = ORDERTESTHOSPITAL1
> last = ORDERTESTHOSPITAL2

load() does not "respect" the order of the UID list - it just loads all matching records.

I am wary of this - why do we have locations with UNICODE issues?
All the locations we import are (painstakingly) correct.
Is this about user-supplied CSVs that they import?

I don't know which locations are causing the problem. I suspect that it is some user supplied location but the error trace doesn't give me any clue, so I am wrapping the code in question in a try except and then I hope that the code will no longer crash (although it might at another point). Once it runs successfully I can then look at the result and work out what location(s) is(are) actually causing the problem.

Sorry, I should have mentioned that I can't replicate this problem locally, and I have (although not currently) tested it with all the location data. So that suggests to me that the cause is user supplied data. But it could be a database issue, python version, web2py version, web server or a host of other differences between the developer and production environments.

If None is a valid option then searching for this (possibly amongst other options) is indeed a requirement.
If None isn't a valid option then it won't show.
"-" shouldn't be the representation for this option, though

F

Waiting to hear back form Dominic if will add this option or would like me to. Think that maybe he has more important things to work on - so I'm happy to.

merged, tx

 "None" search option appears after Any & All - so as it's not confused as one of the options. WE could disable the rest of the search options for the field when None is chosen - although currently we can select None AND other values to search

I like this - good to be able to keep the window open whilst navigating around the rest of the site :)
merged

@flavour It'd be awesome if this could be merged in quickly. There's other stuff that depends upon this.

Looks like I can't tag @nursix here but please let him know I fixed the problems with the quotes.

No need to tag me - watching you ;)

Happens if message limit is enabled.

Adding link to CLA (plus appropriate verbiage) to the README, as per Mark's email.

merged, thanks :)

Thanks.
I moved the represent to a deployment_setting & extended to modified_by to
affect watermarks too
I also corrected the ["UNKNOWN_OPT"] in both this & where it was copied
from since this format won't translate (which is fine for NONE, but not
UNKNOWN_OPT)

Ok, alright :+1: 

I'm unclear as to whether this is ready to be merged since the first step is 'Finalise CSS' and there are several 'move XX from Skeleton to SandyRelief'...seems like these should be done prior to merging?

Why are the non-theme template elements copied to the skeleton folder?
- my feeling is that the 'default' is already the skeleton for templates, no?
  (what I see here suggests a lot of duplication)

Is the idea that the default theme is the skeleton one or not?
Ultimately the default template should be able to pick from a range of pre-defined themes

(I believe the mail to list hasn't yet happened?)

Yes - this is ready to be merged - as I've made sure that it won't affect the current implementation.
What non-theme template elements are you refering to? In the private/templates/skeleton folder? Yes - these probably aren't all needed - this was a copy of default.
Currently Skeleton isn't usable (have a look at it without the sandy.css). We'll need to decide what the right balance between simple and usable (pretty) is. I think that actually default should be re-implemented on top of skeleton.
Ultimately the default template should be able to pick from a range of pre-defined themes.

My point is that this should be changed in 2 ways:
1) Move Sandy-specific stuff out of the Skeleton theme folder and into the SandyRelief theme
2) Delete the whole of the Skeleton template folder as this does nothing & is just duplicate code

I think xtheme-gray.css can also be removed from the Skeleton folder as can be referenced from default?
We then can add a Readme to Wiki about Skeleton Theme (& it being incomplete)

Is this the right plan?

Yes! Thanks!

merged, thanks :)

@flavour Is there a problem with this?

Just the few lines in moduels/irs.py were needed, not the rest. I merged manually, thanks :)

-1 to removing the configuration option from s3aaa.py
Instead the setting would be defined in deployment_settings so that it can be customised per instance without changing core code.

So instead of defiining in s3aaa.py, you want that value to be imported from 00_settings, right?

Afraid not ;)
The issue is that the setting here isn't being read properly by static/scripts/jquery.pstrength.2.1.0.js
The place where this is being done is:
https://github.com/flavour/eden/blob/master/modules/s3/s3utils.py#L999

Seems like the setting name in the JS changed between versions & we didn't update...

As I mentioned before, we really would like this to be customisable in [000_]config.py so adding a deployment_setting to modules/s3cfg.py would be very useful too...

Can this be rebased to make it easier to review?

Many thanks,
Fran.

how do I undo these? how do I backout my changes and remove my pull request?

On 12 December 2012 12:55, Liezl notifications@github.com wrote:

> how do I undo these? how do I backout my changes and remove my pull
> request?

<flavour>
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#Resettingtoapreviouscommit

I tried changing it again, in eclipse then compare the file. All good.
GitHub is showing only the lines I changed (see image below):
![uncommit_changes](https://f.cloud.github.com/assets/1223842/8197/af16631e-4468-11e2-97d8-cdcf387cd775.jpg)

then after I commit the change, git is saying I diff is too large to show (see image below):
![dff_too_large](https://f.cloud.github.com/assets/1223842/8201/dc241a72-4468-11e2-825c-76f87888482e.jpg)

Could this be some setting in my git? Please help.

Also these are the only lines I  changed:

clear_button=$('<input id="%(selector)s_clear" type="button" value="clear"/>').click(function(e){
 $('#%(selector)s').val('')
})
if ($("#%(selector)s_clear").length == 0) {
 $('#%(selector)s').after(clear_button)
}''' % \

Can you promote this so I can move forward? I will try to resolve this git problem later.

merged manually

In put a skip in earlier for these as they don't display anyway, so why work on them?

Yep, sorry -- forgot to rebase after the last few commits. While I'm at it, I'm going to clean it up a little. Will resubmit shortly.

Oops wrong commit :(

Thanks - can the 4 commits be squashed together as 1?
- makes it much easier to review...

Squashed!

Thanks - can you compress these 2 into 1 commit? (rebase with squash)
Also for the SandyRelief theme, the changes should be made to the .less file which generates the .css (happy for it to be in the .css too)
Many thanks,
Fran.

I'll try to rebash, it will be my first time doing I might need your help. What would happen with this pull request. Can I remove the 2 commits here and replace with a new combined one?

On 20 December 2012 12:21, Liezl notifications@github.com wrote:

> I'll try to rebash, it will be my first time doing I might need your help.
> What would happen with this pull request. Can I remove the 2 commits here
> and replace with a new combined one?
> 
> yes

This doesn't make a difference for me

This fix works for me - but Dominic should review

Browser? Works for me on Chrome. Also, how are you exiting full screen mode? What is displayed in the browser's error console?

Closing, as @nursix has merged this into https://github.com/nursix/eden/commit/d2afba2f4b9b53d64e184da4e5f78ed5a8de1dd5.

Most of these comments are also on the task itself: 

1) UI isn't clear (I shouldn't have gotten confused what happens next after  select a region to crop out). 
2) This should show the image then a button to switch over to the Image Crop Widget perhaps? 
3) instructions on what to do would be nice too!

1. I'm adding some help text to clarify.
2. The image is the crop widget :)
3. Dealt with in #1

Traceback (most recent call last):
  File "C:\Users\rob\web2py\gluon\restricted.py", line 212, in restricted
    exec ccode in environment
  File "C:/Users/rob/web2py/applications/imagecrop/controllers/doc.py", line 225, in <module>
  File "C:\Users\rob\web2py\gluon\globals.py", line 193, in <lambda>
    self._caller = lambda f: f()
  File "C:/Users/rob/web2py/applications/imagecrop/controllers/doc.py", line 146, in image
    output = s3_rest_controller()
  File "C:/Users/rob/web2py/applications/imagecrop/models/00_utils.py", line 294, in s3_rest_controller
    output = r(**attr)
  File "applications\imagecrop\modules\s3\s3rest.py", line 933, in __call__
    output = postprocess(self, output)
  File "C:/Users/rob/web2py/applications/imagecrop/controllers/doc.py", line 142, in postp
    args=[path] + points + [S3ImageCropWidget.DEFAULT_WIDTH])
  File "applications\imagecrop\modules\s3\s3task.py", line 267, in async
    exec(statement)
  File "<string>", line 1, in <module>
  File "C:/Users/rob/web2py/applications/imagecrop/models/tasks.py", line 12, in crop_image
    image = Image.open(path)
  File "C:\Python27\lib\site-packages\PIL\Image.py", line 1952, in open
    fp = **builtin**.open(fp, "rb")
IOError: [Errno 22] invalid mode ('rb') or filename: 'C:\Users\rob\web2py\x07pplications\imagecrop\uploads\images\doc_image.file.8ea8c6d9923223fd.323031322d31302d32302031332e32312e33392e6a7067.jpg'

Am a bit disappointed that this still requires upload of (potentially huge) images to the server for further processing instead of cropping/resizing client-side and only upload what's needed. Would very much prefer a client-side solution, and have the server-side solution be the fallback if browser support is lacking.

@nursix I'm having some trouble with my Eden/web2py setup -- if you've got some time, could you come on IRC and help me out?

EDIT:
And when I say trouble, I mean _big_ trouble. With the latest web2py and eden, I get a message saying that my web2py version is too old, web2py's admin interface doesn't allow me to log in, and eden creates error tickets, but I can't see them because I can't log into the admin interface.

This doesn't follow the spec. HUGE and egregious oversight on my part not checking the wiki task description. Re-read it and ping a mentor when it's completed.

The main reason to limit the size of the pictures is bandwidth rather than storage. Uploading/downloading huge image files is a serious bottleneck on low-bandwidth (and/or expensive) connections.

The ideal solution would allow the user to scale the image down to a lower resolution so they can still upload the complete picture, and _optionally_ - in cases where a section of the picture would suffice the documentation purposes - allow to crop the picture to that section. This should of course happen before upload - otherwise the upload of hundreds of pictures will become quite a painful task - and keep the server busy.

This widget allows cropping of images, and is certainly nice GUI-wise. But it does not seem to really solve the bandwidth problem (i.e. the actual reason why we want to limit the size of the pictures)?

IMHO it would be much more reasonable to utilize any available client-side option (HTML5, Flash, Silverlight, Gears or whatever) and even suggest the user to install such capabilities where possible (which in case of Flash would be just a small one-time-download) - before falling back to server-side processing as an absolutely last resort. That is, I'd argue that downloading and installing Flash once is a much smaller pain than to upload and post-process hundreds of large image files - and if the user already has such capabilities installed, then I find it hard to justify why we wouldn't use them.

29 dec 2012 kl. 23:59 skrev robbyoconnor notifications@github.com:

> This doesn't follow the spec. HUGE and egregious oversight on my part not checking the wiki task description. Re-read it and ping a mentor when it's completed.
> 
> —
> Reply to this email directly or view it on GitHub.

@robbyoconnor The task description and the details given at http://eden.sahanafoundation.org/wiki/Contribute/Code#ScaleUploadedImagesGCI don't match up -- one of them calls for scaling, the other for cropping.

Regardless, I'm going to give it one last try with Canvas. Might not work because of security restrictions, but still.

@nursix I couldn't find any (Flash widgets) that are open source...

Here's the design I'm planning to follow:
1. What I already have remains as it is.
2. When instantiating S3ImageCropWidget, you'll be able to provide a tuple with an "ideal size", and the image will be scaled to fit that bounding box.
3. When Canvas support is available, it'll be used to crop and scale the image client side, and to upload the image asynchronously to a different controller, which will decode the image, save it, and pass back the path.
4. This path will be returned to the server as part of the regular update operation.
5. The postp() method in the controller can then change the file field to match.

Could anyone confirm that this is OK?

This is a significant amount of code, so I'd like a bit of an extension to the task deadline: http://www.google-melange.com/gci/task/view/google/gci2012/7960219

Web2py parse_version added a new value to the tuple it returns. <whine>Said new value could have been tacked on the end, where it would not have affected the offsets.</whine>

Can this be rebased/squashed if there is still work to be merged?

Thanks :)

Deprecated - fixed properly in the OptionsFilter widget

A fair lump of JS there, which would be better moved to Static rather than pushed to browser inline.
Inlijne pushing is usually just tiny snippets which contain server-side config for the bulk of the functionality in Static to run with.

Appears to make things worse for me - I don't see any problem before this commit - sure the Paragraph formatting isn't visible after displaying the preview window, but I hardly see that as a bug - & if it is it's upstream, not in our implementation.

After this patch, the paragraph window is too large & overflows it's container - ugly...reverting. (FF)

+1 -- put it there because there because it was already that way

Why?

We keep this file to only strings which actually are different between en-US & en-GB

Looking good, although need to also ensure that you catch the read of the OSM settings in modules/s3/s3gis.py in show_map()
Also, no need to bring current.db into scope in controllers.

Done :)

@flavour Just curious -- why are functions from modules not copied into s3db unless their names are prefixed by a table name? auth_user_options_get_osm sounds like a quirky name ;)

U sent a pull request or il commit the changes and send it?

auth_get_osm would be fine - it's only the module prefix which is mandatory, not the tablename...

nursix fixed this issue generically, however I still agree with making the deliver to field read-only on req tabs - so adding this into prep of facility controllers (such as hms/hospital) is still welcomed :)

This is included in my fix - flavour. If a request is made from a facility, the facility field becomes readonly.

This is WAY too much text to read - can you provide a quick reference please?

(for http://www.google-melange.com/gci/task/view/google/gci2012/8149205)

Fran, is this okay now?

Please hold off from merging this -- I want to get some more stuff in, and doing it at once would be better, I guess.

Hmm, I thought there were several long comments by Dominic in this pull request, but Github is not showing them to me now. I may have them in email.

The wrappers for simple DAL getters are gone. I've left in clear_table in order to have a "matched set" with read_table and load_table (and because someone was allowed to commit an entire file called clear_table.py!) but if that is regarded as a serious roadblock to acceptance, I'll take that out.

I've simplified the usage of InterceptCall, provided default behavior that may satisfy a lot of use cases, and added an explanation to the class docstring.  Please see if the modified docstring is sufficient, or if a summary is still needed.

Have to break off here -- sleep calls. I'll modify compare_table to return the actual table row that caused a failure, along with which criterion it failed. Most tests stop on the first failure (i.e. they just have asserts as they do each check) rather than attempting to collect up all results before failing, so this behavior -- returning the first failure -- is no different. A full diff of the table vs. the supplied patterns might be useful if the test data were prepared entirely for the specific test, and not full of prepop data not relevant to the specific test. An option for a full diff could be added, but do we need that, given it's not what normal tests do?

Lacking the comments, I'm responding to what was in them from memory...

IIRC one objection was that test writers should gut through all their test setup explicitly because this makes debugging easier. I disagree. If we use helpers to simplify setup and analysis in tests, so that instead of pages and pages of repetitive error-prone boilerplate we can have more compact code in which the actual test data and the execution of the system under test is what's most visible, then people are _more likely to write tests_. If people don't have to spend lots of time working around irrelevant data and figuring out how to pick out their results from lots of irrelevant database contents, they're more likely to write tests. If the detailed analysis of results can be packaged up in a helper, then people won't be tempted to just spot-check, or do incomplete checks like "how many rows were added". I'd rather have the helpers and get more tests written.

IIRC another objection was that this looks complicated and "requires 3 years at Harvard". IMO it's not complicated and contains minimal Python trix. The DBMS-specific stuff for enabling and disabling constraints is a consequence of the quirks of the DBMSs we use. And as far as complicated goes, I have just one word: s3. Pointers to examples of "complicated" available on request. ;-)

I suggested to Fran that we could simplify testing, and cover a lot more with unit tests if we practiced "design for test". That term is more commonly applied to hardware (e.g. use of scan chains), but is equally valid and useful for software. I'll add a description of how that's done in software to the testing blueprint.

+1 to insert_resource, although I'd like to see this properly prefixed. Unfortunately, this doesn't support the additional post-commit-hooks yet - maybe they should be added as options. Update_super should also be made optional (can still be default).

For the other helpers (database observation) I'm still -1, I don't see that pattern currently and don't want to promote it for low-level tests. Higher-level test cases /may/ have some benefit (in terms of DRY, not necessarily in terms of robustness), so if at all, then they should probably be moved into the Web2UnitTest class.

For the interceptor, I would prefer if you re-submitted this once you are starting to submit the code for which you intend to write unit-tests for which you intend to use this. I don't say /you/ don't need this - but right now, for the rest of the system this is purely academic (intentionally not saying premature here - which initial design would not be).

Style-wise I'd still wish you would reduce comments to facts (sober reference documentation instead of prose) and remove any design discussion/suggestions (this can happen in a BluePrint). Todo's are fine, but not for discussion.

The rest of your discussion above I can't follow anymore - so not commenting on that.

Let's get insert_resource fixed up:

> I'd like to see this properly prefixed.

Specifically?  insert_s3resource?  Isn't that assumed?  It shouldn't be anything like s3_insert_resource as it's not part of any framework -- it's just a test helper.

> Unfortunately, this doesn't support the additional post-commit-hooks yet - maybe they should be added as options.

Sure, which are those?

> Update_super should also be made optional (can still be default).

It looked like it did the right thing if no superentities were needed (which, IMO, is good behavior).  Hence here it can be called even if it turns out to be a no-op.  The point is that the user doesn't need to state what to include -- the helper just does whatever's needed.

Hmm, you didn't change anything - did you?

By "properly prefixed" I meant typically "self." ;) But more than that, insert_resource is misleading because you can not "insert a resource". You can create a record and execute the post-commit hooks defined by the respective table model. So, if at all then it is something around create_test_record.

The point about making update_super optional is not primarily that it should do by default what's required, but more that it should _not_ do something that's not wanted. Update_super is not necessary for most of the unit tests, and sometimes even undesirable.

Apart from that: all that stuff happening implicitly is exactly what I don't want in unit tests - mainly because unit testing is not primarily QA:

Primarily, I'm writing unit tests as part of the design process, i.e. _before_ I implement the functionality. I do this to validate the design. Consequently, I would implement every little step separately, because only then I can see the dependencies I'm creating - and in that I'm _intentionally_ leaving out dependencies which I do not want to be there. 

Only then I implement the new functionality so it works with exactly the dependencies I defined. Implicit fulfillment of dependencies is a problem, especially where I can't see them because they are in a helper function far away from my test class.

In other words: if I want to implement a functionality that shall not depend on update_super, then I do intentionally not do update_super - even if that is a normal pre-condition.

Some of the unit tests - typically for critical core functionality - would remain in place so they can also be used for continuous testing. But this is not the primary goal - it's rather a meaningful recycling of the output of another part of the process. I do however try to keep this small - i.e. have as _few_ unit tests for routine checking as possible: first of all so they can be run before every commit (requirement: all routine tests together should not take longer than 30 seconds), but also to not create too much rigor because re-design/re-architecture is a normal part of our development process.

So, all other unit tests, especially for higher-level or non-critical functionality, would be removed once the development in this space is complete - or even never get published. Hence, out of the almost 20000 unit tests I've written for Eden, only about 250 got ever published - the majority of which targeting critical core functionality.

Another purpose of (typically temporarily) publishing unit tests is collaboration - typically where on developer depends on a certain behavior of a component while another developer is working on it. In this scenario, the test cases mainly support the communication of requirements, but also help to overcome communication bottlenecks such as time zones or different working hours - i.e. I can check whether my stuff works for Fran without asking Fran to test it and give me feedback, I can in fact get the feedback immediately and 1000 times a day while Fran can focus on other stuff. However - once done with the component, only the critical tests remain in place so that they don't get in the way (~create extra workload) when new requirements come in.

To make sure the top-level requirements (at the surface level) are still fulfilled, we have the functional tests and CI.

In the light of this, your test helpers have a rather very limited purpose within unit-testing. They may be useful for what you intend to implement - but for that I suggest you move them into the respective unit test class, and reduce them to what you really need there.

Apart from your own needs, I am currently your main consumer - and I'm really sorry to say that again: your helpers don't help me, I see this as purely academic and unrelated to our development process. The other test suite (QA) may benefit from this, though.

Yes, I changed things prior to your comment. I overwrote the previous commit.

Or in other words: in most cases, broken unit tests indicate a change, not a defect - and so they only create extra workload unless kept to a critical minimum. Avoiding this rigor is a priority when we want to be agile - the overkill-testing does only create problems, not solutions.

Innovation comes with bugs, and certainly - testing can prevent the introduction of bugs. But I don't want to end up with a perfect system, always only testing the old stuff and never getting a single step forward. 

The current obsession to "find problems" (~to subordinate the whole development process under that headline) has a reason that is not related to our software.

Hmm, sounds like we may not have the same view of what the ultimate fate of unit tests is, but you're arguing against other people's views.  I don't want to go into detail here (and I'm sure you would rather I didn't, too), so briefly, the test philosophy I subscribe to is:

1) Test philosophy is situation dependent and fungible.  Thus the following get modified as needed.

2) Tests are (or should be) written as part of design and specification.  I've never heard of removing them afterward.  (Perhaps, when you and Fran use tests as collaboration, you're writing "provisional" tests to explain your concepts to each other, rather than tests for the eventual committed code?)

3) In agile (the claim sometimes is) the tests can substitute for documentation, i.e. people using the functions can go look at the tests to see what the things being tested are expected to do.  They also serve to document any changes to the specs -- the developer making a change also changes the test.  (Whether tests _do_ adequately function as documentation is debatable, especially for new developers, who need to see how the pieces connect up, which typically can't be seen in unit tests, as those isolate each function under test.)

4) The amount of detail in the tests depends on risk:  If you're testing flight software or a virtual memory system or a medical device, you test all edge cases under all conditions, and the tests (even unit tests) may involve hardware support for controlling environment and timing and...  Eden is lower risk but there is still a concern with correctness of data manipulation, for instance.

Back to the immediate question...

What's an example of a "post commit hook"?  (Asked Fran.  He didn't know.)  Do you mean onvalidation, onaccept, ondelete?  Hmm, no, those happen before Web2py does the commit.

I'm just trying to deal with [whatever insert_resource ends up being called] at the moment.  And in order to do that, I'm trying to find out what you'll accept. I know what I want, which isn't the same, so hoping I can satisfy both.  My use for it is _not_ for testing the very functions it relies on, but rather for setting up test data.

Disregarding all except the last paragraph in your comment:

insert_resource (please consider "create_test_record") should have all "post-commit hooks" (sorry for that mythical term - will explain below) optional _including_ update_super. It could be a (class) method of a subclass of unittest.TestCase instead of being an isolated function.

"Post-commit hooks" means all the possible things which could need to be performed after creating a record, and that includes update_super, set_record_owner, and onaccept (this list could vary). None of these is mandatory in unit testing, so they need to be made optional regardless of what the standard conditions are.

The appropriate counter-parts are update_test_record (running onaccept accordingly, and probably updating the realm entity), as well as delete_test_record (running ondelete, and regulating the cascade options).

And...

plase do not forget to update all existing unit tests to use create_test_record accordingly before you re-submit your pull requests.

While I'm looking for all the "post commit hooks", I see I forgot one question, re "prefixing" or subclassing TestCase.  Maybe I don't understand what you're asking for, because it sounds like not a good thing.

> By "properly prefixed" I meant typically "self." ;)
> your test helpers have a rather very limited purpose within unit-testing. They may be useful for what you intend to implement - but for that I suggest you move them into the respective unit test class, and reduce them to what you really need there.
> It could be a (class) method of a subclass of unittest.TestCase instead of being an isolated function.

Limiting the discussion to create_test_record:  -1 to duplicating the function inside each unit test that needs it.  -1 to adding a new TestCase subclass that any test needing the helper has to subclass.  It's cleaner to not mess around with the unittest module -- there's good unittest docs and examples, and it would be nice if people could just use those.  unittest does not supply support for database manipulation, or test data creation, so it is an unnatural place for that.  We could monkeypatch them into uniitest outside of any of its classes, but we don't do that with other Python library modules.

It would be possible to have the create_test_record functions inside a class inside a (test utils) module, instead of just inside a module, but what is the benefit?  They're not at global scope, they're in a module, so their names won't collide with anything.  They don't need local (instance) data, don't seem to need (class) constants.

If I misunderstood what you were asking for, please let me know what you meant.

Are there currently tests that could use delete_test_record or update_test_record?  In most cases, cleanup will be taken care of by a rollback in TearDown (though that can be defeated by the numerous commit calls scattered throughout Eden, or by an exception thrown in a test, which seems to end up with any db mods committed).  In line with not adding helpers in advance of need, I'd rather not add those unless there is a use for them.

Well, ok - if you're -1 to my suggestions, then I'm -1 to your pull request.

I think that's enough now - done discussing. I've tried.

We already subclass Unittest: Web2UnitTest

Dominic, I asked what you meant and why it was useful. I gave two reasons why it might not be a good idea. I used the same -1 +1 terminology that you used. I don't have your answers to either question -- what you mean nor why it's useful. Without knowing what you mean, there isn't even a way for me to do what you might want. For one thing, I don't know if you meant the helpers should share one class or should each be put in the individual TestCase subclasses -- both appeared in your comments.

Fran: Ok, "prior art" is more to the point. One test, in modules/tests/smoke/brokenlinks.py uses that directly. Currently none of the unit tests in modules/unit_tests use Web2UnitTest. I suggested some while ago rearranging the test-related directories to facilitate common code, e.g.:
modules/tests/unit
It would be a tidier, though a bother, to put the Selenium tests in a subdirectory too, e.g.
modules/tests/selenium
I suggested that before but not suggesting it now, especially when people are actively changing the Selenium tests.
The interception / mocking helper I want for unit tests does not seem as useful for Selenium tests, as it has to be instantiated in the same process as the code being tested. This is a feature -- it does not require code changes to support the tests and does not add a time cost in production. For a Selenium test, it would have to be instantiated in the server process. So Web2UnitTest, which is a parent class of SeleniumUnitTest, is an inappropriate place for it. Given that there only two uses of the name Web2UnitTest, maybe that could become Web2Test and Web2UnitTest could be a subclass of that for unit test-specific helpers.

The mandatory operations that go with inserting a record seem to be:
DAL operations: onvalidation, onaccept, ondelete (and their variants)
S3 operations: update_super, s3_set_record_owner, (maybe) audit

What I mean by "mandatory" is that they need to happen for internal correctness or are required by site settings, and happen automatically as a bundle when a record is inserted via a request. The "required by site settings" operations, like writing an audit entry, might not be needed, or would be optional.

Are there other mandatory operations?

Then there are other non-mandatory operations that would be part of adding more settings to go with a record. Some of those are only relevant to specific resource types -- setting roles is an example. I'm assuming we don't want that, but the mention of realms might indicate otherwise.

What's a "realm entity"?

Ok - re-iterating my points:

1) In low-level unit tests, I do - deliberately - want to see each and every assumption the test case makes _explicitly_ and within the particular test class. This is essential for rapid diagnostics, and therefore a requirement of our current (real, not theoretical) development process.

Moreover, when using unit tests to validate a design, I need to be in explicit control of each and every of these assumptions - even if they can be made for higher level functionality - so that the function in question runs with exactly the premises I want it to depend on and nothing else that I could not see because it is in a remote helper function.

For higher-level functionality unit testing (e.g. messaging), where it is appropriate to make all these implicit assumptions, I prefer regular framework methods to create test data - the most obvious of which being XML imports. This method is used quite frequently in the current unit tests, and to me it is the easiest way to setup even complex test data.

I do therefore currently not see any need for the insert_resource helper, but I would accept it inside a particular set of unit tests which makes use of it. For other people, however, I do explicitly recommend not to use such a helper, but to stick with regular framework methods (e.g. the XML import).

2) For the interceptor class, I can remotely imagine a use-case in unit tests for messaging. However, the design of this class and the usage-pattern is currently heavily obscured by way too much theory - so I prefer that you submit this only together with the unit tests you intend to implement for the functionality you intend to implement. 

Right now, this is purely academic - and as an example to demonstrate or discuss a possible pattern it is perfectly placed in your own (very well publicly visible!) repository.

3) For the rest of your commit (database observation helpers), both 1+2 apply.

I agree that we disagree. But re-iterating this seems pointless, so I'm not going to reply to this thread anymore unless you make significant changes towards my suggestions.

Another aspect of helper methods outside the framework is that they will run out of sync with framework re-designs (e.g. new post-create methods), and therefore create a (potentially significant) parallel maintenance effort. Using regular framework methods avoids this.

Won't work I'm afraid: auth.s3_logged_in_person() gives the person_id not the pe_id

Now I'm completely confused. You said +1 to create_test_resource earlier so long as all the options were optional and it called the other mandatory functions, and tests that used that same create pattern were updated. Sounds like you've changed your mind, and have a good point that S3 might change. I agree that it would be better to use an S3 function that performed a combined operation for the various S3 mandatory functions -- the Web2py mandatory function (onvalidate, etc.) would still be surplus to this. The same pattern of doing just a subset of the "mandatory" methods -- insert followed by update_super -- was used throughout the tests, so I figured it was acceptable and having to change it in one place would be less work than changing it in many places. I'll remove insert_resource and put it just in my tests, but not use it in any existing tests.

Using a file load to create one record is a significant overhead, especially since there is concern about the speed of unit tests. Another option is to refactor the (XML) import to split off the file load itself, to allow it to be used programmatically rather than from a request, e.g. with a string argument, and to return errors rather than raising HTTP. Would that be acceptable?

The remaining helpers have no dependence on S3 and so do not incur any maintenance overhead on S3 changes.

I'm sorry - this is getting more and more abstruse.

There is no such thing like "mandatory web2py methods" - all the on... hooks are S3 and whether or not they are needed for a test depends very much on what you're testing - and whether the premises for the tests are created by such a hook (for example OU hierarchy in Auth). But then again it is often better to create these premises "manually", to circumvent other dependencies.

Furthermore, you should not confuse the XML importer with the REST API. The XML importer is a pure back-end method (a method of S3Resource) which does not raise any HTTP status, and does not take files as input but works from ElementTrees, which can easily be generated from a variety of objects including strings. There are certainly  various components which use the XML importer (it is more of a nexus) and not less than 5 of them are even implemented as REST method handlers - but for unit testing you would typically use the importer directly.

Maybe you need to update your knowledge about our software rather than constantly rail against its poor design and try to teach us how to do it right?

I wish I could mute this thread, mainly of course to relieve the repo maintainer - but somehow It does not work. I already said that re-itering this is pointless, this pull request is not going to lead any further - so I suggest you close it, kindly move your proposal into a BluePrint and then discuss it via the mailing list, and submit a new pull request once there is a consensus/solution?

merged thanks

Any suggestions ?

Please see the discussion regarding this here: https://groups.google.com/forum/?fromgroups=#!topic/sahana-eden/MrhD1es-WAU

Yeah - looks like a pretty straight-forward replication of the search widget logic (could this be made even more generic by using S3Search._build_widget_query()?).

Note that this does /not/ test the search functionality, but only the search widgets (i.e. the transformation from the HTML form into Python search criteria - whilst the query construction mechanism is exactly the same). This is deliberate, as Graeme stated - yet I find it important to mention this somewhere.

Closing this -- will add notes to wiki if useful & bundle helpers w/ tests that use them

Checked it -- fix works fine!  Thanks!

This is a lot of changes in a single commit - what's the requirements behind all this?

It seems to partially work around or dismiss previous changes I had made in order to implement DRRPP requirements (e.g. deployment setting to hide/show report options by default)? Also, combining options reset for filters and report options doesn't seem right to me.

I don't think the changes in reports are appropriate for trunk. They maybe for DRRPP, but I have no visibility of the related requirements.

Manually merged the RMS roles/User Imports/DRRP style.
Left out the S3Report stuff for now whilst it is evaluated better

I saw the online documentation for anytime.js, which said that type should be made "text"
See here http://www.ama3.com/anytime/#AnyTime.picker

I will update it to datetime anyways

On 17 January 2013 11:39, Somay Jain notifications@github.com wrote:

> I saw the online documentation for anytime.js, which said that type should
> be made "text"
> See here http://www.ama3.com/anytime/#AnyTime.picker
> 
> I will update it to datetime anyways
> 
> No, follow that docs - maybe add a note in a comment to the code

F

Generally,

I would prefer to have the reports in DRRPP rendered by a custom method handler.

I don't say you need to do that now, take it rather as a "future warning": I'm very sure that we can not retain all of the DRRPP specifics in future designs of S3Report (nor that we actually want to).

Can we get this rebased ready for a merge?
Many thanks :)

I'm answering my terminal exams, so I'm a bit busy atm -- I want to fix up all the other issues (OAuth included) and do this _properly_. So, can I have some time?

Okay I will change it to what you said. :)

This has already been merged, no?

In the previous one, I had changed the class name of the 'Clear' button.
This is a better version, if you could stash that merge and replace it with this.

This is in context to what Dominic and You were talking about here 
https://groups.google.com/forum/?fromgroups=#!topic/sahana-eden/MqybGgSS7oA

Looks like this is the same thing to me:
https://github.com/flavour/eden/commit/59e9da5c57831f2a191feac921863becb14b7b05

Oops, sorry. 
I did not realise I pushed it to this branch, and it got updated. I will close the ticket :)
Thanks

On 4 February 2013 00:19, Somay Jain notifications@github.com wrote:

> Organization was given in the options field instead of National Society /
> Branch
> The HTML page has options with the name National Society / Branch.

This is only in the IFRC template

We should avoid the Test Suite being hardcoded to the IFRC template.
Instead the actual label should be looked-up from the
currently-running Template.

This is an advantage from running the tests from within the Eden environment.

It also makes the tests more adaptive to code changes, rather then fragile.

F

I have added the variable for organisation_label.
Please see.

Sure, I will make these changes and push again.

First we need to enable OCR module to test it.

I don't get this at all - why does this have anything to do with #1313?

Ignoring that, I don't see why we'd want to add all these fields relating to recurring requests into the main req table?

In #1313 the bug was that by enabling the module, if we want the pdf of the form, a ticket comes, so we cant able to download the form...The error was that the required field were not there in the database.
You can check it on your localhost by enabling the module and trying to download the OCR form, but it wont because there is a ticket coming. 

Just follow the description in http://eden.sahanafoundation.org/ticket/1313 and the result will be a ticket.

I added the Traceback in the Ticket - I don't see how this pull request relates in any way.

Look at the Traceback what i am getting in the ticket, i have commented.

Can you just explain me the fix given by Dominic. ?

The resource.component dict uses the component alias as key, which defaults to the unprefixed tablename, but can also be set explicitly. S3OCR did not handle this, it looked for "task" (as in "scheduler_task") but the actual component alias here is "job" - and the fallback to the master resource is wrong.

I was actually looking at get_struct, though. We recently introduced filtered components, which means that that same table can be added multiple times as component to the same master. This requires aliases, but get_struct did not export the component alias at all, so subsequent form builders (like in S3OCR) would construct forms incorrectly.

I fixed get_struct, and http://eden.sahanafoundation.org/ticket/1313 appeared to be collateral damage, so I fixed that as well. External form builders (XForms client) still need to be adapted.

Note that for requests, the scheduler task should not appear in the form at all (this is to be done via deployment-setting, though). So, this was only a partial fix - actually just an update to current methods.

I got the first part about the alias part but not the part what get_struct is doing.
I'll spend some time experimenting with it and will try to understand.
Though thanks a lotttt. Nice fix :D

Thanks for the catch :)

Ideally we'd be able to introspect whether a field is Autocomplete or Select (dropdown option)
- this can be done by looking at field.widget & field.requires
  (This will definitely vary by deployment)

Fran,
Sorry for such a large commit. I tried but I think there is some problem with my text editor, I think. 
The test's working fine.

Invalid data entered so a error occured.

This needs to be done in all the controllers to maintain consistency. If this fix is appropriate, I will do it.

Looks goog to merge!

hey @nursix I understood the add class event,  but why r.interactive ? What does it do ?
By the way it worked..
vishrut009

r.interactive is interactive HTML modes only (not XML/XLS/PDF) so is good for fiddling with CRUD forms et al, but allowing the exports/imports to be unaffected.

Ohhh, so it doesn't affect the import export.Got it.
So, this works fine. Merge it and the previous pull request also which was for Selenium tests.
Thank you!!!

What I see here is still a try/except?

I made another commit. Its not there, deleted it.

Thanks - I'll merge, but a couple of notes for next time:
- Great if you can rebase commits so that it is easier to review & gives less churn in the main codebase
- HTML is deliberately minimally formatted to keep the number of characters sent to browsers to the minimum that we can keep readable...I know this is a minor thing, but since we often often operate on congested/expensive comms links, I like to be as frugal as possible (back-end/un-minimised code has the opposite perspective where readability is the optimised-for aspect...since the comms links never see the extraneous material)

style is being added by the JS widget & from the minWidth value, which defaults to 225 px.
I have set our use of the widget to default to 0 minWidth.
The widget is still setting a style of 220px
Are you trying to go smaller or higher?

I guess exams are over? ;)

This makes FF much worse btw & Chrome still not ideal (in hover mode).

I have merged this, however would this not again be better done introspectively?
i.e. read the represent values of the data & use these, rather than hard-coding the represent values.
(Represent values may change over time or even between deployments)

Any chance this can be rebased?
- compressed to a single commit on top of current trunk 

<flavour> hardikj: Your pull request seems good thanks :)
<flavour> I'm a little concerned about the date-> datetime type changes, but think it should be OK
<flavour> There are a few whitespace issues
<flavour> e.g. https://github.com/hardikj/eden/commit/1ee970c7073f4a52850f365185f801fc54e23fae#L1R1107

Done

Why?

It's "latin x" versus "cross"

Regards,
Aviral Dasgupta http://www.aviraldg.com.

On 28 March 2013 20:24, Fran Boon notifications@github.com wrote:

> Why?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/438#issuecomment-15592789
> .

Generally, the table ID of a datatable can be chosen freely, so I'm not so sure about hardcoding this in tests. 

But IF, then "datatable" is correct, "list" isn't right anymore.

This hasn't been changed in s3search yet (my bad), but will - so I'd recommend to change all tests into "datatable", not some.

Dominic

31 mar 2013 kl. 23:31 skrev Somay Jain notifications@github.com:

> The table id of the results displayed is sometimes "list" and sometimes "datatable".
> This can be seen here - http://127.0.0.1:8000/eden/org/organisation and http://127.0.0.1:8000/eden/hrm/staff/search
> This was breaking some of the tests like SendItem and AddStaffToOrganisation.
> 
> So, it is better to find the element using class name(which remains same) rather than searching on the basis of id.
> 
> Also, a fix for the broken test CreateProject is also provided.
> 
> You can merge this Pull Request by running
> 
>   git pull https://github.com/somayjain/eden seleniumfix
> Or view, comment on, or merge it at:
> 
>   https://github.com/flavour/eden/pull/439
> 
> Commit Summary
> 
> Fixed tests based on search(datatables dependent)
> File Changes
> 
> M modules/tests/core/core_dataTable.py (8)
> M modules/tests/project/create_project.py (12)
> M modules/tests/web2unittest.py (4)
> Patch Links:
> 
> https://github.com/flavour/eden/pull/439.patch
> https://github.com/flavour/eden/pull/439.diff

...wants to say: sometimes - even if we're not used to that - a broken tests indeed indicates an error in the tested code that should be fixed in the code ;)

Right, I had observed that it gives the table id = "list" in s3search, but thought that it was there for some reason.

Also, we seldom have the option of searching on the basis of id and class, how do we decide which one is better? (This is a general thing I am asking)

I will modify it here to search on the basis of id="datatable" anyways

In this case (testing S3Search) it is certainly better to find the result table 
by its element ID - however, that should be "datatable" because now where we 
have an additional "datalist" method the "list" identifier for a datatable is a 
bit confusing.

The datalist uses "datalist" as element ID for the result, hence "datatable" 
should use "datatable" to be consistent.

Remember that S3Search is going to be deprecated, so maybe good to, instead of 
investing a lot of effort into fixing the tests, rather plan to migrate the 
tests to / implement tests for filter forms.

Fix pushed for S3Search (to change the ID into "datatable")

Regards,
Dominic

måndagen den 1 april 2013 03.27.47 skrev  Somay Jain:

> Right, I had observed that it gives the table id = "list" in s3search, but
> thought that it was there for some reason.
> 
> Also, we seldom have the option of searching on the basis of id and class,
> how do we decide which one is better? (This is a general thing I am asking)
> 
> I will modify it here to search on the basis of id="datatable" anyways
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/439#issuecomment-15711100

Okay, I have updated this to search on the basis of ID.
I will pull again, and run the tests once to check.

where is the code pushed for changes in S3Search?

Obviously you'll have to wait until it gets merged into trunk ;) ...could take 
a while.

Dominic

måndagen den 1 april 2013 04.15.32 skrev  Somay Jain:

> where is the code pushed for changes in S3Search?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/439#issuecomment-15712128

I have deleted the backup file which was added accidentally to the commit 

I still think it's better to determine the opts automatically rather than prepopulate this list - this will certainly be true for the IFRC case.  

Hey, I tried to do without the option method. But it takes the pre-populated data only and not the new group name if I add. So I had to define a function that takes all the groups(of type "Relief Teams") by running a query on the current database.

Not true, it will take the new group into the options as soon as there is at 
least one group member.

Otherwise the option is pointless - if the group has no members why have it as 
option to search through?

Automatic option is best here.

Dominic

fredagen den 12 april 2013 04.32.11 skrev  Vishrut Mehta:

> Hey, I tried to do without the option method. But it takes the pre-populated
> data only and not the new group name if I add. So I had to define a
> function that takes all the groups(of type "Relief Teams") by running a
> query on the current database.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/443#issuecomment-16288127

@nursix  .Yeah u are right. I have commented option method from S3Search but kept the hrm_team_opts function, may come handy in future.

Strange -

actually, settings.get_l10n_datetime_format() should return exactly this, unless you overwrite it in your config (which you should not do). I don't think the search widget needs to be changed - probably update your local config instead?

Dominic

14 apr 2013 kl. 15:18 skrev Somay Jain notifications@github.com:

> Tested on the IFRC template. 
> The datetime format for the S3SearchMinMaxWidget is not same as used in validation.
> 
> You can merge this Pull Request by running
> 
>   git pull https://github.com/somayjain/eden upstream
> Or view, comment on, or merge it at:
> 
>   https://github.com/flavour/eden/pull/444
> 
> Commit Summary
> 
> Fixed the datetime format compatible with the new calendar.
> File Changes
> 
> M modules/s3/s3search.py (6)
> Patch Links:
> 
> https://github.com/flavour/eden/pull/444.patch
> https://github.com/flavour/eden/pull/444.diff

I did this because the jquery widget takes in date format and time format. I could'nt figure out if it could take the datetime format in it's input. I am talking about this - https://github.com/flavour/eden/blob/master/modules/s3/s3widgets.py#L385
If it does, then specifying that as well is the best solution here.

So, the datetime format needs to be date + time format. In templates such as IFRC, sometimes this is not followed. So, it would handle this issue.

You are right that local config file should be updated as well.

Hmm,

an inconsistency between the combination of the date/time formats and the 
combined datetime format doesn't sound right to me - that should be same, 
shouldn't it?

If there are in fact (deliberate) differences, then we need though to change 
the calendar widget, not the search widget - otherwise we're (wrongly) 
ignoring a configuration setting.

The other point is that the search widget is going to be deprecated anyway, so 
updating it is rather a temporary workaround.

I'm still not convinced that the difference is deliberate, I would take this 
for an oversight.

Dominic

söndagen den 14 april 2013 10.20.59 skrev  Somay Jain:

> I did this because the jquery widget takes in date format and time format. I
> could'nt figure out if it could take the datetime format in it's input. I
> am talking about this -
> https://github.com/flavour/eden/blob/master/modules/s3/s3widgets.py#L385
> 
> So, the datetime format needs to be date + time format. In templates such as
> IFRC, sometimes this is not followed. So, it would handle this issue.
> 
> You are right that local config file should be updated as well.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/444#issuecomment-16354692

Yes, you are right. There should'nt be inconsistency between combination of the date/time formats and the combined datetime format. 

Given that we have this difference, it is correct to say that we need a new calendar widget(probably anytime.js datetime calendar is ok). But, if we limit ourselves to this widget, then we have to include changes in the search, as I have pointed out in my commit, or oversee it. 

If we oversee it, then we should port the search to filter quickly, otherwise the datetime range searches become useless in templates like IFRC.

Hence, temporarily, it would be okay to merge this commit.

I would actually prefer to indeed abolish the datetime config setting if that's 
appropriate, or to otherwise fix the datetime widget to support separate 
settings rather than modifying the search widget to ignore the separate 
settings.

Don't get me wrong: I just think that providing a setting yet ignoring it 
doesn't make much sense - either remove the setting or take it into account 
appropriately.

Your fix is to ignore it, my suggestion is to remove it - I'd like to hear 
Fran's opinion here.

Dominic

söndagen den 14 april 2013 12.59.20 skrev  Somay Jain:

> Yes, you are right. There should'nt be inconsistency between combination of
> the date/time formats and the combined datetime format.
> 
> Given that we have this difference, it is correct to say that we need a new
> calendar widget(probably anytime.js datetime calendar is ok). But, if we
> limit ourselves to this widget, then we have to include changes in the
> search, as I have pointed out in my commit, or oversee it.
> 
> If we oversee it, then we should port the search to filter quickly,
> otherwise the datetime range searches become useless in templates like
> IFRC.
> 
> Hence, temporarily, it would be okay to merge this commit.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/444#issuecomment-16358249

Good work - other than the small changes mentioned, this shows good understanding :)
Please fix, rebase  & resubmit :)

Good start :)
I can see how this will exclude non-settings variables, which is an improvement already.
However it would be great if we could lookup other variables if the process for settings works...is this possible? (I'm not sure how that process works).
Either way, could you fixup the little issues mentioned inline, rebase & resubmit? Thanks :)

Looks nice & shows some good understanding :)
As a prototype of an example, I don't think that is mergeable though, I'm afraid.
- this won't affect GSoC application though, don't worry.

What we really need is the ability to easily configure these.
- initially via Code (i.e. Programmer-customisable)
- later via UI (i.e. User-customisable)

I would look at the current S3Profile method.
- use the DRMP template to check these out
- this is definitely a work in progress but I think shows how to do the 1st part

Extending this to support additional options would be really useful:
- Graphs
- DataTables (although I think that a DataList is nearly always suitable here)
- More flexible layouts (currently only supports 2 columns with an option for some widgets to take up a whole row)
- User-customisable

We also need to support Dashboards which don't link to a specific resource - e.g. /eden/event/dashboard rather than the current /eden/event/1/profile
For users I think maybe this would be /eden/default/user/dashboard

NB I think we are deprecating matplotlib-based graphs in favour of flot-based ones as JS graphs provide better interactivity which is what users expect these days.

Hopefully this steer will allow you to create something mergeable.
- adding some kind of prototype graph widget into S3Profile would be a valuable & achievable goal perhaps
- look at S3Report for generating flot-based graphs (I'm not sure if you can call those functions directly or need to extract out a common set)

This prototype lacks any kind of access authorization - which is a critical requirement in any kind of data representation, dashboard or not.

I highly recommend to use S3Resource for data access, or at least to properly authorize all non-standard all data access (via direct DAL) using current.auth.

I think we should focus on developing dashboard widgets before we implement complete dashboards - simply because that's the harder part of it. Any widget should be properly authorized, filterable, and tolerate multiple of its kind in the same page.

Sorry for the delay in reviewing this.

General comments (for future reference):
No models should be defined in models/ - only in modules/eden so that we can load only when-required.
You should minimise code changes - why add all that whitespace into menus.py?
The whitespace is also inconsistent in the code - should be consistent & follow PEP8 where-possible.
Our Python code should use " not ' where possible - see Coding Conventions on Wiki
If there are multiple commits, these should be rebased into a single commit.

Functionality comments:
I think this is already implemented on a per-Site basis as s3db.req_site_needs:
https://github.com/flavour/eden/blob/master/modules/eden/req.py#L1926

Your implementation didn't link to sites at all.

@nursix @flavour  : thanks for your feedbacks
@nursix  : this only serves the purpose of demonstration for gsoc, and as flavour said , i'll try now to inculcate s3profile and make use of DRMP template

I see - I was reviewing this as a pull request into trunk, but it was actually rather a code review request for design discussion for a potential GSoC project? For the latter I think an email to the mailing list with a link to your repo and maybe to some screenshots (or even just wireframes) is good enough ;) and is also likely to reach more people.

hello,

I am writing this because i think github must not have notified you,
sorry to disturb u if it has

I have submitted all the changes you mentioned.
please review, when free.

thanks

Could you rebase/compress these 2 commits into 1 please?

Thanks,
Fran.

I removed the separate option - agree with Dominic that we need consistency here.
We do lose a little flexibility by not being able to specify a datetime format separately, but I think that's the least bad option here.

@nursix : absolutely , thanx :) 

I'd actually remove the hrm_team_opts function...I think it's misleading.

Then please rebase/squash so I can merge.

Thanks,
Fran.

Sorry for the delay in reviewing this - was away camping in New Zealand.

The Date fix looks good (although I've not tested).
However the map fix is wrong as too global a scope...please either remove the map fix for now or fix.
Then rebase/squash so that I can merge.

Many thanks,
Fran.

Great when it tracks down to being a simple solution :)
Try to fix the space issue & then squash again - should be possible.

There are a number of .bak files added which should be removed.
Also the 'Training' module from the Book Tutorial should be removed...

I think you're along the right lines with the ltr !important etc, however I'm not sure that the current placement of these is right?
Would be good to see a before/afterwards screenshot in both English & Urdu

![english after ](https://f.cloud.github.com/assets/4039827/403314/50214e24-a91b-11e2-9cec-ca6bf4e6cb8c.png)
![english before ](https://f.cloud.github.com/assets/4039827/403315/5028a6f6-a91b-11e2-8774-ae2ebe2be27a.png)
![urdu after ](https://f.cloud.github.com/assets/4039827/403316/502bdef2-a91b-11e2-9762-3e2c8555c460.png)
![urdu before ](https://f.cloud.github.com/assets/4039827/403317/5064f37c-a91b-11e2-86a3-84434e36a58b.png)

Thanks - can cleatrly see that English isn't made worse.
However the Urdu screenshots still have a lot of English in them - do they still work properly if you translate those strings? This is my concern...

It is looking like this after translating a few lines
![urdu translated ](https://f.cloud.github.com/assets/4039827/403454/082eb2a0-a920-11e2-8b7d-0a487d72ab64.png)

Are these lines inside an ltr !important?

yes, but only the first line

ok, so if you're convinced that this is good, then please resubmit a cleaned pull request (please do include the extra Urdu lines).

What would be good is to think about how to make these changes as generic/global as possible & to document on the Wiki how to make use of them.

pardon, i didn't get...which extra urdu lines ??

You translated more strings? So presumably in the languages/ur.py
If not then that's the way to test (not by editing the View directly)

The final look of the page

![urdu final ](https://f.cloud.github.com/assets/4039827/403767/2ea8343c-a92b-11e2-8f85-ded289dca91f.png)

I can't read urdu to know if this is correct - my concern was that I saw text inside an ltr! important
If you'
ve tested it ok then all good - previous comment re: clean commit/pull request (inc new Urdu strings) & then looking at how this can be generalised or at least documented ion the wiki as best-practise

This is not clean - take a look!
https://github.com/MDNishan/eden/commit/19dcb18a18fb3345e22ebfb3db9bc22d6ba7deb1

@flavour : Please review

All I can see here is a new minified file? In 2 separate commits...

Yes. But I fixed the bug which I reported. I'm sorry that the first commit was a little mistake. Please have a look in the UI.

Thanks.

What about debug users? Would still be broken for them...

& you'll need to rebase/compress the commits into 1

I'm sorry. I'll work on that.

I sent a new pull request for ticket #1407. Please have a look. Thanks.

Merged manually due to conflict with 'modules/eden'=>'modules/s3db'

Lovely thanks :)
I provided alternate fixes for the 2 bugs found by Smoke tests.
Can you rebase & resubmit pls?
Many thanks :)
F

Sorry didn't look up the five lines or so necessary to see the line you uncommented in controllers/cms, I had also tried to fix the skills search function but failed, so thanks. Having that function working helped me to see a problem with the test data en-dashes had been auto changed to em-dashes in the skills creating new skills, now fixed.

True  :D (Gender distribution Is good starter data to test on ) , I wanted to display piechart using s3profile , and it was in response to quick call for code contribution for gsoc . Well definitely it can it be extended to display different chart type . 

The w_type is good and overall this shows some level of code understanding.
However as Dominic says, we don't want the piechart widget hard-coded to any particular usecase - this needs to be configurable.
One of the configuration options is the context, but others would be the table, etc.
It would indeed also be better if the data for the chart came from the existing maintained and optimised function: S3PivotTable.compact()

This isn't mergeable as-is I'm afraid, but I look forward to seeing the next iteration :)

@nursix  : Ok i'll comment it out

@nursix : i have made requested changes

I am sorry , I forced push the branch , and it seems comments were lost

@flavour : spaces fixed an getvars removed

@flavour  :added fallbacks , hope this solves the issue 

@flavour  : please have a look

Can this be rebased/squashed to a single commit?
- makes it much easier to review & reduces repo churn

Apologies for not testing milestone part actually I was not able to figure where it was implemented
I have tested the project/task and project/project/n/task, they work fine.

I am really sorry, one must always test the changes, I will keep it in mind next time.

You can test it by adding:

settings.project.milestones = True

to 000_config.py

No need to 'fix' the upstream file.
Proper fix is within this commit:
https://github.com/flavour/eden/commit/cb290fc55321b3e29e3f128cbee6f76768007235

@flavour  :please have a look

Can this be rebased/squashed to a single commit?

makes it much easier to review & reduces repo churn

@nursix works fine milestone also 

thanks :)

Well then...looking forward to see it merged.

Would a simple Selenium test be appropriate for this functionality?

I have taken the concept from here & put into correct place in current code

Can this be rebased/squashed to a single commit?

makes it much easier to review & reduces repo churn

@graeme-f : I don't think that's necessary before merge, and apart from that I have a problem with collecting huge quantities of tests before the test suite design has improved significantly - we already have too many tests which don't give conclusive and reliable results.

Can this be rebased/squashed to a single commit?
- makes it much easier to review & reduces repo churn

Partially-merged

Thanks - can this be rebased/compressed to make it easier to review?

Can this be rebased/compressed to a single commit to make it easier to review?

(I should see just a single commit on this page: https://github.com/flavour/eden/pull/490)

Great work Hardik! I would love to see some Selenium tests for this.

Partially Merged

I have rebased the code and squished it into one commit -- this should put us back in sync.

hello @michaelhowden 

Apologies for the late reply, github didn't notified me about your comment here.

Actually i have my terminal exams from 20th, So i am bit busy with them.
I am really excited to write tests for this task and i have already written for project/project/1/task
but i am getting some issues for project/task i will solve it soon 

So can i have some more time?

Sorry for the slow response, but thanks for the comments. I'll work on those once my research project scramble is over.

Please discuss Demo vs Standard with Graeme

Can this be rebased / squashed to a single commit?
Thanks :)

This should just show me a single commit, whilst currently I see 7

Interesting,

I had fixed that already:

https://github.com/nursix/eden/commit/f1fc1029526394bf328e150d82310dd1c8f7496f

Where did it go?

Dominic

söndagen den 9 juni 2013 12.05.48 skrev  Somay Jain:

> Email is extracted in a pr_email_contact object and phone is in a
> pr_phone_contact object.
> 
> Solves http://eden.sahanafoundation.org/ticket/1409 and
> http://eden.sahanafoundation.org/ticket/1413
> 
> Aplologies for logging #1413 when #1409 was already logged.
> You can merge this Pull Request by running:
> 
>   git pull https://github.com/somayjain/eden upstream
> 
> Or you can view, comment on it, or merge it online at:
> 
>   https://github.com/flavour/eden/pull/502
> 
> -- Commit Summary --
> - Added the fix for adding person email, phone no when selecting from
>   registry
> 
> -- File Changes --
> 
> ```
> M static/scripts/S3/s3.select_person.js (24)
> ```
> 
> -- Patch Links --
> 
> https://github.com/flavour/eden/pull/502.patch
> https://github.com/flavour/eden/pull/502.diff

It got removed here - https://github.com/flavour/eden/commit/73b7736538b2493410ba22bcc6d8e8afc4d7e426#static/scripts/S3/s3.select_person.js

I think we must have 2 competing usecases.
1 needs the format in your pull request.
1 in the format that I found needed to be fixed.
Could you modify this to work with either format?

Could you elaborate on the second use case?

I am looking at the usecase when someone selects from the registry, all fields in the form which are available ought to be filled.

I'm not sure where exactly it cropped up, but when I was reorganising this I tested it & found it incorrect so fixed it..
Whereas you/Dominic are fixing it the other way.
There _must_ be 2 pages which show this differently, so we need to be able to support both formats.

@flavour I think it would help if you could recall the case which you tried to fix.

This is related to the contact component in pr_person - in the standard case, it's two filtered components (pr_email_contact, pr_phone_contact), but there seems to be a case where this is a single component (pr_contact).

It is relatively easy to have the script introspect the object, but is this inconsistency of component definitions (same table = pr_person) actually correct? It seems that the single-component case should be upgraded - so, where is it?

Dominic

I explained to Somay the cause.
We can't track down the usecase, however I see no reason to change the back-end for that case.
I prefer to have the widget tolerant of both which is already done (just being fixed-up)

I'd personally prefer shorter IDs as this keeps pagesize & AJAX calls as small as possible.
- I know this is small but I just hate bloat.
  What's wrong with 'list'?

F

There is no problem with 'list' if all the ids are made 'list'.

It was when we adopted jquery.dataTables, some ids were changed to 'datatable' but some were left as 'list'. So, to bring uniformity, I changed all of them to datatable because we are using jquery.dataTables, hence more intuitive.

"list" is simply wrong.

The ID is used to identify the target for filter updates - and since there can 
be multiple targets, they need to be unique.

Possible targets are data tables, data lists and pivot tables - and if you 
identify datatables as "list" - then what would you identify datalists as? 
"table"?

And if you identify data tables as just "table" - then what ID would you give 
pivot tables?

Certainly - you can identify targets as just "1", "2" and "3", as long as the 
IDs are unique. But that doesn't really make the code more readable.

"datatable" is about clarity with identifiers: therefore the default ID for a 
datatable is "datatable", for a datalist it's "datalist" and for a pivot table 
it's "pivottable".

-1 to "list".

Dominic

måndagen den 10 juni 2013 02.37.29 skrev  Somay Jain:

> There is no problem with 'list' if all the ids are made 'list'.
> 
> It was when we adopted jquery.dataTables, some ids were changed to
> 'datatable' but some were left as 'list'. So, to bring uniformity, I
> changed all of them to datatable because we are using jquery.dataTables,
> hence more intuitive.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/505#issuecomment-19189129

måndagen den 10 juni 2013 12.48.07 skrev du:

> Possible targets are data tables, data lists and pivot tables - and if you 
> identify datatables as "list" - then what would you identify datalists as? 
> "table"?
> Yeah - and maps, and filters, and...who knows what else is there to come.

The "bloat" argument seems shot from the hip - without really looking at the 
reasons why it has changed: originally we had only the data table, and called 
it "list" for no obvious reason.

But now we have a diverse range of objects, and IDs are clashing, and scripts 
targeting the wrong object - clarity with identifiers can help to prevent such 
bugs _before_ the test suite finds them.

Focus is good, but not if you can't see left and right from your path anymore.

Dominic

I don't see any problem with keeping 'list' for the default list method (i.e. dataTable)
datalist can then be 'datalist' to distinguish

However it's not a big deal - if you feel passionately about this then make it 'datatable', fine ;)

@flavour : Good to merge, or should I make some changes?

Looks good to merge from me. @flavour Or would you like all @somayjain commits to be merged through me?

@flavour : Merge please 

@somayjain, @flavour's waiting on @graeme-f green light for this. @graeme-f?

Sorry, I didn't realise that you were waiting for me. It looks fine. :)

I merged.
The approach seems good for getting us a useful step closer very easily :)
The "this template" part works perfectly, which is great, thanks :)
However the list of preselected modules wasn't accurate on my system though for some reason....I was running the DRMP template at the time.

After fixing that, the next steps would be to hide core modules:
Auth/Default should be inside Core
Appadmin/Errors/Sync should be inside 'Admin'

We should probably have name_nice displayed rather than the actual names if this is to be used by non-core devs.

We should also build a dependency system, so that e.g. 'supply' gets selected when modules which use it are selected (i.e. Inv/Req).

Another example of dependencies:
modules/s3survey should only be included if the Survey module is selected

Much better :)
Will merge shortly...

Merged

I still prefer a get_confirmation() wrapper to replace the 3 instances of browser.find_element_by_xpath("//div[@class='%s']" % current.s3tests.confirmation_class)

Thanks, will merge

Are other helpers in current.s3tests?
I don't mind that being where helpers are stored, but want to be consistent...

@flavour : Moved the helpers to SeleniumUnitTest class. Please review.

Looks good now, thanks!

Does this also work with non-Bootstrap?
Are there any CSS elements which need tweaking in any template?

Yes, this did work with non-bootstrap. Because of a table format in SQLFORM in non-bootstrap, it wrapped the DIVs into TRs.

I see both CSS & JS linking to the IDs of these elements which have changed type...this needs some thorough testing which I don't have time for tonight...about to crash...

No problem. I will test it as far as I can, if there is something crashing then I will let you know. You can test it then whenever you get time :)

Not just crashing, but visual glitches - in non-BS templates

@ptressel @flavour : Good to merge ??

I suspect that you will need s3db.doc_document when using the Scheduler (i.e. Production servers) as then the  Task will be run in a new thread.
I believe you've currently only tested where there is no Scheduler running & hence the task runs in the same thread & doesn't really go async...

Thanks, fixed...pushing shortly

The approach is generally good, however, as I suspected, this change is very incomplete:
There is CSS which is linked to the TR/TD structure:
https://github.com/flavour/eden/blob/master/static/themes/default/widgets.css#L849

Modifying that to remove the tr/td then produces very ugly results as DIVs are being put in strange places (A subheading with box_bottom above the table)

Note that EmbedComponentWidget & LocationSelecorWidget use the same CSS classes too & should be modified in the same way.

I've backed out my experiments in this area as it's taking me too long to try & resolve.

Thanks :)

Looks good!

This needs to be rebased - not mergeable as-is

@nursix : When we are going to migrate to the new version then ??

Done. Sorry - you can drop this now.

tisdagen den 2 juli 2013 08.29.19 skrev  Vishrut Mehta:

> @nursix : When we are going to migrate to the new version then ??
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/530#issuecomment-20353197

@nursix  :sill facing errors in unit tests. Are these due to web2py version??

Traceback of the one of the 7 errors. All have this same error.

ERROR: testMergeVirtualReference (**main**.MergeOrganisationsTests)

## Test merge with virtual references

Traceback (most recent call last):
  File "applications/eden/modules/unit_tests/s3/s3resource.py", line 2120, in setUp
    org1_id = otable.insert(**org1)
  File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 8579, in insert
    ret =  self._db._adapter.insert(self, self._listify(fields))
  File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 1209, in insert
    raise e
IntegrityError: column name is not unique

Yes, I think so.

Which version are you using? Try upgrading to the latest web2py trunk.

Dominic

tisdagen den 2 juli 2013 10.58.34 skrev  Vishrut Mehta:

> @nursix  :sill facing errors in unit tests. Are these due to web2py
> version??
> 
> Traceback of the one of the 7 errors. All have this same error.
> 
> ERROR: testMergeVirtualReference (**main**.MergeOrganisationsTests)
> 
> ## Test merge with virtual references
> 
> Traceback (most recent call last):
>   File "applications/eden/modules/unit_tests/s3/s3resource.py", line 2120,
> in setUp org1_id = otable.insert(**org1)
>   File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 8579, in insert
>     ret =  self._db._adapter.insert(self, self._listify(fields))
>   File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 1209, in insert
>     raise e
> IntegrityError: column name is not unique
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/530#issuecomment-20363575

@nursix : Yeah i did a git pull for web2py trunk and its the latest version. Still the error remains

Err - hang on, I misread:

It is not "column name is not unique", but "column _name_ is not unique".

That happens if your previous unit test crashed without rollback (which should 
actually not happen, but sometimes it does) - then you need to wipe out the DB 
and re-populate from "IFRC_Train" template, then run it again.

tisdagen den 2 juli 2013 20.01.58 skrev du:

> Yes, I think so.
> 
> Which version are you using? Try upgrading to the latest web2py trunk.
> 
> Dominic
> 
> tisdagen den 2 juli 2013 10.58.34 skrev  Vishrut Mehta:
> 
> > @nursix  :sill facing errors in unit tests. Are these due to web2py
> > version??
> > 
> > Traceback of the one of the 7 errors. All have this same error.
> > 
> > ERROR: testMergeVirtualReference (**main**.MergeOrganisationsTests)
> > 
> > ## Test merge with virtual references
> > 
> > Traceback (most recent call last):
> >   File "applications/eden/modules/unit_tests/s3/s3resource.py", line 2120,
> > 
> > in setUp org1_id = otable.insert(**org1)
> > 
> >   File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 8579, in insert
> > 
> > ```
> > ret =  self._db._adapter.insert(self, self._listify(fields))
> > ```
> > 
> >   File "/home/vishrut/Sahana/web2py/gluon/dal.py", line 1209, in insert
> > 
> > ```
> > raise e
> > ```
> > 
> > IntegrityError: column name is not unique
> > 
> > ---
> > 
> > Reply to this email directly or view it on GitHub:
> > https://github.com/flavour/eden/pull/530#issuecomment-20363575

@nursix :+1:  

@flavour : Good to merge?

Needs rebasing/compressing

Can you rebase/compress?

Done.

On Thu, Jul 4, 2013 at 1:40 AM, Fran Boon notifications@github.com wrote:

> Can you rebase/compress?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/533#issuecomment-20441917
> .

Am letting Dominic handle pull requests

In general this looks great & I'm really looking forward to seeing it merged :)
As you say the CSS/JS needs to be only added conditionally and then there are a few little suggestions inline to the commit.
None of this is major so shouldn't delay it coming in long & then people can have fun designing the tours :)

I guess there's no UI for designing tours? ;)
- other than the CRUD UI for the tables of course ;)

I think that I have got everything sorted out (well for a first run anyway)
Thanks for looking at the code. I had a problem building the minimised
dataTables javascript file. Even without my code change it is failing on my
system, the guided tour js & css is fine. So I'm not sure if it is my
closure (I had used the remote and them downloaded it but neither worked)
or if their is an existing error with the datatable javascript. That means
that I was only able to partially test the code with debug off (I wasn't
able to extract data from the datatable).

You asked if all tours should be available for authenticated users. I
thought not since I was imagining that a tour for a registered user would
be written differently than one for a visitor. One would be an overview of
functionality the other would be about how to achieve a specific task or
workflow. If their is a demand to have them available them obviously this
is easy to do in code (and they will always be there) or by importing the
same data but as a tour that required authentication (which could be done
if just one or two tours are required)

UI for designing tours... I was actually thinking that Selenium IDE could
be used for the initial work and then a script to convert it to a guided
tour. See this linkhttp://pronovix.com/blog/kvantomme/documenting-drupal-collaboratively-interactive-tutorials.
When I'll get to look at that, I'm not certain :)

Graeme

On 12 July 2013 02:23, Fran Boon notifications@github.com wrote:

> In general this looks great & I'm really looking forward to seeing it
> merged :)
> As you say the CSS/JS needs to be only added conditionally and then there
> are a few little suggestions inline to the commit.
> None of this is major so shouldn't delay it coming in long & then people
> can have fun designing the tours :)
> 
> I guess there's no UI for designing tours? ;)
> - other than the CRUD UI for the tables of course ;)
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/547#issuecomment-20835600
> .

Awesome - thanks!
Great idea to use Selenium IDE to build guided tours...that should be cool :D

Can this be rebased/compressed as-usual pls?

Well, I thought it would be better to have unrelated commits separated (I
thought you usually want it that way).
Anyways, I will rebase ;)

On Wed, Jul 17, 2013 at 12:44 AM, Fran Boon notifications@github.comwrote:

> Can this be rebased/compressed as-usual pls?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/551#issuecomment-21066016
> .

@flavour  : Rebased.

I think that this is better.

@flavour : Fixed.

Thanks, I'll merge despite the comment...but I do wonder why we're being so sloppy/inconsistent elsewhere that the lower() is required...I'd much rather fix at source...

Looking at the code the jquery library uses aaData whilst eden uses aadata. Having run some tests request.extension always appears to be lower case so I think that it is unnecessary. I have also been able to add a small fix to inv/index2 (the ajax url was wrong).

Added role restrictions to guided tours. If I have not done this correctly (or not covered all the requirements) then please let me know the other fixes are fairly low priority and can wait I'm sure.

Updated based on feedback

That looks better, thanks :)

@flavour Fixed again ;)

Can you please close this pull request and submit a new one when you're ready? Feel free to submit to my master instead.

It doesn't make sense to me that you use S3Search (i.e. POST query) for load tests instead of filtered GETs (i.e. GET query). I thought we had agreed that no new code will be written for S3Search - and that includes tests.

Yes, I know S3Search is deprecated. But, I included this because this is the request that is being sent currently.

@nursix : Could you give an example of filtered GET request, so that I may change it.

@somayjain: The TLDRMP 'Updates' page (renamed now as 'news feed') 

@flavour @nursix : I have changed the search request to a filtered GET request. Please review.

Looks good to me!

Will recommit

applications\eden\modules\s3\s3msg.py:1752: SyntaxWarning: import \* only allowed at module level

Looks good, with some tweaks...also I'd prefer the 2 commits (or 3 with fixes) to be rebased/compressed into 1 - many thanks :)

Would be great to get the server updated with any of these - but no pressures...

Done already, no need for this.
My solution re-used an existing s3db.configure, so slightly less overheads

@flavour : Please review. Is it good to merge?

I've re-enabled some CSS which was removed on the menu because there was an error reported. This is what it should look like. The only difference the new CSS (should) make is that the link is longer...
![screen shot 2013-10-01 at 11 53 10 pm](https://f.cloud.github.com/assets/1373438/1244562/f611cb40-2a87-11e3-8ed6-6b1677e6c5f6.png)

This reversion brings back the breakage on Firefox at least:
![explorecommunitydata on ff](https://f.cloud.github.com/assets/389592/1245177/67a95758-2a99-11e3-8940-f971e3acb208.png)

Ahh.. thanks for the screenshot. Works for me on FF. Could you see if this works if you drop 190px -> 180px? 160px?

@somayjain @flavour @michaelhowden : Updated tests.py files

Looks good to me!

@flavour @somayjain

The event module is not activated for DRRPP, SandyRelief, CRMT.

So, remove the test from these templates because it is not supposed to work on these.

Looks good otherwise

@somayjain  I have edited the required files.

Looks okay now.

@flavour I used the document to find out the Test Case ID. 
https://docs.google.com/spreadsheet/ccc?key=0AmB3hMcgB-3idG1XNGhhRG9QWF81dUlKLXpJaFlCMFE#gid=15

Sure...the bug is in the docs, but no need to copy to code...don't take docs as gospel but instead fix at the source...

Looks good!

Whilst there's nothing wrong with this per se - I'm wondering what this really tests which the existing tests don't?
- That the IRS module is enabled in these templates
- That the core IRS datamodel loads
- That the IRS controller parses & this function

It would be great to see a little more - like testing out any widgets on the page by trying more fields.
I don't think we can get any extra models in the pure Create...although maybe there are additional tabs which can have data put in.

Anyway, this is OK as a bare-bones start, but I'd be keen to see more development of test cases rather than more very simple test cases which test fundamentally the same stuff..

Thanks :)

Large Binary files shouldn't really be included in Revision Control as they bloat repos massively.
Can we handle the PDF in a different way? i.e. Copy into static manually...

Sure - this is actually just an empty file now. Not sure if it's best to 
leave this in place - or remove it - your call.

Cheers

Michael Howden
Director, Sahana Software Foundation
Managing Director, AidIQ
michael@sahanafoundation.org
skype: michael.howden
+64 (21) 126-1360
+1 (213) 261-4250
twitter:@michaelhowden

On 15/10/13 12:37 AM, Fran Boon wrote:

> Large Binary files shouldn't really be included in Revision Control as 
> they bloat repos massively.
> Can we handle the PDF in a different way? i.e. Copy into static 
> manually...
> 
> —
> Reply to this email directly or view it on GitHub 
> https://github.com/flavour/eden/pull/609#issuecomment-26314536.

I think I can merge this tomorrow, sorting out the issues I mentioned if you don't get to them...

Can these 6 commits be rebased/compressed into a single one?

Many thanks :)

I tried the usual way giving me some weird errors - will try again later.

Thanks :)

Interesting - it doesn't wrap for me (FF 24.0 here). How does it look in other browsers?

Many thanks.

![screenshot from 2013-10-29 10 12 52](https://f.cloud.github.com/assets/808895/1426393/924effb8-4069-11e3-9a0e-a976db5ca3c4.png)
Here is screenshot of Google-chrome on my laptop

Thanks.

Could you please check which font your browser is using? This doesn't seem to be the same as what my FFox is using, despite the CSS prescribes one.

Here is font of navigational elements 'Arial Negreta system Used as: "Arial"'

Right - that's what I suspected. My browsers use "Helvetica Neue" which is a little narrower.

So this might happen to others too - depending on which font they have installed.

Can these 3 commits be rebased/compressed into 1?
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git
This makes it much easier to review & means that there is less churn in trunk.
Thanks.

This seems to build on old S3Report rather than S3Report2, and you seem to have added your wrapper script(s) to the bytescoutPDF library rather than to the S3 scripts.

Both not entirely wrong, but not exactly the strategy I'd expected either. S3Report is about to be deprecated, and we usually keep our adapter scripts separate from 3rd party libraries so that we can easily upgrade them.

Also, we need to be careful about licenses which exclude commercial use because Sahana Eden is being used commercially and it shall remain possible to do so. The BytescoutPDF licensing statement though forces us to remove this library from any commercial version (or buy a commercial license), and I'm rather -1 to leave this in.

Looking at the bytescout website, I'm even more -1 to use this library in Eden. Very dubious, and quite expensive.

Definitely not suitable for trunk (redistribution is not allowed!!!)

Hmmm... maybe Shareabouts would be a better fit for what you're trying to do.

http://openplans.org/work/shareabouts/

Especially the click on a map and submit reports part. Ushahidi as well.

http://demo.ushahidi.com/

Whether this is best done within Eden or as a separate app depends whether this is a means in itself or a feeder into Eden workflows.
The irs/ireport/create form is basically what you're after, but this needs work to get it working nicely on Mobile.

There doesn't seem anything for me to merge here?
000_config.py should NOT be included in the repo& all you've done is activate a couple of settings...no new code here?

Thanks @rukku @flavour 

@flavour The problem was that the subscription field was not defined in schema. I deleted the lines referring to the field.
I tried adding the field and it also works fine with that.
If we have to add the field i will add it and send another pull request. 

Thanks, that was ugly before!

Is this one available in all Templates?

Could we introspect this by reading the first one from the DB?

F

I meant /inv/track_item/search.

I got it. I will try to fix the  functions and raise exceptions in cases of none.

No, I think you got it wrong.

It does already raise exceptions in case of None - that's why this link is broken. You need to fix the caller.

Oh the caller should not in first place itself send none as tablename ?

See https://github.com/nursix/eden/commit/3eb582492ea9bf34420c84e01d835a0ec18b39a2

The actual bug was in the calling controller. If this misconfiguration does not lead to an exception, nobody will understand why this does not work (since the configuration is obviously accepted) hence the problem is much harder to find.

The actual error was: orderby-settings must always specify the table, either by using Field-expressions or prefixes. 

Otherwise the orderby-setting will be ambiguous, since views typically involve multiple tables - so which table holds the field? 

Surely, we ignore invalid configs, but at a higher level (i.e. s3_orderby_fields) and not at the lower level of S3Model. Low-level functions can not make the decision whether an error situation is safe to ignore, so they should - deliberately - always raise exceptions if there are invalid parameters.

However, I do agree that the exception here is not very conclusive - I will try to improve that.

Oh now I get it. Basically it is possible muktiple tables have same fields names and so we need to explicitly define the field of which table are we referring to.
I will close this pull request since it was not the right way to deal with it.
Thabks for your help.

https://github.com/nursix/eden/commit/3deb54d76165055aa782ed93c66f4a365e0414fc

makes it clearer and helps debugging.

Yes :)
Thanx again.

We could (with some effort) make it fall back to the main table - but in this case, out of all cases, the orderby-field is not in the main table, so that wouldn't have helped.

I prefer to get the config fixed - not only is that the only way to fix this case, it is also generally faster than fallback-introspection.

can't we add the order-by field to the main table itself??
Which config are you talking about. I didn't get the last part clearly.

Yes, we can and we do add the orderby-setting to the main table itself. But that still doesn't mean that the view only involves the main table - and the orderby-field can be in a subtable.

A shortcoming here is that the S3DataTable constructor does not specify which the main table is - so s3_orderby_fields has nothing to fall back to, and therefore the orderby-setting must always specify the table.

However, the general problem with your fix was that it was in a low-level function. 

Low-level function means that it has many different, even orthogonal use-cases - and for some of these use-cases it may be safe to ignore invalid parameters and return a default (like for s3_orderby_fields) - but in other cases this can be dangerous.

Low-level functions should never make assumptions - if a parameter is invalid, or for any other reason why no valid specific result can be produced, they must raise an exception - simply because the developer needs to know that (s)he needs to change something in the code (s)he just wrote.

Accepting an invalid case silently is allowed at higher levels where we know the exact case and the potential consequences of invalid parameters.

So, in the orderby-case it would be safe to ignore an invalid setting (it wouldn't be nice, but safe).

In the more common case of s3db[tablename], though, a default-result could lead into a whole cascade of errors with potentially dangerous consequences for the database - and the default situation is nowhere being caught.

So your "fix" would have solved that one broken link - although rather by ignoring the error than by actually correcting it - but at the same time it would have obscured potentially dangerous programming mistakes elsewhere, and that we really shouldn't do. Wrong must be treated as wrong - at least in debug mode.

But if you still want to do something useful in this regard, you could actually modify the S3DataTable constructor so that it specifies the tablename of the main resource to s3_orderby_fields (instead of passing None).

As far as I can see that is the only case where s3_orderby_fields receives None as default tablename.

I'm quite apprehensive to do that as it IMHO fosters bad habits and laziness as it would invite ambiguous configuration settings - I'd prefer if people are more explicit when writing code, but maybe you're more brave in this regard and dare to implement the assumption.

Please review it.

@flavour : Instead of taking predefined skill name, took the first row of data after introspecting the database. If there isn't a row, added a row to the database and sent that into the test. The test runs for all applicable templates. 

@flavour : Thank you so much for the previous review. I have made the changes. Please review it again. 

Thank you. 
Will do that next time around.

@flavour  updated the pull request as per discussion.

@flavour  please review

So this would be part of a represent for document_id.
Makes sense.
NB No-one else is logging feature requests in GitHub, so I'm not sure if we should encourage this as it sprawls such things...currently feature requests are on Trac. This is small enough to be a ticket, so I logged it there:
http://eden.sahanafoundation.org/ticket/1427

I'll leave the Issue open as it's possible we'll end up moving over here...

My bad! Thanks @flavour 

Cool,t hanks - Skills should be easy to copy, 14 days is a fine default, no need for setting right now

Great thanks - perfect :)

The images have been directly taken from Google images. Is that fine?

This is just a match up to another project as I've mentioned above. If I get time I'll try coming up with a better design.

I don't think we want the DRMP images uncommented, but rather new ones creating - especially if they can target the 3 usecases.
The new pics looks fine, but we could also keep the existing one to have 3?

<}flavour{> You can use auth.s3_has_role("ADMIN")
<}flavour{> No need to do extra DB queries
<}flavour{> s3_has_role does a simple lookup in the session so much faster
<}flavour{> & I'm not sure why you patch the settings.get call
<}flavour{> That doesn't seem to help
<}flavour{> I want to be ale to deliebrately control the User view & the Admin view separately
<}flavour{> I think this needs 2x different settings
<}flavour{> So if s3_has_role(ADMIN): check the Admin deployment_setting
<}flavour{> else: check the normal user setting
<}flavour{> normal user is the current one
<}flavour{> 'registration requests'
<}flavour{> We can have the  get_auth_admin_sees_organisation call fallback to the normal user one
<}flavour{> This will be fully backwards-comaptible which is alwys good

Closed as it's being rebased? :)

Hi @flavour ,

If you had some spare cycles, could you please review my changes? This is to address issue: 1412 (http://eden.sahanafoundation.org/ticket/1412)

Also, as mentioned in the testing section of the pull request summary, I was not sure proper check in procedures in the developer guidelines.  I was hoping to gain some insight to this as well.

Thanks in advance,
-Jason

This is just a reversion, not a 'fix', right?

This looks excellent - great stuff :)
There are minor formatting issues to take note of...although I can fix these up this time, it would be good to have them be right in future.
More importantly, I'd like this to be rebased: In general Pull Requests should be a single commit to make reviews easier & to minimise repo churn.
In this case I actually modified that same file a lot just recently so it won't auto-merge anyway...I can pick this through manually, but nicer if you could ;)

In general, yes running tests would be nice, but isn't essential...we have CI running them automatically anyway:
http://eden.sahanafoundation.org/wiki/Testing

It would be great to extend this enhancement from Orgs to also cover the other Autocomplete routines too if you can find the time...?

Forgot one:

This was hand tested.  It could have both Selenium and unit tests.  Pretend there is a ToDo in the code for that.

I reworked this into a DRYer solution with a hook into the addPersonWidget...thanks for doing this work as it helped me to clarify my thinking :)

Not a complete reversion. Keeps the changes to the menu items - just puts them back under the cog

Yeah, so not a 'fix' just a 'modify styling'
I prefer good descriptions.as 'fix' makes me think 'what was the bug?' which takes longer when there's no actual bug to be found! ok, I'll merge/update server

Hi @flavour ,

Thanks again for the review.  I really appreciate it.

I have gone through and performed the requested red-lines.  Does it look ok?

I have also retested it and it performs as described.

Also, I would love to extend this feature to work with other auto completes.  Perhaps I shall create a tracking bug to do so?

Thanks,
-Jason

I see a lot of changes to core files, so assume these have been tested in CRMT & DRMP?
I'll merge and update PH anyway, thanks :)

F

We already have an internal 'support requests' system:
https://github.com/flavour/eden/blob/master/controllers/default.py#L1119
https://github.com/flavour/eden/blob/master/modules/s3db/support.py

This is certainly extremely primitive & could be enhanced, but I don't see that building a parallel system is a good idea.

What I'd really like to see is optional integration with Trac &/or Sunflower - i.e. being able to have requests logged here be synced to these existing ticketing systems.

We could even consider not having a separate module to handle this & just using project_task...although this has 2 potential problems:
(1) project_task is used for other things & so we need to clearly filter between the 2
(2) if the bug is in project module this may prevent us reporting the ticket, so a simple separate system may be safer
- it can always optionally create a ticket in the local project_task...which would then make a sync to Sunflower easier...I actually like that workflow a lot: Dedicated simple module to be reliable: OPtional pass to project_task, optional Sync to Sunflower after that. Each step fails safe & allows the previous step to complete OK

Fran -- A better place for that info would be in a relevant blueprint.  Review comments are not widely seen and will vanish with the commit they're tied to.

Use of project_task has been discussed at some length, but there is one new item not previously mentioned anywhere that I've seen, which is the existence of a "support" module.  Surely that would be a relevant piece of info for the kanban, which is a _view_ into the underlying tasks / tickets.

The time to deflect from the task was before it was started.

@ptressel 
Re: review comments are not widely seen: You are aware that you can "Watch" a repo, and thereby get notifications about all pull requests and comments? This keeps you in the loop.

If you find it useful to copy contents of a review comment onto a wiki page, then you can easily do that.

And these conversations don't really vanish - you can find old discussions which you received notifications for under https://github.com/notifications

> You are aware that you can "Watch" a repo, and thereby get notifications
> about all pull requests and comments? This keeps you in the loop.

Pull requests are after the fact -- after the discussion / design / etc. that led to them -- hence not "in the loop", but more like trying to reverse engineer it without the plans, something one only needs to do if "out of the loop".  I'll go watch the repo, but it's clear others are not using it for staying "in the loop" -- have a look, not even Michael is watching...

I rebased this again and will push --force a new version.

To be honest I think a better workflow is to simply have editors not default this field at all...as the change on Org is only useful for that 1 case & I think we can assume that most donations by call center staff aren't for them directly.
I made this change.

The helper function is there because there are potentially a lot of these "one thing toggles another" situations -- there are half a dozen right here, we just aren't using the others yet.  I'm sure it's not actually confusing.  How about let's try it and see if anyone else barfs?

I agree about not defaulting the committer in that case -- said so in the hackpad.

Let me go rebase and find out if anything is still wanted from this.

Ok, ready for another look. Summarizing my replies:

I believe edit() is clearing full_name.

ook out organisation_id -- thanks!

Can we try hide_show for now? The idea is not to repeat slight variants on the same code. Right now there's just one use, but I'd like to add another that's a blurb for orgs taking in-kind donations. Some may have both, some may take only one or the other. But having that lets the org say briefly what type of goods they need. And we might want a 3rd blurb for volunteers. This also gives the donor a hint of what kind of work the org does, if they're not familiar w/ it. The first 1-2 lines of each blurb can be shown in the request thumbnail. If we add those, there will be 3 uses of hide_show. I'm fairly sure we have this hide / show controlled by a checkbox elsewhere.

Ok, that last was more expanding on than summarizing...so here's the actual summary:

Oh, pleeeeze can I keep hide_show? I'll take him for walks and clean his litter box and...

Of course, things which are discussed outside of GitHub, you won't get notified about from GitHub. However, by watching a repo, you can at least keep yourself informed and important information doesn't just vanish in the dust of the battle.

However, if you think that this particular piece of information would be better to have on the wiki - regardless of the reason for you to think that - why don't you just copy it there? Or do you mean that that would be Fran's responsibility because he used the wrong comm channel in the first place?

> 22 nov 2013 kl. 10:52 skrev Pat Tressel notifications@github.com:
> 
> You are aware that you can "Watch" a repo, and thereby get notifications
> about all pull requests and comments? This keeps you in the loop.
> 
> Pull requests are after the fact -- after the discussion / design / etc. that led to them -- hence not "in the loop", but more like trying to reverse engineer it without the plans, something one only needs to do if "out of the loop". I'll go watch the repo, but it's clear others are not using it for staying "in the loop" -- have a look, not even Michael is watching...
> 
> —
> Reply to this email directly or view it on GitHub.

Hmm...I just re-read this, and...

> To be honest I think a better workflow is to simply have editors not default
> this field at all...as the change on Org is only useful for that 1 case & I think
> we can assume that most donations by call center staff aren't for them directly.

...maybe we shouldn't go clearing it either, unless we know we set it...but with your change, that won't happen any more. They might start by filling in the committer, knowing who they want in that field to begin with, and then select the org.  Then if we clear it they will not be happy.  So, since we never set it, maybe we should just let them deal with changing what they entered.  Guessing which way the coin will land...nah, this isn't urgent, so I'll wait for a reply to take it out.

As you say, req/commit/create change would now be a bad idea as the original problem has gone away (of the committer being defaulted incorrectly).
For the helper, I agree that this is a common requirement, however this solution makes things more complex for me, rather than simpler. I still have to inspect the page to work out all the IDs, I then need to plug these into the JS & then work out where to put them in the Python wrapper....so the Python wrapper is thus extra work not less....and is less extensible since as soon as I want to do anything else I still need to go back to custom JS.
If the wrapper could be made smarter somehow then I'd think again - i.e. it was more introspective...so I could just pass it Field1, Field2 and it would hide field2 until field1 was selected...have the table pulled out and the property & suffix all introspected. Ideally Field could be passed as either Field or FieldSelector but the latter would then need resource passing in & be more complex...so I'd be fine with just Fields support...but as it is this is very complicated to the point where it creates more work to use/maintain than raw JS

Ok, I took out hide_show. You're right -- I could get the table and field names from the Field objects. I don't believe suffix could be inferred -- there might be a different relationship between the two elements. This isn't general enough -- the checkbox might not even be a resource field -- it might have been stuffed into the form. (Recall that checkbox for school vs. hospital in cr that I put in for Pakistan?) But here's what worries me: someone writes a bit of code for some behavior, inline, then someone else writes different code for the same behavior elsewhere...then we decide we want to do them all differently, and have to go find all the different ways people thought of to do that one thing. Can't grep for a pattern...

Replaced that change with this:  The req/organisation_needs update form had a menu widget for the org, and an Add New Organization link. I expect we don't want people to "move" one org's need entry to another org...?

There was a reason to remove the truncate-method: Datatables has a built-in expand method, which allows the user to expand the abbreviated text. But for this to be possible, the server must deliver the full text to the client and not truncate it.

Please remove the truncate-method - I fixed S3Search.

Apart from that: S3Search is to be deprecated - i.e. if anything is needed to keep S3Search working, then it must be done inside S3Search, or, if that's not possible, the page must be migrated to the current framework (S3Filter).

Again: no method whatsoever should be used to truncate long text server-side for datatables. This takes away the ability of the user to see the full text which is a major usability restriction.

We want the full text transported to the client, and do the abbreviation of long texts client-side (i.e. in JavaScript) with the option to expand it into the full text. This is implemented in the new s3.dataTables.js script and it is the standard behavior there. 

Hence I removed the function server-side - and it shall not be re-introduced, especially not for S3Search. Instead, I removed the call in S3Search (which I had missed originally), so you can just remove the truncate() function from your pull request.

@nursix @michaelhowden :  Fixed it 

@flavour please review 

How about if I rebase this and push it again...

I'm not sure of the purpose of this function?
It seems to not be called by anywhere?

It is for this gci task -http://www.google-melange.com/gci/task/view/google/gci2013/6177035386880000 

I still don't see this ever being called?
We need to have a way to access this function...e.g. a deployment_setting which ensures this gets called and that setting should be present, commented out in private/templates/default.py

Please let me know what's wrong with this so I can fix it.  I have other stuff stacked up behind it.

Okay got it :-)  , but the indent thing is that whoever I push the codes it changes automatically . what to do now . I am using sublime text 2 .

1) A checkbox is provided to select/unselect if a new layer needs to be created for new Search query.

2) A new folder named 'Twitter' is created under which new Search keyword are added. You can select/unselect to decide if the tweets related to that Search keywords needs to be displayed or not.

Gotta move on -- pushed the next thing, as a separate commit so they don't have to be picked apart if one or the other has to be tossed on the scrap heap.

This is still not called from anywhere.

I'm afraid I can't provide support for editors...I personally use Notepad++ & some Eclipse

Can this be rebased/compressed to a single commit to make it easier to review & reduce repo churn?

Many thanks!

but i could not find this file - "private/templates/default.py"

On Tue, Nov 26, 2013 at 3:18 PM, Fran Boon notifications@github.com wrote:

> This is still not called from anywhere.
> 
> I'm afraid I can't provide support for editors...I personally use
> Notepad++ & some Eclipse
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/648#issuecomment-29279151
> .

Since the new commit will need work, and I'd really like to get the previous commit either in or turned down, I'll revert the new one while it fixing up.  Is there a standard workflow for this case -- old pull request hanging around, and new work waiting?

Since it will then be hard to find inline comments, I'll reply here.  Some of the replies are just notes on what I need to do, but there are some actual questions, indicated by presence of a question mark ;-).  Replies to the notes are welcome too, especially if the notes look like snipe hunts.  Consider the notes a mini-stand-up, since we have no PM for managing volunteers.  Were this a stand-up, I'd also include what's in the notes in the PH hackpad.

GitHub Markdown seems to have done odd things to my blockquoting, so now it is muddled and unclear. I'll try it again and this time put in extra newlines.

> We have moved away from concluding the tablename from controller/function or controller/function from the tablename.

What is the standard procedure now? Explicit controller and function strings, or a model query? The "hrm" "person" case appeared to be handled explicitly. I'll look at how class=dl-item-delete works.

> Apart from that we do have a crud_button() function, which I would prefer to be modified in order to deliver those buttons rather than having two new helper functions.

Ok. Maybe I can infer the need for datalist-style buttons from, say r.representation == "dl"...unless that is only for Ajax updates of existing dl items, and there are also non-Ajax cases where the whole page gets generated (like when the containing page is initially built) and those are r.representation == "html". I'll go check. And I'll need to see if those icons came with bootstrap and have alternates if that's not in use.

> Thanks, but this doesn't set the row to be hidden initially does it? which is the most common use-case

Visibility is determined by the value of the controlling field in the database. E.g. boolean field "money" in req_organisation_needs controls visibility of field "money_details". It should not be initially hidden, but rather whatever value is in the database. The .change() on the end takes care of that.

> NB I'll add this, np

That's not on a line so I'm not getting what it refers to...?

> commit 1 is merged already

In re. notifications and such, if you do it by merging the pull request, it will send a notification, I believe.  Otherwise, I won't know about it, since there are no notifications for pushes nor the insertion of commits.  Otherwise, I'll be waiting to see it go through, and won't know it's happened.  Grepping the log doesn't seem like a good use of time.

commit 1 is merged already

> commit 1 is merged already

Another reason for using the pull request mechanism, and poking the merge button on the site, is that it will use the same revision number.  Then a rebase or merge on my end will make have no conflict.  Alternatively, even if the pull request is still open, if the commit is added with its original revision #, it will avoid hassle.  Additionally it assures me that the commit was correct -- that it was not "fixed" before being inserted.  I've mentioned before that it will help you get commits as you want them if we see what you have to change before putting them in.  I'll pull out my commit and yours and compare them -- avoidable overhead.

I gave up trying to maintain a "clean" revision history (i.e. identical to trunk) long ago - it doesn't actually help anything, and there is much more overheads to avoid conflicts than to actually fix them.

Furthermore, I gave up to try to make commits exactly the way Fran "wants them" - as that requires either supernatural powers, or endless forth-and-back discussions. If it is acceptable, he will merge it, and iron out minor issues himself - otherwise he'll comment on the commit before merge.

Making it convenient for everyone would (and does) overload Fran - so it is, especially in times of heavy workload at his end, indeed easier to push the hassle back to you (or me).

Yeah - it drives me up the wall every now and then, especially when you try to get something done that requires a whole bunch of different stories to get merged together.

But the other angle of it is that without Fran doing so, the delays between merges will get even longer - and those delays are just as painful as you will admit. So, it's either soon or perfect - fast and "dirty", or slow and painful.

And at the end of the day, it is more important for me to get certain changes merged soon than to get it perfect. 

So, Fran's excused from my side.

However, I think procedure should be discussed on the mailing list or in meetings rather than in comments on commits. Don't you think?

I apologize for my "spam" here.

> However, I think procedure should be discussed on the mailing list or in meetings rather than in comments on commits. Don't you think?

Heh.  Since I said the same thing a while back, then yes.  I'll just reply to two specifics, then we can start over elsewhere.

I don't think this is a "Fran's burden" vs. "our burden" thing -- not a zero-sum game.  If we can smooth out our GitHub procedures, we may be able to reduce _both_ ends of the burden.  BTW I don't mind fixing up the code on my end.  Just need to know what's wanted.  Maybe the rest of us should start assembling a "Fran quirksmode" doc.

It's not a merge vs rebase or clean ordering thing.  After all, we get a merge commit if we use the pull request merge button.  I removed from this comment a description of two ways people might think of to do the git fixup I'm doing now, where one order of git cherry-pick vs git pull (with or without --rebase) might introduce bugs due to failing to detect conflicts, and (say) accidentally removing someone else's mods.  It's long, so more appropriate for a thread on git safety and improving GitHub processes.

Dominic, if you're still awake -- just want to know what's the new standard procedure:

> We have moved away from concluding the tablename from controller/function or controller/function from the tablename.

What is the standard procedure now? Explicit controller and function strings, or a model query? (The "hrm" "person" case appeared to be handled explicitly. I'll look at how class=dl-item-delete works.)

No, you don't need to know 100% what's wanted - that's what I wanted to say. I'll take that in a separate email.

For the other thing: what I mean is that tablename and controller/function shall always be specified explicitly by the caller. If necessary, then these parameters shall be passed all the way from the S3Request/S3Resource down to the helper functions. But you have all three parameters anyway, so it's just to require them all rather than concluding one from the other.

Anyway - I don't think there should be separate helper functions for CRUD buttons in data lists. Much better to modify the existing function to include the bootstrappy stuff as option.

Grrr...looks like this task may be another "training exercise".  Turns out there is already a DMS represent for lat lon.  It uses directional letters rather than signed values, so it will not be the same as this one.  So Anurag will be able to tell which one he's seeing when he substitutes his for the current lat_lon_represent.

Very nice - especially the fading one :)
I'm merging, but can we then get the CSS in at least the default theme to make use of these?

This basically reverts a previous commit, so looks wrong...I think perhaps there needs to be a case distinction

@flavour https://github.com/flavour/eden/commit/50d9c1c1ce60ae9b4821ea45aaa45240a6c707b1
the first problem was that the database changed according to template so we couldn't values so it had to be pulled from database which arnav sharma fixed.
But the problem arising from that was that the hrm_skill_certificate table need not be queried for the test to run sucessfully. Since the table is empty even after pre-population and hence returns a None row object. So now i check the database for the first entry in hrm_skill and insert that into form.

Still useful to have an if not row branch in case prepop not run?

Hi, should I update only for the default theme, or wherever the old one is used? I can do either one.

@flavour in that case should i raise an exception ??

There should not be any problem because the form has dropdown and i am selecting directly from the database of dropdown. If the database is not there for the dropdown the form makes no sense and hence test should fail ??

I can't see why that table needs to be queried in order to have the test run successfully - can you explain?

Raising an exception would be wrong, though.

I think the default theme only is safest at this point...of course the SSF theme will definitely use this :)
Once we have it in the demo site (which uses default theme) then we can assess better how widely to use it.
Note that there are some places where we use a smaller image which I'm not sure the sunflower will scale to - needs experimentation & assessment...

@nursix The reason being the same test runs for many templates which have different values in their drop-down. So by querying the table we are adjusting the value we insert into form according to template rather than hard coding a value for it (it may pass in some templates and fail in others due to hard coding).

I like being introspective like this - much more adaptive.
I'd still prefer to create a record if none found in prepop - this way we can still test the GUI...this test isn't supposed to validate the prepop.

@flavour it wouldn't be able to create a record incase of none because the form is a dropdown. And if there is no option to select from dropdown we cant submit a record. 

Dominic --

Erk. I'm not doing anything except answer GCI questions... I snuck away for a moment to ask:

1) I'm hoping to infer whether a call to crud_buttons wants the dl card form or not, but haven't found anything that distinguishes that case other than the mere fact of having been called from the custom PH code.  I'm wondering if we don't yet have a packaged dl card maker, and so the only instances of that type of button are hand-generated, and maybe only in templates.  (Haven't grep'd everything yet.)  If so, then maybe for now, I'm stuck with the caller passing in a flag for that format.  So...is there some way of detecting that a dl card is being rendered? or should I have to caller say they want it?

2) This isn't to do directly with this mod.  I was wondering if some Ajax requests might come in to render a single dl card, and if those have r.representation == "dl".  (That doesn't help with 1) since the cards also get rendered in container pages like profile, which have r.representation == "html".)  So then I was wondering, if I needed r, what would be the best way to hand it over from someplace it's available.  I see we pass it explicitly, unlike most other things, that get stashed in current.  So I was wondering, why don't we put r in current?

I am suggesting creating the record in DAL just like the current code

Okay, I made a style.css in a new SSF folder. Should i just include the 2 classes(that have the throbber) to override from widgets.css? And then just add that file to the style.cfg in private/templates/default?

i will do so.

@flavour  please review :)

Yes.
css.cfg

How is this? :)

Fixed it. Thanks for telling. Have to be efficient with code, haha.

Thanks :)
- mroe about being DRY to ease maintenance than reducing filesize or load on browser

Can this all be rebased/compressed to a single commit?

I'm not sure how to do that exactly? Could I just close this and setup a new pull request from my latest commit?

http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#RebasingafterpushingtoGitHub

A new PR won't work unfortunately.

@flavour that wont work since it would not populate the dropdown . And for submitting we would need a field in the dropdown which the form fetches through database. By creating a dummy row it would give us an option but since that option wont be in dropdown the form will through error and the test fail.

Well, that didn't work out as planned. I followed the instructions.

I did git reset HEAD@{4}, then committed. Since, it said above there were 4 total commits in this pull.

Nothing easier than to check the DB before creating the form, no?

@nursix yes i have already checked that but 2 cases arise:
1) if db has values : then test works fine
2) if db is empty : I insert a row into the db and then test works fine. I didn't raise an exception. Can't create a dummy row since it wont actually be in db and the form requires one that actually is in db. Hence the test would work fine in both the cases.

Oops, seem to have lost some work here, sorry

I still have it in the uncommitted changes. No worries. How should i do this from here?

If i commit the files, there will be in total 2 commits. Then do i do the reset HEAD@{2} and commit?

No, you misunderstood: It is clear that you can not have the newly inserted record in the drop-down in the form if you insert it /after/ you generate the form. Hence - check the DB and insert a record if needed /before/ you open the form.

Cool, yes :)

I think this is all just lacking a db.commit()

@nursix i have done that before i call create i have inserted the new record used it to create the form :)
db.commit() is there on line number 69 :)

Err - there are two commit here, one adding the creation of the record, and one removing it. Which one is the later one?

If you insert the record and commit, and /then/ open the form, then the record should be in the drop-down. Can you explain why it isn't there?

If that is the reason why the test fails, then the failure of the test is actually correct behavior.

Could it be that you're trying to fix the test to ignore the bug instead of detecting it?

@nursix  no i am not doing that. my file just has one commit . where can u see the other one and i am not removing any record . 
https://github.com/arnavkagrawal/eden/blob/master/modules/tests/volunteer/create_volunteer_certificate.py

But that is not this pull request: https://github.com/flavour/eden/pull/650/files

Oh, you updated it! Alright.

Yes - this should work. If the test row does not appear in the drop-down, then something's gone wrong and the test fails for good reason.

Its the same file. The pull request is showing diff stats. The file needs to same since a pull request only changes the changes between file at my branch and fran's ?? 
EDIT : I had rebased(an hour ago) in between and it is showing the right file.

Yes, I can see it now. Now it seems to do what I meant - so it should work with or without prepop.

I must admit that the self.create() helper is obscuring the flow massively - difficult to see what's really going on (too much delegation is not good for tests), and hence whether the test case is valid. But that is certainly not subject of this discussion.

@nursix so this seems fine ?
@flavour  please review :)

It's not working for some reason? Now i have the 4 same uncommitted files again...

No, it looks terrible :D but yes, your change seems right.

Hahaha :P

I meant: It is the over-use of massive and complex DRY helpers here that looks terrible. 

Whilst DRY is a good strategy in regular methods, it is not the ideal strategy for test cases. DRY helpers, if at all needed, should be small and simple and largely explicit - not big and complex and massively implicit like .create().

It is difficult to judge whether the test is actually valid, i.e. whether it can detect the type of bugs I want it to detect - and even if it did report a problem, I couldn't tell whether it's the test case that is broken or the code that is being tested. In my eyes, we do need tests which test the tests before we use the tests to test our code.

And apparently, there are way more defects in test cases than there are valid bug reports coming out of them - at least there is more effort being spent on fixing the test cases than on fixing the bugs they report - which defeats their actual purpose.

So, I'm not really happy with the test suite - but the change you made seems to correct a previous error, hence fine.

@flavour changed it . Please review.

After messing around with it like 10 times I finally got it to work. For some reason i needed to git add those 4 files. It said they were untracked. I don't know why though.

Cool, I just realised that for new files, you'd need to git add .
I'll update the docs for that case

@flavour i also wanted to talk about the task you assigned me but i dont see you these days on irc? How can i contact you ?

An example so you can understand what I mean: within this test function there is not a single check for success/failure of the action being tested - you can not see when or why this test would actually fail. The whole definition of the test and its success/failure checkpoints is delegated to the helper function, while the test case only defines the data payload for the test.

That is obviously the wrong way around: this "test case" is actually just a helper function to define example data, whilst the .create() function is the actual test case - and since there is only one create-function, there is actually only one test case for creating records, though run on many different examples.

This reduces the value of the test suite massively.

No, we can not put r in current (it's not a global singularity, but a parameter - there can be multiple instances per run, and any routine must know from which of them it's being called), and I can't see the purpose of that either. If I find it in current, I'm afraid I'll have to remove it because that's wrong.

To be honest, I don't really understand your problem at all - can you simplify your question so that I can answer it?

Why do you need to introspect the case, anyway? You implemented two separate functions to render the buttons, which obviously had to be called explicitly (how else would that work?) - well, and if you can call them explicitly from a place where you know that you need DL buttons not standard CRUD buttons, you can just equally well pass in this condition as a parameter - no?

All I suggest is to not have two more CRUD button renderers - especially not separate for every button type and front-end layout. It bugs me massively that we already have to make so many case discriminations just for bootstrap - everywhere code is being duplicated just because it uses a different layout.

This is bad style and a stupid strategy - one day bootstrap will be out of fashion, and something new will come up, and then we'll have to change hundreds of functions all over the place in order to adapt to the next fashionable GUI layout? Arrgh - no! Stop it! Centralize the rendering, and parametrize the layout - that's the minimum we can do. Even better would be to convert it into hooks, like S3Navigation does it.

The core functions (i.e. S3CRUD) should always only contain the default renderers - everything else should be passed from the template via hooks. And I'm sorry - there is a bootstrap-mania at the moment, which tries to make it an alternative default BUT sorry, there is no such thing like an alternative default (that contradicts itself!), it is either parameter (or hook/setting etc.) or default.

So, the trick is to override the default button renderer in crud_button with a parameter or hook - and /that/ is the right way to do it. Not introspection - but parametrization/configuration (preferrably the latter, but if it's dynamic then it might have to be the former).

And just to point that out: naked icons as a replacement for text links do NOT provide for better usability.

Dominic -- It seems I've stepped into some ongoing debate...I was asking which approach to take, not proposing.  I was asking why r wasn't in current, not threatening to put it there.  So now the r question is (mostly) answered (I asked a related question before, about requests within requests, and didn't get an answer -- the same dangling end is here too, but it can wait).

For custom buttons and custom layouts, it sounds like what you would really like is to have the custom support _outside_ of crud_buttons after all, but merely called from there if a hook is set, and supplied from the template.  At the moment, since a) we don't have a template hierarchy, 2) several templates use cards, 3) this is for a near-term deployment, 4) there is other bootstrap stuff already in there, and 5) I have other things stacked up, may I put the card code inside crud_buttons, or call it from there, for the moment?

What I'm hearing is that you'd prefer crud_buttons to be just the gateway, and that it would dispatch based on a hook, and that the custom code should not actually be incorporated into crud_buttons after all.  If so, then perhaps these should remain packaged as separate functions, but called from crud_buttons if the caller sets the appropriate option and if a custom hook for it is set in the template.  If that's what you'd prefer, I'll structure it that way, rather than integrate it tightly into crud_buttons.

The option for which type of button is wanted -- dl item buttons, dl widget title bar buttons, full page buttons, popup buttons, etc. -- is orthogonal to whether there are custom hooks provided for them.  That is, even in the default template one might want different (say) sizes of buttons on different types of elements, and different types have different classes and hrefs.  Thus a "format" option might specify a dl item button, but the default would merely use the dl behaviors, but not bootstrap.  A custom template might set hooks for either of those.  One trouble here is that there is complex behavior built into the dl buttons that should not be replicated in the template.  Ok, I'm going to shut up here -- this is for later, and could be part of a larger discussion of how to refactor templates, themes, prepop.  That would be better on the mailing list.

> And just to point that out: naked icons as a replacement for text links do NOT provide for better usability.

The original cause for this change was that I saw that the delete buttons had no tooltips and looked like window-close buttons.  Some UI frameworks (cough cough Java Swing cough cough) have the option to render either an icon, text, or both.  But this isn't really about icon vs. text.

The following comment was in the hackpad -- is it related?

> Logically, we should have a render_buttons in S3Profile (equivalent to the one in S3CRUD which is also a method handler).

@flavour is it fine ?

No, sorry - since now you don't create the Testing record if missing so it wouldn't appear in the dropdown!
You need to create it still...just that you don't need to then re-read it...
& yes, you will want a db.commit() after creating & before launching the Selenium to access it via the Web UI...

@flavour  exactly what i meant :)
will do it :)

@flavour  is this fine ?

@flavour this works fine with both cases. Both prepop and non-prepop :)

Yes - the desired architecture is to use s3layouts.py for any type of 
renderers, and have them hooked into the respective method handlers.

Templates can customize parts or all of the layouts (in their local 
layouts.py), whilst the central s3layouts.py contains the defaults.

None of the core method handlers should have any element layout hardcoded, but 
should merely provide the data and then invoke layout hooks to get them 
rendered.

We have implemented this architecture for menus (=S3NavigationItem), and I 
think that can and should equally apply to other action items.

Of course there can be multiple layouts for various types of action elements, 
different buttons and so forth - and I don't mind if s3layouts.py would include 
more than one standard variant that can be switched between by a central 
setting.

The main thing I want to see avoided is to spread out HTML layout and styling 
elements in request method handlers. That introduces a need to customize 
method handlers when you need layout changes, despite the method itself isn't 
any different. Hence - separate layout and logic.

I know you're not proposing - but I am!

torsdagen den 28 november 2013 01.50.21 skrev  Pat Tressel:

> Dominic -- It seems I've stepped into some ongoing debate...I was asking
> which approach to take, not proposing.  I was asking why r wasn't in
> current, not threatening to put it there.  So now the r question is
> (mostly) answered (I asked a related question before, about requests within
> requests, and didn't get an answer -- the same dangling end is here too,
> but it can wait).
> 
> For custom buttons and custom layouts, it sounds like what you would really
> like is to have the custom support _outside_ of crud_buttons after all, but
> merely called from there if a hook is set, and supplied from the template. 
> At the moment, since a) we don't have a template hierarchy, 2) several
> templates use cards, 3) this is for a near-term deployment, 4) there is
> other bootstrap stuff already in there, and 5) I have other things stacked
> up, may I put the card code inside crud_buttons, or call it from there, for
> the moment?
> 
> What I'm hearing is that you'd prefer crud_buttons to be just the gateway,
> and that it would dispatch based on a hook, and that the custom code should
> not actually be incorporated into crud_buttons after all.  If so, then
> perhaps these should remain packaged as separate functions, but called from
> crud_buttons if the caller sets the appropriate option and if a custom hook
> for it is set in the template.  If that's what you'd prefer, I'll structure
> it that way, rather than integrate it tightly into crud_buttons.
> 
> The option for which type of button is wanted -- dl item buttons, dl widget
> title bar buttons, full page buttons, popup buttons, etc. -- is orthogonal
> to whether there are custom hooks provided for them.  That is, even in the
> default template one might want different (say) sizes of buttons on
> different types of elements, and different types have different classes and
> hrefs.  Thus a "format" option might specify a dl item button, but the
> default would merely use the dl behaviors, but not bootstrap.  A custom
> template might set hooks for either of those.  One trouble here is that
> there is complex behavior built into the dl buttons that should not be
> replicated in the template.  Ok, I'm going to shut up here -- this is for
> later, and could be part of a larger discussion of how to refactor
> templates, themes, prepop.  That would be better on the mailing list.
> 
> > And just to point that out: naked icons as a replacement for text links do
> > NOT provide for better usability.
> > The original cause for this change was that I saw that the delete buttons
> > had no tooltips and looked like window-close buttons.  Some UI frameworks
> > (cough cough Java Swing cough cough) have the option to render either an
> > icon, text, or both.  But this isn't really about icon vs. text.
> 
> The following comment was in the hackpad -- is it related?
> 
> > Logically, we should have a render_buttons in S3Profile (equivalent to the
> > 
> > ## one in S3CRUD which is also a method handler).
> > 
> > Reply to this email directly or view it on GitHub:
> > https://github.com/flavour/eden/pull/645#issuecomment-29451407

I would also argue, that all kinds of action buttons can easily be made 
S3NavigationItems (or a subclass of it), which comes with the additional 
advantage of built-in authorization.

Ok, so S3Button(S3NavigationItem) in s3layouts?  Then either 1) subclass that for the layouts available by default, or 2) supply a format name in attributes, or 3) subclass it but provide a factory that hands back the appropriate subclass instance given a format.  3) is a common pattern as it avoids having the caller know what's inside S3Button or details of each subclass constructor, and the format may be available already.

I was going to use the keyword format but that's in use for extension (i.e. popup).  Might not conflict to use it for either, as the meaning would be the same within the layout, i.e. it's naming a layout.

We seem to have a plethora of button methods over in S3CRUD.  Some of that could move over to S3Button -- I'm not sure yet where the boundary would be, i.e. what parts might need to be deferred back to S3CRUD.

S3Button will want to know the action (meaning CRUD action or the additional terms in render_buttons).  Looks like that could go in m, except "edit" would become "update".  It would also be used to select the label from crud_strings, and to show read rather than update based on permisson.  S3Button subclasses for dl items would want it because delete and edit differ beyond the URL.

The floor is open for discussion / correction / suggestion...

Don't hit me but...if some templates being tested do not have the desired record, why bother testing if it's there?  Just create a test record and use that one.

(Inserting a batch of "test data" as a "convenience" that may or may not be appropriate for all tests, and may in fact interfere with some tests, seems counter-productive.  I have not seen it done elsewhere.  Much more common for functional and unit tests is to isolate tests completely, and prepare their test data individually.)

That's pretty much what I was saying!
If we have suitable prepop, then fine to use that but otherwise, simply create it.

I'd then moved on to making the tests more auto-adaptive to deployment_settings

@flavour thats what is being done right now. I am a little confused on what you want me to do with the test?

@flavour please review.

A submit button isn't strictly a navigation item, but it has a layout (meaning, its style could differ per format).  Should submit buttons be in here?  How about buttons that just execute JS (e.g. "save" an input value from a widget into its hidden field)?

@flavour please review.

@flavour please review :)

Hi @flavour ,

Could you please review this?  Pics of various site auto complete enhancements are on: http://eden.sahanafoundation.org/ticket/1429

Thanks!
-Jason

As I say - ideally you retain the ability to specify a URL, but catch the click where it needs to be caught and preventDefault it. This has the advantage that it works for both, standalone forms, popups and embedded forms.

You're asking all the right questions here! :)
Whilst I personally love the power of being able to search by so many options, like you I worry about this being very heavy to parse the results of.
I think the solution is to make all the different options configurable and perhaps the default should be the simple name.
Such configurations of this widget would then replace the SiteAddressWidget in a better way.
Other than the small suggestions inline, I think that the configuration options also address the bandwidth issues since we can decide which fields are useful for the context. e.g. for the DoH site, Org is irrelevant, as is address/postcode, yet the L1/L2/L3 could be useful (although probably not in most cases as the site name is very clear & matches the L3/L4 already)

Ignore the changes to the DRMP images - those file names wreck havoc with my git

Hey @flavour ,

Thanks for all your input!  I went ahead and followed through with all the changes.

As for the larger issue with having some of these options be more configurable, I attempted to do this by modifying the configuration in settings to contain some additional logic that could dynamically parsed by the auto complete.

Any feedback you have on that would be greatly appreciated.

Finally, in regards to the auto-complete defaults, it is defaulting to site name right now, but the additional auto complete fields are dynamically read in through the settings.  

Auto complete fields that have no values are omitted from the return value even though they may have been configured to be there.  That way we get to save on return value space.

Could this be a compromise?

Thanks,
-Jason

I've already stated that I don't see why we have a 'new module for reporting bugs' when we already have a native support requests system in place. I cannot review the code until it is rebased/compressed into a single commit

Why add ever more tests for S3Search?

Fran -- we have this because it was included as a GCI task, apparently scraped from the Projects wiki pages along with other leftover tasks from last year, and no-one objected.  Recall that this very task, and the fact that it was obsoleted by an equivalent feature, was _precisely_ the impetus for me asking for a way to be more "in the loop".  Had I known that the equivalent had already been done, I would have said something.  As per repeated discussion with other GCI mentors, if we have left an old task in the list, and a student does the work, then they get credit.  You don't have to review the code -- I've already done that.  I've asked Nishant to squash and rebase -- that is good to know how to do regardless.  Then Nishant can move this to a branch, for reference, and close the pull request.

How about scanning the few remaining Eden code GCI tasks, to see if any others are obsolete?  This is not something I can determine, as it may just be "we decided we don't need that any more" or "we are now dealing with that need in a completely different way from the suggested fix" -- not something I could tell by groveling through the code.

I am not commenting on GCI credit...merely on whether this gets accepted into Trunk.
I have no idea how the task appeared on the GCI task list.

re: Bandwidth saving by omitting empty fields, big +1 to that... a possibly small but useful optimisation.

I'm happy with the idea of fields being configured in settings - we already do this, however I worry about the complexity of the proposed structure & find it's specifics very confusing.
I don't think we need this to be infinitely extensible, so am happy for the config to be only able to choose from those which are supported by the pair of functions in .py/.js...dropping mistakes with just an s3_debug() seems like a useful enhancement. (I am open to this being fully extensible if this can be achieved simply, but it's certainly not a requirement, and simplicity of config/lower bandwidth usage are higher priorities)

Nice - merging :)

Thank you :)

Can this be rebased/compressed to just a single commit?

This makes it much easier for me to review & reduces repo churn

many thanks!

Despite the large number of inline comments, I'm actually pretty pleased with this :)
Look forward to seeing the next revision :D

This is a good effort - well done! :)
However I won't merge as-is - other than using r much more I think this is the wrong place for a resource-specific config. We want the per-resource config with the other profile configs...in model/controller/template (In this case it's Philippines/config.py) & then we read that config inside s3profile. s3db.configure(tablename, key=value) there & then retrieve with s3db.get_config(tablename, key) in s3profile :)

ok, so this addresses some of the issues, but not the fact that this adds resource-specific functionality in the middle of a generic function which is to be avoided if at all possible otherwise we'll end up with 100 of these & it will make it hard to see & slow to run. (We already have another immediate usecase with req/req/x/profile)

Generally the way we handle this is to store a resource-specific setting in a key/value store.
To Store:
s3db.configure(tablename, key=value)
To Read:
s3db.get_config(tablename, key)

If no value stored then simply move on, if there is then take action.

For this usecase I think that profile_layers would be a good key name (as we may want multiple in future even if the current usecases call for just 1)

So the s3profile part would have profile_layers = s3db.get_condfig(tablename, "profile_layers")
if profile_layers:
 for layer in profile layers:
 fappend(layer)

& then we can configure the profiel_layers wherever the profle is being configured - in this case in templates/Philippines/config.py

@flavour  the problem i am facing is there is no specific marker for facility in the defined tables. and it doesn't have a specific layer id too. So do we need to add that into database ?

I pointed out to you previously that the Philippines template has 4 different layers for Facilities & they each have a Marker defined. Look at my psuedo-code to see how to get the right one.

just saw that and what about the facility id ?? cant just use record.facilty_id because there is no such field there.

facility_id = r.id (which you already had)

@flavour  please review. The problem with the marker still exists since there is no controller function having controller as org and feature as facility in the db. So the query would give no result. Hence used default marker here.

As it says, this can't be automatically merged - it needs to be rebased...please also compress that to a single commit at the same time as this makes it much easier to review (as well as reducing repo churn)
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git

I worry about 000_config.py comments - this should NOT be included in the repo - it is left out deliberately.

In the Philippines template, there _are_ 4 records in the gis_layer_feature table with c=org & f=facility:
https://github.com/flavour/eden/blob/master/private/templates/Philippines/gis_layer_feature.csv

Just because you may not have prepopped them doesn't mean this isn't true for the PH template - which is where this code is living.

The default marker can be used as a fallback in case other people are using the system without the data being prepopped, but the primary usecase is a production server which does have the data or a dev machine which has been properly prepopped.
It is always good to have a sane fallback though

@flavour please review

Hi Fran,

I did not really understand how to pull all these changes into a single commit. Could you please give me your feedback on these changes? 
I've succeeded in adding a facebook channel and a facebook_message for pushing messages onto facebook. I've also added a person with Facebook as the contact method and I'm trying to test it out by the 'compose' feature in /eden/msg. The recepient has an autofill feature which does not allow me to add the recepient. Could you please let us know what might be going wrong? If this is working, we can test if the messages are actually being posted to Facebook.

Thanks

I'm sorry, I can only easily review the changes if they are 'rebased' & 'compressed into a signle commit'

The instructions for doing that are all over the web including the Eden website here:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git

@flavour please review.

@flavour please review.

@flavour  please review :)

@flavour  please review .

How does that work if the user doesn't have permission to update?

Oh yeah, thanks. Can anyone give me a lead to the source of the problem. I'm experimenting but can't seem to find it. In Assets it works fine, but in Vehicles, it has link eden/vehicle/vehicle?viewing=asset_asset.1 instead of just eden/vehicle/vehicle/1

The record ID seems to get swallowed somewhere, but I can't tell where without digging into the code myself. If you can't find it, it may be best to re-open the ticket - I can then look at it when I get around to it.

Ok, checked it. 

It's a quite common problem you have here: when re-using a controller across modules, the prefix and resource name must be hardcoded in order to override controller/function (otherwise it would look for the nonexistent vehicle_vehicle table).

However, the None-tab shall of course ignore that and use the native controller (i.e. the controller which originally received the request). This can be achieved by setting the Tab to native=True:

https://github.com/nursix/eden/commit/06011fbb109cd0233d6a481355c005c43e091ae4

Hi nursix, thanks a lot for helping and explaining. I have updated and added a commit for the pull.

Dominic fixed this now, thanks

This is changing a generic function to massively hardcode for 1 very specific usecase, so can't be merged.
Building a Popup from remote JSON data is a good usecase, but this isn't the right way to solve the problem.

I would recommend actually that the better approach is to import the data in this case into an Eden model & then can style popups easily.

If we really need the data loading live off the server then we need to have the HTML templates configurable per-layer.
This could just be a field in gis_layer_config (like the existing style) or maybe even extending style

The alternative for USGS is to use an iframe, which support I have added just recently, although isn't tested for this usecase so may need tweaking.

I would prefer to deprecate the S3Search function that this tests instead of testing it & then having to modify the test once the functionality has been migrated to S3Filter

Fran -- I was wondering about that...
Joseph (?) -- Where was the obsolete USGS URL being queried from? Was that in the front end or from the server?

(Yep, Its Joseph Neiger)
Pat -- I believe it was from the front end.
Fran -- Correct me if I'm wrong, but I think the data needs to be somewhat up to date. I'll try using the iframe as that is what I'm most familiar with.

Hi @flavour ,

Third times the charm! 

If you get a free moment, could you please look over these changes?  I have went ahead and implemented and tested the suggested red lines.

Thanks,
-Jason

Maybe we could switch this to a different represent function, that would benefit from a bulk call?  This is already well-described in the wiki, at http://eden.sahanafoundation.org/wiki/BluePrintLazyRepresentation, so writing it up isn't something we could make into a task.  So, some options:  Regard this as training, and stop here.  Find a different represent that does need a bulk call.

This needs rebasing as doesn't apply cleanly to trunk.
Also the rebase should do a 'compress' so that all 3 commits are one so that it is easier to review
Thanks

Samsruti --

Why was this closed? Fran just wants it "squashed" and rebased to match the current trunk version. You can still use this same pull request. As I suggested in the melange task, let's set up a time on IRC when we can go over the git commands to squash and rebase. ;-) Are you still awake now?

-- Pat

Dominic, Samsruti -- Thanks! Let's just continue using this pull request for the code review.

Yes I am awake .

Joseph -- Want to set up a time on IRC to go over this?  Probably best when Fran is available too.  What timezone are you in?  Fran is in UTC, I'm in UTC-8 but can arrange to be online whenever.

Pat -- That would probably be the best idea. I'm in UTC-6, but I can also arrange a time to be online whenever.

Ok!  I'm online now and should be for the next 5 hours or so, but Fran is asleep.  I'll be back online at maybe 1pm your time tomorrow, and will be online for about 3 hours after that.

Alright. I'm currently away from my computer right now, but I'll be on tomorrow. 

Hi @flavour ,

Just wanted to bump this pull request in case it got lost.  I know you get thousands of email a day!!

Thanks,
-Jason

I'm back, but it's too late for tonight. Let's watch for Fran to appear online tomorrow...unless Fran would like to make an appointment? There are some things we can do before that, though, such as have a look at where the old code generates the bad URL.

@flavour Please review it

@flavour Please review it again.

What's the point with adding a static HTML file to the theme whilst the ticket is about a dynamic widget that is used in many different, dynamically generated forms?

Sir by mistake i save that html file in Phillipines themes but it has to in default theme.
In that html file i jst added a <script>.........</script> , for the mechanism of dropdown menu .

The actual pages where the problem occurs are dynamically generated - adding static HTML files won't have any effect on this. You need to apply this fix in a generic way.

Also, the location selector is used in various forms - not just the office page.

It is also difficult to see where exactly you added the <script> tags.

I actually added the

inside the <head>and </head>
![asf](https://f.cloud.github.com/assets/6136117/1800299/468ba92c-6bc1-11e3-8755-3855f6f2fb7d.PNG)

But you can add anywhere. I

Well, I understand that this may be the cause of the bug - but in order to fix it, you need to find out where this JavaScript fragment gets inserted into the pages and add the script-tags there.

Modifying the static image of a dynamically generated HTML page doesn't make any sense whatsoever.

Didnt get you sir. Can you please be breif ?

Ok - let me put it that way:

What you're doing here is to add a static image of an otherwise dynamically generated HTML page to the respective theme. But since the actual page is still dynamically generated, this doesn't make any sense.

And neither do I think that this is the cause of the problem. The script you're talking about here does not exist - it is part of the location selector widget script, and is thus not added into the HTML at any time.

The actual cause of the problem is the missing size of the expand-icon in widget.css (whilst the expanded-icon has it, so you see the triangle to collapse, but then don't see the triangle to expand again). This is really very easy to fix.

See:
https://github.com/nursix/eden/commit/1b98d3f98f9bb4f7cbc4b9bc8869672bd7fdc83a

The expand-icon had size zero, so you could neither see nor click it. It was there, the script worked perfectly - but it was invisible.

By contrast, the expanded-icon (the one to collapse the widget) has a size of 16x16 pixels, so it is both visible and clickable.

Interestingly, the ticket already had the patch attached - it just got never applied (no idea why).

I think we can close this - there is apparently more effort going on to review it over and over and attach new screenshots than it would take to fix it. Weird.

Now I applied the patch that was already there, hence will close the ticket.

Can you tell me sir , whether my work is good or bad.

No - I can't tell you whether your work is good or bad :D I can only check it for validity in regard of the ticket.

And what I already said is that there was already a valid patch for this ticket, which just had not been applied yet. 

So all that needed doing is to apply this patch and close the ticket - which I did now, though, so you can close this pull request. Thanks, however.

Can you please my task complete by merging the pull request .

No - the issue has already been fixed in another branch.

Apart from that I can't merge this pull request as I'm not the branch owner.

Okay thank you.

Ouch - this "broken link" was actually only the tip of the iceberg. 

The full story is fixed here: https://github.com/nursix/eden/commit/1ea59f4599a99b73ab0d943305c682c4f44cf287

Filter means the vars parameter to URL(), I believe.  That is the "query" part of an URL -- the part that looks like ?a=1&b=2.  The vars parameter is a dict, so is {key:value,...}.  The args parameter specifies the "path" part of the URL -- the part after the hostname that looks like /x/y/z.

A single-record method means a controller method that acts on a single record.  "read" and "update" are examples.  The record id is the first element in args, and the method goes after it.

Your code apparently just changed, so I can't see it any longer.  Will have to post this so I can refresh the page.

Please Review my bug.

Hi Nostraa, even though this task/ticket is for the front page. What is your thought on increasing the small font-size for the overall template? That small font is on most of the pages and is hard to read.

Also what do you think of this Fran(flavour)?

Please squash all commits into one, so that it can be reviewed.

Also - don't change dynamic elements in the view template into static contents or add static HTML files. Make use of datalists to compose the view, and s3_trunk8 to collapse multi-line elements. Format field labels and contents differently.

You should not minify JS or CSS (this is done by the trunk maintainer anyway).

@flavour  Please review this..

Works (almost -- see below)!  I like that it opens a new window for this, as it demonstrates another option for opening map links, besides a custom represent or summary in a popup.

I wonder if the choice between popup with summary, and opening in a new window, could be made by passing an option from the server, e.g. something set per layer, so that we could have other layer's info open in a new page.

Ok, here's the "almost":  If there is a group of events with one marker, clicking it shows a popup with a list of links.  Clicking one of those launches the earthquake page properly, but back on the map page, one gets this (up to the event id) in the location bar:

javascript:S3.gis.loadClusterPopup("default_map", "http://earthquake.usgs.gov/earthquakes/eventpage/usc000lqwn", "-599bf5be")

and the page shows only the word "false".  I'm going to guess this is something to do with closing popups (?) but I have not looked into it.

Can some one review my work .

I think i squash all the commits into one
Whether the problem is fixed or not ?

Hi Dominic,
   I did indeed test this, but I might not have hit the error spots that you have seen. Is there anywhere specifically you would like me to double check?
-CShah

No, you can not have tested it. Otherwise you would have run into a name error right away.

Fixed a tabbing issue. Could you tell me how to reproduce this name error - this way i can go back and fix it once and for all.

Hi nursix, is the problem with this code that around eden, it is still calling hrm_training_event_represent when it doesn't exist anymore? Do you need to add something like

```
hrm_training_event_represent = hrm_training_eventRepresent()
```

This is the first fundamental mistake, yes.

But then you also access non-existent variables in **call** - and apart from that, overwriting **call** is wrong in itself. Doing so, you're disabling the functionality of the superclass - so then there's no point in subclassing at all.

Sorry, but that is not how it works.

Ah, I understand the mistake now. I was using some previous code refactoring from anurag as my role model... I'll rework this. Thanks for the help!
-CShah

@nursix what is your opinion on doing a mass search and replace in the eden folder and changing the function name?

I think you should star by implementing a functional represent-class before trying to replace anything.

Else I don't think it's used in many places.

I grep'd the whole eden repository... hrm_training_event_represent is only used once - in the definition of the function... Could you tell me its purpose.. If we could talk on IRC, that would help.
Thanks!
-CShah

Confirmed. I searched the whole eden directory too. This function is never used. I assume there is no need for this then:

```
hrm_training_event_represent = hrm_training_eventRepresent()
```

Since, whenever you want to call it, you will use the new name anyways.

Are you going to implement something meaningful here? Otherwise please close this pull request.

@chaityabshah: The purpose of this function is to represent values of the foreign key "training_event_id" in e.g. hrm_training. It is not used there in the default template, but the purpose of the foreign key is explained there in a comment, and for that purpose you need this represent function.

To replace the existing represent function by an S3Represent class aims at the ability to represent values in-bulk, i.e. multiple values with a single call, thus allowing optimized DB queries. These optimized DB queries are implemented by the S3Represent base class - but where you need additional data (e.g. from joined table, like in this case), you need to extend the base class and override the standard functions lookup_rows() and represent_row().

Lookup_rows is the function to extract rows (instance rows for foreign key values), while represent_row is the function to represent a single row. Consequently, represent_row should never perform any additional DB lookups - all that should happen (in an optimized manner) within lookup_rows.

Before you submit a pull request, you should make sure that the code you implemented does what it is supposed to do - usually by testing it. S3Represent subclasses can easily be tested by calling them from the CLI, either calling the instance directly with a single value, or the .bulk() function of the instance with a list of values. These should return the correct representations for the respective value(s).

Apart from that, lookup_rows should count the queries it performs in self.queries. Doing that, you can unit-test whether the bulk lookup does indeed only perform the intended number of queries. Furthermore, S3Represent does not construct a value representation twice. Even that can be tested.

If you don't have a current use-case for your class, then the best way to prove it works is to create a test case using the Python unittest framework. That way, you can easily repeat the test without having to re-type all the CLI commands over and over again. You don't need to add the unit test to the repo, I just recommend this as a means to develop.

Pull requests mean you wish your code to get merged into trunk, hence code reviews in pull requests are to make sure the code follows the guidelines and integrates with framework concepts and does not break other use-cases, it is not to evaluate whether your code works - that is genuinely your responsibility. 

If you just want to discuss a design, please do so on either the mailing list or on IRC, and use pastebin tools or story branches in your repository to share your code.

And one more tip: it is common practice in software development to understand the use-case(s) of a particular function before starting to work on it. Changing code without knowing what it does is...ahem...I don't know how to express this in a polite way.

Yeah, sorry about my rush before, I thought (naïvely) that after simply testing it in eden... it was done. Thank you for your advice. The explanation is helping greatly. I'll commit the code when i'm sure its done. Thanks again!
-CShah

Whoops, thought I tested that.

It was actually how I was exiting out from the loadClusterPopup method. I was doing a "return false" when I should have been just doing a simple "return". Just from playing around with it a bit, it seems like you can "pass" anything back, like html.

Ok, works now in both cases! I vote we accept the task, and then we can decide on the pull request at leisure, i.e. is it ok to have the special case in s3.gis.js for now? or do we want a general solution that allows specifying popup vs. go to the url in a new page?  The special case isn't something that takes a lot of time -- just one string compare -- so IMO is worth having now, while puzzling over a possible general case.

Joseph -- hop online on irc sometime, and we'll go through the ritual of squashing and rebasing your commits.

@ptressel: the concept is that subclasses implement "lookup_rows", not "custom_lookup_rows" (that is unnecessary, "lookup_rows" is already custom). Which subclasses implement a "custom_lookup_rows"?

@ptressel: see pr_RoleRepresent about calling foreign S3Represents in lookup_rows in order to prevent row-by-row lookups later. Quite a minor tweak with a huge effect.

@flavour Please Review This..!!

@ptressel: since S3Represent stores representations, you can just call the bulk-method of the foreign represent you want to embed in your lookup_rows, and then call the same instance of the foreign represent with individual values in represent_row.

This fully facilitates the match-up, yet retains the separation of the two represents while at the same time preventing row-by-row lookups.

It is not useful to create multi-table joins - they tend to be slower at scale than multiple separate queries, especially when some of the lookup tables have relatively fewer records (the threshold is as low as 30x!). Query passing is also more complicated, and would have to be implemented in every subclass - not ideal for maintenance.

Threshold 30 means: if one of the tables in the join has ~30x fewer records than another (e.g. 100 orgs vs. 3,000 volunteers), then a separate query to extract the data from the smaller table is faster than a left join even with a single field. This is even more significant when not all records in the smaller table are referenced by the bigger table.

We had an example of 60,000 volunteers vs. 20 orgs, where only 8 of the orgs were actually referenced. With a separate query for the orgs, we extracted 8 org names, whereas in a left join, we extracted 60,000 org names.

...whilst the overheads of a separate query are only about 30x the effort of extracting an additional field (see benchmark tests). The exact threshold of course depends on the hardware, the underlying DBMS, Python implementation, module versions etc etc. - but we are very often far beyond these numbers, in lookup tables typically several thousand times.

Dominic, nevermind about custom_lookup_rows -- had another look and they're setting self.lookup_rows under a conditional, so they don't always define it. Here are examples:
org_OrganisationRepresent
org_SiteRepresent

Dominic -- Ok, thanks for all the explanations! I'll have to go look at the "matching up" part. ;-)

Anurag (et al.) -- We still need to find a way to get your code actually called. All I can find is places where the __init__ gets called, but not represent_row. It's not even being used by lists of inv_track_item.  If it's just not being used anywhere, then you may need a test that calls it.

A bit unorthodox method - make an error intentionally in the code and see whether an error comes up or not . 
Hope it works.

Represent_row is called from the lookup-method of the base-class. Subclasses just implement it.

None of the custom methods in subclasses need to be called explicitly (should not, to be more explicit).

Note that represent_row gets only called when needed (lazy method) - so the deliberate-error-method may be misleading.

Subclassing S3Represent is only needed if you need alternate represent_row and/or lookup_rows methods, otherwise the base-class should be used. In most cases, you do not need to subclass. And if you subclass, you should still retain the base-class' general mechanisms, i.e. really only implement the alternate low-level method mentioned above, not alter the whole thing.

Hey Dominic is this code fine ? Just asking .

There are a few bugs in it, which you can though easily find yourself by testing (you really should test it).

Also, try to follow the coding guidelines about whitespace use - it seems you omitted a few too much.

Not sure you really need two different instances of the class - but this isn't as critical.

Rebase Link: http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#RebasingafterpushingtoGitHub

@flavour Please Review This..!!

Wow. I think you replaced all id's to a class. That's not what to do. It was only those 2 you had to change, because you changed them to # when they were originally .'s

Err - I already said: you've got to test your code before you submit it for review.

Note that the extra indentation in CSS is not necessary - 2 blanks is quite enough.

I had tested my code, its running according to the ticket. The only thing is not working the truncate , which is not necessary for now.
Is anything wrong with my code ?

Pat - I think I was able to do it per these instructions. (http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git)
I'll be on IRC tomorrow in case it's not.

Dominic i have done some changes .

It looks like it worked.  You can re-open this and the new commit should be included here, in place of the old one (I believe).

Yep, That's the new one. Awesome.

It shows rather odd behavior when the text is getting longer (suddenly moving the right hand boxes below the list since width is not limited), and the italic font is harder to read. Labels should have a distinctive look (currently look the same as values).

I don't think this solves the issue appropriately.

In this case, you have submitted the wrong commit for review.

Not in this pull request: https://github.com/flavour/eden/pull/694/files

I have downloaded and tested this ^ and it does not work as you say.

Well, of course you need to submit /all/ modifications in the pull request - that modified HTML is missing from the pull request and can thus not be reviewed or merged.

@flavour Please review this

This looks like working now.

Suggestions for further improvement:
1) use standard datalist (instead of custom method) to generate the list of latest projects
2) render labels more distinctive (e.g. bold), (left-)align values (easier to read)
3) use s3_trunk8() rather than overflow=hidden and text-overflow=ellipsis (so one can expand the truncated text)

Can now it be merge ?  I can improve it later as so far i hav to compete in the GCI . So they require it to be merged . 

The GCI mentors are to decide whether or when this is sufficient for your task.

I'm reviewing this primarily in order to give you feedback on code quality - and from this perspective, it seems to be working now and not breaking anything, hence it is /safe/ to merge into trunk. It won't be merged now while the trunk maintainer is on holiday - and there's no urgency with it.

As for the Trac ticket, your changes provide some minor improvement. However, I don't see the ticket resolved yet: in particular, I'm not convinced of the truncated text without option to expand, and that the field labels and values still look alike.

As for the solution architecture, I think that the custom rendering method in private/templates/DRRPP/controllers.py should be replaced by a standard data list - but /that/ is certainly beyond both the ticket and your GCI task. However, it would make the difference between sufficient and good.

Hey Samsruti. I'd say in order to close this ticket you'd have to make sure the visibility issues are resolved (with bonus points for applying the "standard data list" change Dominic mentioned). 
To me, your solution has 2 main problems: 
- It still does not make any distinction between "labels" and "data"
- It looks pretty misplaced (completely different and very obstrusive font). I'd suggest using the theme's default font with a greater line-height and size or atleast a less obstrusive font.

However, I would not mind that much about cut-off text. If a user is interested in any of those projects, (s)he could still click on it (as Pat already mentioned in the comments of the ticket). If you want to add truncation using s3_trunk8 that would earn you additional bonus points, but to me it's out of the ticket's scope.

Tested and works but a something that I noticed: 

English has many "dialects" such as en_AU, en_GB, en_US -- (Americans don't speak the same English that British people do and similarly Australians seem to have their own version though likely closely related to British English) -- why have you removed those? It should not be just "en" -- too ambiguous...which dialect is this? Not sure if this is going to hold back the merge but I do think it's important to leave those...they're not "extra" -- they're agreed upon convention.

Please see comment posted here:
http://eden.sahanafoundation.org/ticket/1369#comment:7
The ticket was changed some 3 weeks ago, and the change has rendered it somewhat ambiguous. The changed version asks that there be two separate lists of languages, one for languages in the data, and one for the languages in which the UI is provided.  The current pull request addresses an earlier version of the ticket, that merely complained that only English and Spanish were listed as languages for location names.  Adding more languages there might break the main menu, if people want to have location names (or maybe other data) for which there was no UI translation.  I recall chatting with someone online about this, and saying that this ticket required a new setting, for a second list of languages.  I'd recommend adding another setting, and having a list for the UI / menu languages, and another for what can go in the data.

I agree with the comments here and the implied conclusion:  This does what the GCI task asks, so we can accept that.  This is certainly safe to merge into trunk, but there are some ways to improve it, that would also be good Eden training.  So l'll close the task, and Fran can merge it as-is if he wants.  Then when Samsruti has time, he can improve this with the above recommendations.

As a side note: the "list of latest projects" does not seem to show the "latest" projects - neither ordered by their start date (which is often missing) nor the date of their registration (which is always given, but mostly unrelated to the project's time frame). It just shows 3 arbitrary projects.

The ticket is certainly aiming at improving the user experience with the index page, but I wonder what that is worth if it so obviously ignores the functionality and usability of the feature. 

How would the user decide whether one of those latest projects is interesting to open and find out more? In most cases, that is based on the country - i.e. whether the user's country of interest (e.g. home country) is among the project's countries - followed by the organisation. 

By contrast, detailed descriptions are rarely available in the production database, so this seems fairly irrelevant.

Thus, cutting off countries (the countries list is usually long) without option to expand them forces the user much more often to open project pages just to decide whether it is actually interesting to open it (i.e. whether the country of interest is among the project's countries) - hence we're introducing a reduced usability of the front-page feature in favor of a better look?

I'm rather concerned that we're making too much a science of stylistic details while ignoring the user's needs, eventually forcing them into cumbersome patterns which look pretty, but are harder to use. Apart from that, it seems that in this particular case the feature doesn't even work as intended, rendering it completely useless.

I think, our self-proclaimed UX experts are completely missing the point here ;)

Btw - see http://www.drrprojects.net for the production site.

A very useful improvement - in view of usability of the feature - would be to alpha-sort the countries list, so that it is easier to see whether a certain country is listed or not. Fonts are fairly secondary to that ;)

graemef , i think what ptressel has also warned about this change , is it possible that this checking starts before eden has been created ? Just curiosity , but if it does then i think we should report a new defect or maybe fix it.

Anurag's comment was for the edenstart pull request, so we should reply over there...

Hm, what about making sure that the user's current country is always the first one listed (for logged-in users this should be easy and for not logged-in users we could still find out the country via IP lookup)?

BTW: Since the font (Exo) looks quite broken at small sizes I'd suggest updating it to Exo-2 (http://www.google.com/fonts/specimen/Exo+2). I'll send in a seperate pull-request if that's okay.

Thank you Ptressel Mam for approving my task . Yes of course , I will try to make the changes as per the Nostraa and Nursix . I am not doing task particularly for GCI but also to help Sahana .
:D

Here is a resize option(see if the freezing problem occurs to you like it did to me):

```
onResize = function() {
   if (( $("#menu_modules").height() + $("#menu_options").height() + 10) < $(window).height()) {
     $(".aside").css("position","fixed");
   } else {
     $(".aside").css("position","absolute");
   }
}

$(document).ready(onResize);

$(window).bind('resize', onResize);
```

New pull: https://github.com/flavour/eden/pull/697

We're just chatting in IRC.  CShah is going to add another setting value in modules/s3cfg.py.  So there will be one setting value for the UI / menu list, and another for the "languages in the data / local names" list.  Doesn't matter which one gets a new name, and which keeps the old name.  For the current task, only the locations need to use the "languages in the data / local names" list, but it would be good to search for uses of the current list (e.g. grep -i "l10n.*languages" to find all of l10n.languages, l10n_languages, get_L10n_languages) and see which ones are really UI / menu languages, and which ones refer to data.

Why not unify the settings? Or would that not work?

Just chatting with CShah and Daniel. We want to be sure there is no change in behavior for existing sites or existing templates, if the site does not override the defaults, or only specifies settings.L10n.languages. Here's the change to do that: Instead of defining a separate default in get_L10n_data_languages, have get_L10n_data_languages call get_L10n_languages for its default case.

Ok, looks good. Will accept the task. Fran can have a look when he's back from vacation.

Note we encountered several issues (in other code) while looking at this.  (After updating to the latest trunk revision, the main menu bar buttons were broken, but clearing the browser's cache _and_ restarting the browser got rid of the issue.  Attempted to do gis/location/create -- poking the map no longer seems to load lat lon, at least not visibly.)

Dominic can you please see this pull request .

Dominic i have done the changes.

Updated the code . 

Dominic i have change those -  https://github.com/flavour/eden/pull/696/files#diff-6fcb3119ec58fe524a5a62e4ac618956R40

Sorry for delay in replying...am on holiday ;)
A couple of comments inline to fix & then ready to merge :)

Hey @flavour !

Good to see you again!  

Hope you and your loved ones had a Merry Christmas and a Happy New Year!

I'll get to work on these redlines right away.

Hi @flavour ,

Redlines have all been implemented and tested.  Please let me know if it looks ok.

Thanks!
-Jason

@flavour Please Review This.

@samsruti : it is not necessary to say "please review this" - if you send a pull request, review will happen automatically.

Furthermore - I can't see what you are fixing here. The ticket has been reviewed and found obsolete, so why does this need a fix?

Where it is fixed, in the ticket it is not marked as fixed.

It has been reviewed and found obsolete, i.e. the problem doesn't occur anymore and hence doesn't need fixing.

So - what are you fixing here?

The slidebar is not working so i fixed that one

I'm not sure I understand what you mean by "not working"? If you think there is still a bug, then please describe it in more detail - I can't find any of the issues described in the ticket still applying.

I can see that you've made a lot of changes which don't seem to have any effect whatsoever - it would be good to reduce this to those changes which actually change something (much easier to review).

Please explain what exactly you've fixed - and how. I can neither see the problem nor the solution here.

When you make the web browser screen small in Urdu language , the content box "Administration" is not completly displaying. Have a look at this link : http://demo.eden.sahanafoundation.org/eden/admin/index?_language=ur and the content are aligned right. 

Of course the contents are right-aligned in a right-to-left language - that is intended.

However:
- the side menu is on the left (wrong in RTL, should be on the right)
- the contents DIV scrolls to the left but overflows to the right (while should overflow to the left in RTL)

I don't see that these two issues are fixed by your commit, though - nor that they are mentioned in the ticket.

The fact that the contents DIV overflows to the right but scrolls to the left leaves the overflow inaccessible - and this /maybe/ what the original ticket relates to (without mentioning it, though).

But as I say: your commit doesn't fix that.

Note that the footer shows correct behavior: it both overflows and scrolls to the left. But it is the only DIV that works properly - why?

Note: this is relatively easy to fix. You need to reverse the alignment for RTL for .col1, .col2 and .col3 as well as for .aside and the .fright and .fleft classes in the top menu. All in all ~6-8 additional CSS rules for body.rtl.

This is how it should look like (browser wide):

![urdu1](https://f.cloud.github.com/assets/1257183/1849687/e3cb3b0e-76ba-11e3-8cd5-581c83ebd160.png)

That way, the contents DIV overflows to the left when you make the browser small:

![urdu2](https://f.cloud.github.com/assets/1257183/1849698/0d8223ae-76bb-11e3-99d4-15ac77b6b716.png)

I created you a new ticket: http://eden.sahanafoundation.org/ticket/1504 including a suggestion for a solution. Good luck!

I don't know - I will check it out.

I think  right alignment is not looking appropriate. 

Then you may be mistaken. 

In right-to-left scripts, it has to be right-aligned and overflow to the left - that's just correct. See my screenshots above.

But its looks improper.

Shall we continue with this stupid discussion?

Again: right-alignment is just as correct for right-to-left scripts as left-alignment for left-to-right scripts. 

Compare: http://www.bbc.co.uk/urdu (right-to-left) vs. http://www.bbc.co.uk/news (left-to-right)

If you refuse or are unable to understand this, then this may not be the right task for you. In any case, repeating your "but it looks improper" is not helpful - it's just a waste of time. Either you understand it - or you leave it.

ok.. Sir, i will do this for you. :D

Err - no, not for me. You do it for the people using right-to-left scripts.

Ok sir.

This Pull Request modifies the whole file (probably due to line endings), which makes reviewing harder.
I also see 3 commits instead of 1 - please rebase/compress as well as resolving the line endings

This seems quite clever & useful - I'll merge & cleanup :)

@flavour Okay, thanks!. Initially I had it like this:

```
...
```

Then, Nostraa suggested we do not need onResize in the global scope, so he told me to make it like this:

```
(function {...})();
```

So, you need to use 'var' for it not to go into the global scope?

> So, you need to use 'var' for it not to go into the global scope?

Yes

Thanks, Sorry for the delay!

Alright, working on it. Thanks for the comments :)

Still working on making it a development_setting. Will get to it when i return from a conference this weekend.

Sir, without changing the .fleft the Urdu page will not look like as given in above mentioned pictures.

Hey Fran i have done the style changes

I thought I had other comments too, but I don't see them now, of course :/
I think 1 was around the 2nd part being the 2nd phase of the import?

Some style issues remain as well

Oh yes , that "wait" ,  I just forgot about that sorry going to add it 

This functionality is now in trunk

This was proposed almost 1 year ago

On Wednesday, January 22, 2014, Fran Boon notifications@github.com wrote:

> This functionality is now in trunk
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/481#issuecomment-33006234
> .

## 

Regards
_Mayank Bhola_

Thanks for this effort :)
The main issue with it is that it doesn't understand how Super Entities work, which is a common mistake.
Would be great if you could review the docs for these & see how they could be improved to help avoid people making the same mistakes:
http://eden.sahanafoundation.org/wiki/S3/S3Model/SuperEntities

Other than that, the layer enable/disable seem much better within a GIS module.

There are also the usual sprinkling of formatting issues, e.g. PEP8:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/CodeConventions

I'd had a look at the wiki page about Super Entities prior to committing; and I found it a bit hard to understand. 
I suppose it'd be easier to understand the topic if there were some real-time examples in the wiki page. 

Examples can be found in the code - it isn't so useful (for maintenance reasons) to repeat code on the wiki.

A fantastic example is modules/s3db/doc.py

Apart from that, the wiki page /does/ provide some examples, which do indeed really exist ;)

Seems Good :)

flavour, I've made changes as you'd asked and have added the commit.

There are 2 commits here which should be rebased/compressed together as 1
I've not yet looked at the code, but I echo Dominic's comment that a select after update_super() isn't required to retrieve the layer_id - this can be collected from the 'record' variable

I am working through this merge, but need to do a lot of testing before I can complete push back

@flavour Did you want me to make changes based on your feedback? Or wait?

wait...I hoped that was clear from what I said: "I am mid-merge"

Thanks, looks good.

I'm currently trying to salvage this module for a specific case - is there any particular interest you have in this module, so that we should coordinate our efforts to not end up with conflicting changes?

@flavour: can you merge?

This looks about right - I think it can be merged (@flavour ?)

Be careful though when hunting down @todos - many of them may be obsolete or irrelevant (in fact, many of them are just ideas), probably better to check with us (=mailing list, IRC) first.

Can this be rebased/compressed?
- perhaps as 2 commits (instead of the current 5) as I see 2 very different things being worked on & I might wish to cherry-pick just one (I confess to not understanding the point of the original pull request yet, but then I've not put time into studying it in too much detail yet)

3 things were being worked on:
1) http://eden.sahanafoundation.org/ticket/1513
2) https://github.com/flavour/eden/blob/master/modules/s3db/hrm.py#L3755 (ToDo)
3) http://eden.sahanafoundation.org/ticket/1514
each in a separate commit

Thankyou - the new one is a lot clearer :)
I need to make time to review it...today being Valentine's isn't a good day ;)
(Have spent most of it cooking as well as my usual running around taxiing everyone ;))

Looks great - impressive stuff, many thanks :)

Very nice - thanks :)

Great, have been expecting s3_debug to migrate to something like this. Can the s3_debug() wrapper call be maintained but have that just make use of s3.log internally?

We should also migrate the individual module Debugs

if s3_debug calls current.log, then would loose the caller info, so it would be better to replace s3_debug("message") with current.log.debug("message")

ok to add migrations to this pull request?

This seems to be 100% backwards-compatible, right?
i.e. defaults to just console & supports both caller & message? (All appears so but I've not tested it)
If so, please proceed with migrating calls - thanks!

yes, call signature is backwards-compatible, the log file is optional although more useful on remote servers

could add request url and/or user id to log messages if that helps

can wait with migrations if you want to test first and send a new pull request later?

No, no proceed as-is :)
Adding request URL/User ID can come later...

I like your choices of error vs warning vs info - sweet :)

thanks, good night

@flavour : I have updated it to assign permissions to Anonymous and using a table based security policy. Please see

+1 fine by me, go ahead.

The current.ERROR idea is compelling. Well done.

+1 from me too to deprecate s3mgr/current.manager - I have taken steps in that direction already
(Haven't reviewed the commit yet)

don't merge yet just saw a mistake i made

What a stunt!

It looks ok to me, but of course requires testing. I'd recommend you run the unit tests like:
  python web2py.py -S eden -M -R applications/eden/modules/unit_tests/suite.py
...after running a fresh prepop (use default template to run all tests).

I assume you already tested CRUD functions manually. (you did, didn't you?)

Once tested, I think it can be merged. Many thanks - tough agenda you have.

i have been running these unit tests all the time, it would have been insane to make all these changes without unit tests - just ran them again and all pass

Ran 296 tests in 30.924s

OK (skipped=2)

ptressel pointed me to the selenium tests but so far i couldn't get those to run at all, i followed http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Testing/Selenium but no luck - as it says, the tests won't work with ffox 17 or above while i have 26.0, so switching to chrome driver now.

it wasn't fully clear which tests it had to pass before sending a pull request sorry. hang on

ok that was sobering

Sahana Eden
Start Time: 2014-02-20 09:50:59
Duration: 0:21:54.208264
Status: Pass 11 Failure 3 Error 52
Template: IFRC

thanks for the pointer, will look into these

Nah - if it passes all unit tests then it's good to merge.
The selenium tests don't currently match the specifications, they test a lot of stuff that has been superseded. Feel free to update them, but don't bother verifying this PR with the current selenium tests.

But hey - how did you get it working so fast? I've tried a couple of times and always gave up after hours of wrestling with webdriver exceptions. Still can't get the webdriver to do what it is supposed to do.

hello nursix
sorry i spent the last days debugging the selenium tests but i could not figure out how to fix them so instead i started to encode some simple robot tests which i can use at home without spending most of the time debugging test code see https://github.com/nerdis/edentest

these tests are very easy to write and maintain e.g. https://github.com/nerdis/edentest/blob/master/tests/org/org_organisation.txt - but of course now i need to understand what needs to be tested

is there a list of mandatory tests that code must pass before submitting pull requests?

No, there is no such list.

Generally, you can assume that any test worked by the time it was published, 
and that is was created with the idea that any subsequent code version should 
pass it as well - so if you wonder, then it is simply /all/ existing tests. 

However, we have not been able to maintain the tests as much and keep them in 
sync with development, primarily due to a lack of resources.

I've been constantly maintaining the unit tests, and keeping them in sync with 
trunk - so for this part I can state that they are up-to-date and can be used. 
The test coverage is low, however, so that they won't catch everything - but 
at least the most critical parts are covered.

What you have there looks cool - just tried it out and it worked fine. Maybe I 
can help you there with some test cases? Looks simple enough :)

However, note that the Eden Selenium tests are meant to be run on the 
community CI server, therefore fixing them has higher priority. If you like to 
join the salvaging efforts then that would be much appreciated.

söndagen den 23 februari 2014 03.00.05 skrev  redsin:

> hello nursix
> sorry i spent the last days debugging the selenium tests but i could not
> figure out how to fix them so instead i started to encode some simple robot
> tests which i can use at home without spending most of the time debugging
> test code see https://github.com/nerdis/edentest
> 
> these tests are very easy to write and maintain e.g.
> https://github.com/nerdis/edentest/blob/master/tests/org/org_organisation.t
> xt - but of course now i need to understand what needs to be tested
> 
> is there a list of mandatory tests that code must pass before submitting
> pull requests?
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/723#issuecomment-35829011

Looks good, thanks - I'll fixup the minor issues post-merge :)

Looks good other than the inline comments...looking forward to a fix/rebase & then I can merge :)

trying again

better now?

thanks :)

thank you
the nested bulks is the best possible compromise between performance and maintainability so one can change org_OrganisationRepresent and it will automatically propagate into inv_InvItemRepresent yet it will never perform more than two queries - i copied this from concept from pr_RoleRepresent

agreed? or shall i change into a local join?

I'm happy with what's here :)

Thanks :)

F

Thanks :)

@flavour  please review :)

@flavour did a retest its working fine. It does go into try block. Please review.

@flavour : Rebased and updated the commit. Please review.

As Dominic said, models should never return None but a dict(), and must define what declared in "names" for integrity reasons.
The availability of id fields in case of disabled modules is ensured by safe defaults, added one in cms.

That is correct - an S3Model subclass, if enabled, must deliver on all names it declares, otherwise second-line references can run into errors which are difficult to debug. The resolution of cross-module dependencies should always happen in the disabled module (using the defaults-function), not in the dependend modules.

Reason is that if the dependend module does not deliver, all name references to that module would also need to be checked, which is much harder because the dependend module is actually enabled and hence expected to deliver what it promises. And if such second-line references need a check, then third-line references would also need one, and so forth...and there is no reliable mechanism to enforce that, so that it easily becomes a rich source of trouble. Hence - dependencies must be resolved at their origin.

The return value of the model-function should always be a dict (None-values are currently caught, but this should not excuse such inconsistencies).

A model that can be disabled should define a defaults() function that returns safe defaults for all non-table names is exposes. This is a "should" because some of the names may only be used inside the same module and hence not required if the module is disabled. Mandatory models do not need to define a defaults() function.

Controllers, by contrast, can either return an error if a module they depend on has been disabled, or alter their behavior accordingly.

I disagree with this rule being strict.
In this case these are simple link tables that have no value if the module they link to is disabled.
Sure safe defaults can prevent a crash & adding one to cms is useful, but the event link tables shouldn't clutter up the DB if they're not needed.
Sure the system may not be significantly affected by spurious tables, but it makes it harder for humans to scan through the long list of databases & can make data migrations harder with extra spurious tables to clean up manually.

Sorry, but there is no reasonable compromise here.

If a model declares a name, but doesn't deliver it, then this will lead to an exception - and these exceptions are not caught.

And your concern about "clutter" isn't right - if the table is never accessed, it will never be created in the database even if you call the model. That is a consequence of web2py's lazy table model: tables are only created when you access them - a mere define_table doesn't do anything.

This rule must be strict for integrity reasons, so I would insist.

I see the tables listed in appadmin & they appear in databases/*.table so the clutter is there even if there is no entry in 'show tables' or whatever the native equivalent is...
I've personally never seen a table in .table which wasn't also in the actual DB even where it had no data, so I'm suspicious about this never getting created by the load_all_models()

Even if, not delivering on a declared name is still not correct.

If you want this to be allowed, then all s3db.<tablename> must be put into a try/except.

One way or the other.

Could it be that we're running DAL() without lazy_tables = True?

A try/except doesn't seem onerous if this allows a more meaningful error, which is apparently your concern, right? (error hard to debug)

lazy_tables seems to be a new feature which defaults to False....so correct that we're not using this yet. (I'd never heard of this feature before). Sounds like it could be a useful optimisation...especially for Classes which define many tables....wonder why it's not enabled by default?

Yeah - that is the problem here. 

lazy_tables = True should be enabled. It's not new, it's almost a year old, and I was certain that I had enabled it (since I catch it in S3Model.table).

Let me figure this out

I see you're saying that the try/except should be in the call to s3db...that would be ugly indeed (I had thought inside s3db).
Honestly, how many times have we had hard to debug issues from these link tables being accessed when their module is disabled?
The one case I know of is when Michael had stats disabled & wanted to use org_resource...which isn't a link table.

To me '1 year old' in web2py means 'new' as we're not tracking features closely ;)
I see your checks for it in S3Model, but it's not in our instantiation in 00_db.py yet
Very happy to try enablign it...would be good to know what we'd need to test: I guess all 3 supported DBs with the Unit Test suite should be a sufficient initial test?

lazy_tables was introduced in 2012.

I see why it hasn't been enabled, though :/ and it can't be enabled, sorry. 

Anyway - still not correct.

Either we put /all/ s3db.tablename in try/excepts - or we rely on that a model delivers the names it declares. Allowing convenience patterns at the one end requires strict rules at the other - can't be lazy at both ends.

lazy_tables can not be enabled because of the way we define them.

With lazy_tables, define_table returns None, and only db.tablename (or s3db.tablename, respectively) will then create the table.

However, we have so many places where we do:

```
table = define_table(...)
table.field.requires = ...
```

which doesn't work with lazy tables. So, enabling lazy_tables would require serious work.

I had that discussion with Massimo last year, and he strongly recommended that we switch to lazy_tables as it gives a _major_ performance gain. But I couldn't do this right away, because that means to get people to learn a new pattern.

If we can change our models to not use the return value of define_value, then we have a chance here. That prevents more than "clutter" in the database - it is rather a massive supplement of the lazy model loading.

Not impossible.

I can do that, if that "clutter" is your main concern - but then I would want insist on the strict rule that models must deliver what they declare.

Clutter is more of a concern to me than strictness, but I'm not sure what exactly you're saying you can do?
Move us to lazy_tables? If that provides a significant performance gain then it seems a good idea (although I suspect this is less significant for us since we already have lazy model loading).

What is the effort though? There aren't too many table.field.xx = in the core models...just a few although generally these are for good reasons & hence hard to modify....the bigger usage there is in reusable field definitions, but I think these would be easy to change.
Of course we have many example of this in the controllers and customise_ functions...but maybe we could have s3db apply these lazily to the db.table when-required?
Would be good to get some idea of the Cost & Benefit here...I'm happy to help with the Cost side if we have a good idea of both...

It generally means that we do not use the return-value of define_table or super_entity. 
That's basically all it is.

The hard part is to learn this pattern - not to rework the models (although that is a bit of an effort, too - but not too hard, I can do that in a day). The rule is simple: define_table and super_entity don't return anything.

Re-usable fields are easy to change (just replace table by "reference %s" % tablename), and field modifications inside models need to be moved in-line with define_table. 

Custom controllers can remain as they are - since they actually use the tables, and don't access the return value of define_table. 

Some tables defined in S3 modules need to modified (primarily S3AAA), although they can be made mandatory anyway. Not a big deal here.

The benefit would be less clutter, and (according to Massimo) a "massive performance boost". I can't really measure it without trying it ;) but I don't see why we shouldn't make this step.

Right, I said reusable fields would be easy...but the table.field which are not inline already are generally that way for good reasons so less trivial than you think.
e.g. table.field = Field.Lazy
e.g. adjusting meta_fields

Field.Lazy can be moved in-line.

Adjusting meta_fields - example?

2 different examples here:
https://github.com/flavour/eden/blob/master/modules/s3db/gis.py#L236

Just that? I think it's acceptable to make this particular case non-lazy (mandatory model anyway).

Else - longer term we can move these adjustments in the function call of s3_meta_fields

Note that for all cases where we don't have a trivial solution for the access to the table immediately after define_table, we can always do:

```
table = db[tablename]
```

immediately after define_table. That would make that particular table kinda non-lazy, sure - but then we do still have our lazy model loading ;)

For "clutter"-tables, we can though generally avoid this I think.

Goodness... sorry Claudio, I just realized that you get copied on the whole discussion as this is your pull request :S

Fran: can we agree to merge Claudio's proposal here (because it is the better solution integrity-wise), and I work towards lazy_tables a.s.a.p? I mean, eventually Claudio did the right thing, and I don't see why we should be stubborn about this.

I'm wary of mandatory models, but happy to have a few be non-lazy & just use the existing conditional loading...especially if we can move some later (e.g. the meta_fields call).
ok, I'll merge the PR

Hey don't worry, actually I'm happy to be notified about this discussion :)

adding a commit for ticket 1522 hope it's ok to add it to this pull request

Both commits look great - will merge when I get home :)
np having 2 issues resolved cleanly in separate commits - this is easy to review & if-necessary I can cherry-pick just 1 if the other still needs work...
Thanks for the birthday wishes :)

Hi Francesco,

It's great to see that you're ready to start merging the EVASS work back into trunk - thankyou :)
Unfortunately, it will need a bit more work before this can be done:
- This is currently 58 commits, which is impossible for me to review (I know that Dominic has been reviewing, which gives me confidence, but I still want to be able to understand too)
- This isn't automatically mergeable anyway due to conflicts

You should rebase/compress into a single commit (or perhaps 2-3 commits with each commit containing clearly separate patches...to maker the review easier & potentially cherry-pick 1-2 patches ahead of the rest)

In general I would urge to 'merge early, merge often' as there are a lot of things within this one PR which makes it hard to review - I'd personally much rather have a few more smaller PRs which can be merged more frequently.

This lacks some changes I made in 
https://github.com/nursix/eden/commit/36116de8557f87ee395476e2332d4b1f03e0adfb#diff-3

...which I would though recommend to include (this fixes a bug that is relevant in trunk).

@nursix thanks for the help. "r.record" worked like a charm. I have sent another pull request. See if it is alright.

I have not yet understood how your changes here are related to ticket 1234.

Can you explain what this intends to do?

@nursix when you open a created template, it doesn't show the incidents that you had previously selected. It neither highlights them nor shows them separately. Here i have created an extra field that stores the previously selected incident.

@nursix if i change the "incidents" field to "list:string" then incidents start showing in a weird format while searching templates.
![incidents](https://f.cloud.github.com/assets/3251587/2491898/8a80453c-b204-11e3-8e84-493411dba2f7.jpg). Any idea what might be the problem?

Hmm, doesn't make any sense to me - we want the values stored in the _incident_ field, not in a separate field.

However, the values _are_ stored - it's merely a representation problem.

Hang on a second, I'll send you some code so you see what I mean.

@nursix yes its a representation problem only. Values are still getting stored in the incident field. It is just to make it more intuitive.

This commit:

https://github.com/nursix/eden/commit/a67a4169450b23894a188c94741b2c0dad4b0c26#diff-59bf1eeed7c39491fc28b7a977ef8b0cR324

changes the field type into proper "list:string" (instead of "string"), so that the widget can handle it. I also fixed that for the other fields mentioned in the ticket.

I also changed the widget (to jQuery MultiSelect, which is more intuitive than the default options list), and the representation function (to S3Represent, to save repeated code).

Yeah, well - and a bunch of style cleanups, but these are not relevant for the ticket ;)

Can you see what I mean? No new field needed.

@nursix the problem of multiple field solved when i changed it "incidents" field to "list:string". But what to do with this new error which comes while searching for existing templates?

Which error? I don't get one here.

@nursix no error...see the image that i attached in an earlier message.

Ah yes :D you may want to try my fix ;)

![ss9](https://f.cloud.github.com/assets/1257183/2491922/799379cc-b206-11e3-9ece-2dff6ff14550.png)

That's how it looks like for me ^

Can you see why? ;)

@nursix no...i added a S3MultiSelect widget there but to no effect. :(

Did you remove list_string_represent? ;)

@nursix yes...my field looks like this right now

Field("incidents", "list:string",
    label = T("Incidents"),
    requires=IS_IN_SET(cap_incident_type_opts,
                       multiple=True),
    represent = S3Represent(options = cap_incident_type_opts,
                       multiple = True,
                    ),
    widget = S3MultiSelectWidget(filter = "auto"),
    ),

If you use this:

```
represent = S3Represent(options=cap_incident_type_opts, multiple=True)
```

...then it will deal with the list:string type correctly. An alternative would be:

```
represent = lambda v: ", ".join(cap_incident_type_opts.get(opt, UNKNOWN_OPT) for opt in v) if v else "-"
```

but that's ugly, of course.

Remember that your database is borked - save the form once with the new field configuration (to override the wrong field value), then check the table again.

I leave you to it...need to force myself away from the computer now ;) (weekend+family time)

Happy debugging!

@nursix yeah...ill debug it till it gets solved :)

@nursix Adding "S3Represent" did the trick. Please approve the pull request. :) 

Now the pull request got a bit messed up, probably missed a "rebase" at some point.

Now, as you may have noticed, I applied the changes already to my repo (when I gave you the hints earlier in this thread) - so you can basically just close the PR, let flavour merge from my repo, and then pull and rebase from trunk.

Still a good learning experience if you intend to continue working on this module ;)

@nursix...yeah sure!!! Should i close the ticket? And please do commit the changes asap as i won't be able to make any commits until i rebase my repo.

Anurag Sharma sent you an invitation

Twitter helps you stay connected with what's happening right now and with the people and organizations you care about.

```
Accept invitation
```

https://twitter.com/i/1626bb14-58fd-4a78-81e5-8ef20effe16b

## 

You can unsubscribe from receiving email notifications from Twitter at anytime. For general inquiries, please visit us at Twitter Support.
Unsubscribe: https://twitter.com/i/o?t=1&iid=4786b971f303467abca20a6d54d2f787&uid=0&c=IuVwbCB3dgHTmVT%2Fnh0myPW5kT4uIQsD8kyz%2BMXNgBwSPqLF4E3ZDub7fSqIi%2BcQq58nedIx4bCaE8yiEuQUWkSLuQD%2FHKKnfMreyjZHs4UXcIoEQ6XAmg%3D%3D&nid=9+26

Need help?
https://support.twitter.com

@flavour: Please wait for @nursix's review before merging

I couldn't see anything controversial, so merged...

Yeah - the idea with "wait for review" was a different one here ;) it was indeed meant for me to review first in order to give feedback. Misunderstanding :S

I guess you're right about the reason why this started breaking, but as you say an easy fix :)
Although you seem to have lost a few of the field settings in this fix, so they should be either in the Reusable field (if default) or in the instance (if not).
Also one Reusable field doesn't need declatring outside of class.

Actually I'll just fix these up - no need to rebase ;)

Thanks for sorting it out, those omissions were a bit careless of me.

On 29 March 2014 22:49, Fran Boon notifications@github.com wrote:

> Merged #744 https://github.com/flavour/eden/pull/744.
> 
> ## 
> 
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/744
> .

Merging, will cleanup minor issues & can be enhanced later with per-template optional_requirements.txt

Good to see you back :)
Hope you had fun? :)

@flavour please merge this. 

@flavour i fixed the problem of whitespaces as well as language inconsistency. Please merge this. Optimizing the entire javascript will take some time. Will do that soon. Exams going on.

@flavour please take a look at the latest PR

@flavour Take a look now. Made the suggested changes.

I did a cleanup of the issues I commented on which you didn't yet address & then took it further including creating a minified version of the JS for use in Production.
I think that a good next step would be to have a template which had the CAP module enabled & included some prepop Alert Templates?

@flavour yes. I will get on it in a day. Two exams tomorrow and one day after.

Be very wary about not importing all countries as even when a deployment is focussed in one country, they can have staff with other nationalities & work with organisations coming from other countries.I can see that you'd like a way to control this as there are odd usecases (i.e. the one you're currently focussed on) where this isn't required, but I think the default should still be all countries (for all templates other than this one)

I will merge & cleanup - remaining ones are easier to just do ;)
- the comms remains valid of course for future :)

@flavour Thank you very much for merging and fixing. I do appreciate the feedback, but multiple rounds of review do get a bit tedious!

I'll clean this up...merging

Thanks Claudio - this looks almost ready :)
However:
- I don't see the mentioned controllers/evr.py? (& presumably modules/s3db/evr.py)
- There are many duplicate files (& lines within files) copied wholesale from the default template
  I'd much prefer less of this & more DRY: copy across only what you're using/changing & leave everything else in default. You can refer to default files without issue. This makes maintenance a lot easier when we're doing codebase-wide updates.
  Looking forward to taking a look at this & trying it out :)
  Thanks!

You don't see evr because in this pull request I didn't include it. We though that merging our whole work in just one time (as proposed before) can be too tricky, so instead this pull request is limited to the new template, without any additions or modifications to the core system.
The rest of our work will be structured in a later pull request, in the meantime it would be awesome to work at least in part in trunk :)

ok, I'd prefer to see the draft version of controller/module in Trunk too, but I am also happy to see the partial merge.
Are you ok to do the cleanups I suggest?

Of course, I'm working on them now

This last commit should contain all your suggestions, let me know if this needs further work. Thanks!

I'll fix this up

Great, that al;l looks good :)
Can you rebase/compress to a single commit?

Squashed to a single commit, done

Awesome - thanks :)

location_filter is NOT about permissions, so we can't assume that is taken care of already

Wouldn't you agree that if there are values in the records, then those values should also appear in the filter widget? 

I find it odd to filter the filter options independently - that way you would have some records in the list which you don't have filter options for, so you can de facto never isolate them. What's the point with that?

location_filter should only be used for the widget options when it is also used for the list, of course.

Exactly - but if it is used for the list, and you look up the filter options /from/ that list - then the location filter for options is superfluous (because the list is already filtered). That's what I mean.

De facto, you only need to location filter in s3_get_filter_opts because it doesn't lookup the options from the pre-filtered resource. But the default S3OptionsFilter options lookup uses the pre-filtered resource to lookup the options - so all filters applied to the resource will apply for the options as well.

Absolutely: if the location_filter is applied to the resource & so are the options then no need for an additional filter

@nursix the reverse lookup does not apply the resource filters nor is the resource here filtered by org_sector.location_id, agree with @flavour that location_filter needs to be retained, i have indeed missed that

Thanks - looks generally good, although I don't think we need the separate deployment_setting?
Have you had any time to fix the Bootstrap styling? Would be lovely to have that included as the current hardcoded reversion is a tad ugly ;)

sorry for the delay but i was sent on mission again, need to recover first then will look at the bootstrap styling

what would you suggest instead of the separate deployment_setting? can we safely conclude that the login form always uses the inline variant of the crud formstyle? what if that doesn't exist?

Delay is fine, of course :)
'mission' sounds interesting? :)

I see the issue with the Inline login form now that you mention it...I rather see that as the edge case & the standalone page as the norm, but perhaps taste differ ;)
Can we add an option to auth.login(inline=True) for the inline case & then use the appropriate formstyle from that?

I reviewed https://github.com/flavour/eden/pull/766 after nursix comments.

I know this could be an annoying thing but now, Claudio can't continue his work... 

There is some great stuff in here - e.g. fantastic to see the old shelter/presence finally being removed :)
There are a few issues that I see...especially the configurable pr_group_opts.
I would be happy to do all the cleanups I highlight post-merge if you are happy with the idea.

Just giving a suggestion, why don't you guys use semantic-ui. It is much easier to code and also look much more prettier that bootstrap. And also it will be something new.
PS :  It is just a suggestion. 

I think that's religion - can't see any obvious technical advantage of semantic-ui over bootstrap (nor a major difference at all), and the "easier" argument is moot after you have learned the class structure.

There is though a significant advantage of BS3 over BS2 - customizability, which has improved significantly, and is now more aligned with the foundation and bourbon frameworks (all three now using SCSS). And /that/ is a strong argument to stick with those frameworks in future (Eden currently supports both bootstrap- and foundation-based themes), as it gives us the freedom to design our own widgets (which is necessary) yet use a responsive CSS framework.

For sunflower, the theme was already bootstrap-based - this commit is merely to apply it to the homepage too.

The critical step for Eden would be to migrate to BS3 - and this is not really "just a suggestion" ;)

This page, over here points out some of the advantages and cons of  semantic-ui https://coderwall.com/p/ham3gg

And by easier, i meant this -

```
 Semantic UI 
<main class="ui three column grid">
       <aside class="column">1</aside>
       <section class="column">2</section>
       <section class="column">3</section>
</main>

Bootstrap 
<div class="row">
    <div class="col-lg-4">1</div>
    <div class="col-lg-4">2</div>
    <div class="col-lg-4">3</div> 
</div>
```

You can very well tell which code is more understandable. 
As given in that post semantic-ui may become more popular than bootstrap or foundation in the <b>upcoming years</b>. We could move on to it then. 

We do however have the principle in Eden to not follow advertisements but evidence. And if there's something missing from that blog post it's exactly that: evidence. It's pure populism, subjective and a petitio principii - not a trace of serious, critical analysis. It just says it is better because it is better.

I still don't see how the HTML classes are more understandable than with other frameworks. The bootstrap one seems simpler and clearer to me? Just this kind of non-evidence that the whole post is built on.

It's a good old habit of mine to not give much on the extreme praise, but judge by the hardline critics. 

Meaning: it's just as easy to find similar articles for any other CSS framework all over the web. And they all praise /their/ discovery :D not useful.

I have removed those variable, i found some more from that module to removed those too. I hope thats fine. And i wanted to know what is an inline component ???

@flavour please review :)

:+1: 

@flavour i am closing this one and will send another PR with a small addition.

Oh...i thought i might be getting used somewhere else :P

@flavour done!!!

seems more intuitive to allow overriding the formstyle like auth.login(formstyle="default-inline") and default it to settings.formstyle

no - didn't have time for the bootstrap cleanup yet, day job keeps eating up all the time, will try again

@flavour i have done those changes in the file.

@flavour please review :)

You kept ADD_BUDGET but then didn't re-use it in the reusable field?
budget_location_id can be done the same way too & budget_staff_id, budget_kit_id, & budget_item_id.
Also note the change in Help text where-appropriate for these Add -> Create

Thanks - this looks like a step in the right direction :)
Why would bootstrap for login forms not be desired?
Consistency of formstyle is generally a good thing & the bootstrap one isn't actually far-off the default  (we mostly get it looking ok with just the btn.btn=primary)
I'm actually more worried about the default formstyle (labels above inputs).
Although there are a number of themes which use Bootstrap, most don't have custom Auth CSS so fixing one should fix them all (or at least most)...I'm personally happy to take the pain now & get them fixed (my personal focus being NYC as that's the one I'm currently updating from trunk).
I'll merge & fix

you mean i need to change "Add" to "Create", right ?

in case of budget_staff_id, in the reusable field should i change it to T("Create Staff Types") or use T("Create Staff")

Are you creating a Staff (e.g. 'Fran Boon') or a Staff Type (for budgetting purposes) I think it's the latter...

@flavour done.

FYI: I have it all working fine locally for Bootstrap (inc Registration & others), now fixing up other formstyles ;)
It is def cleaner like this, even if a non-trivial task to changeover ;(

Thanks for actioning the various comments :) Is this ready to be rebased & compressed to a single commit ready for merge?
Once that's done, are you happy for me to cleanup any missed items myself?

Awesome, thanks - great to see that SQLFORM supports 'buttons' :)
Seems to have been around for over a year, which is what our current dependency check checks for, so no need to modify that :)

Dominic is right - the restriction was the ToDo

learned from the master: https://github.com/flavour/eden/blob/master/modules/s3/s3forms.py#L331 ;)

@flavour  please review :)

I think It is all ready. 
If there are remaining issues, let me know them or if you want, you can fix them without any problem.

@flavour @nursix 

@flavour  please review

Merge done & cleaned-up.
Please take time to review the cleanup to see what was done (some optimisations, some style things & some backwards-compatibility.
You probably also want to run through some tests to see that your settings are correct ;)

@flavour Please review. 

@flavour please review :)
1) Set up the page http://eden.sahanafoundation.org/wiki/InstallationGuidelines/Chat. (there in the comments of 000_config.py. Will setup other pages and link them.
2) Changed the filename from chat.js.cfg to sahana.chat.js.cfg

@flavour : Rebased, please review whenever you're free.

@flavour : Rebased, hope that it is fine now

I merged the non-controversial stuff

can this be rebased/compressed?

okay will do it in a moment

On Fri, Jun 6, 2014 at 4:37 PM, Fran Boon notifications@github.com wrote:

> can this be rebased/compressed?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/788#issuecomment-45325601.

@flavour  done 

Can this be rebased/compressed to a single commit?

@flavour done.

The template_id hard-coding is the part I least like to merge...can this be resolved prior to IOTX?

@flavour The template is purely an eden thing. It is not there in the CAP specifications. What we thought that we can map every incoming alert to a default template as there is no mention of a template in a CAP alert. That was the reason of hard coding it with 1.

Templates are not in the CAP spec.  They are our invention, I'd guess as a way to pre-fill alerts with typical information.  As such, there is no expectation or requirement for incoming alerts to have them.  The only reason for tying incoming alerts to _any_ template is because we have the template_id as a required field.  We can remove that requirement so long as, in our own alert composition, we copy all values from the chosen template to an alert that is being composed, rather than leave alert fields blank and fetch them from the template on send.  (I don't know whether that was the intent -- I'm about to go look.)

Likewise, IMO, we do not really need the template title field.  The template values speak for themselves, in particular, the category, (hierarchical) event code, and event.  If we want an out-of-band descriptive field, maybe that should go in an instructive comment, like, "Use this form of alert for blah blah blah..."

We could even do without the is_template field, by adding a status of Template.

I think Fran means hardocing of the template_id in the XSLT - this should be done in the onaccept instead.
Hardcoding DB (foreign) keys in the XSLT is a no-go!

Yesbut...  I'm saying we don't need it _at all_.  There is no concept of "template" in the CAP spec.  That's our invention, for convenience and speed of composing alerts by pre-filling forms.  So we can either do away with that field (if we just copy the entire chosen template into the alert form), or make it IS_EMPTY_OR.

Given that IOTX is coming right up, I'd say make template_id IS_EMPTY_OR, and don't set it at all for incoming alerts (neither in the stylesheet nor onvalidate nor onaccept).  We can decide if we want to drop it entirely later.

I would be much happier with making template_id not required.
This seems the much more correct solution for how to handle incoming Alerts which don't map to a template.
I think Nuwan introduced the concept of templates to ease the creation of Alerts, based on requirements from his users.
I don't see this being in any way useful for inbound though.

Yup, whichever - just saying that hardcoding IDs in XSLT is not right either way. Not just a design glitch, but a bug.

Ok, looks like the last of the issues is fixed up.  We have some ToDo items that we've deferred til we can consult with Nuwan.  Fran, over 2 you.

@nursix : Please review. 

i will send a new pr with the required changes.

@flavour done.

@flavour Please review :)

@flavour please review :)

@flavour  please review :)

@flavour please review :) 

Best place to put this is default/widgets.css - that gets included into all themes

Take a look at css.cfg in the templates to see which files are included, and in what order

:+1: 

The action button icon stuff introduces bootstrap specifics into the core, which isn't really good. It also seems that the view changes of the default views are breaking some CSS/JS in other templates?

We're allowing alerts to have no template now, since templates are a convenience feature we added. Right now, the custom alert form wants a template, so will need to tidy that up.

Just noticed I have a long line in the import.xsl.  (Was getting spurious line breaks &#10; generated so removed all the line breaks.)  Let me fix the formatting...

Ok, ready.

Merged manually as my changes meant it couldn't be done automatically

Added Fran to the CAP Trello board so he can see what work is in progress, to avoid duplication, given that there is going to be CAP work during IOTX.  Is there anyone else who should be added?  Also would be good for Ambar and I to watch each other's repos, if we're not already.

So I have to set the unique value based on the deployment_setting for the module, right ?

deployment_setting for the deployment...in the template or 000_config:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/DeploymentSettings

Added to deployment_settings.(the setting is common to both offices and facilities)

No, sorry - a common setting for both doesn't make sense - should be independent.

@flavour please merge this.

Fran, do you want the comment explaining that xml_post_render is called before components are added removed?

@nursix @flavour : Please review 

Thanks for merging! :)

I agree, vehicle primarily comes under the asset model,so it could be placed in the Asset model and being a part of Transportation could be controlled from the Transport controller.
I will check with Fran as well :)

Alright. Closing this pull request. Sending a new one with the GET variant.

@flavour : Done as asked. Rebased.

Because of various personal reasons I couldn't work further on this enhancement and get it committed. Now that I've ample amount of time, can I continue to work on this?

I think there is still some useful work that can be done here, yes :)

Ambar -- you could squash those two commits.

Reviewers, note -- where broker info is stored is coming up soon, but is not part of this step. Ambar will be starting an email thread about it, so I won't spoil it here.

@ptressel they are both separate issues. There were some trailing whitespaces in s3cfg.py . Removed them all.

Will I have to open a new pull request now that this is closed?

Once you have something ready, yes pls :)

It'll be ready in some time ;)

Overall, this is impressive - shows promise :)
I'm personally ok with the record.delete not resource.delete() for now, but the layout is still wrong...even though I know you've moved it as per your interpretation of my request ;)

as per previous comments, enable_layer/disable_layer should be very generic functions which just do that: no create/delete/no twitter-specifics.
I'm not sure how much value there is in a wrapper for adding/removing layers...I guess it could be reused.
Again, the core function shouldn't have any twitter-specifics though: anything twitter-specific should be passed-in as a parameter

Okay, so the only thing that needs to be changed is the enable/disable_layer (which should be generic), right? Or is there any other changes that should be made?

& add/remove layer

Until I see the whole thing again, I can't easily review ;)

Do you think it's a good idea to add a toggle field in the tables to enable/disable layers? 

Yes

I think the better philosophy is actually to distinguish mandatory, optional and demo prepop settings in the template, and use the special strings "optional_data" and "demo_data" in the 000_config prepop setting.

By default, if 000_config says nothing, it would load only the mandatory data (production). With ["optional_data"] it would load the optional data sets specified by the template. Then I can still add my own data sets on top of that, like ["optional_data", "IFRC/Train"]. Analogous with demo data.

In the web setup, you can then just tick the boxes you want.

More flexibility can be achieved by a string pattern like "template:optional", "template:demo". This can easily be extended into "template:demo_small", "template:user_training" etc. The corresponding deployment setting in the template would resolve the data sets into the actual sublists:

settings.base.prepop_sets = {
    "mandatory": ["locations"],
    "demo": ["demo/users", "bla1", "bla2"],
    "training": ...
}

and then I can simply tick the box I want. Or configure my 000_config accordingly (note that "mandatory" can not be overridden, nor selected in 000_config).

Obviously, the resulting lost of individual tasks.cfg needs to be deduplicated - but a simple resolver should be easy to implement.

I think this satisfies both - the wishes of template dev's and the needs of web setup. Wouldn't you agree?

Or, actually we would have in the template:

```
settings.base.prepop_options = {
    "mandatory": ["locations"],
    "default": ["x", "y"],
    "demo": ["template:default", "z"],
     ....
}
```

and then, if there is no prepop-setting in 000_config, it would load mandatory+default. Otherwise, I can override like:

```
settings.base.prepop = ["template:demo"]
```

...to get the mandatory+demo data populated.

Or, if I want my own stuff, I can add it on top of that:

```
settings.base.prepop = ["template:default", "demo/users"]
```

...which loads mandatory+default from the template, and demo/users on top of that.

That way, I can also switch the template without need to modify my setting (which is pretty common for devs) - still getting what the template says I need /plus/ my custom stuff.

How does that sound?

Sounds better than making prepop a dict. Fran mentioned that country prepop will be separated in the future as well. That can go in the prepop_options dict too I suppose.

For resolving tasks.cfg duplicates, we can read them all and find unique lines. Does the order of import in tasks.cfg have any significance? Is it fine for the resolved tasks.cfg to have -

Unique lines of tasks.cfg (from folder X)
Unique lines of tasks.cfg (from folder Y)
...

No, identical lines in different tasks.cfg can still mean different csv files, so this is not about de-duplicating lines inside tasks.cfg, but just tasks.cfg. 

The order of the individual tasks.cfg should not matter that much, but I would however try to avoid shuffling around their first occurences as that may mean that the importer has more to deduplicate (e.g. when referenced records are imported only after the references) and hence need much longer.

And yes, country-specific prepop options can absolutely go into the prepop-options, namely that is what I was originally thinking of. Or org-type specific prepops (e.g. UN, non-UN), or - as we had it in two cases - "dmz" and "public" (or "master" and "slave", respectively).

The last case is particularly relevant because that is when you run two synchronized instances (one inside a DMZ, one public), where you obviously would prepopulate only one of them (the master), and then share the records via sync so that both instances have identical references.

I think this must be made more flexible than "prod", "test" and "demo" - and I think Fran would agree. And having a separate is-demo, is-prod, is-test, is-something variable for each case will become very chaotic - not very extensible.

Note that the prepop-options pattern could easily be extended for other settings (rather than having multiple config.py per instance type, which would be a maintenance nightmare).

This could almost grow into a template-inside-a-template pattern :) not that I would propose that, but I can see it coming (site-type as additional setting besides template).

NB The order of tasks.cfg  _does_ matter
Prod is meant to come before Demo
I appreciate that Prod/Demo/Test + Country is limiting, however we need to be able to make progress without taking on too much here as it becomes very complicated very quickly.
Theer is nothing against adding extra prepop values in your own 000_config.py.
In fact my original idea was to have WebSetup write exactly that.
So: config.py has prepop= [](base) & demo_prepop = []
WebSetup asks, which template? Demo Y/N? and Country.
It then writes to 000_config.py the template (& hence core prepop) and in the post-template processing section appends the demo prepop and prepends the country prepop (country generally needs to come first).
Nothing stops a manual installer from writing their own routines here...this is just convenience for the 
WebSetup to simplify UI & get /something/ into production quickly as I have strong fears about getting bogged down here trying to change everything. A backwards-compatible solution is highly-desirable whilst all the template restructuring goes on

I _do_ very much see inherited templates coming soon - this is a key part of a Country template:
the country-specific settings (which includes demo data unfortunately, as well as production, which is where it gets really messy) should be in a country config.py and not in the main template's config.py
I've not tested running a 2nd config.py but it shouldn't be a big issue at all...in fact for country we could provide this support direct in 000_config.py as it's so critical.
We /could/ envisage other usecases for nested config.py & whilst technically not too hard I think this makes things unnecessarily complicated so am not keen to work on that right now.
Template + Country is a big step fwd already :)

Hmm - why is that so complicated?

This seems easy:

```
settings.base.prepop_options = {
    "mandatory": ("locations",),
    "default": ("default1", "default2"),
    "demo": ("template:default", "demo/users"),
    "training": ("template:demo", "training"),
}

settings.base.prepop = ("template:default", "template:training")
```

Here is the resolver:

```
def resolve(options, setting, resolved=None):

    default = resolved is None
    if default:
        resolved = set()
    seen = resolved.add

    result = []

    def append(item):
        if item not in resolved:
            seen(item)
            if isinstance(item, basestring) and \
            item[:9] == "template:" and options:
                option = options.get(item[9:])
                if option:
                    result.extend(resolve(options,
                                        option,
                                        resolved=resolved))
            else:
                result.append(item)
        return

    if default:
        append("template:mandatory")
    if setting:
        if not isinstance(setting, (tuple, list)):
            setting = (setting,)
        for item in setting:
            append(item)
    elif default:
        append("template:default")
    return result
```

This can be used in zzz_1st_run.py to resolve the setting like:

```
poplist = resolve(settings.get_base_prepop_options(), settings.get_base_prepop())
```

and it gives you a fully resolved list of tasks.cfg directories - retaining the original order.

Very simple. I don't see what holds us back.

In fact, the settings.base.prepop is duplicated in my above example.

```
settings.base.prepop = ("template:training")
```

would be good enough (since training contains default).

This gives you easily the option to add country profiles:

```
settings.base.prepop_options = {
    "germany": ("locations/germany"),
    "brazil": ("locations/brazil")
    "default": ("default1", "default2"),
    "demo": ("template:default", "demo/users"),
}
```

Then choose:

```
settings.base.prepop = ("template:brazil", "template:default")
```

Or, to set up a demo:

```
settings.base.prepop = ("template:germany", "template:demo")
```

Very simple. I don't see how this makes things more complicated, really.

And yes, obviously this is backwards-compatible.

Looks good :)
settings.base.prepopulate not prepop
I would have a single settings.get() function to both read the 2 values & also do the resolving.

Yes, putting the resolver into .get_\* seems more than logical, especially since the resolver is re-usable for other settings.

Btw - I could imagine to make S3Config country-sensitive like in:

```
settings.xyz.example = default_value
settings.xyz.example.us = us_specific_value
```

And then have a special setting:

```
settings.profile = "us"
```

so that all the "us"-specific settings would override their respective defaults.

Surely, the alternative is to have an include-option for 000_config like:

```
settings.include("us")
```

plus a separate config.us.py in the profile that just contains the overrides. Same processing effort, but maybe the separation is better for maintenance?

Not for immediate discussion - but maybe something to talk about when you return?

I think that 99% of country settings would apply to all templates, so no need to have per-template
If we do get to the stage of needing per-country overrides to base country settings then we /could/ look at that kind of thing

Yup, and then that is also hierarchical - as so many country settings would be the same for a whole bunch of countries (e.g. currencies and units of measurement in Europe vs. US), so inheritance seems an obvious requirement.

I /think/ I have an idea how this can be solved ;) seems /quite/ obvious to me.

...but don't have more time for that right now :/ sorry

I don't see a need for it anyway - seems too much complexity for too little value
The country <> template separation is high value

I was thinking of:

```
settings.locale = "us"
```

to switch all relevant defaults in S3Config accordingly. That way, you can still override them, but where you don't, it would fall back to the locale-specific default rather than a generic default.

The nice thing is that you can still switch the locale in 000_config.py - and yet all overrides in template and 000_config would still apply.

That can be re-used for every setting with a getter - and it is very maintainable.

Thoughts?
No, I won't implement that now.

...and it would be lazy (i.e. only cost processing time when you request the particular setting, not on every request) - so much better than CSS-style overrides.

This works for the settings, but we still need a different set of prepop and countries can be multiple - so a simple individual locale wouldn't work (neither would naive application of successive country/config.py of course)

Well, for prepop we do have a pattern now and that can obviously be re-used for other multi-locale settings.

uhm... it sounds strange but I receive it just logged as Administrator...

This may be incomplete (just updated a day ago) - maybe wait for @flavour to fix it. It seems to me that default type="point" shouldn't be commented in s3cfg?

coder006, Can you update the pr as per Dominic's comments? If you don't want to squash the s3cfg commit but do want to combine your fixes with the main publishing commit, you can add a new commit with the fixes, then rebase -i and change the order of the commits to put the two you want to squash next to each other. Also need to rebase from trunk, either before or after doing the fixes.

If you're able to read this, then I guess the power is back on...

@nursix ready for review!

I think it's mergeable, but it still needs more work.

Authorization is weak, logging/success checking insufficient, the form shouldn't be handcrafted so it supports standard form validation, and if you allow configuration of various channels, then it should actually support various channels (potentially multiple simultaneously) - otherwise the configuration pattern is somewhat pointless.

@flavour @michaelhowden : Updated and rebased.

& then should be rebased to a single commit ;)

@flavour 
@nursix

I have added the authorization for EdenTest. 
- In the setup, using a http_basic request admin permission is checked. So, only someone with admin permissions can run tests on that server.
- In the get_settings action of the default controller, if the testing mode is not set in 000_config.py file, it will throw an error.

How to push the changes made in 000_config.py files?

Tidied up and ready for review.

Ready for review

If you need to add a new setting to 000_config.py then do this to the version in private/templates

I think the point is that you should be able to protect production servers by denying remote test runs even /with/ admin permissions. 

The need for this setting is a consequence of the ability to store admin credentials in the test config - if you had to explicitly enter them to run the tests, then that would probably be safe enough. But if you can store admin credentials, then there is a risk of accidental test runs from remote - and the server should be able to deny that.

However, the setting should default to true, so that you do not need to set it in order to /allow/ tests - but rather that you /can/ set this in order to explicitly disable testing.

@flavour Done as asked  and rebased. Can you merge it please?

@flavour @nursix 
Done as asked. Please review.

@arnavsharma93 Can you review?

Done and rebased. 

Also, the requests library reports the 405 error raised as 500. So, I am catching that too.

Done and rebased (after battling with git and successfully solving merge issues)
Also, request library somehow is not catching the 405 error raised and is reporting it as 500 error. So, I have done a workaround of that.

I have reviewed it. One test case is missing an assertion, other than that, it's just awesome to see someone using EdenTest!!

@flavour Can you merge please?

Ready for review

[#836](https://github.com/flavour/eden/pull/836) - Moves running of EdenTest from within web2py and a few other modifications. 

Probably, that can be merged first and those modifications can be incorporated in this. It would just require removing the `Suite Teardown` and `Suite Setup` functions from the testsuite file and modifying the .gitignore file.

@nursix Done as asked and rebased.

@flavour @michaelhowden : Good to merge?

@nursix @michaelhowden : I have updated the commit, making the /contacts method permission aware and using 2 tabs in the profile - basic details and contact details. 
Please review

ops I forgot 
Feel free to edit it!

Francesco - pls give me some time to look through it, am in a conference call atm

Generally, please fix indents and line breaks :)
Else - see inline comments.

@nursix @flavour @graeme-f : Please review

Reviewed - but I need to test it, which I can not do before it's rebased (it has currently conflicts), ideally squashed into 1 commit, and then merged into trunk. So: you = rebase+squash, Fran = merge ? ;)

What are the command line arguments for? It's difficult to see where they are defined, i.e. "smoke_tests -o NONE -l NONE -r NONE"

@graeme-f : pybot -h

 -o --output file         XML output file. Given path, similarly as paths given
                          to --log, --report, --xunit, and --debugfile, is
                          relative to --outputdir unless given as an absolute
                          path. Other output files are created based on XML
                          output files after the test execution and XML outputs
                          can also be further processed with Rebot tool. Can be
                          disabled by giving a special value `NONE`. In this
                          case, also log and report are automatically disabled.
                          Default: output.xml
 -l --log file            HTML log file. Can be disabled by giving a special
                          value `NONE`. Default: log.html
                          Examples: `--log mylog.html`, `-l NONE`
 -r --report file         HTML report file. Can be disabled with `NONE`
                          similarly as --log. Default: report.html

Dominic, I made an update of my pull request adding your notes.

At this time the note I am not able to do is the filtering of housing unit using the jQuery script. 
Can you help me please?

Yes, I can help you - as soon as this has been merged and I find the time to ;) 

May not happen today.

Done.
@flavour: Can you merge please?

Just merge this. 
I will close the other pull requests.

Needs to be rebased/compressed into single commit, then I can merge :)

Looks good to me now..I see this also includes the 2 commits from the other PR.
Rebasing/compressing all 3 to a single commit is ideal for me:)

Does this include the changes from the 3x commits from the other PRs?
- am a little confused on open PRs here.
  Other than the new deps, all looks OK to me

I have removed that dependency and rebased all the commits into a single commit in [PR#840](https://github.com/flavour/eden/pull/840)

I will close all other PRs after then. :D

Looks good, but needs rebasing now before I can merge.

This needs rebasing now that EdenTest has been updated and taking Arnav's latest comment into consideration.

@flavour : Rebased.

@flavour : Updated and Rebased

@flavour : Updated and rebased

@nursix : Updated and rebased

But the extension should be on the last argument, i.e. organisation.iframe/1/office is actually wrong, and organisation/1/office.iframe is right. So better fix it for the correct case?

Or is that case you fixed? (commit message is a bit ambiguous)

This commit provides a solution for the bug(found in the second case). The solution works for all cases.

Ok, then in with it! :)

Yup - ok. @flavour: pls merge

@nursix: Done as asked. 
@flavour: Please merge.

:+1:

Ready for review

@arnavsharma93 ?

@flavour please review :)

@flavour : Updated and rebased (again)

@flavour please review :)

Changes implemented, ready for review

@flavour please review :)

@flavour @graeme-f  please review :)

@graeme-f done :)

Changes implemented, ready for another review ;)

Awesome @graeme-f  
@flavour: Please merge.

Awesome. 
:+1:  for using `Start Testing If Template Is SSF` as `Suite Setup` for SSF test suite.

@arnavsharma93 : Updated and rebased.

Looks good to me. Nice beginning of regression tests for Sunflower.
@nursix @michaelhowden 

Needs to be rebased

Still needs rebasing: "We can’t automatically merge this pull request"
- need to do this after merging trunk

@flavour done :) Rebased now mergable :)

@flavour please check this one instead of that. 

Seems to have not addressed 90% of my previous comments

Please take more care before submitting PRs - you have a _lot_ more time than I have (& yours is paid, unlike mine), so please value my time more...

Thanks...no need to minify normally...I'll do this (otherwise the different minifier versions can give slightly diff results)

Can this be rebased./compressed to a single commit?
Thanks!

Creating a new PR with the commits squashed into one

Edit: updating this PR instead

Rebased into a single commit

Various cleanups to do...please take time to look for other occasions of the styles which I am advocating...I didn't take time to mention each & every incidence

Thanks for the cleanup...can this be rebased into a single commit?
(I know that we're after pencils down, but I don't see this as a code issue...just a normal part of community contributions now)

Apologies for not having time to review this earlier - looks great :)
Can it be rebased to a single commit, so I can merge? :)

Thanks for all this work, on reflection I think this is best kept as a separate module for now.
Individual deployments can have the Vehicle menu items within the Transport menu if-desired & perhaps we should do that for the default template too

No problem, Sure..will do :)

Deprecated

Okay :+1:

Does this still need merging? I thought I saw something similar merged more recently?

@flavour Can you see if these changes are correct ? If they are, I can send a pull request soon.

Minor tweaks, then we're good to go: thanks :)

I had implemented smoke tests inside EdenTest. This was part of my SSF internship work. 

It works and is the fastest option there to run smoke tests but it crashes unexpectedly because of PyQt.  I would say, let us keep it like this for a while and take a decision on it when we are removing/migrating the old test suites. 

@nursix @graeme-f 

I am unclear on what your answer means:
(A) We close this PR & ignore
(B) We merge it

What I meant was, not taking a decision on it right now.

Rebased :)

@flavour @nursix Please review

@flavour : good to merge

What makes you say this?

This is seen in mostly all the web applications.

-1 having logout on top makes accessing it much easier - and is customary in other applications.

Which web application does have logout at the bottom except Facebook (which I find very fiddly in this regard)?

In fact, most web applications have it right on top - as a separate menu item and not hidden inside a menu. This is the very best solution - but obviously requires space. But if it has to be inside a menu, then it should be on top - Facebook and Twitter may serve as very bad and fiddly examples here (but they do not really want you to log out at all - whilst we /do/ want that for security reasons).

https://bitbucket.org/
wordpress
outlook.com
gmail.com

Still - login/logout are priority items, and thus belong on the top of the menu. Ideally, as I said, this would go as a separate menu item (like HERE) - but we can't really do this (not enough space for that).

Hiding it at the bottom of a menu is not really a good idea - very fiddly.

And:
- GitHub
- Trac
- Wikipedia
- Agilefant
  are counter-examples, so stating that "most" web applications have it is not exactly true.

And believe me - the idea of placing the logout button at the bottom of the menu is really to motivate the user to stay logged in, which works well for applications that are usually used from home on a private computer that is owned by the user. 

For Eden, though, we want to motivate people to log out and not leave their account open so that it could be accessed by others. So, we should make it easier to find and access, not harder. The IFRC template for example places it right on the top as separate menu item - for exactly that reason. Most banking software does too, and many other software that is typically run in an office or public environment.

Btw - my wordpress has logout as a top menu item ;) but that happens if you use a themable GUI

Just like some Eden themes have it at the bottom (I guess all the Bootstrap-based ones)

Oh ... ok ... i see !!! :)

Hey, I just was wondering, y isnt it posible to make a seperate logout button? like i tried it and it fit in the space

Varies based on the menu structure and screensize...could make this a deployment_setting or else just leave it up to custom themes.

In which space? I already need to widen the browser window so that left and right menu don't overlap ;)

Also note that the menu structure in the default template isn't fixed (it's introspective), so you're making guesses here.

Generally, though, I'm very much +1 to a separate menu item for logout - although I'm currently satisfied with having it on top of the user menu.

This overs the Python side, but not the JS

i.e. If the user searched for a 'Albino' and this is the alt_name for something called 'Jackson', then they'll be very surprised to see 'Jackson' in the search results
If the alt_name is matched then we need to include the alt_name in the results...and ideally this would be highlighted...just like the site autocomplete I pointed out to you

Looking good, thanks :)
1 query on functionality & then a minor code style issue

Great thanks...sorry misunderstood: code was fine, but indeed was just the comment which was misleading ;)

:)

@flavour: good to merge

Thanks :D , It works...so there's no need of importing again

It is possible, I just thought of placing it in the 3rd col ;)...... I guess inline would make it more reachable

I'll make the necessary changes :)

I'm sure you're on the right way - just a bit difficult to understand your explanation.

By default, any organisation record (i.e. regardless whether root organisation or branch) is in its own realm. That means, only users who have a role for that organisation's realm can access the organisation record.

When using hierarchical realms, branch organisations are /also/ in the realm their parent organisation. That means, users who have a role for the parent organisation can /also/ access the organisation records of all branches of that organisation.

Now, it is not entirely clear what you're trying to change about this - you say that the realm_entity of an organisation shall be set to that organisation, whilst the realm_entity of a branch should be set to the branch. But that is actually the case - so what's the problem exactly?

Looks good, but needs to be i18n & a few minor formatting issues
NB No need to close a PR & open a new one - can update the existing PR if you rebase/compress & push then it updates automatically...just add a comment to PR saying 'done' to ensure we get notified :)

Ok. It finally works. 

:)

Perfect :)
- other than the unscoped JS vars...

Switching between python and JS makes me forget such small things :P

Deleted whitespaces

cleanups and style changed :)

Added a try/except block. 
I think this is enough ready to merge! :+1: 

Should I be changing the minified css ?

Should I add the throbber css in the style.css of other themes as well ?

No need to amend minified CSS, no...I'll do that to reduce conflicts there

I wasn't able to understand your comment clearly. Users will override this throbber if they want ? right ?

Default (in widgets.css) should be the same default throbber as the rest of widgets.css
SSF & Default theme can override this with the Sunflower throbber

Okay, so keep it default in widgets and then override it in the style.css, making it themeable, right ?

Yes

:)

:+1: 

I assume the other fix (in hrm_compose, as proposed) goes into a separate commit?

Yup, or I'll rebase if this one is still open by the time I finish :)

@gnarula Hi, I have a business inquiry, please email me at amin.a95@hotmail.ca

@nursix , Shouldn't this
https://github.com/hitesh96db/eden/blob/master/models/00_utils.py#L266
be: 
 r = s3_request(prefix, resourcename, **attr)
so that we can send override variables such as args, vars, etc, for eg:
https://github.com/hitesh96db/eden/blob/master/modules/s3/s3rest.py#L139 
which allows us to override it.

No - we do not want to override request data, that would have dangerous side-effects!

These constructor options for S3Request are not really meant to "override" request data - they are actually intended for the case where you want to "fake" a REST request from the back-end (i.e. execute a REST request without having an actual HTTP request). 

In that case you must have an option to specify the args/vars/method for that "faked" S3Request, with the current.request data as fallback.

But in all other cases, request data are taboo - the controller must not modify the request (whilst it can, and should, modify the _response_).

Besides: **attr are controller arguments for the method handler, i.e. a completely different class of arguments. The flow of arguments is:

HTTP client => REST interface:  request.*
controller => REST method handler: **attr

You should never mix different classes of arguments into one and the same set - that would open pandora's box of unintended and undesirable side-effects, it would be confusing and inconsistent, and it would spiral out of control very quickly. Request is request, and *_attr is *_attr - different sources, and different targets.

And normally, there should never be a need to "override" request args or vars in a regular request. If you come across such a manipulation, then that's always a "hack" and only because the respective developer didn't put in enough thought to resolve it in a proper way.

:+1: for the explanation :)
I just thought of it while trying to get this,
http://127.0.0.1:8001/eden/hrm/compose.iframe?human_resource.id=58
through the REST interface, because REST determines the method and id from the url in format given as '/prefix/resource/[id]/method',
However, I get your point, I'll probably need to look at more URL requests in Eden to see if these types of url formats have already been taken care of in REST ;)

If I am unable to think of anything, I could use your initial solution of putting 'r' in output.
"pandora's box of unintended and undesirable side-effects" has already opened up in my system due to that s3_request change ;)

Definitely - S3Method puts "r" into output automatically, so this is the standard. 
hrm_compose does not do that, but I take that for pure negligence ;)

And yes, this "?human_resource.id=58" is a regular REST filter, if you call e.g. /pr/person?human_resource.id=58, then you will see that this gives you a single record - i.e. the pr_person record to which the hrm_human_resource record with id 58 belongs.

That means, /if/ hrm_compose would apply the S3Compose method handler to a regular REST request, this would automatically be taken care of - and in fact, that is the preferred solution here.

But the other option (putting r into output) works just as well ;) no need to rewrite everything. Only if you have the time and are happy to make things right. Would be great if you did, however.

In principle, S3Compose() is a regular REST method handler, so it should be possible to just apply it via s3_rest_controller, e.g. like:

```
def compose():

    def prep(r):
        if r.representation in ("html", "iframe"):
            r.method = "compose"
            r.custom_action = S3Compose()
        else:
            return False
        return True
    s3.prep = prep

    return s3_rest_controller("hrm", "human_resource")
```

Ok - that is a simplified version, there's certainly a bit more to take into account here - but in principle, that makes that you can just call /hrm/compose/58.iframe instead of hrm/compose.iframe?human_resource.id=58.

It is this hrm_compose function that makes it more complicated than it needs to be.

Thanks, I'll take that as a rough template to start with :)

This makes the request go through the REST interface ,and uses the "hrm_compose" function, removing the problem of 'None' showing up in the .iframe format of 'compose'

Btw - I think the hrm_compose function can actually be completely abolished ;)

(Sorry for keeping you busy - you're doing really great otherwise, totally on the right way, so please don't loose your patience)

As long as you're guiding me, my patience is not a problem ;)

remove hrm_compose and use S3Compose instead ?

Yes - or do you see any reason to keep the wrapper now that you have (r, **attr) as parameter list?

I'll have to understand the behaviour of S3Compose first, and then check if hrm_compose is actually needed ;)....So if it's possible, not to have hrm_compose, then I'll add the required changes :)

@nursix Removed hrm_compose and made it a part of S3Compose. 

Suggestions ?

Yes:

1) The postp sets the title in the output. If that is consistent across all use-cases - then obviously it should be part of S3Compose() - which removes all the postp's

2) The preps set the method - but why can't you just call that method? That is, instead of /hrm/compose, you call hrm/human_resource/2/compose - or hrm/group/8/compose. Not only does that remove the need for the prep, it also removes the need for the compose() controllers altogether - and it is actually more RESTful.

Obviously, to introduce (2) you need to also change the "custom action buttons" in the respective controllers - but I wonder why "compose" shouldn't actually be a standard action button (whenever you detect that the target table is a possible recipient), and thining even further - why not outright make it a standard method altogether? Doing that will remove a lot of custom postp's, action buttons and custom controllers, and make it a lot more maintainable.

I'm sorry - that is really asking a lot, but what you have hit here is one of the cases where essential functionality has started as a hack, and is then being generalized bit by bit. You are perfectly on the way to accomplish that, so please keep going - it will help you to understand the architecture, and it will greatly improve the code. And put an end to the endless copy/pasting of bad examples ;)

Hi hi, I hadn't sent my comment yet - and yet you did what I proposed! Telepathy?

hahaha, I noticed it myself before you commented ;)

Of course you did. Now, keep going - this is absolutely the right path.

Just one thing: please make sure you /test/ this - ideally make yourself a list of all use-cases and run them through whenever you have completed a step. You can even automate these tests.

The point is that I don't want you to make the same mistake as many other people, and refactor code only from the perspective of a single use-case - and a complete set of test-cases is the ideal way to prevent unintended regression.

Yup, I agree, I've only tested it with a few modules, I could be missing a few use cases. I'll continue to work on this, and since it might take some time, it's better to get the SSF 'None' fixed quickly, so I'll remove the SSF fix from this commit ;)

I'm not yet sure where the urgency for the SSF fix comes from - I didn't see this being reported as a bug anywhere? But yes - since you have a quick "fix" for that, maybe send that first in a separate PR, and then continue on this one without pressure.

In ( or any other similar eg ) http://127.0.0.1:8000/eden/deploy/human_resource/5/profile
the organisation link next to the Job title is displayed as text and not as a link

(Update)
I've made the necessary changes so that 'compose' is now a 'method' instead of a function, and also changed the respective URL calls. Changes for 'event' module, and 'compose' as a standard action button remains to be done.

ok, I see you did explain...the Org isn't a link in the template I'm looking at anyway, but I can see that it can be in some templates

That is very simple. You have that line with "m=user.id" - which is not a valid method (a method is always either None or a string).

All in all a bit too complex - you can achieve the same result with less.

But a general question: /why/ should this use S3Navigation rather than hardcoding? What's the idea behind this task?

Maybe use existing methods, that are meant to do this ? NYC uses a similar procedure for its bootstrap menu.
@nursix 
Should I continue to make changes ? Or keep things simple as it was ;)

Hmm - I think understanding /why/ this should use S3NavigationItem rather than hardcoding will help us to better determine /how/ this should work and look like.

I suspect that the main purpose is the automatic disabling/hiding of unauthorized items - which is the only thing you have not really implemented yet ;)

The other aspect may me improved maintainability - which would mean to reduce and simplify code, and to make it as introspective as possible.

And a third possible aspect could be to develop a standard layouts.py for bootstrap themes that can be re-used for other templates.

But the Sunflower task doesn't really tell what the idea is (which is what I dislike Sunflower for - it's just dumping out tasks, not explaining any thoughts behind or goals, not justifying anything).

I can't tell you what to do - but if I was in your shoes, I would squeeze a proper justification out of the task author: if (s)he demands such efforts, then the very least that is required is an explanation as to what exactly (s)he thinks could be improved by this refactoring.

Or - if you see Sunflower as /your/ tool (which you obviously do since you work on tasks listed there), then please tell me what you think is wrong or doesn't work with the current menus that would justify such a refactoring.

And if the Sunflower menus work completely fine for you - then why are you doing this?

...and if you're looking to work, I had a juicy task for you ;) jump on IRC so I can explain.

I've got a few other tasks as well in my mind, but I thought this would be a good way to learn about NavigationItems which I did, in a way ;).
I've still got to complete the 'compose' task and there are some minor bugs that I found ;)
There's some problem with my college net right now, so I can't really access freenode for now

......and when tasks are put out in Sunflower, I'm assuming they are to be implemented to make things consistent and better, however I might be wrong with my initial assumption( this task is a good example ? ;) ). Maybe next time, I'll double check with the author as to why he really wants it if I can't see why :)

Well - just like you I think that the task author must have had a good reason to request this refactoring, but it is always a problem to just mechanically execute a task without understanding what it actually tries to achieve.

In this example I think your refactoring was certainly a good exercise so far - but I could not yet see what it would improve, nor how (if it is not meant to improve anything just yet) it would be a first step to prepare a future enhancement. That makes me wonder - could it be that it is a leftover of an abandoned road map? Is it still relevant? I'm not so really certain about that.

Now - don't just throw away your work, but maybe you should check with the task author what the actual goal was and whether your re-implementation does achieve or at least prepare that. That gives us something to decide whether we should merge it or not.

To me, to be entirely honest, this refactoring looks like overkill at the moment ;) which doesn't mean you did the wrong thing, but it means the task may not be ready yet to be worked on.

Rule of the thumb: if there's nothing wrong with a feature, then a request for re-architecture or redesign of it requires clarification of the problem/goal. Or, to cite the golden rule of open source: only change the code if you can improve it (...and not just because you can change it).

I used this to help fix the issues identified...many thanks! :)

:)

The idea is to "improved maintainability - which would mean to reduce and simplify code, and to make it as introspective as possible." However I'm not sure if this has been achieved (or is achievable in this context?)

Long term - I think that we might end up migrating to a Foundation theme for Sunflower (as this is what the default theme is built with) - so I don't think that it is worth investing in a reusable bootstrap layout.py 

I hope that helps!

Hitesh - great job working through this task btw :)

Okay :+1:
Thanks :)

@AnirudhTiwari : Some minor changes, otherwise a good start. I hope you went through the documentation. Any suggestions/improvements on that?

Made the suggested changes. Thanks @arnavsharma93 .

@flavour : Please merge

@flavour  , I am not sure of the permissions, i.e, what they should be. Eventually, each module implementing a 'compose' method would be accessing the msg_outbox table and therefore we can check for 'create' permissions on that table. Or should this be more specific( not sure as to how that can be done ), i.e, check at the controller level itself ?

@flavour: I can fix the issues I mentioned post-merge.

@nursix thanks for the feedback. will take a look at changes that you make for future reference.

Looks great thanks, sorry for delay in merging! :)

:+1: 

yes, I tried it for the CMS module in the default theme as well :)

wesome! )

Lots of inline styles - could some of them be moved into static CSS?

Also: series selector inside summary tabs applies jQuery UI style which is a bit unfavourable - may need fixing.

Good prototype, however :+1: 

NB looks ugly in IFRC theme - needs layout fixes.

@nursix thanks for fixing

Great work! Thanks!

I think this version upgrade needs in-depth testing first - e.g. filtering/sorting, Ajax-reload, etc.

i did test filtering, sorting and ajax reloading all appears to work normally, will fix semicolon and other themes

@nursix fixed and re-tested with some templates, deactivated for those i could not test

Thanks. Generally I don't see how this is useful yet, look like UI gimmickry to me. 

Overflowing datatables can easily be scrolled left-right on mobile devices - which allows for better comparison of items.

if you say so

Scrolling can get very fiddly though...and this looks better (which means users treat as more professional & hence engage better).
Since it can be controlled via deployment_setting anyway, I don't see an issue with including this? It doesn't make it especially more complex to maintain?
In general I'm very happy to get the core dataTables component upgraded to allow exactly this kind of thing anyway.
Unfortunately I see the master branch has been 'force-pushed or recreated' so I can't simply merge...redsin, are you able to reopen? Thanks.

yes i can send a new pull request but obviously it would be good to understand who of you calls the shots here. don't want to leave you in disagreement.

We disagree all the time...although luckily usually only temporarily ;)
This is part of 'healthy debate'.
Dominic was questioning the value, which is good...unfortunately this was interpreted as a rejection...I can see why, but think that was premature.
Hopefully we don't need to 'call shots' as we can reach consensus...but ultimately I am responsible for this branch, which the community kindly considers as the mainline integration branch at this time....partly from history (I started the branch), partly from trust that I generally do the right thing eventually and partly due to my elected role as PDC chair.

not sure what PDC is, and you're right i should probably have defended it rather than taking it down sorry for that. i just did not want this pending pull request to get in the way for subsequent unrelated commits for the sunflower project which is why i decided to withdraw this for now and move on.

PDC = Projects Development Committee...the replacement of the previous PMC (Project Management Committee) which is like other projects have or they call PSC (Project Steering Committee).
i.e. group of people interested in technical governance of the project...as opposed to the Foundation Board whose role is the non-technical aspects: Partnerships, etc

I'm sorry - my last comment was not meant as objection, but rather to start a discussion. I should probably have put a question mark behind it to indicate that.

Nothing really in the way for it to get merged - I pointed to some minor technical issues before and you have cleaned them all up. So, fine to have it merged. And to discuss it.

Had to split get_bounds. It contained two completely separate, isolated parts. Only the "parent" part or the "features" part was used in a given call, and the two parts did not even have the same return value type.

I see there is a CI error. That "works 4 me", so not sure why it is different in that environment. I'll look into it, but am not awake, so might do it tomorrow.

If you see anything else wrong, please tell me and I'll fix it.

Ok, fixed it so it works 4 CI too.

Good to see the CI having immediate impact of allowing you to fix that before I even review ;)
I see the value in splitting the get_bounds function

Cool that the CI server can feed the message right in here.  Is that a GitHub config option, or some fancy trick?

It's a GitHub service ;)

The Travis integration with trunk is proudly presented to you by AidIQ ;)

Cool!!

It's after 5am, so I have to go crash.  Please post and I'll fix it up tomm...later today.

OT re. new GitHub services...  Try "forgetting" a comma on the end of some csv file line (so the # of commas differs in one row) and see what GitHub says...

Let me know what else needs to be done...

OT re. new GitHub services...  Try "forgetting" a comma on the end of some csv file line (so the # of commas differs in one row) and see what GitHub says...

This needs rebasing: "We can't automatically merge this pull request" because it must be referencing older code.
Please also compress the 2 commits into 1 when doing this.

I'm going to close this PR and open it again -- I pushed an update to the same branch, but this PR is holding onto the old commit. Wonder if the PR semantics have changed...

problem with this is that 'Back to CAP' assumes we start in CAP which won't be true in 99% of the cases.
Most templates don't even have CAP enabled, so the minimum would be to check if the module is enabled before rendering this. Having unified menus seems to be the better solution.

thanks for the review and solution. 

Since this was a squashed commit and a forced push, the past comments are on the old commit, which was:
https://github.com/ptressel/eden/commit/ccb02ef2685aa3d15324147b266ef6e9f3e2d0a6

All fixed except the request to take the all_locations decision out of propagate -- see comments on the old commit re. why not.

It's not "agreeing to disagree" when one party has no control over the outcome...

I see 5 commits here...these should be compressed into a single commit.

is there any  issue with the pull request? My team embers are waiting for the updates

Exactly what I said twice before: these commits should be compressed into a single commit.

http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#Squashingcommits

Once this is done, then I can review

it is done. Please review it and please update demo site

I still get "We can’t automatically merge this pull request." so it can't be rebased on current trunk.
I still also see multiple commits (4 currently)

![screen1](https://cloud.githubusercontent.com/assets/6831827/4764321/e925f59c-5b22-11e4-9095-ca2b6bf4e521.png)
![screen2](https://cloud.githubusercontent.com/assets/6831827/4764328/fb9b41aa-5b22-11e4-96fb-dc7f40ffd6e0.png)
![screen3](https://cloud.githubusercontent.com/assets/6831827/4764329/01cc7b84-5b23-11e4-8465-a342bab0a142.png)
![screen4](https://cloud.githubusercontent.com/assets/6831827/4764333/0759d916-5b23-11e4-9132-b4c2099d6f6a.png)
Update Image Form
![update](https://cloud.githubusercontent.com/assets/6831827/4771254/3069403e-5b8d-11e4-8ee0-fb2a33e1930c.png)

Please don't do an S3ImageCropWidget2, there is no need whatsoever to retain the original, or to append a "2", just replace the original.

...especially since the limitations you mention are not new in this version ;)

Some whitespace/indentation cleanup would be nice (I didn't mark all inline).

The obvious question is: how is that in update forms - can I crop again (the previously uploaded file I mean), or does this only work with newly uploaded images?

Else it looks goods, very difficult to get a good UX out of that - especially on mobile (where the widget is most important, because of the often built-in camera - taking a pic and uploading it are connected). We should test specifically for mobile, not sure how good the hardcoded height/width work there, or the cropping as such.

I'm also not so sure that we always want to scale - in many occasions we want to crop the image, but retain the size and resolution of the section. It is not clear how this can be controlled. Mandatory scaling should however be configurable in the Python class (in form of a maximum size).

done :)

It's looking good - the few minor issues I highlight don't need to hold-up the merge :)
Is it ready for merge otherwise?
Has it been tested on other Themes? (I think this is critical before merge as otherwise we can break them...especially IFRC & NYC (latter via bootstrap))
Has it been tested in an InlineComponent? (Not critical pre-merge but was my main issue with the previous version)

I tried it on SSF and works fine, some styling needs to be done for bootstrap themes. 

I didn't test it with the InlineComponent but I think that can be fixed. Need some time to look into the issue, IS_PROCESSED_IMAGE was the key reason and I don't think it's needed anymore since cropping is done at the Client-Side, but I can send another PR as a fix later ?

IFRC has some issues, so don't merge as of now. will fix it ;)

Good to go :)

Thanks ;)

Yay! :)

Oops, in this case I see that it was existing code using tabs! Wonder how that happened?

This happenned to me previously also. There's some problem with github indentation. Actually my vim editor shows me correctly.

> This happenned to me previously also. There's some problem with github
> indentation. Actually my vim editor shows me correctly.

This is NOT a 'problem with GitHub indents' but rather that Tabs are
_never_ reliable for indents as this is an Editor-specific variation...so
Github is different to your Vim which doesn't mean it's a Problem.
The problem is the use of Tabs not Spaces within the file.
In this case it was in existing code, not yours though.

Okay I consider that. So are fine at this or a new PR is required.

@nursix In order to get this working with InlineComponents, I need the validator to be run again because I would receive a encoded file( cropped image ) and then would have to decode it and store it, but the problem arises here,
https://github.com/flavour/eden/blob/master/modules/s3/s3forms.py#L2238
where the validator is not run in case of "upload", so then I thought of adding a condition to check if there exists a field.requires along with the "upload" field , but I am not sure if that's a good move ?

Every "upload" receives an encoded file which is then stored through _store_file, so what's different about this upload? Why do you need to run the validator again?

And which validator btw - I thought IS_PROCESSED_IMAGE is not needed anymore?

I thought it wouldn't be needed but it is still required, because I would still have to run this,
https://github.com/flavour/eden/blob/master/modules/s3/s3validators.py#L2685
,i.e, decode the base64 string

Generally I'm trying to move away from the widget-validator combo. I know that we still have that for S3AddPersonWidget2 and S3LocationSelector2 - but the better way is what I did for the S3HierarchyWidget:

1) Add a validator for the embedded real input:
https://github.com/flavour/eden/blob/master/modules/s3/s3widgets.py#L5206
This embedded validator is executed /before/ the field validator is called, but it is not called during form construction, which is both safer and more robust. The embedded validator converts the widget input  format into the actual field data format, which can then be validated by the actual field validator
2) Implement the embedded validator inside the widget:
https://github.com/flavour/eden/blob/master/modules/s3/s3widgets.py#L5281
The advantage is that you don't need to configure the widget-validator combo anymore, but only the widget, and both parts - widget rendering and server-side processing are in one and the same class (in the widget class), which is better maintainable - and can even be subclassed. Another advantage is that you can easily hand over data from the widget to the embedded validator (via self), e.g. configuration settings, or introspection.

And you can still use normal field validators with the field (if required), because that happens only /after/ the conversion of the widget input.

This is also the proposed architecture for S3PersonWidget2 and S3LocationSelector2, but since it wasn't me to refactor these two, I couldn't put it into practice yet.

## However, for new widgets, we should /not/ replicate the old pattern with the widget-validator combo anymore.

However - in _inline forms_, the widgets are not processed server-side at all. If you can /not/ Ajax-validate them (and that is not possible with file uploads, no), then you will have to add a case discrimination to _store_file which checks whether the uploaded file is a base64-encoded string and converts it into a FieldStorage (or equivalent Storage) before running the store-procedure.

I think you can keep this generic without checking for the .requires - just check for the type of value (base64-encoded string => convert, FieldStorage => don't convert). That way, it can be used for other file-upload widgets, in case we introduce such.

One thing that worries me is that you don't seem to take the encoding type for the base64 encoded string into decode? Shouldn't it be applied?

I didn't write the base64 part and don't know much about it either, so I'll look into it, plus I think I might have to add more JS specific to this cropwidget in inline_component, not so sure as I haven't yet understood the code.
....and the names are really long and confusing in inline component forms for a newbie ;)

Please be aware that I'm doing a major refactoring of inline components at the moment - so if you want to wait with your changes for a couple of days, it may become easier to understand then.

Generally though I think there should be no need for widget-specific code in the inline component framework, all that should be encapsulated in the widget itself. Maybe you find a solution for /that/ before I get around to look at it?

Okay, so I'll wait, as I have to look at the code and then think of changing the widget code so that it can adapt to Inline forms,

Only a few minor cleanups here - I can do them after merge if needed.

Sorry for the shouting comment - that is actually not how I typed it, but rather accidental markdown style.

Looks ok to me..
@flavour @nursix : Can this be merged?

Are these changes really only suitable for the SSF theme?
or all Bootstrap themes?
or all Themes?

I confess I don't see any issue with the page you hyperlinked to.
Can you share a pre/post screenshot?

It's specific to SSF, didn't check on any other bootstrap-based theme. I noticed that the bootstrap files are slightly different from the standard ones so these changes were added.
Before:
![pre](https://cloud.githubusercontent.com/assets/6555434/4965813/9946ba4e-6797-11e4-82f8-bea6ddeafc7d.png)
After
![post](https://cloud.githubusercontent.com/assets/6555434/4965815/9e5ac1ec-6797-11e4-9df1-7d14d7cc6330.png)

I can see a difference but am not sure either are correct or wrong.
I personally prefer the original as there is less space wasted in in useless left margin.
If we assume that there should be a left-margin which matches the menu, then both are incorrect as the whole page inc title/action_btn are further to the left.

@michaelhowden  Please review :)

I'm surprised that this is all "custom" rather than using standard API, and it is concerning that it does not involve any authorization whatsoever. I can easily hand-craft HTTP requests and bypass any security here.

You also work around the framework in DB operations (e.g. manual deletion, value extraction without representation) - which /may/ break integrity.

I wouldn't accept it as is - but I don't have the time right now to guide you through all the details.

Needs significant work.

@nursix Apart from not using the API completely( for db and authorization check ) and those several things you mentioned in between, I hope this method, even though "custom", is alright ? Before starting the refactoring, I want to make sure that the way this works is ok ?, I couldn't find any such "standard' eden functionality for this, an outline of the method used:
https://groups.google.com/forum/#!topic/sahana-eden/QDJGpNVRo8s,
I've mentioned it after Pat replied ^

You're asking to validate your implementation of a Sunflower requirement?
Sorry - but that really needs to be done by the people you've agreed the requirements with, or actual users. To me, neither the requirement nor the implementation make any sense - but Sunflower is not my tool.

Maybe, rather than changing the keyword from DataTable Row to Table Cell it
would be beneficial to look at how the *Should Contain *keyword works. The
understanding that I have from that keyword is that it should be true if
the search string appears in the row, maybe it is failing if the row
contains more than what is being searched for. If that is the case then I
think that the keyword is in error.

On 11 November 2014 23:53, Gaurav Mittal notifications@github.com wrote:

> ## These Tests gave Error. This solution Fixes It.
> 
> You can merge this Pull Request by running
> 
>   git pull https://github.com/gauravmittal1995/eden EdenTest_Hrm
> 
> Or view, comment on, or merge it at:
> 
>   https://github.com/flavour/eden/pull/923
> Commit Summary
> - EdenTest: Fixing the Hrm TestSuite
> 
> File Changes
> - _M_ tests/implementation/testsuites/hrm/human_resource.txt
>   https://github.com/flavour/eden/pull/923/files#diff-0 (4)
> 
> Patch Links:
> - https://github.com/flavour/eden/pull/923.patch
> - https://github.com/flavour/eden/pull/923.diff
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/923.

"Should Contain" checks for the occurence of the string one or more time.
According to the docs: 
"Fails if item1 does not contain item2 one or more times." (http://robotframework.org/robotframework/latest/libraries/BuiltIn.html#Should%20Contain)
 So i guess it works if the to-be-searched-string is more than what is searched.

done

So why was the original test failing?

On 12 November 2014 11:08, Gaurav Mittal notifications@github.com wrote:

> "Should Contain" checks for the occurence of the string one or more time.
> According to the docs:
> "Fails if item1 does not contain item2 one or more times." (
> http://robotframework.org/robotframework/latest/libraries/BuiltIn.html#Should%20Contain
> )
> So i guess it works if the to-be-searched-string is more than what is
> searched.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/923#issuecomment-62683233.

It says {Column not found in datatable: "Organization"} for the prev test case.

The "Organization" is the column title? However if you have a different
language set, so that the spelling is different then that test would fail.
So does that mean that the dataTable test will only work with a particular
language selected? Should this keyword be updated so that it can manage a
translation of the title?

On 12 November 2014 19:25, Gaurav Mittal notifications@github.com wrote:

> It says {Column not found in datatable: "Organization"} for the prev test
> case.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/923#issuecomment-62746016.

The given method solves that problem as well. Also I ran the testcase in default english language set and yet it failed.

If the problem is that the dataTable keywords are not working correctly
then your solution, whilst it might mean that the tests run, ignores an
underlying problem. Typically, it is better to address a problem than
ignore it. When you run the test what are the values of the headings? Is
the dataTable keyword looking in the right place for the headings? Try to
understand why it is failing and thus can you then find a way to correct
the keyword?

On 12 November 2014 21:53, Gaurav Mittal notifications@github.com wrote:

> The given method solves that problem as well. Also I ran the testcase in
> default english language set and yet it failed.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/923#issuecomment-62772275.

@graeme-f Yes, It seems that it was failing in the keyword. This corrects the keyword and runs the original test without fail

@nursix Can u look at this?

:+1: 

Good to merge.

Can you explain why you implement this test case?
a) you are intending to modify the functionality (e.g. you found a bug, or you want to improve/extend CRUD), and therefore need to run this sequence frequently
b) you want to learn how to write test cases and use this as your learning example

Otherwise, what is the point to write a test case for a functionality that already works?

I wanted to learn about implementing test cases and used this as an example

Alright - so why is this a pull request then? Why should it be merged?

Your test cases inside the Asset test suite are not independent, i.e., if `Find Asset By Asset Number` is run as a stand alone test, it will fail but it should not as the functionality works. 

Please read this - [F.I.R.S.T Principle](http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Testing/EdenTest/WriteTestcase#TheF.I.R.S.TprincipleofTestDrivenDevelopment)

@arnavsharma93  So should i remove the "Delete asset" testcase and for "Search" use an asset which exists?

@nursix I just wanted to make sure that there are tests that checks that the asset module works as expected.

That is what prepop is for. You can search/delete an asset which is already present. Another way to ensure repeatability for your tests is to create a keyword for creating an asset but there the problem is that if creating an asset functionality is not working, delete and search would not work as well.

Oh, i see. So should i create a keyword or do it on an existing record?.

For future reference, do it on an existing record. But, I am not sure if this can be merged. 

Let me rephrase my question: you've recently stumbled upon a bunch of broken test cases - what do you think why were they broken?

The point is: they were working when they got written. 

But they went out of date - the tested code changed, and nobody updated the test cases. Shame on us. Or?

To be realistic: we are just a few people, yet we are dealing with a vast number of constantly changing requirements, rapidly progressing technology and tens of implementation variants. We are swamped with keeping the production code up to date, and simply can not maintain a regression test suite for all thinkable use-cases.

None of the test cases for end-user functionality would ever be valid for more than just a few weeks, if at all. Some break on the next day. And a suite of outdated regression tests is just as good as no regression tests at all.

The idea of maintaining a regression test suite for Sahana Eden is simply not feasible. Therefore, our current regression testing is limited to the unit test suite (which targets core functionality that doesn't change frequently), and smoke testing (which is introspective and therefore automatically adapting to changes).

But regression tests can be relevant or even critical for particular, largely fixed requirements sets (e.g. for project templates, like Sunflower).

However, our main focus with the EdenTest framework is another one:

Normally, when you modify code, you will just naturally run it to see whether your modification was successful and it works as intended. If it does not work, you need to modify further, and then run your "success-check" (=verification) again.

To speed up this again-and-again-and-again-and-again testing while developing code, you can use the EdenTest framework and automate this step. When the verification is very complex, this can save you many hours.

As an extension to that, you can write automated verification tests for a whole set of end-user stories, which you e.g. want to implement in the current development cycle (iteration). This can additionally help you to stay focussed on your goal - and make you submit the code early for user validation (=this is an important aspect of agile development - don't wait until the code is perfect before you show it to the user).

Obviously, using the EdenTest framework this purpose becomes _a lot_ easier if there is a broad palette of Eden-specific test keywords readily available. And therefore, exactly /that/ is the main task for people working on EdenTest: implementing keywords.

Arnav argued that to be able to do that effectively, you will of course need a test case to verify the keyword with. I agree - we do indeed need test cases to verify and develop the keyword library for Eden.

Now:
- if your test case is intended to help the development of EdenTest keywords for Eden, then it should be in trunk.
- if your test case targets a template-specific requirement, then it should also be in trunk provided that it is encoded specifically for that template.
- if your test case is an exercise for yourself to learn how to write automated tests, then it should not be in trunk unless you're planning to do any of the former
- if your test case is intended as an example for others to learn how to write test cases (i.e. as documentation), then it should be on the wiki, not in trunk

Arnav? Agreed?

Couldn't agree more :D

@michaelhowden Please review

This wasn't a replacement for the "Members for Tasks" PR, but is a PR for a /seperate/ task for modifying the rheader which I rebased in the previous PR(i.e, "Members for Tasks") but since that one needs major re-work, I thought this could be completed....
I wasn't aware it could be DRYed even further :+1: 

Better you focus on one think and focus our input on one thing too! :)

I don't think S3ResourceHeader would help here, because the data.rows[0] that I get using "resource.select" is a dict that is of the form { "tablename.field": value(represented) }. This data is passed as a record for S3ResourceHeader in the call.
S3ResourceHeader can process fields that are either a string or an actual DB Field. Can't send a string because it's not a part of the table. I can pass a Field object but field.name isn't in the record( because it's of the form "tablename.field" ).
As far as I can see, there's not much of a benefit in using it( unless the structure of the dict is changed ).Sorry, for carrying out the discussion in a separate PR. I'll take care next time :)

I understand that, but the issue is that hrm_AssignMethod checks for "selected" instead of applying the empty selected - and that is wrong. And generally, bugs should be fixed where they are caused - not being worked around in a different place, breaking other cases.

Besides, it does not work - because it gives a wrong number of selected records.

@gauravmittal1995: Can you please close this PR?

Also, please add instructions of how to run the testsuite at the top of the testsuite.

It looks good to me. Please just run each of these tests independently to see if it works as expected.

No, so I set those variables in the test "Create Staff Member" itself. Also I added instructions for each testsuite as to how to run them.

:+1: 

Thankyou for consolidating these :)
I'm not clear on the CSS change?
I worry this must have been put in for a reason & it will break the other usecase (which may be the NYC newsfeed)

@arnavsharma93 All of them are working independently.

@flavour : I changed it for http://demo.eden.sahanafoundation.org/eden/hrm/human_resource/1/profile in default.
Also for NYC theme, even if I keep this line it makes no changes to the email field.
NYC newsfeed?

This has already been resolved in this [PR](https://github.com/flavour/eden/pull/931/files). I'll suggest you close it.

@arnavsharma93  That one is for "Select from Multiselect." This is "Deselect from Multiselect"

@michaelhowden Please review..
I've kept a 'Watch' Button and all the members can be seen in the form.

Travis build is failing, but that seems to have been a problem accessing Github rather than real code failure, but if there are cleanups to await then that will trigger a fresh build anyway, so I'll await those?

@flavour Yeah, I'll make the required changes...Could you merge this one https://github.com/flavour/eden/pull/936, need it for this functionality ;)

@flavour done 

Doesn't make any sense to me - what does this fix?

Also, rebase all of your commits into one when sending PRs. 

Generally you should squash commits into one before submitting a pull request.

Okay. My bad. 
:+1: @flavour: Please merge.

I'm appy to review in order to give feedback, but I'm -1 to merging this into trunk. Please remove the generic test cases unless they are needed to implement new test keywords.

Please understand that there is no point in writing test cases unless you have a /particular/ requirement to verify.

Such test cases would need to be maintained (=updated whenever the requirements or the implementation change), which requires manpower and time - and since we're short on those resources, we need to limit our test suite to what is necessary and meaningful. 

Therefore, regression testing for generic functionality is currently limited to unit tests (which I'm maintaining), and smoke tests (which are introspective and hence don't need so much maintenance), but no functional tests cases - especially not repeated for the same underlying framework functionality in multiple modules (what's the point, really?).

Regression tests can be implemented for specific templates _if_ the respective project (e.g. Sunflower) defines certain critical requirements. 

However, Funflower, out of all projects, is rather weak on specifying requirements or even defining concrete user stories - so it is difficult to judge whether or not the tests are valid. Those should perhaps be confirmed by Somay before they get merged.

@nursix , right now if we have multiple contacts of same contact_method (say two emails) , it just displays one[1] . This changes it to displays all the contacts.

[1] http://demo.eden.sahanafoundation.org/eden/pr/person/93/contacts?person.pe_id=1509

I don't see that it only shows one - it shows all for me.

Your fix doesn't make sense to me either.

The current code does use itertools.groupby to group the records by type. This gives a result like:

```
{"EMAIL": [{"value": "email1@example.com", "type": "EMAIL"}, 
                 {"value": "email2@example.com", "type": "EMAIL"},
                ],
  "SMS": [{"value": "12345678", "type": "SMS"}]
 }
```

Next, it iterates over the keys in this dict and then over the list of records for each key in order to build the output - which does show /all/ records, not just one.

I don't see where this would be broken - it works fine for me.

And your fix seems to actually do the opposite of what you're saying by only appending the first record in each list?

Dominic

See this:

```
>>> from itertools import groupby
>>> contacts = [{"x":1, "y": "a"}, {"x":2, "y": "a"}, {"x": 23, "y": "b"}]
>>> print [(k, list(v)) for k, v in groupby(contacts, lambda c: c["y"])]
[('a', [{'y': 'a', 'x': 1}, {'y': 'a', 'x': 2}]), ('b', [{'y': 'b', 'x': 23}])]
```

When you now apply your code, it would give this:

```
{"a": [{"y": "a", "x": 1}],
 "b": [{"y": "b", "x": 23}],
}
```

i.e. only report one record per group.

That doesn't make sense with what you say the problem is - it would cause exactly that problem, not solve it.

Just to demonstrate that:

```
>>> contact_groups = {}
>>> for key, group in groupby(contacts, lambda c: c["y"]):
    ...     if key not in contact_groups:
    ...         contact_groups[key] = []
    ...     contact_groups[key].append(list(group)[0])
    ... 
>>> contact_groups
{'a': [{'y': 'a', 'x': 1}], 'b': [{'y': 'b', 'x': 23}]}
```

That is exactly the problem you describe - caused by your "fix".

The original variant works:

```
>>> contact_groups = {}
>>> for key, group in groupby(contacts, lambda c: c["y"]):
    ...     contact_groups[key] = list(group)
    ... 
>>> contact_groups
{'a': [{'y': 'a', 'x': 1}, {'y': 'a', 'x': 2}], 'b': [{'y': 'b', 'x': 23}]}
```

Also tested to add a second email address on the demo, and it seems to work just fine:
http://demo.eden.sahanafoundation.org/eden/pr/person/93/contacts?person.pe_id=1509

Looks ok - but didn't you forget one?

grep gave me 2, and now None.

Gave you 2 what?

There are three subclasses of S3SQLInlineComponent - but you resolved only two of them.

@flavour : Removed the css change for now. @raj454raj wants to work more on that.
Good to merge otherwise?

@nursix considered that!

Yup - looks ok (except for the missing blank, but that's not really a reason to hold off merging)

Are you talking about having a newline after 3438(T=current.T), if yes I can squash one more commit before its merged

Thanks, but I think that should be many-to-many (at least that would be logical).

Or think: multiple gis_locations per budget_location, not the other way around like this.

I think this data model should only be reworked when we have a concrete case, not for cosmetic reasons. So unless you have a case right now, I think the todo can (and probably should) be left alone.

Yeah probably, that makes sense :+1: 

There are a couple of todos in modules/s3/s3forms.py if you're looking for work ;)

I'm especially interested to see S3SQLCustomForm to support component-only forms (i.e. without master record data).

"component-only" why/how would a component be used without a super entity ? Or i think i didn't get it.

We may have custom forms with only inline-components, but no master-record fields. That is currently not supported by S3SQLCustomForm - without master data in the form, no record would be created (and hence no components either).

This needs fixing, a todo is in place.

I think in fact that pr_PersonEntityRepresent is just fine for the case - why do we need a dedicated represent. Surely you need to turn off labels and types, but that is already configurable. Apart from that - it's already good enough, isn't it?

:+1:

Editor swap file left in - else fine.

Thanks - hopefully the longer path was a good learning if ultimately not needed :)

Makes sense :+1: 
Thousand thanks for the translation update :)

It is better to have the CSV files in English (so that they can be re-used), and set the representation functions for the respective lookup fields to translate=True (which of course requires the translations of the base strings to be in the translation file languages/it.py).

Most of the dropdowns should actually automatically translate as soon as you have the translations in languages/it.py? Have you tried that?

The problem is that they wouldn't translate into other languages if you provide them in Italian in the CSV, so it would always be Italian even if you switch the UI to English or Arabic.

The change must be made in the underlying style.css, not in the minified eden.min.css.

The CSS sources will be re-minified after merge, and hence your change would get lost.

If you can identify the style that needs changing, then I can point you to the respective selector in the source CSS.

Hi Dominic,
style.css is on the same directory of eden.min.css file:
eden\static\themes\EVASS.
I think that changes you are referring should be:
.button-home {
  width: 135px;
  padding-left: 1rem;
  padding-right: 1rem;
}
with
.button-home {
  width: 205px;
  height:45px;
  padding-left: 1rem;
  padding-right: 1rem;
}
Is it correct?

Hi Dominic,
I uploaded new changes.

I removed changes in minified file.

Great, thanks - can you compress the 2 commits into 1 with a rebase -i ?

Hi Dominic, I understand what you mean, I will provide another it.py with drop down strings and remove the .csv files translated.

Actually, you can merge it if you want, but I think we know it's going to pick up one merge commit from the merge into the GCI repo, and another merge commit when it goes into trunk.

Yes, would be better from my pov to not have the merge commits in, but I know the only way to do that is to rebase out the original commits which means students don't get visible commits into trunk :/
This will be less of an issue if the trunk PRs are consolidated across multiple commits & maybe the interim merge commits can be rebased out? Just leeaving the real student commits...

Hi Fran, 
I run a git rebase -i HEAD~2 command and I changed the command for the second commit to squash, so to have:
pick 1a991e5
squash 35f6c99
.
From git command line it seems that command correctly worked, but I still see 2 commits in the relative pull request.
Was I wrong? Sorry for the question, but I am new with git.

Please review and update the demo and production sites 

Interesting functionality, but needs work. The javascript should use module pattern to hide variables from global scope. Consider to use jQuery nodes to address elements rather than hardcoded IDs.

Please do not put the script on every page, but inject as needed. Onclick-attribute containing user data is very risky - should not be used that way (apart from the risk of syntax errors due to apostrophes in the address, this is also a security risk as it can be abused to inject arbitrary javascript that is executed with user permissions, so it is definitely a no-go).

Please squash all commits into one before re-submitting.

Not this way, no - please explain what this intends to do and provide the corresponding screenshots.

Make sure you test this cross-template, and for default theme also cross-language as well as cross-configuration.

:+1: 

You may want to squash this into a single commit? Thanks :)

@samsruti  You're not supposed to send a PR here, please send it to the "samsruti" branch in edengci.
Before sending a PR, ask a mentor if you're not sure.

Hi Dominic, is it ok now?

There are still 2x commits

I still see two commits?

lol

Attempted to merge a few times, but procedure accidentally included upstream code. Will rewrite to one commit from another repo

Yesterday I run these commands:
C:\Users\Administrator\Documents\GitHub\New folder\eden\languages [master]> git
checkout DropDownStrings
Switched to branch 'DropDownStrings'
C:\Users\Administrator\Documents\GitHub\New folder\eden\languages [DropDownStrin
gs]> git rebase -i HEAD~2

pick 33c1dc3 New strings in it.py
squash acb1a7f New Strings in it.py for Drop Down Lists

# Rebase 33c1dc3 ..acb1a7f onto 04f8358

#

# Commands:

# p, pick = use commit

# r, reword = use commit, but edit the commit message

# e, edit = use commit, but stop for amending

# s, squash = use commit, but meld into previous commit

# f, fixup = like "squash", but discard this commit's log message

# x, exec = run command (the rest of the line) using shell

#

# These lines can be re-ordered; they are executed from top to bottom.

#

# If you remove a line here THAT COMMIT WILL BE LOST.

#

# However, if you remove everything, the rebase will be aborted.

#

# Note that empty commits are commented out

Squashing into a single commit
Need to run some other command?

If I run again
git rebase -i HEAD~2
I see the following commits:
pick ce2b6d1 Minify
pick 04f8358 New strings in it.py

The first one is obviously an upstream commit which is fine as it's already there.

I'm usually doing something like the following:

```
git checkout master
git fetch upstream
git rebase upstream/master
```

Then check my commits on top of upstream/master:

```
git log -3
```

If there are more than one, I reset to the last upstream commit:

```
git reset --soft HEAD~2
```

(...or HEAD~3 if there are 3 commits, or HEAD~4...)

Then commit it all again as one single commit:

```
git commit -a
```

...and push:

```
git push -f origin master
```

Wanna try this?

Thanks Dominic, now I see just a commit.

...which though contains a little more than you actually did? Weird.

Let me check the commit history of this branch...

Seems your merged commit has included a few of the last trunk commits ;) That's not generally harmful, but we need to rebase this again.

I can try to do that later today from my repo, although it may remove you from the commit log. Or alternatively, you can do it again - this time of course without the reset ;) just rebase.

That is, this sequence:

```
git fetch upstream
git rebase upstream/master
git push -f origin master
```

...should actually reduce the HEAD commit to what you really changed.

Note the "This branch is 1 commit ahead, 3 commits behind flavour:master" at the top of your GitHub page. It should not say "3 commits behind" - just "1 commit ahead".

Merged commits into one

I'm afraid this is impossible to review as it says you changed 527 files!
I can't see the tiny change(s) you made amidst all the ones from other unrelated commits...
(This was a minor issue with the other one, but I could still pick out yours...here it's completely drowned!)

Doesn't seem to resolve all the issues I raised with the previous version.
Critical:
- models/000_config.py~ shouldn't be in the commit at all
- the directions JS should only be injected when needed, not on every page in scripts_top.html
- there is a repeated query for location_id - is this really necessary?
- what I said in the last PR.

This looks like a copy of someone else's work - their name is still in the screenshot!

Those are my screenshots, we are collaborating on this solution! Did the incorrect procedure in the previous codebase by pulling upstream commits into our line of commits, so the merge conflicts were overtly time consuming to rebase. Team is still working on the edits!

That seems to be only half the fix?

Can you explain why you want to change this?

Please close the PR, I'll fix it properly

@nursix the [1] has the delete button disabled. But [2] has the delete asset button. I take it that the delete button was disabled in [1] to avoid deletion of assets and hence this removes it from [2] as well.

[1] = http://demo.eden.sahanafoundation.org/eden/asset/asset/summary
[2] = http://demo.eden.sahanafoundation.org/eden/asset/asset/344/update

No, I don't think this is a valid assumption. I think that the removal of the delete button is a hack that was introduced for a specific use-case, but for the default template it should very well be possible to delete assets.

You can try to identify the case and check it for consistency, of course - and maybe fix the default case the other way around?

Further - the index controller should not be removed. It's a CMS page that can be modified by the user (which is why it is empty initially).

Oh ... ok ... thanks for the feedback

@hitesh96db - like this:

https://github.com/nursix/eden/commit/86b22ef9b4cae0717a5b785ad81836fbd0f4344e

?

:+1:

You're on the right way, but the module-global assignment from current is not acceptable.

There is still way too much inside in the try/except - what exactly throws the exception? Only that should be inside the try/except.

I know it's not "your implementation", so if you're not up for refactoring then fine. Can otherwise be merged.

The following I find a bit odd:

```
try:
    date = strptime(....)
    return date
except ValueError:
    do something...
    try:
        date = strptime(...)
        return date
    except ValueError:
        return date
```

What's the point?

To me, it seems that you will return date in any case, regardless of any exceptions.
So why not move the return to the very end?

Be patient, I'll check this again tomorrow with a clear mind.

Okay :+1: 

You may perhaps take a look at dateutil.parser as it is used in s3codec - it appears to me that this could actually replace the whole passage with a single line ;)

Err, I meant https://github.com/flavour/eden/blob/master/modules/s3/s3codec.py#L204

and https://github.com/flavour/eden/blob/master/modules/s3/s3codec.py#L146

I'll check it.

I reviewed the original code again, and I think that a rewrite using dateutil is by far the best solution for this.

Of course, a mere "cleanup" of the function is certainly also acceptable - but for that I would like to see:
a) no raise inside a try-block
b) try/except only around the statement that can actually raise the exception
c) a single return-statement at the end of the function
d) a maximum nesting depth of 3 "if" blocks

However, I reckon you'll find a rewrite with dateutil easier ;)

P.S. A tip: before refactoring the function, write a unit test based on the description in the docstring.

Okay thanks for the review. I will implement using dateutil. Shall I close this and send a fresh PR ?

A new PR is good to indicate when you're ready (new commits won't be notified).

@nursix : Turns out the module using this needs rewrite according to flavour since the function using this redirects to error url.

I'm not sure I understand this yet - can you give more details? Ideally file a bug report on Trac, including URL and traceback.

_Sorry for the long comment but tried to be as informative as possible_
Many functions in controllers/survey.py need to rewrited by S3Method(Refer the todos). These are implemented by web2py default and need to be replaced by S3Method.

**Traceback**:(I was trying to find where is this function which checks for the date format is used)
survey_question_type dictionary uses the function survey_dateType
This dictionary is used in controllers/survey.py L294 used in templateTranslateDownload().
So this function always gets redirected to error_url because https://github.com/flavour/eden/blob/master/controllers/survey.py#L281 this table does not have any rows. 

Please correct me if I am on wrong traceback.

Pass - I'm afraid I'm unable to follow.

Please squash into a single commit, thanks.

(Albanian is actually a demonym, not a language)

If this is rebased/squashed to a single commit, then I can merge/cleanup

Here: https://github.com/flavour/eden/blob/master/static/scripts/S3/s3.contacts.js#L172
Reason for bug: 
There's no div with a "popup" id, so the form submission url doesn't change. It's id is "iframe".
Doubt:
So, atleast for forms, if I make a url call using a .iframe extension, should the div have an "iframe" id ?
and if it's .popup, should it have a "popup" id ? 
I could just change the id lookup to "iframe" to fix it, but I found it a bit inconsistent.

the throbber doesn't exist, so I changed that to the bootstrap one.

Just change the id? I mean, if it's never going to be "popup" why keep it? .iframe will always return #iframe no?

On the other hand - you could simply introspect the ID after the GET, or (even better) use the inserted jQuery object instead of a selector.

.iframe returns #popup also. Should this happen ?

Okay

To explain it: you insert an empty <div>, and into that <div> you insert the form. Which means - you are in control of the outer <div> - so you can give it a class, empty() it based on that class and even find the form inside it using find(). No id required whatsoever, or?

Drat - GitHub markdown formatting. Let me try again:
To explain it: you insert an empty DIV, and into that DIV you insert the form. Which means - you are in control of the outer DIV - so you can give it a class, empty() it based on that class and even find the form inside it using find(). No id required whatsoever, or?

:+1:

Good catch! @flavour: good (and important) to merge

done

Hi Fran,
do you have any comment for this request?

@flavour: can be merged as-is. @eimmirzi: no comments, all fine.

Sorry, but we already have a requirements specification for this from IFRC (which isn't compatible) - what is your use-case, or who are the users?

I'm sorry - but I have to reject this. If you have a real use-case at OSU, then please move the specifics into a template, and keep the core implementation generic. Please do not modify the existing core implementation without adapting the use-cases that depend on it (IFRC in particular).

What's the purpose of this model? The coefficient table isn't referenced anywhere, nor is it used for calculations, nor is Sahana actually intended for salary calculation, let alone with the specific OSU business rules (that's not reusable).

The salary-coefficient model was actually intended only to track the actual coefficient for a salary record, not to compute it, let alone to store the factor table. In the use-case that we have, the coefficient would be merit-based with varying regulations by region.

The model you have implemented is very specific for OSU, but I'm not aware that OSU are using Sahana to calculate their salaries, or to track overtime hours of their employees - nor would Sahana actually be intended for that purpose.

The CRUD strings you added are not needed in any way, only adding overheads. The modifications of the AddResourceLinks breaks existing use-cases, without them being adapted to it - but I don't see the purpose of these modifications anyway unless you say that indeed OSU are your client whom you are implementing this for.

Is that the case? Is there a (tentative) deployment by OSU using the salary model, and if so, have they specified this as the particular requirements for their case?

I think the best you could do with this is to propose a model for discussion (in a BluePrint plus a post to the mailing list) - /if/ you have actual requirements for this particular case. But then be prepared to discuss questions about generalization, efficiency, added value and data life cycle requirements.

Question is, however, whether tracking /regulations/ for salary coefficients isn't a bit beyond scope of Sahana. Tracking salaries makes sense - but a coefficient table? What for?

:D No - the deployment setting shall be about whether the user must have the EDITOR role, or any other particular role - not to call the role check, of course.

Okay.

...and to whether or not to show the field at all. It could be like: True = show always, "Role name" = only show for this role (or make it a list for a list of roles), False = show never. That'd make sense.

Didnt get you^.
deployment setting -> the function in S3Config should check whether the user is editor or not ?

No. It shall become configurable whether or not the field is to be exposed, and if, then for which user role(s).

An S3Config function shall never check whether the user has a certain role - that's what we have s3_has_role() for.

Which field ?

> ...and to whether or not to show the field at all. It could be like: True = show always

The point with checking for the EDITOR role in these functions is to determine whether certain fields are to be made visible/editable which would otherwise be hidden or readonly. You can see in the code which fields this concerns.

This happens in order to support particular workflows. Not all deployments need these worklows though, and some may want other user roles for the editor-role, hence we need a deployment setting to make this configurable.

What I would imagine is to have a setting by which you can configure either True (no special role required, fields are always visible/editable), False (Fields are never visible/editable) or a list of roles (Fields are visible/editable for these roles).

Generally, with such fixes, you should describe what you are fixing. 

In this case, I don't see what the issue is - there is no interactive use-case I know of that would require these CRUD strings. 

And the deletable=False was certainly there for a reason, so if it is to be changed (which may indeed be correct), it would however require the use-cases which do have that requirement to be adapted (e.g. by a deployment setting). 

Unless, of course, you have knowledge that the requirement has changed in those cases - in which case you should include that in your commit message.

Thanks for the feedback. 
I added the CRUD strings because if we go to the RESTful controller for these tables then it gave the default "Edit record", "Add Record" ,etc. .. so just to change it to what the "Record" is.

Sure - but there is no interactive use-case for these controllers, currently they only exist for Ajax lookups and imports - neither of which needs any CRUD strings. The mere fact that the controllers exist does not imply that they are used interactively, and a mere "could be" isn't enough as requirement.

Generally we strive to perform in models only as much as needed for the standard case, and do the rest only if and when needed.

The disadvantage of doing too much configuration in the model is that it causes unnecessary overheads for the default case, whilst customizations need to override it anyway - adding even more overheads.

If there would be repeated pattern to add the same CRUD strings across multiple templates, then surely we would move them into core in order to DRY - but for this particular model I don't think that's the case currently (or at least I haven't seen it yet). AFAIK the salary model is currently only used inline which does not need any CRUD strings at all. That's why I did not add any.

I do certainly understand the desire for "completeness", but that's more a aesthetic feeling than a real reason to act. 

The incentive to add additional processing comes either from a real use-case, or from system integrity/security requirements. Otherwise the first imperative is to reduce processing wherever possible - even at the expense that things may look "incomplete". 

Sometimes we would add the extra code in order to document the "how it could/should be done if and when needed" - but comment it out, so that it doesn't impact the critical path without real reason. But that has disadvantages, because even commented code needs to be maintained and migrated when framework or APIs change.

Admittedly, that's not always easy to understand - but before adding code, try to make yourself clear which use-case would require it and is that use-case real or potential?

Thanks ... i will try keeping this in mind the next time.

@nursix , Removed the visibility setting and added another setting in msg for unique code in basestation

Please think about what the purpose of these charts is. They are not really for the user ;) (normal users can normally not access this page).

We have left them in the page as documentation (example) how simple, non-introspective charts could be realized - not intending to make them look nice. 

Now, meanwhile these examples are a bit out of date since we have moved away from jQuery/flot. So, a real improvement would be to rewrite the example with nvd3, including responsive design.

It's not so important whether they look perfect or not, or make much sense, but the code should have precedent quality (rich comments, well parametrized etc...) so that it can be copied/pasted to where it is really needed.

Good work, thanks :)

done

custom_lookup_rows should provide whatever data is required to represent _without further DB lookups_ 
As I say, using s3_fullname is fine, but the DB lookup should be Bulk not per row...this is the whole point of S3Represent

F

Can't make sense of the error message change - though the other change in widget.py seems ok.

> Can't make sense of the error message change

Please consider this a doubt:
If a field is marked required and it is not filled --> error message = "please fill the required field"
If a field is entered in invalid form --> error message = "the field entered is invalid"

Shoudn't these errors shown independently ?

I think "Please enter a valid email address" fits for both cases - not entered anything, or entered an invalid email address. I don't see the need for two independent messages here - that's splitting hairs, really.

Okay :+1:  if it is so. Is this kind of implementation only for email field?

Probably not - but please also think of the work a new/changed UI string causes for translators!

Every changed/new string needs to be re-translated into tens of languages, and really _this_ is one of the most ubiquitous messages. If you change it - many users will suddenly see an untranslated message after the update, and we need to activate a lot of people in order to get all the translations updated. And what's the value of it?

So, every UI string change must be considered very carefully.

Further, the philosophy with error messages is to communicate to the user what can be done about it - more than to say what's wrong. 

And considering the difference between "Enter an email address!" and "Enter a valid email address!", I think users who see those consecutively would think we're taking them on a ride.

A step forward would be to render a placeholder into the field, explaining how a "valid email adress" should look like.

> but please also think of the work a new/changed UI string causes for translators!

;) yeah

Thanks for the review.
@nursix : Is this not a temporary fix?
If no shall I close the PR?

I think there isn't really anything to fix here - IMHO, and for practical reasons, the chart functionality should be commented out.

@flavour: critical bug fix indeed, pls merge

@michaelhowden Please review

Technically fine, but please clean up a little ;) then good to merge.

done

Good idea, but vulnerable as hell. Must catch invalid inputs, and should not override an Expiry date that has already been set. This script should be in static, not injected - and definitely it should not be id- bound (as ids may change!). Also lacks an option to turn off completely.

But else - like the approach.

Also remember that date fields are localized, so yyyy-mm-dd is not necessarily the right format.

@nursix  Hey, in which file in static should i place the code? Also, for for date-format, can i use switch case for returning different format?

:+1:

I would create a new S3.hrm.js which gets minified into the main S3.min.js

For the date formats, I would lookup using:
https://github.com/flavour/eden/blob/master/modules/s3cfg.py#L62

@flavour : tests failed? New PR?

Look at the logs of CI: This is an issue with web2py site, not eden build.
Meanwhile you can remove the fields unnecessary variable ;)

sure :+1: 

5 commits should be compressed to 1

Do you want me change anything? Can this request be integrated?

My comments haven't yet been considered - i.e. moving the obscure languages (Albanian.Filipino) to the EVASS template

I can fix that post-merge, though

@nursix Hey, this checks for valid days difference (Integer and >=0). Also doesn't override if expiry date is already set (during update). And also checks for the date format.

Does not check for invalid input in date, does still overwrite the user input in end date when the user changes the start date, config parameter validation shouldn't happen by the getter, but by the applier function, and it seems to me that the datepicker might already give you the functionality to extract the Date so that you do not need to parse the format yourself?

Renaming a variable inside a function (r=request) is an inacceptable antipattern, especially renaming into a much more obscure variable name.

@nursix Hey, I've disabled the updation in case of expiry date already is set. Also used DatePicker for changing formats.

This is a very questionable edge-case - something that can only happen if you first do something terribly wrong: enable DVI, create a morgue, then disable DVI.

Generally, once you have created data in a database table, you can not simply deactivate the underlying model anymore - because that necessarily compromises the database referential integrity.

Any data in a module can be referenced by other (still active) modules - and thus every module becomes /required/ as soon as it has data. If you deactivate it, thereby denying access to the referenced records, then you have made a mistake.

And since that mistake causes an integrity issue I think the system should crash rather then hiding the problem - because integrity issues can potentially cause data loss and seriously damage the data.

Besides, catching this one here will only delay the problem a little bit. There are at least 3,546,237.35 other places where it would still crash.

Okay :+1: 

> There are at least 3,546,237.35 other places where it would still crash.

Quite Precise ;)

I closed this Pull request because code has been merged with New size for .button-home request.

I closed this request and opened Added Skills for EVASS template request.

"We can’t automatically merge this pull request."
It must need rebasing

@flavour Hey, Please Review

Which one is for GCI ?

Ah, we're about to have the first trial of the "round trip" from edengci into eden. Would like to hear comments on the process, as well as the code...which is supposed to have been fully reviewed.

Whoops, procedure wasn't followed. The edengci/eden staging branch was supposed to have been renamed.  I'm going to close this and redo it.

@ptressel closed the pr :)

3 commits to compress -> 1 :)

Or, no, I'm not going to close it -- I can't -- GitHub is not offering me a close button.  Looks like Arnav A. will have to close it, or we'll have to break the procedure this once, and continue with the PR on this branch, thus freezing GCI submissions, which is what the documented procedure was designed to avoid.

done.

"We can’t automatically merge this pull request."
- must need rebasing

Hi Fran,
what do you mean with "We can’t automatically merge this pull request." ?
Why need to rebase? Has code level changed?
Please, let me know.
Thanks.

This is the message GitHub gives me. I guess the code changed somewhere, yes...not obvious to me where, but we got this before when you compressed...perhaps the it.py as that has the most changes...but we wouldn't have changed that here.
Anyway a clean rebase/compress should hopefully resolve it.

Your it.py has a lot of strange entries...looks like you're trying to translate LatLons?
'-0.055': '-0.055',

hmm,, they're in my copuy now too...I will clean these up...but I can't see how they got in except from your branch as I don't update this file

I cleaned up some other errors in the file it.py, so rebase with that

If I run a git rebase master command I get the message "Current branch master is up to date.". LatLons have not been translated, they appear in it.py file because they were in .xls files that have been generated from Administration > Translation > Select Modules which are to be translated.
I deleted the old branch Skills that had it.py, may be this help.
Could you please, try again to merge?

Still says 'We can't automatically merge'
Maybe you need to update your master branch before the rebase?

I will split this request to other two different requests; one for it.py and another for other files.

This needs a lot more care...please don't just wipe what was there & replace...please only make required modifications

@nursix So, should i add a select widget with the above option and also have the end_date selector but which is disabled ( visible but can't edit ) but gets updated dynamically according to what the Duration is? And if the duration is selected as "enter date", then its not disabled anymore and the user can enter his/her own end_date????

@nursix : notnull=True is used at many places, why cant we replace all of them with IS_NOT_EMPTY() ?

notnull = True is good when all deployments have the same settings...DB-level constraints provide most security. However if it can change based on a deployment_setting then we should use the softer IS_NOT_EMPTY()

@flavour : I found 1 more similar one, can I somehow add to this PR? or a new PR?

The one is not a replacement for the other.

notnull is a database constraint that requires a field to not have the value NULL. NULL is a special value that, unlike in Python, doesn't match anything (e.g. it matches neither True nor False), is not consistently sortable, can not be aggregated, does not join....therefore, keys for example (like id, or uuid) must not be NULL. 

However, a notnull constraint means that the database wouldn't accept NULL values, but it does not prevent a form/record with a NULL value from being accepted by Eden - and that is a problem. Since postgres halts db transactions upon db errors (instead of skipping invalid record), this would break bulk imports. Therefore the requirement to /additionally/ secure a notnull constraint with an IS_NOT_EMPTY validator so that the form/record can be caught by Eden before it hits the database.

Unlike notnull, IS_NOT_EMPTY is enforced /before/ a form/record gets accepted by Eden (one level higher up), and thus effectively prevents notnull from ever being hit.

But then, IS_NOT_EMPTY is a bit more than notnull: while notnull would still accept empty strings or such consisting merely of blanks - IS_NOT_EMPTY would not. Thus, for enforcing a non-empty name in a named record, IS_NOT_EMPTY is not just a choice, but necessary.

But since it prevents notnull from being hit anyway, we can avoid disturbing existing databases by introducing a notnull constraint (because changing such a db constraint requires a db migration). But a db migration is also required when you remove that constraint - so changing notnull in either direction must always have a good reason (and ideally a migration script).

The same thing applies for unique vs. IS_NOT_IN_DB.

Or, in short:
1) where there is a notnull, the MUST also be an IS_NOT_EMPTY
2) where there is an IS_NOT_EMPTY, notnull may not be required
3) changing notnull should be done with utter care as it requires db migration (regardless whether it is removed or added)

:+1: Thanks :)
 I found 1 more similar one, can I somehow add to this PR? or a new PR?

I can't answer that without seeing it ;)

Generally, you can go through and make sure that notnull never stands alone, but is always accompanied by IS_NOT_EMPTY. For all other cases, you will need to ask.

Btw: COUNT(1,2,NULL) gives 2 not 3 - which is another reason to not allow NULL in certain cases.

...new PR, since this one is closed

yeah done. I was trying to restore and stuff but unable to :p. :+1: 

NB There is a traditional requirement that notnull-fields always should have a default. Hence, fields for which you can not establish a default should probably not be notnull, but rather IS_NOT_EMPTY.

I think that is a very simple guideline.

Yeah got you, I think I got confused because s3 framework gets a reqd field both by notnull=True and IS_NOT_EMPTY(). But now understood :+1:  

Boolean fields, by contrast, should rather be notnull and always have a default - because NULL matches neither True nor False. That is even more true in web2py which stores bools as strings.

I'm sure many models would need correction for such aspects, but as I say: very carefully. Always remember that there are live databases which may be allergic to changing constraints, and could suddenly cut off users from upgrades. Every data model change must therefore be weighed for its benefit vs. harm - can not just be a matter of principle.

:+1: Makes sense to me.

Okay :) Thanks, got most of your explanation but if taken an overview we are implementing a str() method for datetime objects then why cant we just call the method and equate it with expected and unexpected strings and assert accordingly.
Btw still didnt got why are we taking a table?

Also in your tests probably you should add tests for separators (/ and .) and same date.

@nursix , Hey, removed the usage of S3DateTime. Please review.

Thanks...I merged manually with a few cleanups (the Warnings at top were out of date with code & a few too many Strutturas capitalised ;) )

Thank you so much Fran.
Merry  Christmass !! ;-)

Likewise :D

@nursix , Done, moved it in the table defination.
Thanks for your feedbacks :)

@flavour , removed the widgets and selector variables.

I think you did you work here - don't want to be too petty about the JS style...

...but there should be a blank before and after + ;) 

...I mean, next time...

Really ;) I know we are a pain in the... at times.

Lol, its okay ... no problem ..  i will change it :)

@flavour I have hardcoded the selectors for now.
@nursix  Added the space before and after the + ;)

@flavour @nursix Please review

@nursix , Added it to S3DateWidget. Please Review.

No time right now - I'll be back on Tuesday, and if it's still open then I 
will review.

Regards,
Dominic

fredagen den 19 december 2014 05.16.49 skrev  Gaurav Mittal:

> @nursix , Added it to S3DateWidget. Please Review.
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/1000#issuecomment-67636494

@flavour , Hey, can u review?

Yay, thanks - is this a sign that you're getting better? :)

If anyhow possible, we want to avoid tables to be instantiated in the model. This particular case does not need it - the widget should return the file (this has been discussed before). Relying on specific request parameters is not possible - nor can you specify a widget-specific validator at the model level as either will break in non-interactive requests and imports.

Could you describe what this is supposed to implement?

Allow represent links to open a 'Map' in a div, rather than a popup window.
Moved the l10n query into a custom lookup row.

@hitesh96db Please make sure the represent_row does work from fake rows (as that is used by S3LocationSelector.represent for yet-to-be-created rows). Those shall not be displayed on a map, though, since the selector widget embeds a map anyway.

Okay thanks for the review I am looking into previous commits.

Just started being able to drive. Mostly back to normal :)

I get what you are saying. Also I see that ImageCropWidget is not working for inline-forms. Okay :+1: I'll see  

S3HierarchyWidget and S3LocationSelector may provide some guidance if you are going to dive deeper into this matter.
Anyway, your fix was actually fine, no need to close the PR - just maybe instead of adding another sub-condition to the "if", update the doc-variable instead.

@nursix : After this line https://github.com/flavour/eden/blob/master/modules/s3db/doc.py#L405 there should be:

```
        doc = form_vars.file
```

doc variable is set in the if condition before. Please correct me.

@nursix Please review 

This is a GCI student sending PRs to the wrong repo - please close. 

done

This looks great, thanks :)
The bit that I'm not clear on is the 'working with fake rows'?
Has that been tested? I'm not sure what is reqired to get that working...

@flavour : Well, then shall I merge the nickname with the firstname because else it ignores it
Also is that commented code required.

I wouldn't merge nickname with fitrst_name, no
Basically the only way to m,ake use of nickname would be to add that field to the data model and I've seen nobody ask for that yet so I see no reason to do that yet

What about the todo?

And also at present if a name is given "Jonathan "John" A. Smith", then John is not stored anywhere?

The ToDo has a question mark...it's a reminder that if we have a need for this then it can be read here.
Currently no need, buit I still see value in retaining the info that this data is accessible here

Correct, it won't be stored...but I don't have any users complaining about this...how many people enter this format into fullname fields?

Not many for sure. :+1: Thanks for review.

Yeah, I've tested it and I've taken care of the 'fake rows' so that shouldn't be a problem now ;)

So, I'll go with the cleaner variant then, i.e, define a "inline_represent_row" that does the lookup of l10n and paths, and then calls the represent_row.

Also, l10n_languages wasn't defined in some models.
@nursix I think "inherited" should also be added to the fake row ?(set it to False ?), or else if I select co-ordinates on the map, it shows as "ID : 0" after validation.

Hi @vipulroxx , please stop sending PRs to flavour/eden. We have edengci/eden set up for GCI Tasks. @flavour / @nursix, please close this PR.

ramdesh: Sorry....wrong repo

Needs fixing + cleanup.

@nursix Please Review, Also What should i give the default value for the interval? 1 Year?

@flavour done

Sorry - what am I reviewing here? Description/screenshots would be nice.

Is it possible to avoid the name spill into the global scope in s3.datepicker.js?

I don't think we want an extra Field here - and that makes it much less (re-)usable. A pure client-side widget that can just be added to one of the datepicker fields would be a lot better.

There's a lot of JS in the global scope without need - should really be encapsulated and only executed when needed. The Date prototype extension maybe nice, but we don't really need all that globally and all the time - in fact, it's not really visible or reliable, so it can well be local.

Careful with hiding the whole form row like .parent().parent() - that breaks easily with different formstyles (you may end up hiding the whole form ;)). Better to just operate on the widget.

I like the approach via interval selection better than the mere automation of end-date - but this needs a bit more work.

Besides: do you imagine to add a way back from "set date" to "select interval"?

@nursix Thanks for the feedback. [1] is the screenshot for when the person selects a predefined interval ( i.e Not "Enter end date") and [2] is the screenshot for when the person selects "Enter end Date".

[1] -> http://picpaste.com/Screenshot_from_2014-12-31_01_26_07-hjlmbssD.png
[2] -> http://picpaste.com/Screenshot_from_2014-12-31_01_28_45-hNGLKIca.png

@nursix , You mean that if we manually enter end date say 6 months from start date, the interval value gets selected to 6 months??

I think the nicest design for this would be to make this a datepicker plugin, and add the buttons for interval selection directly into the datepicker widget ;) This looks cool, and gives optimal visual connection and feedback.

Think the normal datepicker widget (=the calendar) with four or five additional buttons at the bottom like "+6 months", "+1 year", "+2 years"...etc., and when the user clicks any of these, the calendar automatically jumps to the target date. So the user move freely between date selection (using the calendar buttons) and interval selection (using the interval buttons) - and sees the result right away.

Something like that - just brainstorming. Widget design is hard - and doesn't really start with code.

For the plugin-technique with UI widgets see multiselectfilter - relatively simple, and perfectly encapsulated.

Thanks for the screenshots - this looks nice, but is a bit fragile implementation-wise.

I think you've understood the idea pretty well - now let's figure out the best way to implement this.

So, for normal user(!=admin) - He should see the recipient tab but not the add recipient button? @nursix 

@nursix , Regarding the datepicker plugin, wouldn't that dismiss the ToDo in the first place, as the user would still need to manually select the end date (but will have a few helps in the datepicker widget to navigate i.e the buttons to jump to dates). We still need total automation right? 

Also this would create the same problem as the previous one, i.e that the user would like to verify the value generated and indirectly will be calculating the end-date

No, they should not see the "Add Member" link inside the Add Recipient form ;)

But yes - since there is a "Select Recipient" tab, the "Add Recipient" button seems a bit redundant too.

Nah - not really.

As I say - the primary objective of the "ToDo" is to help the user enter an end date when he has only start date and interval. If you have interval buttons inside the datepicker widget, you do exactly that - while you also show the user the resulting end-date /without/ switching the widget or input field. 

If you will, yes, it means that you just add an end-date calculator tool to the existing datepicker widget - so the user does no longer need to calculate it manually.

At the same time, there /may/ be some cases where the user actually has an end date - and then he could just enter it, using the day-buttons in the date-picker widget instead of the interval buttons. Again, without switching to another widget (=no additional click).

Total automation is actually much less important - but of course the widget could set a default end-date either when the user first sets a start date (implicit default), or when he first opens the end-date widget and it doesn't yet have a date set (explicit default). 

IMHO the latter (explicit default) is preferrable - as the former means you have to explicitly remove the default if you don't want to set an end date (which is seen as a UX anti-pattern), but we'll see how that feels like in practice. 

Defaulting that to start-date plus one year seems reasonable.

NB Sometimes the reason for a ToDo is that the requirement/idea wasn't mature enough by the time the original feature got implemented, yet it was clear that "something" needed to be done.

A small and old ToDo is a typical sign of immaturity of the idea ;) hence requires deeper thinking.

@nursix , I see, So basically the layout is going to be same as the one in screenshots but with the interval options in the datepicker widget of the start date as different buttons? So when the person selects the startdate option he sees a widget with interval buttons and the calender for start date. Selecting the date and interval sets end date (which will be hidden as in the screenshot) . Should we keep an option to set the end date ourself in which case the end date widget becomes available?? Is this correct?

Also for the explicit default, what i understood is that if there isnt any end date set, and we select the set end date interval, the end date widget defaults to start date + 1 year. Is this correct?

So what do you suggest - I should check for the permissions and remove the button or not?

No, not suggesting anything - just leave as-is

:+1:

Not 100% how I meant it.

Both start date and end date would be visible as normal, and both would have a datepicker widget. But when the user has selected a start date, then the /end date/ datepicker would additionally have those interval buttons to allow selection of an interval relative to the start date instead of picking a day.

When the user selects an interval, the datepicker would jump to the corresponding day (and select it), but of course the user can also pick any other day "manually" (instead of selecting an interval).

No additional field needed, nor hiding/showing of form fields. It's just an extension to the existing datepicker (implemented as a plugin).

Additionally, when the user opens the end date datepicker for the first time, it could automatically select a standard interval, so that the user can just accept it (=explicit default).

Thanks :)

Question: is there any point whatsoever with these year numbers in the copyright?

...apart from the obligatory New-years-commit, I mean?

I know I started it - but I don't really know why... :$

So, Should those be removed ?, I guess that's better, no need to update it every year ;)

No no, all good. I wasn't that serious ;)

@nursix done

ok :+1: 

Sometimes (I said that before) a ToDo is a sign for an immature idea - and hence it should make sense to you before you action it. The general rule in open source programming is "change the code if you can improve it" - not change it because you can change it ;)

Sorry for that :p , I actually thought I'll ask flavour for that on IRC but he wasn't around. 

I am a bit uncertain about the is_affiliated-extension of the business rule here: what does it mean? Do we only check permitted facilities if the user is affiliated with an organisation? Can't quite make sense of it yet. An explanation would be nice.

My feeling is that there must have been a reason why it had not been done before despite available - if it would have been /that/ simple, then it wouldn't have been a ToDo.

Okay one doubt: mpr module doesnt have its table definitions in s3db, is it not intended to make one or the module's not in use.

mpr is an extra perspective of dvi, not a module of its own.

Ok. :+1:. No answer to the previous comment Sorry. ;)

i.e. it doesn't have its own model, but uses pr and dvi models.

Generally, you can consider controller files as "perspectives" (or use-cases) rather than as "modules" - Eden isn't really modular in that sense. Some models have multiple perspectives, e.g. doc and gis are ubiquitous, supply is used both for req and inv (but has no independent use-case), stats is a meta-model, as is sit. 

And there are also perspectives which extend others, and do not necessarily need any additional model of their own: mpr extends dvi (no extra model needed), vol extends hrm (minimal extra model), ...

NB Are you GCI contestant, or Sahana volunteer? Just wondering why you're trying to action arbitrary ToDo's.

Sahana Volunteer.

Rami, Arnav K A --

I'll be back in Seattle later today so can help w/ any remaining cleanup then.  We should make a note of what we missed in reviews, so we can look for those things in future reviews.

Don't squash the student commits -- want them to have their names on the commits.  Can put all our cleanup in one commit, though.

Also think about the process, since this is the first time we've tried a separate GCI repo.

Sorry, but this is nonsense - the "answer" field needs to be developed to store multi-type data.

I am currently working on this module, which is why these are "ToDos" - but they are to myself, not meant to be actioned. See status-tag: WIP

Oops :( Sorry.. I wasnt completely sure about that .

I would request this to be left alone for now - I'll remove the status tag once I'm done with this.
Fine if you want to experiment with it, though (which is why it is shared in trunk)

Sorry Sorry , I m trying some other todo

No need to apologize - it's not obvious.
But it's an incomplete implementation that needs development - no just "fixes".
I wasn't quite sure whether "answer" should become JSON, but that's the most likely solution - I left it a ToDo, so that I can find it more easily. However, there's a lot more to do here than the ToDos alone - this needs a widget, a representation and reporting capability - so your "fix" isn't really helpful, even if with good intention.
But if you want to experiment with XForms, then this is certainly something you can work with - input and feedback welcome.

Tip: best you start with ToDos where you are certain about the meaning.

Sometimes (or rather often) they are not meant to be executed "by the word", but actually require more in-depth thinking and development. If it was that easy, then it wouldn't have been a ToDo ;)

Thanx @nursix  for your suggestions . I will surely implement that :+1:  :D

Implement what? :O 

Implement your suggestions :P

@flavour - https://github.com/edengci/eden/pull/69

Fran -- Thanks for the comments!  Rami, Arnav -- Let's figure out the best way to get Fran's changes in.  Would be good to let each student fix their own work -- is that feasible?  So long as the number of students involved is small (and it is), then there could be one additional commit from each student with fixes for their own sections.  (There are other options that still retain the students' names on their work, but they're a bit more complicated.)  Alternatively, we could do one pass with the fixes, ourselves, but that has the disadvantage of not letting the students learn from the comments.

Sounds good :)

I wasn't certain if they should be on the repo or not. My thought was that putting it there gives a record of what was produced before any changes, obviously I can do that locally but any record of what was produced before any code changed would be lost and so it would make it harder for others to check the changes. So by putting them in the repo I'm trying to make it easier for reviewers but maybe that is not necessary.

The PDF files are small enough to include if you wish to have them there and are text not binary, so will diff nicely as-changed.

Well the PDF is not a true text file, the contents are hidden in an embedded stream, https://github.com/flavour/eden/pull/1023/files#diff-190e5e45744b7f646a827f4c2f96d217R68.
The generator adds a timestamp here: https://github.com/flavour/eden/pull/1023/files#diff-190e5e45744b7f646a827f4c2f96d217R103 and a unique id here: https://github.com/flavour/eden/pull/1023/files#diff-190e5e45744b7f646a827f4c2f96d217R149. All of  which makes an auto compare between the old file and the new non-trivial.

So I might be putting forth arguments against putting it in the repo.

@nursix , I still have to inject the script in a seperate file, This is just to verify whether the functionality is correct or not.

So, initally the end date is set to one year ahead of start date. The user has an option to clear this if he wants a permanent credential. this can be seen in [1]. Next if he changes the start date, end date changes with 1 year as an interval. If he puts his own end date (or clears it), then end date wont change if start date is changed

Next if he opens the end date widget, he sees [2]. Here he has an option to select the interval. Selecting any option adds the interval to start date and sets the end date. Then if he changes the start date, end date automatically changes according to the newly selected interval.

[1] -> http://picpaste.com/_1_-rGkD7ukx.png 
[2] -> http://picpaste.com/_2_-v2QBy0Dy.png 

@nursix Any suggestions?

The separator was not added. The hard-coded '/' was replaced with os.path.sep; which I felt was safer - It was failing when run in Windows. Until I could invest more time, which I would like to do, I didn't want to rewrite this function. To properly check any changes to this function I would need to extend the test, and run it on both Windows and Linux.

Just saying that adding OS-specific separators is the actual point of os.path.join ;) so no need to add any separator to the path components ;)

Yup, that does what I had in mind - except for the explicit "clear" instead if explicit default (it should be blank at first, and default on click, maybe make this an option). Styling can of course be improved, but shouldn't be the initial focus.

Now you need to move and clean up the JavaScript - ideally, as suggested before, into a datepicker plugin, and only inject the options. Let's make sure that we do not hardcode any element IDs or relationships, and avoid globals (full encapsulation).

Good work so far :)

@nursix done

@nursix , Hey, so should i put the js in s3.datepicker.js ? or create a seperate file and inject the file from the python script?

@nursix : done.
Doubt: Whats the difference in these three --> 
1. using limitby(0, 1) and rows[0]
2. using .first()
3. using both limitby(0, 1) and .first()
Thanks.

s3.datepicker.js is fine

To answer the question:

rows[0] is the same as first() except that it is not fail-safe. If no rows are returned, rows[0] will crash, while first() will return None. So, either you explicitly check len(rows) before using rows[0] - or you use first() (recommended).

Secondly, if you intend to only ever use the first result, you should use limitby=(0, 1) - for efficiency. Otherwise the database will try to find and return /all/ rows, unnecessarily. 

The tightest bottleneck herein is the DAL converting the DB output into Python objects - this takes a lot of processing since values need to be parsed and converted, so any unnecessary row extraction should be avoided.

And as a more general efficiency/performance guideline: never handle any data that you don't need, only ever do just as much as is absolutely required for the operation.

That ^ is btw also a /security/ guideline ;) (not touching anything that you don't need)

The way to import from controllers.py would be to use this trick:
https://github.com/flavour/eden/blob/master/views/generic.xls#L5

Moving to a module not only avoids the potential memory leak (which the original link described clearly as only being an issue with a 'del' method, but still avoiding executing them is good as someone /could/ unwittingly add such a method later) but also about caching (modules are not reloaded every request except in debug mode).
Of course, this isn't critical.

Not quite true - imports into the exec environment will be removed when the exec-environment is destructed so there is no caching advantage here ;)

...but a module would be compiled only once (whilst config.py is compiled every request), and then byte-code executed - which indeed saves some processing. Question is whether that is faster than the constructed exec - or at all relevant.

The clean, pythonic solution would be to treat config as a module (and the template as a package), instead of executing it, which is possible with some refactoring (we do e.g. handle template menus and layouts as modules rather than executing them).

I think the critical thing here is not to hardcode the application name - the rest may belong into a wider problem area with the current template framework.

Looks ok to me.

IMHO we have way too many function and class definitions in config.py - which should ultimately lead to a framework change. Either we move templates into modules/templates thereby allowing direct imports, or we treat templates as packages and config.py as modules (i.e. importing them rather than executing them). The former is easier (and a lot cleaner) - whereas the latter is somewhat "softer", with a lower learning curve and friendlier for downstream projects.

What's your opinion Fran?

This is indeed a question of re-compiling config.py on every request - not so much about the (slightly far-fetched) risk for memory leaks. If we look at some templates, then there are thousands of lines of template-specific code in config.py - and that's actually intended to be possible.

Friendlier to downstream seems good to me

For a gradual shift, though, we could simply introduce modules/templates for template-specific modules, and leave the config.py execution as-is yet gradually moving the classes and functions into the modules folder.

In this case, it would mean to move the subscriptions() class into modules/templates/ssf.py - and then import it in config.py like:

```
from templates.ssf import subscriptions
```

That would be both downstream-friendly yet clean-pythonic - and it would even allow re-using the same functions and classes across templates (something we wanted for some time already).

The learning curve seems low for this solution - the mere settings.xyz = value would remain in config.py, and we have all the time in the world to migrate bit by bit as we find the time, without pressure.

If you agree, I would start this (once you have merged this one).

The disadvantage here is that it splits a template even more...from 2 folders (private/templates/x & static/themes/x) to 3

Very true - but is that a critical problem or just an inevitable trade-off?

Some more thinking to avoid the issue would be good rather than rushing to action this as-is.
We already manage imports in controllers/menus from private...can we not use the same trick for config.py?

Unfortunately, this would require a refactoring of all config.py's (not impossible, but a fair bit of work).

Since we attempt to access a current-variable (settings), we must move all config.py settings into a callable (either a class, or a function), then import config.py and then execute the callable.

Not sure whether downstreams can deal with such a change (it's not too hard, but at first prevents a simple pull-upgrade) - so introducing an (optional) modules/templates/<template>.py as a start seems a bit nicer.

Alternatively, we could introduce a fallback. If we change the name from config.py into template.py, where config.py is "old-style" (=executable script) whilst template.py is "new-style" (=importable module), then we could look for template.py and if it's not there, then execute config.py as we do now.

New templates (or migrated ones) would then be written in template.py style - whilst old templates would still work.

A new-style template should then look like this:

```
def config():
    settings = current.deployment_settings

    setttings.xyz.abcdef = "something"
```

We would then import and execute this like (via a constructed exec):

```
import applications.<appname>.private.templates.<template>.config as template
template.config()
```

With this style, theoretically (if that makes any sense to you yet), you can define template globals and access them from everywhere. For example, if template.py would define a function:

```
def example(x, y)
```

you can later access it like:

```
template.example(x, y)
```

...without a need for a setting. So the hooks could introspect the template dict instead of calling S3Config, which is a fair bit faster (and cleaner).

...but of course it makes templating a bit harder since you couldn't just introspect S3Config to find all possible hooks ;) so, this is purely theoretical.

But - and this is where it really comes nice...

...you could have more than one config's in your template, e.g. different configs for different orgs. You first execute the common parts, then run sub-configs per org. That would be fantastic e.g. for the IFRC template - a lot less if/if/if to execute for every request just to determine the right config for this particular org.

...i.e. less processing in the hooks (e.g. preps) - the prep would already be org-specific.

Yup, tested with default - works fine. So, the requirement is to move the template's config into a callable (I used a function as described above). Fallback for old-style configs can be implemented, so that there's no urgency for downstreams to migrate.

Anything that speaks against this mode?

> We would then import and execute this like (via a constructed exec):
> import applications.<appname>.private.templates.<template>.config as template

This means that we're not caching though since we need to do this via exec()
This is what we're currently doing with menus.
Can we add private/templates to the Python Module Path?
If not, can we avoid this by moving the whole private/templates to modules/templates?

> Unfortunately, this would require a refactoring of all config.py's (not impossible, but a fair bit of       > work).

From what I see this appears pretty trivial to me...I'm certainly happy to do this.

> Not sure whether downstreams can deal with such a change (it's not too hard, but at first prevents > a simple pull-upgrade)
> Alternatively, we could introduce a fallback. If we change the name from config.py into template.py,    > where config.py is "old-style" (=executable script) whilst template.py is "new-style" (=importable           > module), then we could look for template.py and if it's not there, then execute config.py as we do   > now.

This eases migrateability for templates which aren't in trunk but implies changing a lot of docs.
I'd prefer to attempt new style & warn about the need to migrate if not new-style (as I say, the migration seems pretty trivial & I'd be happy to help individuals)

> But - and this is where it really comes nice...
> ...you could have more than one config's in your template, e.g. different configs for different orgs.   > You first execute the common parts, then run sub-configs per org. That would be fantastic e.g. for > the IFRC template - a lot less if/if/if to execute for every request just to determine the right config   > for this particular org.

I can certainly see some benefits here, although the per-Org differences aren't always settings.xx so we won't remove all of the prep changes here, but can remove a few.

Moving the whole of private/templates into modules/templates would be useful (as it would allow in-template imports), but doesn't solve the need to put the template config into a callable - so this would still be required.

Changing the Python module path from inside the application seems a bit unsafe to me (interfering with the custom importer) - and would prevent the custom importer from auto-reloading. But sure, we can test it.

I would though prefer to stick with the modules path - as that's a lot more logical and doesn't require any additional "tricks". Why are templates in private anyway if they are meant to be in the repository? I never really understood this.

Btw - attempting to first import config.py, and then look whether it is old or new style involves a certain risk to the global namespace (because the config.py's we have would import, but execute illegal assignments at the module level).

Better to give new-style configs a new name - and fall back to config.py if no new-style config present.

...however, it can be done that way of course. Just a bit risky.

But _what_ we can do is to combine the migration with the move to modules/templates ;)

If the template is in modules/templates, then we expect a new-style config.py - whereas if it is in private/templates, we would expect old-style.

I appreciate that this requires a lot of docs to be changed ;) happy to help with this (need some guidance, as I am not so familiar with the docs).

But it would allow a gradual transition rather than all-at-once.

ok, so I think we're getting ready for a comms to mailing list on a plan...I don't think it needs a BluePrint:
(1) We are moving private/templates to modules/templates so that we can import template-specific modules without needing to use exec => can cache
(2) We are restructuring config.py as a module so that it can be cached & doesn't need to be compiled every request
(3) We will migrate all existing templates in trunk
(4) Non-trunk templates will still work fine through a legacy-support option, although we recommend that they are migrated to the new location/structure (we will provide docs on this)
(5) We will update Docs (Wiki / Book / Slides)
- assistance welcomed :)

Does that look right?

All we then need is a timetable...I suggest we make the change 48 hours after the communication.
I can merge the core code from you, along with a template of your choice to prove it, & then migrate the templates before I push to GitHub (I know I don't need to do /all/ of them but I would rather do so).

F

Fine by me - I'll do the core code, and you can expect me to do default and skeleton to document the intended pattern, and potentially EVASS for testing (and as downstream-support). 

48 hours seems fine for me, gives me some time to test it thoroughly and iron out some path dependencies (e.g. prepop, views).

But now you can certainly merge this one now, right? ;) before we forget about it accidentally.

@nursix , Please Review
I was thinking that for the default, it should be the one as above (i.e initally it should be one year and not blank) because, if he wants blank and default is one year, he can simply click the clear button and be done with it. But if he wants  1 year and default is blank, then he has to click on the end date and then somewhere else to hide the widget. Therefore , in the first case, only one click is required and it is easy as the method to clear is clearly visible. But in the second case, two clicks are required. Therefore I think that by default, it should be one year (i.e end date based on start date) and not blank.

+1 to maintaining the 1 year default

Well, to me that depends on whether or not the majority of instances have an end-date. If the normal case is "no end date", then an implicit default is nasty (as most of the time the user would have to remove it).

If we only look at credentials, and it is indeed true that the majority of credentials has a validity period of 1 year, then that may not be a problem.

But for a generic plugin I would make both options of the plugin: whether to set a default upon initialization, and what time period. Both options can well default to what Fran says - yet this should be options.

And if you look at all the things which have start/end date combinations, then I doubt an implicit end-date default is always useful.
However, I appreciate that you wanted to solve this particular case, so you can make this a ToDo

NB I do have a use-case for this plugin where the implicit default isn't nice: RDRT deployments.

While the users want to be able to set the end date from a time period (and hence this plugin would be a useful UX enhancement), they can not set the end date when initially creating the record, because by that time the period is usually unknown.

But once the member is deployed, the record would be updated with a deployment role and with a (prospective) end date - and then a period selection would be helpful. However, not the implicit default, in this case.

@flavour: ok, core code complete - ready to start the migration whenever you're ready.

My +1 for 1 year is for the usecase...i.e. this should be a configurable option for the widget.
I agree that the widget default should be blank

I put the email notification out today. Let me merge you tomorrow morning & work on migrating modules/updating docs through the day

Ok!

@nursix , Please Review.
I have set default to blank as u suggested.
Also added a Todo to make an option to set implicit default.

@nursix Any other suggestion?
@flavour Please review

haven't had enough time today to review, sorry. Hopefully tomorrow.

@flavour : Can you please merge this.

Fix at the wrong end - this was just changed into fieldname as "label" isn't standard. Please fix the corresponding controller.

If you change it back into "label", it will not work with e.g. org_site_search_ac and org_search_ac. So, either you fix /all/ search_ac's to use "label" (then you can hardcode it) - or you fix the particular search_ac that uses "label" to use the fieldname.

To me, fieldname is more consistent and less fragile.

...less fragile because the ac handler allows to extract additional fields - and hardcoding anything would allow name collisions, whereas fieldname would at most "collide" with itself ;)

Like this: https://github.com/nursix/eden/commit/26f4d3a7a68844321510f29b7a38a3f70d46ffd9

Okay :+1: 

I think the problem here is the inconsistency between all the different search_ac's (implemented by different people). Using the fieldname is more or less intuitive, and obviously how most of the devs interpret the overall concept - so let's just stick with this for consistency reasons.

Thanks however for pointing to the issue, I had stumbled over this some time ago, but apparently didn't see the whole picture then.

Yes - he can, just give him a few more hours. If you're looking for GCI points, consider this done.

Shall I revoke my commit, so you can update this PR?

...this would give you a trunk commit ;)

Err...not quite the same thing, is it?

Should be like:

```
record = {"id": row.id,
          fieldname: row[fieldname],
          }
```

...and remove the JS changes.

Hold on: This time I need to apologize. Sorry!

Apologizing again? :D

@nursix :done.

Good :+1: ready to merge.

Well @nursix , I am not a GCI student ;)  

...ok ok, bear with me - just feeling stalked by this sometimes ;) no offence intended

Looks fine to me :+1:  good to merge.

But out of curiosity - is there prior art for this slightly-over-the-top inteospection? If so, then it should perhaps be defused a bit. It's a bit like putting on a hat with a crane ;)

@nursix Please Review

...Tip: a possible alternative to injecting widget options is to bind data nodes to the DOM. However, that's a bit weak since DOM objects often need to be manipulated (or newly created) on the client side, so it could get lost.

Example of a jQuery UI widget using widget factory:
https://github.com/nursix/eden/blob/master/static/scripts/S3/s3.ui.hierarchicalopts.js#L12

...and how it is injected:
https://github.com/nursix/eden/blob/master/modules/s3/s3widgets.py#L6285

There are many more examples in static/scripts/S3 and static/scripts/ui - some are less, some are more complex. Datepicker itself is a UI widget. The principle is always the same, so there's plenty of examples...

Example of a jQuery function (not a UI widget, but still well encapsulated):
https://github.com/nursix/eden/blob/master/static/scripts/S3/S3.js#L1282

...and how it is injected:
https://github.com/nursix/eden/blob/master/modules/s3db/req.py#L638

This wouldn't have the this.element context, though - so the widget pattern seems better for this case.

@gauravmittal1995: ^ I think the above two comments will help you

@nursix  and @raj454raj : Thanks :)

Ouch - that's what I call an ugly hack ;)

Seriously?

...after all the pointers I gave you :( bit disappointing. You can well better than that.

@ptressel I think we should get the students to do it. I think the recent move of the templates is going to affect this though. Thoughts? 

I have send a PR with my fixups, if anyone is free please review it. Thanks
:)

On Thu, Jan 8, 2015 at 1:01 PM, Ramindu Deshapriya <notifications@github.com

> wrote:
> 
> @ptressel https://github.com/ptressel I think we should get the
> students to do it. I think the recent move of the templates is going to
> affect this though. Thoughts?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1015#issuecomment-69145258.

The CSS fix here seems to be needed with Admins using small-width screens - as this is happening for you because there are too many top-level menu items for the width of your screen.& so it wraps.
This issue wouldn't happen for nopn-Admins (as they have less top-level menu items) or for users with wider screens.
Other (normal) users will see a negative from this change as the menu buttons will now be smaller/less easy to read.
The whole NYC template is being revised imminently anyway with less modules activated & the theme will restart from default (i.e. Foundation) so I don't see it as critical to fix.

Thanks for the DRMP catch, which I applied manually :)

Yes! - Is this how you wanted it to be? @nursix 

Yes, thanks.

@flavour: good to merge.

@nursix Please Review

I think you've mixed up resources a little bit here.
1) The action button to download a translation is in the table of translations.
2) You bind the method handler to the template - and pass the template_id to the URL (which would be the same template_id for all rows in the datatable)
3) Consequently, when the method handler is called, the resource would be survey_template, and r.id would be the template ID - and no clue /which/ translation is to be downloaded
4) Yet you (wrongly) use r.id as translation ID
5) The method handler is bound to the template, but in the translation model => but method bindings and table definition must be in the same model

Correct would be:
1) Bind the method to survey_translation
2) Use "[id]" in the action button to pass the translation ID to the method handler
3) In the method handler, use r.id (now the translation ID!) and r.record (the translation record!) to find the template ID (=r.record.template_id)

Also make sure you do never just "redirect". Leave the handling of errors to r.error() and pass a proper error message (so the user knows what was wrong).

Besides, a method handler should always return the format that was requested. So, if you respond to an HTML request, you shouldn't return XLS.

Consequently, the action button here should add a ".xls" extension to the URL - and the method handler should return an error for any other format:

```
if r.representation != "xls":
    r.error(501, current.error.BAD_FORMAT)
```

Actually, looking at this again, there is an even better method to bind this handler.

Since you're running this from a component tab, you can do the following:

1) Do bind the method to "survey", "template" - but like this:

```
set_method("survey", "template",
                    component = "translation",
                    method = "translate_download",
                    action = "survey_TranslateMethod")
```

(remember to do that in the survey_template model)

2) Set the action to r.url(method="translate_download", component_id="[id]")
3) Inside the method handler, use r.record for the template record, and self.record for the translation record - so you do not need any db lookup inside the method

Note that the class name should be survey_TranslateMethod (not survey_translate_method).

...or actually survey_TranslateDownload ;) I mistyped.

To explain the above: the difference is that now the method runs through the survey/template controller instead of a separate survey/translate controller ;) No additional lookup of the master record required, nor an additional ACL for the other controller.

Further, the method is bound specifically to this combination of records (template<=>translation) - so it would be possible to restrict access to translations of restricted (e.g. unpublished/unapproved) templates - without any additional controller logic.

That has wider implications, btw - the survey module doesn't really implement this, but normally you wouldn't want half-ready or obsolete templates to be downloaded and used (e.g. via mobile apps), so this requires a logic to restrict public access.

The new survey module "dc" which I am currently working on does implement a logic to suppress templates in public form lists (not in trunk yet), so that the mobile client doesn't see templates which are not ready for use yet, or not valid anymore.

And of course we do not want the translations of unapproved templates to be downloadable either.

@graeme-f Am not sure of the status of this now? Should I merge as-is or are you still working on it?

@nursix , Hey, Please Review.
Havent done Namespacing yet, Still trying to find out how to do it.

Hi Fran,

I know that Dominic raised a valid concern but I wasn't planning on any
more changes now. Rather get the tests in place and then I can restructure
the code and as part of that process I will implement and test that change.
So I am happy for the code to be merged. I will then work on the
restructuring as and when time permits (school is back so I need to get
into the swing of that).

Cheers,

Graeme.

On 9 January 2015 at 14:10, Fran Boon notifications@github.com wrote:

> @graeme-f https://github.com/graeme-f Am not sure of the status of this
> now? Should I merge as-is or are you still working on it?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1023#issuecomment-69321595.

@nursix : done.
As you said I can access the survey_translate record by self.record, but by that we can only get the record_id. So still one db lookup. Any suggestions?

Yes, you're right - self.record is the record ID, not the record.

Reason for that is that the framework doesn't know which fields you need in the method handler, so rather than extracting everything, it just gives you the record ID. But at least that makes the lookup very simple - use self.record to extract the survey_translate record (be sure to check that it is not None before you run the lookup).

The main advantage here is that you run the method through the same controller as the master request, not that you "save" a db lookup.

Yeah thanks. Any other modifications?

No time at the moment to review - later.

Sure! :+1: 

@nursix I didnt quiet understand the namespacing. Can u help me?

@nursix : done. :+1: . I will send another S3Method in next PR. I know this getting messed up to review.

Read more at http://api.jquery.com/bind 

Every jQuery UI widget should use its own namespaceID for local event bindings. Examples are in the code, e.g. s3.ui.locationselector.js

@nursix Please Review

@nursix , I am sorry i didnt reply to you on irc. Actually i wasn't online. I use IRCcloud and it lets the user be online for 2 hours after inactivity and thats y u saw me as online.

Yeah just a sec I'll send these small changes and for sure I'll be sending a PR for refactoring once I finish moving to S3Method. My next PRs would be two more S3Method in this module followed by a PR for  refactoring!!! :+1: 

@ranshula, GCI PRs should be directed at https://github.com/edengci/eden 'staging' branch. 
@flavour, please close this PR.

@nursix Please Review.

This will fix that URL but break the more common (at least for me) /project/task/x URLs
We need to detect function & change accordingly.
NB One of the changes was already in a function != project

Ahm - it should actually work just fine for project/task/x? ("task" prefix is automatically detected as master if it matches the master alias).

Yes, ^ I tried that, it seems to work fine

It should, because "~.selector" is equal to "alias.selector" if alias is master.

ok, so I learnt something...but one of the fixes still seems wrong since it fixes for project/project/task yet is behind a function!= "project"?

Question is though whether you really need to prefix it at all - normally, when you configure the filters for a table, it will always be the master table...so why the need for an explicit prefix here?

Just _if_ you prefix it, then ~.\* and master.\* or no prefix is all the same thing.

But I still don't see the point of prefixing in a filter widget configuration (there is actually a reason why you do not need that - the table is defined by s3db.configure(tablename, ...))

But then filter forms won't work when viewed in components like project/project/id/task ?

Because these filters are meant to be resolved with the master "task" table and not "project"

Ahm - actually not: filter widgets are resolved against the target resource, not the master resource - and should automatically be prefixed. This would only fail if the request goes to the wrong URL (i.e. ajax URL misconfigured).

I'll check it. Seems like the wrong fix (but it shouldn't harm, however).

Yeah - as I suspected it: your fix is "correct", but in the wrong place. 

What you do here should actually happen automatically - namely: we do pass in the component alias to the filter form so that it can prefix any non-prefixed selector in filter widgets correctly for the current component:

https://github.com/flavour/eden/blob/master/modules/s3/s3crud.py#L1180

But in this case of "task_milestone.milestone_id", the selector /does/ already have a prefix (="task_milestone"), so it was skipped - which is a bit insufficient logic: of course this must check whether it is the /right/ prefix, not just any prefix.

I pushed a fix for that.

So, @flavour : no need to learn anything new ;) filter widgets do not need a component prefix.

So this PR is deprecated?

No, wait...the other part, that is, removing the "Assigned to" field is required

I'll remove the "top" part of the commit, i.e, the "task" part

@flavour done

Yes. deprecated after you merged the fix I pushed.

If you have the time, it would be good to action some of the ToDos.

It could be merged as a first iteration, unless @flavour objects - but I'd expect some improvements rather sooner than later.

I can megre mid-way if green-lighted, but better to merge something more complete if possible...I see the missing i18n as a pretty serious issue.

@nursix , @flavour i18n done.

I will do some of the Todos (the DRY and the implicit default) as another PR. 

I'm sorry - there's at least a thousand things here that should be changed, I simply can't comment on everything at once. We wouldn't ever get to an end.

So, let's stage this a little bit...
Step 1: move out the inner functions, make staticmethods where possible
Step 2: move the style definitions into a function that returns the style list. Should probably be a lazy property, since the style-list doesn't ever change.
Step 3: Fix naming convention wherever easily possible (e.g. local vars) - make sure variable names are clear (Check: do you understand from the name what the variable constitutes?)
Step 4: Look for opportunities to DRY. IMHO at least half of the code looks like repititions

...and then let's review this again.

@nursix : Okay thanks for review. Working on it!!! :+1: 

@nursix : We want this yeah?
https://github.com/flavour/eden/pull/1034#discussion_r22879038

@nursix  I need some clarification on this:
https://github.com/flavour/eden/blob/master/modules/s3/s3rest.py#L1482
the transform expects a full path ? or a relative path(i.e, from request.folder) ?
If it expects a full path(which I think it does), Is it good(or safe) to expose the directory structure publicly in the url, I think I've read that it isn't good to do so(security issues) ?

I saw that but when i opened the admin page of SSF template that page also work fine .

+1 to making a decision to move SSF template from Bootstrap -> Foundation, although that's bigger than this PR as a decision ;)

@nursix I had a doubt, so asked you here: https://github.com/flavour/eden/pull/1033
Sort of unrelated to this or that PR ;)

Yeah - "working fine" is relative. I think you'll take that back on mobile ;)

The point with grid classes (regardless which of the frameworks) is to be responsive, i.e. have it adapt to screen size.

The "transform" variable doesn't take a file path but a URL. This can be used to specify an external transformation stylesheet, i.e. one that is _not_ located on the Sahana server.
For internal stylesheets, you should actually put the stylesheet into static/formats and then just use the respective format extension (like .odt, .have).

@nursix What if it needs to be template specific ? 
For eg: I want to add more fields in task rss feeds and I want it to be on the server.
Can't I add a template-specific export.xsl ?

You can override r.XSLT_PATH in the prep, e.g.:

```
if r.representation == "rss":
    r.XSLT_PATH = "modules/templates/ssf/rss"
```

...and put your custom stylesheets into that folder.

But at this point I don't quite see why it would be template-specific? What fields were you thinking of?

(saying that because so far Sunflower is the only application using project/task.rss - so it could be a precedent)

Task feeds only include the description and title, so I wanted to add more fields such as status, project, and tag...

@nursix Is it fine if it goes in static/formats/rss ?

I think those can very well be in static/formats/rss!

What I would recommend, however, is to move any resource-specific XSLT in the export.xsl into a sub-stylesheet, and then import it into the main rss (I've done similar things in s3csv/hrm/person.xsl). 

This makes it more maintainable - and if we really wanted to move that into the template at some point, we don't need to rewrite everything.

Okay :)

@nursix 
How does importing prevent rewriting ?
say, I import "project.xsl" in "export.xsl", that href would be w.r.t that folder, so how would you reuse it or prevent re-writing everything if moved in the template ?

Status, project & Tag all seem very generic things to be in the general export.rss

Very easy to see: having resource-specific xsl (i.e. the  respective xsl:template's) in sub-stylesheets which are then imported into main export.xsl makes it easy to exchange just those sub-stylesheets rather than having to dig through a mega-monster-everything-in-one-file stylesheet with hundreds of embedded templates.

So, if we would want to replace the generic project/task RSS - then we could just move your project_task.xsl into the sunflower template - and write a new default one, rather than having to write a new all-in-one export.xsl.

That is btw the main purpose of xsl:include and xsl:import - the ability to modularize stylesheets.

Since RSS is in no way limited to only a handful of resources, but can theoretically be applied to each and everything - and yet every resource has specific needs, we are likely to end up with one xsl:template per resource.

Hence, having only the root template ("s3xml") and the fallback in the master stylesheet, but the resource-specific parts in separate stylesheets makes it a lot easier to maintain.

I don't mind that to be per module, however - i.e. hrm.xsl, project.xsl, org.xsl ... to avoid over-fragmentation (and some parts may be re-usable between resources of the same module anyway). But avoiding a behemoth like person.xsl would be very much what I'd recommend.

@flavour - yes, I would think so. They seem generic enough, nothing template-specific there.

+1 to module-specific format extensions. Per resource isn't required, but a behemoth isn't desired either.

Excellent! Many thanks. Tested with Sunflower I assume?

+1 to merge

Now one could say that base.xsl could be moved back into the master stylesheet ;) but hey...

@nursix, @flavour  Please Review

Ok - I think if you clean up the pseudo-overloading of writeToRTF, then this first stage of cleanups is done. Looks a lot better already, doesn't it?
Before you proceed with the next round of improvements, consider maybe having a couple of unit tests to make sure your refactoring doesn't break anything. Strategically, this would be super-smart.

> Looks a lot better already, doesn't it?

Really good!
Will try to write unit_tests, but believe me no previous experience in doing this.

@flavour  Made the Changes. Any other Suggestions?
@nursix Please Review 

@nursix : What should be the target of the unit tests - both the file formats xls and rtf getting downloaded?

> next round of improvements

? Whats next, I'll start working on it.

@flavour Done. Please Review

@flavour Please Review

Very close now :)

@flavour Done, Please Review

@flavour Please review

Travis CI is failing for some reason.
In general I'm very wary about this - seems like we're adding a lot of complexity for little value?
We already have too many deployment_settings really...I suspect these will be very unlikely to be set & so are just more settings that people have to wade through & try to understand when they're trying to configure their system.
Just because we can, doesn't necessarily mean that we should?

Travis CI is failing.
Other than that, this doesn't seem to be using the new widget options, so I guess should be rebased to see / use that?

@flavour Removed the deployment Settings. Should all these have implicit default? or some of them should have explicit defaults??

@flavour Also is there any important instance in one of these where a deployment setting may come useful?

@flavour Done the changes, Also added some more instances of start and end date.
Please review

@flavour : done :+1: 

Good, nearly there :)

Am still wary about looking for too many of these - rather keep it as a useful tool we can easily configure now.
If the issues highlighted are fixed then it can be merged, thanks :)

@flavour  Done.

Really - having this as an option for the widget(s) is fine, but applying without need, just because we can apply it, is rather counter-productive (in terms of efficiency), and can be harmful where users don't expect it.

I'd recommend to focus on the original use-case and do a good documentation so that it can easily be configured for other cases if/when needed - and leave unrelated cases untouched.

And......by the way: S3DateTimeWidget has such functionality built-in, there is really no need to introduce yet another option for it.

I think you should revert the change in S3DateTimeWidget (as that already has such an option). 

Instead we could expose the existing option as parameter for s3_datetime() - but that's a different issue.

Need change lot of files for the merge conflicts. Will be sending new PR. Sorry!

Thanks for the effort, but sorry - it's not /that/ easy. 

The location must use the location-represent ;)

For the other changes, as the status-tag says: WIP (work in progress), I am currently working on this module, but the requirements development is incomplete - so the todos can't be actioned yet (it's an upcoming project, not used yet).

I'd merge the logged-in user default, but not the other changes just yet.

Note that the data model may change significantly - so polishing isn't worthwile yet. I intentionally left these as todo's to not put unnecessary efforts into things which may vanish in subsequent versions.

@nursix I see ... Okay :) , so should i just give the default logged in person and root_org?

Actually, I have already done that in my story branch locally - so no need for you to do that.

Again - many thanks for the effort. I know that branch is overdue - but has been delayed due to other priorities.

That is btw the reason why I put in that status-tag (it's not so obvious, I know) - I have a local story branch which is a number of commits ahead, hence other work would necessarily conflict unless I can coordinate it.

Just consider all todos in this particular module as either done or obsolete - I think I'll push that soon (not today though).

sure!! :)

So, stage 1 and 2 are done - next would be 3.

But before working on 3, you should indeed have some unit tests. Unit tests test functions in isolation, i.e. you call a function with mockup-parameters and verify the results. Ideally, you check both success and failure response.

A schematic example. Say you have a function like this:

```
def myfunc(a, b):
    return a / b
```

Then a unit test could be like this:

```
def test_myfunc():
    result = myfunc(4, 2)
    if result != 2:
        raise AssertionError("Wrong result: should have been 2, but was %s." % result)
```

So you're writing another function to call the function that is to be tested, with parameters for which you know the result, in order to prove that the function really returns the expected result.

Typically, you should have at least one test call for each distinct type of case - e.g. for myfunc() this would additionally be the cases where either parameter is 0.

To make writing unit tests easier, Python provides a library "unittest" that supports more complex testing strategies and assertion checking. See modules/unit_tests - there are various examples of how unit tests could look like.

Important is that you don't ever use the tested function itself to determine which results you should expect ;) because then the unit test doesn't prove anything except for the fact that two identical calls deliver the same results.

Now, in order to write unit tests for this module, you need to look at each function and understand what results it should deliver for which input - and try to find a way to inspect and verify the result. Then identify the assertions (=expected results) for each type of case, and encode it as a test case.

E.g., get_style_list() should always return a dict() with certain members - that is an easy assertion, and quick to code. writeToRTF() is more complicated, but can still be introspected.

You do not need to test the overall functionality - all we need to know is whether the parts still do after the refactoring what they did before, the results are still correct, and no new bugs have been introduced (=regression testing).

Okay thanks :+1: will work on it.

@flavour @nursix Merge please.

:+1: 

Hmm - but the register form should/does not use "foundation_inline". So, no fix needed.

However, this is definitely the cleaner way to inject the buttons - so fine to merge it, provided you have _tested_ it across all templates. Have you?

Don't get me wrong - it is much more likely that the old version fails than the new one ;) and yet I have to ask whether it is tested because it is such a critical and prominent feature.

The devil is in the details here: if you inject buttons like this, they will be wrapped in an additional DIV (unlike in the old version) - and that can break a bunch of CSS rules, especially in the pixel-pusher bootstrap themes.

I tested all the formstyles on a template(SSF), not this formstyle on all templates. This ticket showed up while I was trying to get rid of Bootstrap and use foundation instead, for Sunflower.
Initially I thought of a different solution:
- use row.element search for a INPUT tag with type "submit" which can be done in this "for loop" <a href='https://github.com/flavour/eden/pull/1047/files#diff-490b78a7772eee613a7f16277d7ffe14R1103'>here</a>
- then append the login_link to its parent....

Would this solution be more stable ? I think this would be better, since an additional DIV won't be added ?
But then I looked at how the login form was operating and changed my idea...

No, your solution here is both the intended standard method /and/ the most appropriate solution. I had done the same change in the same way before, but then backed out for CSS problems in bootstrap themes.

You do not need to test the "foundation_inline" formstyle on all templates, no.

What I mean is that you need to test the button injection with all templates with _their_ respective formstyles to see whether the template-specific CSS for this particular form doesn't break. And there is form-specific CSS!

---

On the other note:

To switch Sunflower to foundation should be as easy to start with as to just use the default theme with the default formstyles, with just a custom homepage. Then, later (if necessary) branch off and customize it.

...although the idea of "eating our own dogfood" is to make Sunflower feed back into mainline Sahana, which is obviously the less realistic the more custom stuff it uses - so a custom theme is actually counter-productive.

I think the main barrier is that people think they should retain the specific look&feel of the SSF theme - in spite of switching to foundation as framework. But that doesn't seem to make much sense - overriding the framework-CSS only to make it look like another framework - effectively replicating bootstrap theme on top of foundation. What's the point of switching frameworks then?

To make it harder?

You do actually not need to test the foundation_inline formstyle for the registration form at all - it is simply neither intended nor used for that form.

But you do need to test the change with all other formstyles that _are_ used for this form, and check that the template-specific CSS for _this particular form_ doesn't break.

...and note that your tests should _not_ result in you backing out this change, but actually in fixing the respective CSS ;)

Okay....
Btw I'm making use of the CRMT css files and layout files for Sunflower, which looks much better than the default theme.So for now, I just changed the css.cfg to include the CRMT css files, which I should move into SSF as well ? 

Whether CRMT looks better is a question of taste ;) that judgement is not universal.

Technically, CRMT is a mess - and not recommendable for re-use. Too much custom stuff, and extremely fragile form layouts. The default theme is much more robust - and introspective, hence flexible.

Of course, certain details could be picked from CRMT - the colouring, the gutting, the button style. 
But else, the CRMT theme is a point solution and hence incomplete - it does not support all features in Eden. Certain features do not work at all due to layout conflicts.

So I can only recommend you to refrain from taking it wholesale .

As I said before: I would start with the default theme, and then cherry-pick the nice parts. And eventually you must really ask the question: where is the point with "eating our own dogfood" if Sunflower uses a custom (=non-default) theme?

And be careful with "fashionable" - it was only a few months ago when the current SSF theme was declared _the_ "most beautiful" Sahana theme in the world.

Now it's CRMT that is traded as the top of beauty, but very soon we'll have more designer work (on another theme), and then CRMT will go out of fashion again - and could well be called "ugly" just like you call the default theme ugly now.

Technically, however, the default theme is the top of the line - the best supported, best integrated and most robust theme. And that is what I recommend it for, not for it's beauty ;)

+1 to SSF template using the default theme (base, can still have a few extras in an additional local style.css) as the best way to eat dogfood.
This /can/ be used as a testing ground to port in some speciifc CRMT theme features which are desired, but as Dominic says, the CRMT theme as a whole has some major issues preventing this being used as default....apart from the non-universal taste issue:
- Forms have lots of manual width settings, so non-introspective => not suitable for default template => not suitable for SSF template
- The Summary page layout has the filters only visible on the Table tab, not the Report or Map tabs.

Doesn't make sense to me, sorry - S3DateTimeWidget is to select a time point to the minute, so not typically used to select month-long (or any pre-determined) intervals. I think you're getting carried away a little bit.

This doesn't have a use-case and only complicates the widget class unnecessarily, so -1 to this.

OK 

Don't feel too bad about it ;) You have no idea how many of my ideas I had to back out in order to de-complicate code.

But there is an intrinsic logic to that: any piece of code that is used very frequently will also be maintained - bugs get detected and fixed, documentation is kept up-to-date, the code is regularly upgraded to new versions of 3rd party libraries...all that stuff.

Code that is never used, won't be maintained either - bugs will go undetected, versions won't be upgraded, documentation goes out of date, and eventually it will turn into a rich source of regression issues and maintenance hurdles, so we do well not to introduce it in the first place. 

Moreover, it can very well happen that by the time a use-case for that code finally turns up, the functionality is so terribly out-of-date that it needs to be re-written. Or we have forgotten about it altogether. And exactly that has happened many times before, so requiring an actual use-case has become somewhat a matter of policy - though I am still relatively negligent about that. Fran's a lot tougher when it comes to "potentially useful".

There's a couple of problems here:

1) For ATDD, you would typically run only a few individual tests - perhaps just a single one - many times. That is exactly the scenario where you need repeatability, but copying the whole database just to execute a single test is really unreasonable processing effort and contradicts the requirement for tests to be fast.

2) A deployment setting doesn't make sense to me here - it should rather be a call parameter for the test suite (which defaults to True).

3) There is little point in copying the local database if the target URL points to a remote server.

4) No rollback for the case where the test suite is interrupted - but for test runs, especially for ATDD, this is quite a common scenario. If I see something failing, I will ctrl-c it early.

5) No support for MySQL, but this is required as it is one of our standard databases (I am developing with MySQL, for instance).

6) Smoke tests don't need this - it would only unnecessarily slow them down.

7) OS commands and file system access can fail for many reasons (permissions, duplicate filenames, capacity limits...) but you're hardly handling any error at all.

...and of course commits should generally be squashed together into one unless they really target separate issues.

I'm not convinced of this solution in general - I've had long discussions with Arnav S. about that before. 

The ideal would be to find a way to roll back transactions after individual test cases, but I appreciate that this may be very hard. So I could accept that as an interim solution if the problems named above can be solved.

Besides: this does entirely ignore our developers on Windows.

Sorry, got some merging problem will send a new PR!

@nursix I understand. I have a question:
what of this todo? https://github.com/flavour/eden/blob/master/modules/s3db/pr.py#L3193#L3197
Should there be a autofill widget??

@nursix Tested it with all the templates, and things only get better when 'Register' and 'login' are inside a div - they are displayed inline.
For bootstrap themes, there isn't any change.

Ok, good to merge then :+1: 

@flavour done

@nursix : Doubts -
1. How do I call a S3Method class(series_ExportFormatted) without request object while writing tests. I mean how do I pass r and attr parameters to the apply_method function.
2. How do I create a temporary widget in tests by this -

```
        qtable = s3db.survey_question
        record = Storage(name = "Test for string widgets",
                         type = "String",
                         code = "72H-68")
        question_id = qtable.insert(**record)
```

but the problem here is every time I run the tests it inserts multiple times. Shall do a select first and then see if the record is there or not?
Thanks.

You can just create a request:

```
r = S3Request(...)
```

From there you can either call the method:

```
method = survey_ExportFormatted()(r)
```

(note that you do not call apply_method directly, but execute the method)

Or, if you have the resource and method configured correctly in the request, just execute the request:

```
output = r()
```

However, either way that is a bit too high level for a unit test.

For the second question: 

First of all, unit tests should not permanently change the database status - if they need to create, update or delete records, they should rollback these changes at the end of the test.

Secondly, unit tests should ideally not depend on any particular database status - they should create all objects they need (and remove them again). The only exception is authorization for the test suite itself - this must be pre-defined (chicken-and-egg problem).

As long as you do not need to execute complex cascade operations (e.g. hierarchical deletion or something like that), a simple db.rollback at the end of each test case (=tearDown) should do the trick.

Okay got you thanks a lot. :+1: 

Also should I make get_style_list a staticmethod?

@nursix  I have a question:
what of this todo? https://github.com/flavour/eden/blob/master/modules/s3db/pr.py#L3193#L3197
Should there be a autofill widget??

@nursix Please Review

@nursix  Please Review

I think this needs proper use-case research before hacking in just anything. The budget-related filters for event-sites don't quite make sense to me yet.

Filtering by site name and status is fine, however - that's more obvious.

Also, the fact that the deployment has budgets enabled doesn't necessarily mean that is used for event-sites (it's an obvious use-case, but not a mandatory one). We may need to develop the requirements for this linking first.

The budgeting module has basically just been salvaged, and the requirements for it's use are still rather rudimentary. We do need practitioner input on that.

@nursix So should we create a deployment setting for the use of budget in event-site???

As I say: before we go and implement just anything, we should conduct a proper use-case research, and develop appropriate requirements for this. Right now this looks very much like a "shoot first, ask later" strategy.

We can of course speculate how this case might be, but I seriously doubt that this will lead to a practically useful feature set. It would be much better to get some domain input first (i.e. from potential users).

@nursix I see, so i will keep the list fields same as before and add only the filters for site_id and status. And add a todo to add filter widget for budget filtering

Or

<pre>
if item.authorized and (item.enabled is None or item.enabled):
    enabled = True
    visible = True
else:
    enabled = False
    visible = False
</pre>

Or
Should it use item.enabled and item.visible instead of enabled and visible ?

@nursix Removed the filter widget for the budget, still displaying all the fields as it were (including budget). Added Todos for budget filters.
Also added filter for event_human_resource and event_asset
Please review

NB I used enabled /and/ visible despite that's not actually needed here, because this layout was also intended as an example for how granular things can be controlled.

One could for example have items disabled _yet_ visible (i.e. discoverable for everybody, but accessible only for authorized users or when certain system conditions are met), e.g. having a menu item for "Find People" without any people in the database - the menu item should still be there to inform the user that this function exists, but it can be disabled while there are no records.

I'd leave this in place for future use, even if it looks a bit superfluous right now.

(I'm telling you this because S3Navigation can also be used to control e.g. buttons or button groups in the Sunflower homepage/dashboard/menu - e.g. "My Tasks", which might be empty or the user not logged in, and hence disabled, yet should be visible to inform users that this functionality exists and can be used if...).

Makes sense :+1:

Hard to tell without screenshots

Side nav color, content header color difference
default
![demo1](https://cloud.githubusercontent.com/assets/6831827/5927164/f7ed3738-a696-11e4-9222-be7a166e8ad2.png)
sunflower
![test1](https://cloud.githubusercontent.com/assets/6831827/5927170/fd34f7a8-a696-11e4-99e3-5be6ab165c61.png)
Inline Components color
default:
![demo2](https://cloud.githubusercontent.com/assets/6831827/5927234/19655738-a697-11e4-89ef-27f715c87c60.png)
Sunflower + (comments background-color)
![test3](https://cloud.githubusercontent.com/assets/6831827/5927241/22cfd5f0-a697-11e4-9e0e-6c8f8d6a64c8.png)

@nursix btw you answered only one of the questions asked about the navigation ;), Let me repeat --

As soon as the filter comes off the url, the "highlighted" option in the Main menu changes from "Project" to "Deployment" even if I am in the "Projects" page, because there's no filter to tell it what page it is in - that's how I defined the MM() for Projects and Deployments - the two are distinguished based on the filter.

How can I resolve this ?

Not sure I understand your question re: filter coming off the URL...can you explain, or point to the respective code?

It looks fine in general - but before it gets merged you should probably send another email to the mailing list (because your previous email introduced a different design, so people may not expect this one here).

Either point to this PR, or attach some screenshots, clarify that you have abandoned your previous proposal and this is your new draft - then give people a couple of days to comment and discuss before we merge this.

Ok?

Yes, that sounds good.

@nursix as long as the filter stays in the url, i.e, ?sector.name=None,Project/Deployment, the Main menu shows the correct part being highlighted, I guess it's because of the vars mentioned here:
https://github.com/hitesh96db/eden/commit/a5014026b827f06f9e8ed421f942fa4bbdee49bc#diff-d11854e3068b88cd7e7c34112ff346c9L79 ?
For eg:
http://test.sunflower.sahanafoundation.org/eden/project/project?sector.name=None%2CProject
In this page, "Project" in the Main menu is highlighted.
Click on 'open'
Now, "Deployment" gets highlighted even though you're in the projects page.

Ok - got you.

This is the automatic URL matching - S3Navigation matches the request URL against the item URL to determine which item to highlight. If two items match (like in this case), it picks the first match.

This is difficult to resolve because the paths are identical (project/project in either case). The best thing you can do is to set it manually at the point where you set the side menu. Tag the one menu item as "project", the other one as "deployment", and then set:

```
if ...condition for deployment...:
    topnav = current.menu.main
    topnav.findall("deployment")[0].selected = True
    topnav.findall("project")[0].selected = False
```

This overrides the automatic detection for those items.

well, plus the corresponding "else", of course ;) I think I don't need to say that, do I?

Nah ;), Thanks.

Sure, if the URL still has the filter, then the "Projects" item is the better match (it's tight, but still...).

But the URL project/project/11 only matches up to "project/project" with either item URL - so 100% equal, hence it picks the first match. You can only manually override this.

There is an alternative, though (that is, generally speaking, not a recommendation) - you could also define a separate controller. E.g.:

```
def project():
    return s3_rest_controller("project", "project")

def deployments():
    return project()
```

Both controllers do basically exactly the same thing - but they have different URLs, and hence would match different menu items. But as I say - not a recommendation, but just a possibility.

Btw - the shadow for the headline box contradicts the shadows in the forms. You have the light source at the top right, but the forms have the light source from above - which looks a bit strange.

I would remove the headline box shadow.

Can't have one shadow on the page in another direction than other shadows on the same page ;)

You have a big desire for some artistic extravagance :D but I do have an artistic eye (I've been painting for money some time in my life).

Uhm - and I see that the test instance doesn't yet have the latest default/style.css. Maybe you should update that before pointing to it (it has better support for mobile).

And fewer colours on the homepage would be better IMHO. Too many shades which don't harmonize.

Try to reduce noise: fewer colours (or shades of the same colour), fonts and button styles, maintain consistency. Don't make button labels bold, they are already in a prominent box. Ideally remove the icons, they don't really help here.

Well, ok - so much for now as feedback on the design ;)

Nah - ok, one more: rounded corners for buttons are out :D 

But at least they are inconsistent with the rest of the theme. Either you have rounded corners everywhere (like here on GitHub = bootstrap), or not at all.

@nursix Hey, So this code still needs re-factoring and also the widgets for budget, but logic wise, is this the implementation that u wanted?

@nursix Hey, So this code still needs re-factoring and also the widgets for budget, but logic wise, is this the implementation that u were thinking about?

@flavour Please Review

@nursix : Wrote tests for series_ExportFormatted. What is step 3.

Referring to our previous conversation - step 3 was to eliminate camelCase names and other non-standard coding styles.

Coding convention: function/variable names are all-lowercase with underscore as word separator, class names start uppercase and use CamelCase for word separation (this does not apply for the mandatory module prefix "survey_", however), (pseudo-)constants are all-uppercase with underscores as word separator (LIKE_THIS).

Variable/function/class names should be self-explanatory and indicate the purpose of the variable, cryptic abbreviations like "sftgv" aren't useful.

Further, you can use pylint to evaluate code quality, a rating above 7.5 is desirable.

The unit tests help you to ensure you don't break things when refactoring the code (provided that they are specific enough). You should run them after every little step - over and over again. Consider edge-cases and unhandled failures.

Finally, conduct some testing through the GUI (sometimes all unit tests pass, yet the user-facing functionality is broken).

Also, remember: "Be destructive with testing, and constructive with error handling".

@nursix : Okay just a request, can changing the names done in another PR(Please) - Because this PR is tested with almost all the functionalities and is working. And what about get_style_list? (Static or not). 

Your call - no self-use implies static, normally.

If you want to do a separate PR for the cleanup then fine - but I haven't reviewed this one yet (I am actually trying to work, so I don't have the time right now). I can probably do so later tonight, and until then, in fact, you could do a little refactoring already.

Or, you can help me with something (doing some research) - but we should take that off this conversation.

Okay sure, where then?

Email - send me an email so I get your email address, and can reply to it

Docstring doesn't tell the truth, else :+1: 

done ;) :+1:

Looks like good progress - but the unit tests are rather weak to really detect regression. As a minimum you must test for failure handling, and touch each (relevant) "if" branch at least once.

You shouldn't add unrelated test cases to the suite - unless you have validated them. I had originally removed them because I found them invalid - and I don't see that you changed anything that would make them valid now?

You're mixing in unrelated changes now - which makes it a bit difficult to verify. You should either add some information about those to the PR description, or maybe even put them in a separate PR (though I see they are fairly small, so maybe not worth a separate commit, but having some background what they are about would be very helpful).

Will be adding more tests. Thanks for the review.

@nursix Done. Please Review

@nursix Please review

No need to ping for review - I get PR's notified anyway.

Scheduled for later - no time right now.

@nursix I tried --

<pre>
if ...condition for deployment...:
    topnav = current.menu.main
    topnav.findall("deployment")[0].selected = True
    topnav.findall("project")[0].selected = False
</pre>

But it didn't work, i.e, if I set project to False, it still remains selected. 
I believe it's because of this - 
https://github.com/flavour/eden/blob/master/modules/s3/s3navigation.py#L480,
the value gets overwritten and set to True.
Maybe we can add a check there to see if it has been set before - to either True or False ?

I have a better idea, I'll implement it then get back to you. Hold off this PR for noew.

Okay

I'm not clear why you're making these changes - any requirements specification for that? Or a discussion that I wasn't part of? 

Apart from the name filter for event types, most changes look like a step backwards - reducing clarity and not really fitting with the model and intended workflows.

Apart from the HR first_name-only filter, this looks ok. But I'm unclear about the requirements for filter widgets on the component tabs here - they don't seem to add much value (yet processing time)? Any specifications or discussion that triggered these changes where I can read up on?

Don't get me wrong - I'm not saying this is wrong, just putting it in question. 

I'm generally reluctant to green-light additional processing in models simply because that increases the effort during model loading. And since I haven't yet heard of any requirements to have dedicated filter forms on the component tabs of scenarios, I need to ask where this is coming from.

> Any specifications or discussion that triggered these changes where I can read up on

Not really, just asked on IRC about what these todos were targeted to. Michael said that it should be for the filter widgets and actioning them woudn't take time. 
Fran seemed to be busy that time so he was not able to reply. So your call - required or not. @nursix  

Shall I remove hide_filter = False and keep the filters as it is so when its required this can be added?

A possible strategy to determine usefulness of filter widgets is to try to identify the questions they may answer:
=> If you can't find a meaningful question, then the filter widget isn't useful.
=> If the possible answer is of the yes/no type, then the filter widget is probably at the wrong end of an entity relationship

For example: the text filter on the "Asset" tab of a scenario would answer the following question: "Which assets with the number XYZ have been planned for this scenario?" (obviously nonsense, because the best answer to the question is an asset number - but you already have it, so no new information here).

So, rephrasing this as: "Has the asset with the number XYZ been planned for this scenario?"

Now, this gives a yes/no answer - so we may be looking at the wrong end of the link, i.e. we should probably better look at the "Scenario" tab of the asset (instead of the "Asset" tab of the scenario), and ask:

"Which scenarios has this asset been planned for?"

Now, this _is_ a useful question - but you don't need a filter to answer it, the mere list is quite enough. However, the question can have qualifiers:

"Which scenarios of event type X has this asset been planned for?"

And to answer that, you will need an event-type filter on the "Scenario" tab of the asset! There you have it!

...so that is largely my strategy to identify useful filters where I don't have detailed requirements specifications. Doesn't necessarily mean that each filter identified this way is indeed needed by the users - but at least I can exclude those filters which really don't answer anything.

Wanna try this?

@nursix  -
I'll look into this for sure. Do you want a scenario component for asset? Is it required really?

> And to answer that, you will need an event-type filter on the "Scenario" tab of the asset! There you have it!

So from this, what I understood is - 
Make scenario a component tab of asset. Add a filter to this tab which filters according to event_incident_type?
And what about the other components of scenario - Same for them also?

Ahm - this was actually just an example :$

...not trying to suggest any particular requirements, but rather to illustrate a possible strategy to identify useful ones, just using the given context to clarify.

The general use-case of the "scenario" model is to develop response plans which can then be rolled out in case of a disaster - automatically activating resource deployments including alerting, availability checking, choosing alternatives, and reporting status/progress.

It should perhaps also be able to report on potential costs (for budget planning, fund raising), and allow checking of the status of response plans - and their feasibility (...resource availability, training status, maintenance status etc etc...).

Ability to pull in hazard and risk information, as well as demographics data, while planning responses is another useful feature - and at the highest end of the requirements are probably simulations of scenarios.

If you start with this high-level description, you can perhaps find additional features that would be required or useful, and then the answer to your question would come just naturally.

Ideally, you would also pull in (potential) end-users to the discussion - and listen to them.

In general, development shouldn't start with available functionality - but with the end-user needs. Not solutions looking for problems - but the other way around. So, start with specifying the problem, and then work up possible solutions.

If you come to me with a problem statement, then we can discuss possible solutions. If you come only with a solution, then it's unlikely I can help you much.

Yup, a little patience please, though (it's weekend, so I have some family appointments first). Will work on it later in the evening.

no urgency here.

> Ahm - this was actually just an example :$
> ...not trying to suggest any particular requirements, but rather to illustrate a possible strategy to identify useful ones, just using the given context to clarify.

Okay, what should be the status of the PR(sorry to be too straight) !!!

> If you come to me with a problem statement, then we can discuss possible solutions. If you come only with a solution, then it's unlikely I can help you much.

Will take care of this in future requests.

Umh - I kinda said that already?

The IndexError must be fixed where it occurs, not be worked around.

Adding filters for the main scenario resource, changing the Storages into dicts, and moving the rheader into the model - these things are fine and can/should be merged.

The rest of the changes (=the filters for the component tabs plus the hide_filter=False) are questionable - not technically wrong, but unclear requirements-wise. I would take them out of this PR, and re-approach once there are clear requirements for that.

Okay thanks :+1: 

Pushed. Once merged into trunk, you can do as follows:

```
if ...condition for deployment...:
    current.menu.main.select("deployment")
else:
    current.menu.main.select("project")
```

...though with the menu items in project=>deployment order, you can probably omit the else-branch.

Thanks :)

@nursix : Done. :+1: 
Here's what the problem was - 
The site_id was made non-readable and non-writable-
https://github.com/flavour/eden/blob/master/modules/s3db/org.py#L2670
And it is again made readable and writable in the controller here -
https://github.com/flavour/eden/blob/master/controllers/scenario.py#L44
So now in this function - 
https://github.com/flavour/eden/blob/master/modules/s3/s3resource.py#L3872
The list_fields that we get is just ["id"] which is expected to be ["id", "site_id"], so if we explicitly pass site_id then it works. 
OR
The better one would be make this field readable before the list_fields() function is called ;).

Doesn't make sense to me, sorry.
list_fields is not called before the prep, and even if we get just ["id"], it should still not raise an IndexError - and you have not yet told me where the IndexError is raised. Where is list fields expected to be ["id", "site_id"]? That can not just be expected!

This is still working around the bug, not fixing it.

@nursix : 
At this line https://github.com/flavour/eden/blob/master/modules/s3/s3resource.py#L3882 list_fields should have ["id", "site_id"]. 
The IndexError is raised here:
https://github.com/flavour/eden/blob/master/modules/s3/s3resource.py#L3712

I can not see that  https://github.com/flavour/eden/blob/master/modules/s3/s3resource.py#L3882 anyhow expects ["id", "site_id"] - what makes you think that? There is nothing there that expects any particular list fields.

And https://github.com/flavour/eden/blob/master/modules/s3/s3resource.py#L3712 in fact catches the wrong Exception type - lists raise an IndexError not a KeyError. And that is basically all to it.

But what you keep overlooking:
https://github.com/flavour/eden/blob/master/controllers/scenario.py#L44

"s3db.scenario_site" is not a Field! Setting is readable/writable has no effect.
It should be "s3db.scenario_site.site_id" - and with that, it all works perfectly well.

I pushed a fix for both.

Now, there is one more mistake here. I'll fix that too.

Thats what I was thinking about - your changes didnt work for me

Okay so I'll remove this fix from this commit

Like this:
https://github.com/nursix/eden/commit/3d531bbaf86cd7b3fcd7527bebfce542b4579fed

The IndexError was caused by an interactive/aadata list_fields discrepancy: site_id was only set readable for interactive requests, but not for the aadata Ajax-sorting - so the sorting index would hit a nonexistent field.

However, that should not crash but get caught in datatable_filter (because it's a URL error, and thus "user data" in the wider sense, which should never crash) - but that didn't catch the right exception type.

Well, it works for me with these changes - if they don't work for you, then maybe you have introduced another error somewhere else?

I don't see anything wrong - it's good to merge now.

> Well, it works for me with these changes

Yeah even for me now, I tried your previous commit.

> but that didn't catch the right exception type.

I tried this also but thought that this might break other cases. 
But thanks :) :+1: 

Added one more fix.

@flavour Please review :)

You appear to have been working with an old version of Eden. When making code changes it is essential that you work with the latest version.

Currently impossible to see what was done here as this PR shows 1,887 files changed and is unmergeable...I suggest trying again?

Updated look: http://test.sunflower.sahanafoundation.org/eden/
Changes made -
- ICON instead of hardcoded classes
- Menu font slightly larger
- Header shadow removed
- Round buttons everywhere
- Usage of large, small and medium classes.
- Fixed Menu Navigation problem
- Font sizes in rem

Hey @nursix need some help - 
There's a bug that I found while I was working on survey module,
Add a template(Make sure you enter some value in the name of the questions field). Make a series using this template. Now if I enter some data in "Enter Completed Assessment" -> it adds the answers in the survey_answer table, BUT survey_answer.question_id is not the actual question_id that we actually added in survey_question while creating the template. It is just sequential numbers 2,3,4... Because of which there are problems whose consequences are bad.
So what I found is here -
https://github.com/flavour/eden/blob/master/modules/s3db/survey.py#L2890
form_vars contains question_id as 2,3,4 ... which is not required (It should be something in 1500s - according to present database prepop)
So there is no where in the form that we are passing question_ids(Only codes are made ids of the fields) here -
https://github.com/flavour/eden/blob/master/modules/s3db/survey.py#L736
So we need a way so that we can get correct question_ids in answer_onaccept. Please help.

I'd say: good to merge.

The initial discussion had been open long enough, and subsequent enhancements can only be submitted once this is merged - so no point to hold off any further.

I'd need to investigate this, but don't have the time right now. Maybe later tonight?

If it comforts you: finding such critical bugs is one of the reasons for the refactoring, so that makes your work successful. Well ok - of course we also need to fix them...sure, sure...

So what I am telling is - I didnt even started refactoring the module. This PR actually contains the working code of downloading .xls and .rtf which is not in the main trunk right now. I don't think tests should be stopping this PR from merge(Since we need working code before refactoring).

> Well ok - of course we also need to fix them

So I think I will first make the module working(As it really isn't) and refactoring can follow. Shall I remove the tests from this PR? @nursix 

Added minified CSS file.

No need to add a minified CSS file - will be minified upon merge by Fran ;)

Hmm, there's a gap in your logic here: without the tests, how do you know it's working code?

I would say exactly the other way around: we first need the tests, then the working code - and then we can start refactoring while using the same tests to verify the changes.

Or to make that a little clearer: we may have to insist on evidence that your code here actually works, so (conclusive) test cases are actually required before merge.

:+1: 

@nursix Please Review

I've investigated the issue with the question ID, and it turns out that this is a major flaw in the overall design of this module:

When you generate a template, it does automatically insert some standard questions:
https://github.com/flavour/eden/blob/master/modules/s3db/survey.py#L409

The question codes for these standard questions are hard-coded: STD-WHO, STD-DATE etc.

When you submit the answers for these questions, it would first write them together with the question code into a temporary CSV file, and then import them:
https://github.com/flavour/eden/blob/master/modules/s3db/survey.py#L2766

The import would find the question through the question code, using the deduplicator:
https://github.com/flavour/eden/blob/master/modules/s3db/survey.py#L1062

However, since the codes are hardcoded, they would be the same in all templates that have been created through the GUI! Consequently, all answers would always be linked to the first question with the respective code, even if that's not in the corresponding template. Correctly, the question match would additionally require the template_id.

But this is just the tip of the iceberg - if you look a little closer, then there are hundreds of issues in this part of the process, ranging from DB writes during GET over invalid data not being caught, forms not respecting formstyle, errors neither being caught nor reported...to completely non-conformity with coding standards and a terrible interlocking of process elements.

The latter means: this only looks like separate functions, but actually it's a single monstrous sequence of incomplete steps with processing dependencies that span from the very end to the very top (i.e. even a valid partial result can only be achieved by executing non-consecutive steps, which basically defeats the purpose of splitting into subfunctions).

Fundamental flaws like this one can therefore not easily be "fixed" - the domino-effect of this code structure will force you to more or less rewrite the whole thing.

...which I can only encourage you to do, though.

i.e. the  issue with the question_id is that this uses a pseudo-key which is not actually a key for the question table and therefore ambiguous. Re-design required.

Good start - but needs work:

"trash" should generally be "delete"
"paper-clip" should be "attachment" for the attachment (doc) context - whilst for appraisals in "deploy" it should indeed be paper-clip for now.

Placeholder I-tags should be rendered as ICON("icon") - that is because "_base" will change, but the CSS-selector for the placeholder will always be .icon.

Where you replace variable I-tags, you must check all cases for whether all possible values are actually defined. This can be a tedious job, and is indeed the most difficult part of it (must find and analyse all callers)

Changing a default-icon requires careful consideration - since users may be used to certain icons, and re-training users isn't exactly something you can do on-the-fly. In the case of "offer", however, we do indeed need a different icon because the truck is already used for another item class. The certificate icon is too, though :/ so we need something else.

Else - many thanks for the help :) :) 

P.S. Note that not all ICONs are currently used with font-awesome, nor do all themes use font-awesome. Some use a different icon set, and some even use handcrafted background-images.

For that reason, unfortunately, you must test across templates and verify before/after for every case.

...on the bright side, though, almost every other icon set currently in use in Eden also uses icon-\* classes, so these are sometimes just overrides (which though means you can't just change the class).

The only exception is Foundation icons which looks for fi-*

Ah - and another P.S.: Please try to use abstract icon names rather than descriptive, e.g.:

"paper-clip" => "attachment"

That way, when you configure a new icon set that uses a completely different symbology you can pick alternatives by semantic meaning rather than by visual appearance - which obviously makes more sense.

E.g. if there is no "paper-clip" icon, you shouldn't look for something that looks similar to a paper-clip, but rather for something that can symbolize an attachment.

Good work - just two little things, then it should be good to merge.

Done. :+1: 

Yup - this can be merged, unless Travis objects ;)

Oops travis. Wait a sec, what adding a newline fails the tests?
First it failed for mysql then now for the last one?
@nursix 

Don't worry, it's a temporary Travis-internal issue.

I've pushed a new commit with changes addressing all the raised issues 

@nursix : Done. :+1: 

:+1: 
Should I continue with these(which are in s3db) ?

Yes, please complete this PR - but make sure you're testing everything (especially /deploy/mission and deploy/member with the IFRC theme)

I mixed up it with other version. But the main thing I changed was I edited the config.py file under the default template so that the messaging module is visible in the sub-menu under the main menu. Also some lines under the 000_config.py. 

@nursix: Added some minors. Please review.

@flavour  Please Review

@flavour Please Review

@nursix Changed Accordingly. Please Review

Config setting without use-case? I would re-submit this together with the code that uses it.

This was discussed in the Configuration Editor thread in the mailing list.

Added a link to the coapp in the admin menu.

I'm aware of what has been discussed - but adding a setting without also adding the use-case for it is obviously a bit pointless or at least premature.

Better now - but you should of course use the getter to retrieve the setting, not access the dict directly.

Sorry for that. Done now :)

Question:
@nursix Should Todo [1] be actioned??
[1] -> https://github.com/flavour/eden/blob/master/modules/s3db/cms.py#L193

What value would this add?

@nursix So should that ToDo be removed?

Ahm no - the question answered.

@flavour  Please Review

I'm surprised that this hasn't yet been merged (maybe due to the previous Travis error) - but I don't see much that speaks against merging.

For the form.insert(0, buttons) I need an explanation - obviously they are passed into the view as "subtitle", but maybe the view doesn't apply it correctly. Either of the variants has to go away, shouldn't do both - and honestly, inserting into FORM isn't the cleanest way to do this.

@nursix : ^ Will find a better way to do this. Basically the button was not added to the form. Any help on how this "subtitle" option is handled?

Well, we used to have a {{=subtitle}} in view/_create.html - but that was loooong ago. In the current version, we don't have such things anymore.

Injecting the buttons into the form is risky, because you don't actually know what the exact HTML structure of the form is - nor does this check whether form actually is an HTML structure (and not "").

The better (=safer) method is to wrap the form:

```
output["form"] = TAG[""](buttons, form)
```

...which equally prepends the buttons, but doesn't touch the form in any way.

Note that this ^ does not add an HTML node - if you want that, make it a DIV instead of a TAG[""].

@flavour: What was the hold up on merging this? I think that the static/formats/s3csv/hrm/person.xsl changes will be useful for SahanaCamp Turkey
Travis was failing, although the error was pretty cryptic.  minimal investigation revealed a pretty major bug (now fixed):
-        @ToDo: Add event/human_resource - but this requires extending event_human_resource to link to event.
-        # @ToDo: Add event/human_resource - but this requires extending event_human_resource to link to event.
  I think that the RAD approach is still valuable when there is time and resources - if it delivers the right solution.  Regardless - this deployment does not have much in the way of time or resources to put into it, so RAD is preferable.

"RAD is still valuable when there is time and resources - if it delivers the right solution"

...what a completely hollow statement! Delivering the right solution is always valuable, that's not a value added specifically through RAD.

If you have sufficient time and resources, then RAD components can be used to produce early prototypes - but this strategy is called "rapid prototyping", not RAD. 

This can help to facilitate continuous end-user participation in agile development, which tends to deliver more targeted (and hence more effective) solutions, and can dramatically reduce the defect rate (due to early continuous UAT). 

However - it does eventually cost _more_ effort and not less (which is why you need time and resources), and such solutions are typically much less re-usable - especially they do rarely deliver or improve RAD components (they rather tend to tweak RAD-components into non-RAD).

The key thing for RAD are re-usable, generic, configurable, robust and stable components - as well as excellent conceptual integrity (all components following standard concepts and common principles) and consistency (especially in view of terminology), often referred to as the "no surprises" principle. The most important aspect of RAD is that developers do not need to in-depth study those components, let alone to develop them.

Such components can not be developed through RAD itself - nor does rapid prototyping help (rather the contrary). They do need dedicated development projects with sufficient time and resources both for defining, implementing and testing as well as generalization and conceptual integration of these components.

And that is why RAD - regardless how valuable it is - is not possible without strategic non-RAD projects providing both requirements and resources to develop RAD components and framework.

The CERT template has definitely had enough _time_ to be non-RAD even with just volunteer resources. It was rather lacking requirements development (mainly because it didn't get used much), which is why it remained at the prototype stage.

I still don't see the urgency - it seems that you're rather hijacking this template for a different use-case / target audience (aren't you?), which may be ok if declared that way. Or is there any CERT team suddenly interested in developing this further?

The key aspect of RAD is that full-blown /production/ applications can be developed with almost no programming effort at all - with all forms, presentations and tools introspecting and automatically adapting to the data model and workflow descriptions.

However, it also involves a certain robustness and flexibility for subsequent remodelling, safeguarding data integrity and minimizing dependencies between code and database, basically allowing to re-use the same database with different applications/configurations and vice versa (which implies a 100% separation of database and application logic).

All of this is useful - sometimes, but not always and every time. Quantity is a result of RAD, but doesn't improve it. It creates an incentive, but doesn't produce a framework.

None of this is possible without dedicated framework/component development - which really requires that projects which have sufficient time and resources feed into it by developing new components, field-testing, generalizing and integrating them.

There is a CERT team that is interested in using Sahana - which is why I've made these changes.

There shouldn't be any need for this as I don't see that it does anything different to the existing doc_document resource?
This is already a component via the doc_id super_key

Than what should to do in this
https://github.com/flavour/eden/blob/master/modules/s3db/cms.py#L515

On Tue, Feb 24, 2015 at 12:46 PM, Fran Boon notifications@github.com
wrote:

> Closed #1071 https://github.com/flavour/eden/pull/1071.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1071#event-240721215.

Comments don't yet have attachments, which might be useful

In  this task
https://github.com/flavour/eden/blob/master/modules/s3db/cms.py#L211
can't we just add a new field like this
s3_datetime ("expireson",
         default = "now",
          label = T("Expireson"),
),

On Tue, Feb 24, 2015 at 9:28 PM, Fran Boon notifications@github.com wrote:

> Comments don't yet have attachments, which might be useful
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1071#issuecomment-75783543.

Field name should probably be "expires_on", and the default ideally _not_ "now" ;)

move gis_location to link table and add expires_on field on cms_post
please have a look
https://github.com/yashpalsaini/eden/commit/5bb99e98cb9937d9950e2135883989c6585fb8e9

On Thu, Feb 26, 2015 at 12:36 AM, Dominic König notifications@github.com
wrote:

> Field name should probably be "expires_on", and the default ideally _not_
> "now" ;)
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1071#issuecomment-76032237.

Your new commit looks good - but changing the model is only half of the work required for this ToDo.

There is a bunch of dependent functionality in templates (e.g. MCOP, DRMP) that would break unless you adapt it. Without adapting them, I'm afraid this change cannot easily be merged.

Also note that both templates are in active use (i.e. with existing databases!) - and without migration script they would loose all the existing location links of any cms_post entries, so such a migration script would be a nice addition to your change (although not a hard requirement, as usually a task for the server admin).

NB there may be more templates using the newsfeed, and there is also a general newsfeed list layout involving the location_id - so there is still a fair bit of work to do.

is it ok if i make changes in MCOP, DRMP template  according to new location table 

move on doing some work on newsfeed in cms controllers for location_id

try to write  lazy table for pr_image table
please have a look
https://github.com/yashpalsaini/eden/commit/6f6f7c828d269ffaa5a781f4d66a1a76c72044db
but i am getting error while executing it
please let me know if i am doing it wrong

On Fri, Feb 27, 2015 at 12:57 AM, Dominic König notifications@github.com
wrote:

> NB there may be more templates using the newsfeed, and there is also a
> general newsfeed list layout involving the location_id - so there is still
> a fair bit of work to do.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1071#issuecomment-76249218.

make changes in controllers/cms.py and modules/s3db/cms.py for adapting
changes made in location_id(basically create Posts <> Locations Link Table).
please let me know me if i am moving in right way.
Their still some work to do in some templates

On Sun, Mar 1, 2015 at 2:26 PM, yashpal saini yash1628413@gmail.com wrote:

> try to write  lazy table for pr_image table
> please have a look
> https://github.com/yashpalsaini/eden/commit/6f6f7c828d269ffaa5a781f4d66a1a76c72044db
> but i am getting error while executing it
> please let me know if i am doing it wrong
> 
> On Fri, Feb 27, 2015 at 12:57 AM, Dominic König notifications@github.com
> wrote:
> 
> > NB there may be more templates using the newsfeed, and there is also a
> > general newsfeed list layout involving the location_id - so there is still
> > a fair bit of work to do.
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/flavour/eden/pull/1071#issuecomment-76249218.

oops link
https://github.com/yashpalsaini/eden/commit/eec51a8e4a12ae054ffc994fdd868cd27d5e1084

On Mon, Mar 2, 2015 at 8:35 PM, yashpal saini yash1628413@gmail.com wrote:

> make changes in controllers/cms.py and modules/s3db/cms.py for adapting
> changes made in location_id(basically create Posts <> Locations Link Table).
> please let me know me if i am moving in right way.
> Their still some work to do in some templates
> 
> On Sun, Mar 1, 2015 at 2:26 PM, yashpal saini yash1628413@gmail.com
> wrote:
> 
> > try to write  lazy table for pr_image table
> > please have a look
> > https://github.com/yashpalsaini/eden/commit/6f6f7c828d269ffaa5a781f4d66a1a76c72044db
> > but i am getting error while executing it
> > please let me know if i am doing it wrong
> > 
> > On Fri, Feb 27, 2015 at 12:57 AM, Dominic König <notifications@github.com
> > 
> > > wrote:
> > > 
> > > NB there may be more templates using the newsfeed, and there is also a
> > > general newsfeed list layout involving the location_id - so there is still
> > > a fair bit of work to do.
> > > 
> > > —
> > > Reply to this email directly or view it on GitHub
> > > https://github.com/flavour/eden/pull/1071#issuecomment-76249218.

please have a look over changes so that i move on to some other templates
https://github.com/yashpalsaini/eden/commit/eec51a8e4a12ae054ffc994fdd868cd27d5e1084

On Mon, Mar 2, 2015 at 8:36 PM, yashpal saini yash1628413@gmail.com wrote:

> oops link
> 
> https://github.com/yashpalsaini/eden/commit/eec51a8e4a12ae054ffc994fdd868cd27d5e1084
> 
> On Mon, Mar 2, 2015 at 8:35 PM, yashpal saini yash1628413@gmail.com
> wrote:
> 
> > make changes in controllers/cms.py and modules/s3db/cms.py for adapting
> > changes made in location_id(basically create Posts <> Locations Link Table).
> > please let me know me if i am moving in right way.
> > Their still some work to do in some templates
> > 
> > On Sun, Mar 1, 2015 at 2:26 PM, yashpal saini yash1628413@gmail.com
> > wrote:
> > 
> > > try to write  lazy table for pr_image table
> > > please have a look
> > > https://github.com/yashpalsaini/eden/commit/6f6f7c828d269ffaa5a781f4d66a1a76c72044db
> > > but i am getting error while executing it
> > > please let me know if i am doing it wrong
> > > 
> > > On Fri, Feb 27, 2015 at 12:57 AM, Dominic König <
> > > notifications@github.com> wrote:
> > > 
> > > > NB there may be more templates using the newsfeed, and there is also a
> > > > general newsfeed list layout involving the location_id - so there is still
> > > > a fair bit of work to do.
> > > > 
> > > > —
> > > > Reply to this email directly or view it on GitHub
> > > > https://github.com/flavour/eden/pull/1071#issuecomment-76249218.

@raj454raj Why close this PR?

@coder006 : Sending it on Dominic's fork.  

> @coder006 : Sending it on Dominic's fork.

cool.

For tracking this is for http://eden.sahanafoundation.org/ticket/655

I don't know much about geonames but for HTTP GET requests, can't you use
the request module ?

anurag-ks-29
On 08-Mar-2015 9:18 PM, "alch4" notifications@github.com wrote:

> For tracking this is for http://eden.sahanafoundation.org/ticket/655
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1073#issuecomment-77756719.

The project menu change seems to break a lot of things - not sure that is how we actually want to have it. What happened to the simple project-menu (i.e. neither of 3W/DRR/Task - but just projects tracking, i.e. simple list)? That should still be the default!

Very inconsistent style (PEP8, inconsistent indents, unnecessary line breaks).

Revised and (hopefully) ready to merge

Take 3... :)

Take 4 (Thank you Travis - and great error reporting too!)

Hmm, now you have even removed trailing commas of single-item tuples, which makes it a syntax error. 

```
x = ("a",) # tuple
y = ("b") # simple string
```

The biggest problem with that is that both tuple and string are iterable - so this may not raise an Exception immediately.

With multiple items, it's a style issue:

```
x = ("a", "b",) # trailing comma and closing bracket on the same line
```

This does basically defeat the purpose of the trailing comma, which is to be able to easily add another item. Therefore, if you can expect other items to be added, it should be:

```
x = ("a",
     "b",
     )
```

That does also apply to "names" of models, even with a single item:

```
names = ("my_table",
         )
```

...because this allows easy adding of names by just inserting a line (=no editing of other lines required):

```
names = ("my_table",
         "my_table_id",
         )
```

I thought I had marked exactly those which needed to be corrected?

Note that this does not apply to constructed tuples, i.e. where the tuple is left of a =

```
(x, y) = example()
```

In this case, there should be neither a trailing comma nor a line break.

You did make the ones needing changing - I got a bit over zealous.... fixed now.
Take 5? 

Hmm, still a bunch of coding convention issues, including PEP8. What shall I do now? 

It seems that every round you're fixing 2/3 of them and introducing a couple of fresh ones - so this is going to be a never-ending review I'm afraid. Let me try one more time to indicate all of them - and pls fix only them, but all of them.

I'll give you notice when ready...hang on.

Ok, I think I'm through.

Where I say "can", these are just tips how things could be improved - but not required to action them, since your variant would be correct.

Closing pull request. New pull requested with new updates.

current.deployment_settings.get_gis_geonames_username() should tell you the name to use for geonames search...obviously this is Python side so may need passign through to JS

This is disabled for a reason, so no need to enable by default :)

No no, I needed the python side. Thanks Fran. I've made the change and pushed again. This should finalize ticket 655

A lot of little cleanups, but basically looks good, thanks :+1:
Once cleaned up, please rebase/compress when resubmitting

@flavour Could you merge? It passed Dominic's review. I've just rebased on latest code to save you the hassle. Happy Easter! 

I have reviewed it but you haven't yet fixed all the things I've pointed to.

On a side note: The redirects in index() controllers tend to swallow errors (especially when it's multiple consecutive redirects like index=>index_alt=>summary), so users are left without information that something went wrong, and what went wrong.

If you redirect from index, you must make sure that you preserve response.error, response.warning and response.confirmation (via session) - and obviously, that needs to be fixed in cms too.

Both the  import_font function and the PDF config setting do already exist - you just redefine them, but for what purpose? If your actual intention was to improve them, you should modify the existing functions rather than redefining them.

However, I don't quite see what you wanted to improve - what effectively does it do differently, and why?

Hi nursix,
I was working on this during GCI, here is all the previous talk we did - https://github.com/edengci/eden/pull/80 

That doesn't answer my question: the functionality already exists in trunk, and your PR just duplicates the existing functions, which is clearly wrong. 

If you intended to improve it, then what exactly did you try to improve? If you can explain it, then I may be able to guide you to it, otherwise I'm afraid this PR is not acceptable.

Existing functionality is here:
https://github.com/flavour/eden/blob/master/modules/s3/s3import.py#L4084

So, I don't see the point with this pull request - especially since you're not modifying the existing functionality, but adding duplicates in the same places.

I've given a number of pointers for possible improvements, so if you wanted to action any of those and then re-submit your PR maybe it would start to make sense.

But right now it doesn't really, sorry.

Hmm, I didn't knew someone implemented it already, must have been between the time period of GCI and now, since it's already their I am closing the PR.

I do have my concerns about making summary pages default - it has performance implications which are not generally acceptable, and it is not easy to reduce it (always easier to inflate than to deflate the default).

Is that a block toward making the summary pages default? Or just a concern? 
Where are the performance constraints / difference vs. a filter list page?

NB Making summaries the module index page by default also leads to inconsistencies where the template does not use summaries elsewhere - and with the List-button in the create-view.

I don't think that this is the right approach - it would be better to make the no-method default view in CRUD configurable to ensure consistency.

A list-filter page has about a third of the volume of a default summary page - both in terms of back-end processing, DOM nodes to load/render and JS to run. This does clearly have impact on performance, and if there is no need for a summary page, then why render one?

OK - is it possible to configure the no method -> summary pre-template?

However I'm curious that the summary page is 3x the load of the list-filter, when the the only difference is the tabs(?). Would it be possible to load more of the magic behind the tabs (reports / maps) only on demand?

There is really no point in pre-template configurability ;) But in-template global configuration can be made possible.

Currently, the no-method default is not configurable - but if I'm given enough time I can make that work. That was planned anyway, just a question of bandwidth ;)

pER-template - we're talking about the same thing - just from opposite ends of the day! ;)
That would be ideal... currently we're not exposing the summary page for some resources... :S

Everything should be in order now... 

I wasn't actually talking about server load - but about page performance ;)

Summary pages are primarily slow client-side - the server-side part is acceptable. Client-side performance depends massively on the user device and browser - and that has a very broad range far beyond our control.

The hidden content widgets are all loading only on demand - but that too requires additional JS, and the placeholders to hook them in. And it does inflate the client-side processing massively, as does the cross-tab filtering.

NB the tabs themselves are actually /not/ loaded from the server (in fact, they are not even mandatory for summary pages) - they are one of the many things on a summary page that are JS-generated client-side. That too adds to the page complexity and makes it slow, of course.

Simple datatables is what most clients can manage easily. Summaries and Profiles require fast end-devices, and that isn't exactly the standard everywhere yet.

@nursix Are you happy with everything in this PR now? 

The code was functional (admittedly fragile) - hardly a priority when we're tryng to respond to a disaster... If you have an issue with existing code then I think that's on you to fix. 
However I've made some changes as I really want to get these changes merged so I can move on with some other work. 
How does that look?
Do consider blocking PRs like this de-incentivized people from contributing - not many active contributors right now - which I think is a bigger issue than code quality.
I do appreciate the reviews, but I would have been much happier to fix this in a subsequent PR 

I'm not wanting to make those changes to the IFRC config as I know that AidIQ is managing that

I don'ẗ think your changes here are in response to a disaster, and what I'm asking for is just to make it more robust now that you've introduced a deployment-setting to control the sector filter and hence a third variable which makes it more fragile.

No changes are required for the IFRC template, merely the asset and inv controllers shouldn't pop the widgets, but rather they not be inserted in the first place when current.request.controller == "inv" or "asset".

That's a minor enhancement to your PR and should be less than 10mins for you to do.

Please don't try to put pressure on me - I am not blocking the PR, but trying to prevent potential sources of regression problems - which are much more harmful especially in the middle of an emergency deployment than requesting you to invest 10 more minutes in your PR.

Please try to act responsibly and not use your position to apply thumb screws on gate keepers.

I've done the enhancement already! 
current.request.function != "supplier however... OK?
Can you review?

Personally I think that code quality is _much_ more important than number of code contributors...I think our users would agree too.

I don't see any further issues.

Currently I don't have visibility of any corresponding requirements, so can't validate whether these changes are appropriate. But they seem technically ok.

Changes updated...

OK to merge?

@flavour Would make my git management much easier to get this merged

I don't see why we need the SCSS of font-awesome in trunk? We're not going to customize it, are we?
I think the CSS is absolutely good enough

@nursix + @flavour Just to clarify, I was under no assumptions that this code was trunk worthy - hence no PR. However your review was extremely timely. I've tried to address all of these - with the last outstanding this being the deprecation of FA3

PR Updated

Still a lot of .less files without need. LESS is even /less/ needed than SCSS ;)

CSS and font files should be good enough.

Interesting that you say there was no PR - obviously this here is a PR?

Merging latest changes in base

-1 What's this for? The name rules are enforced by the validator upon import - if you skip faulty rows already in the stylesheet, then you will get no error message and thus they go undetected. I'm relatively strongly against this practise - it is necessary to indicate errors like this, otherwise users will struggle to understand why certain data don't get imported.

Hi, Tudorian!

Yes, there was a GSoC project last year to integrate a chat server -- it uses Openfire.

http://eden.sahanafoundation.org/wiki/Event/2014/GSoC/Chat

Thank you very much!

Ideally, we would deprecate these charts since jqplot was deprecated when we introduced flot, and now flot is deprecated since we moved to D3 - so dinosaurs are more modern than this page design.

Apart from that, this page is normally not accessible for any user except administrators, and thus adds very little value - it merely existed as a PoC (5 years ago), but since we have moved lightyears beyond that, this can really really be removed.

NB when you change layouts or styles, it would make reviewing stuff a lot easier if you could provide screenshots. In this case both - large (desktop), medium (tablet) and small (mobile phone, both landscape and portrait) screen sizes to demonstrate responsive behavior.

Without responsive behavior, this fix would be fairly pointless (yeah, ok, it is anyway - but that is an important general requirement for page designs now).

Good idea.

However, better would be to disable the menu item if the directory doesn't exist, or at least inform the user that we're not showing anything because there isn't anything to show. As you have it here, it would be just empty, and not obvious for the user why (<=which you can be sure will be reported as a bug).

At least, try something like

```
response.warning = T("No test results available")
```

in the except-branch.

Note that the test suite that produces the test results is deprecated and not working at the moment ;) so this "bug" is only the very tip of the iceberg.

What is really needed is something that actually produces test results - and while we don't have that, I would recommend to comment this menu item and put in a ToDo (in s3menus.py). No point to show a menu item that doesn't ever work.

We do have a new smoke test functionality, however - it's just not wired up to show any test results inside the application. And while it isn't, there's no point to have that menu item visible for the users.

Hey @nursix ,

Thanks for taking the time to look at this.

Judging from your comments it sounds like removing the `/pr` pages altogether is the way to go. My plan then is to remove the following:

```
 controllers/pr.py
 views/pr/
```

I am guessing that other aspects of the application might be using the pr table so I wasn't going to attempt to remove reference entirely ie. removing `modules/s3db/pr.py` etc. but I may be wrong about this.

Does this sound like a good plan or is there a better way to go about this?

Oh no, I was merely talking about removing _the charts_ from the pr/index page - the rest of the person module is absolutely essential for Eden!

The only other thing that could be removed is jqplot.

Or in other words: the person registry module is an utterly important, and yet largely invisible module. Most users won't have direct access to this module, and normal users do usually never see the index page - hence the charts add very little to no value. Even if end-users would see them, they do not really provide any relevant information.

They have been a PoC for embedding charts into pages, but we have moved on far beyond that and meanwhile have a generic charting framework, so these charts are obsolete for that purpose.

But the pr module as such is a true core module and there is no (really: no!) other module that would work without it. Eden as a whole wouldn't start without it ;) It defines _the_ core entities for everything - and we do want to retain the index page at least for data maintenance (standard CRUD with Admin level access), and for certain simpler use-cases.

@nursix Changes made - how's this look?

@nursix I thought that was a little weird to be removing the `pr` module hence my comment about how I suspected other parts of the app were using it, but yeah, my bad haha.

So I have updated the pull request to remove the charts from the `pr/index` page and also noticed similar charts were being used on `dvi/index` so I removed those as well assuming the same situation applied (ie. they're outdated). As those were the only two uses of jqplot I could find, I also deleted the jqplot files from `static/styles/` and `static/scripts/` but perhaps I have gone too far by doing this? or maybe there was a more elegant way to remove/disable these jqplot related files?

I've attached screen shots of each the `pr/index` and `dvi/index` in firefox, chrome, tablet and mobile renderings.

![dvi_index_chrome](https://cloud.githubusercontent.com/assets/3066399/7823134/637f5c3c-03ae-11e5-9578-e95d67444f4e.png)
![dvi_index_firefox](https://cloud.githubusercontent.com/assets/3066399/7823135/63803bfc-03ae-11e5-9730-c41bc08b6b4d.png)
![dvi_index_mobile_h](https://cloud.githubusercontent.com/assets/3066399/7823139/6387e8b6-03ae-11e5-8252-38910d68a872.png)
![dvi_index_mobile_v](https://cloud.githubusercontent.com/assets/3066399/7823138/6386ddb8-03ae-11e5-82dd-d9f5cf3f66cc.png)
![dvi_index_tablet_h](https://cloud.githubusercontent.com/assets/3066399/7823137/63856ca8-03ae-11e5-82ab-ebf5206d15cc.png)
![dvi_index_tablet_v](https://cloud.githubusercontent.com/assets/3066399/7823136/63849184-03ae-11e5-85d7-11a39be67ceb.png)
![pr_index_chrome](https://cloud.githubusercontent.com/assets/3066399/7823140/639a1c34-03ae-11e5-8e06-871705350fe2.png)
![pr_index_firefox](https://cloud.githubusercontent.com/assets/3066399/7823145/63b80690-03ae-11e5-8849-c9df8c0d8ab0.png)
![pr_index_mobile_h](https://cloud.githubusercontent.com/assets/3066399/7823141/63b54798-03ae-11e5-9ddf-1a655449af9a.png)
![pr_index_mobile_v](https://cloud.githubusercontent.com/assets/3066399/7823142/63b77266-03ae-11e5-979f-c7e2a86076ff.png)
![pr_index_tablet_h](https://cloud.githubusercontent.com/assets/3066399/7823143/63b7a344-03ae-11e5-8ad6-2b1c046ee41c.png)
![pr_index_tablet_v](https://cloud.githubusercontent.com/assets/3066399/7823144/63b80e10-03ae-11e5-820f-5a9432dbe954.png)

Thanks for the review @nursix . That response warning is definitely a better way to communicate to the user there are no test results. I'll do what you said regarding removing the menu item and adding a ToDo.

Sorry for the delay with the review, couldn't find the time earlier. Please note that there are merge conflicts, so rebasing may be necessary.

I manage to integrate openfire with sahana DB but the chat box does not appear in Sahana. I am using the default template and configured the chat  options in the 000_config.py in the Eden\models folder.

A sample below.

settings.base.chat_server = {
   "ip": "127.0.0.1",
   "port": 7070,
   "name": "sahana",

# # Default group everyone is added to

   "groupname" : "everyone",
   "server_db" : "openfire",

# # These settings fallback to main DB settings if not specified

# # Only mysql/postgres supported

```
"server_db_type" : "mysql",
"server_db_username" : "sahana",
"server_db_password": "******",
"server_db_port" : 3306,
"server_db_ip" : "127.0.0.1",
```

   }

Am I missing something ?

Do you have any errors? Check firebug, or the equivalent on your browser,
to see what the return code is, You can also check to see if you have any
new trace-back in the error folder. I'm away from my dev machine so I am
not able to give you much support at the moment, sorry, but the most likely
cause is an error so you will nee to look for that. The most common cause
of error are either javascript error or a error response from Sahana.

On 30 May 2015 at 07:27, Tudor Bugnar notifications@github.com wrote:

> I manage to integrate openfire with sahana DB but the chat box does not
> appear in Sahana. I am using the default template and configured the chat
> options in the 000_config.py in the Eden\models folder.
> 
> A sample below.
> 
> settings.base.chat_server = {
> "ip": "127.0.0.1",
> "port": 7070,
> "name": "sahana",
> 
> # Default group everyone is added to
> 
> "groupname" : "everyone",
> "server_db" : "openfire",
> 
> # These settings fallback to main DB settings if not specified # Only
> 
> mysql/postgres supported
> 
> "server_db_type" : "mysql",
> "server_db_username" : "sahana",
> "server_db_password": "******",
> "server_db_port" : 3306,
> "server_db_ip" : "127.0.0.1",
> 
> }
> 
> Am I missing something ?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/issues/1087#issuecomment-106986593.

I checked the generated HTML file, no errors are present.

I noticed that S3.chat.js is not loaded . That why I supposed there is a configuration problem.

I identified some problem in the Sahana - Debug Mode . In the production installation still no chat 

TypeError: deps is undefined
http://127.0.0.1:8000/eden/static/scripts/converse.nojquery.js
Line 405

TypeError: geti18nSetting is not a function
http://127.0.0.1:8000/eden/static/scripts/S3/s3.chat.js
Line 10

I found the problem
there is a bug in  s3.chat.js

  i18n: geti18nSetting(), should be   i18n: geti18nSetting,

Thankyou - fix committed :)

Cool -- thank you, Tudor!

You' re wellcome :)

@nursix Thanks for the review. Everything addressed and merge conflicts resolved (nothing major) - hopefully good to merge!

There's a lot of non-standard code formatting here still, like blank lines missing where they should be, inconsistent identation (closing brackets), non-standard line breaks, extra whitespace ... If Fran wants to clean it up after merge, then fine - but I actually think you should do that yourself.

Enforcing the comments field in the XLS codec is plain wrong - especially without any option to turn it off. And neither can I see why you would remove some of the settings from IFRC/config.py.

Regarding the homepage customization patterns - there is a significant difference between the default/index customization and the module index pages: the default/index pattern allows for a multi-page extension, which is very useful for e.g. embedding online documentation. This pattern is by far more powerful and cleaner in view of error handling and forwarding than the customise_xxx_homepage pattern.

I am not sure whether the customise_xxx_homepage pattern should have been introduced - to me it always looked like a hack, and not very thought-through. The idea seems ok, but the design is questionable. Especially it does not take into account that errors redirect to the module index (and sometimes even swallows the errors), nor does it consider the implications on permissions. It is also loading functions without need - which is certainly the ugliest part of it (whereas the default/index pattern only ever loads the functions when you actually access default/index). I see this as a rather weak pattern that needs a lot more thought before being applied everywhere.

Regarding the re-usability of code across templates: you are /not/ limited to controllers.py in any way. As I said: templates are now regular Python packages, you can have as many modules inside it as you like. You can import from templates.XYZ.config just as much as from templates.XYZ.controllers or templates.XYZ.layouts.

However, there are of course "moral" limits - some things don't make sense. For example, importing from a template into core would be stupid, so I would be strict about not allowing that. Nor would I actually want things to get imported from one config.py into another (because that'd pave the road for regression bugs).

Generally, we should _not_ strive after maximising cross-template code sharing - if a certain function or class is relevant for many templates, then it should be core. However, there are sometimes two templates within the same general use-case (e.g. RMS and RMS Americas) - and even if they did share certain elements, these elements would still be specific to the case and not necessarily generic. 

For such cases (derivates and alternatives), it make maintenance a lot easier to import from one template to the other, and helps to maintain consistency.

However, I would suggest to move this debate to a more visible forum - it's a bit misplaced on your PR.

Note that your PR may take forever if you keep introducing new things into every review iteration - better you just fix/cleanup what you already have in it, and leave the next changes to the next PR. Also note that the more different/independent changes you put into the same PR, the harder it will become to get any of them merged (one-change-blocking-the-other effect).

This looks like an upstream issue...this file is vanilla upstream as far as I know.
I would talk to the developrs of that project to get that resolved...and then please pass on the results to us here so that we update the file accordingly.

ok great!

All fine other than the instance-specific settings being in the general config...comment these out & we're good to merge :)

Maybe a more plausible commit message? "Task 1.1" reference is not very conclusive outside of the PM context

Right, good to refer to the spreadsheet:
https://docs.google.com/spreadsheets/d/1N9xUqZQhignq7QM_7CtrV4zv86sq4lMdJj81IQuch3Y/edit#gid=0

i have a new version of converse.jquery.js. How can i generate the minified version of sahana chat?

Did you get this from upstream? General new version or specific fix for us?

1st test it using ?debug=1
If it works well then you can also compile & retest minified:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Minify

or else send it to me for me to include/compile

Yes from upstream. I tested it on my local deployment but without success.  I think there is a javascript loadin problem because sometimes the chat works and sometimes it doesn't

You need to have the nojquery version because a conflict will occur when
both converse and web2py try and load their version of jquery

On 10 June 2015 at 17:16, Tudor Bugnar notifications@github.com wrote:

> Yes from upstream. I tested it on my local deployment but without success.
> I think there is a javascript loadin problem because sometimes the chat
> works and sometimes it doesn't
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/issues/1092#issuecomment-110769915.

I still cannot figure out why the problem appears. Sometimes a value that is passed to converse  is null and a method of converse tries to access a property of that null object

The problem appears in converse.nojquery when fastclick.js call the define function from converse.nojquery

if (typeof define === 'function' && typeof define.amd === 'object' && define.amd) {

```
    // AMD. Register as an anonymous module.
    define(function() {
        return FastClick;
    });
} else if (typeof module !== 'undefined' && module.exports) {
    module.exports = FastClick.attach;
    module.exports.FastClick = FastClick;
} else {
    window.FastClick = FastClick;
}
```

@flavour please review

https://github.com/flavour/eden/blob/master/modules/s3cfg.py#L702

@flavour only commit with "default source, CAP identifier and expire offset configuration"...Please merge it...
Other one I merged from trunk later

Please provide a clean Pull Request for me to merge then

@flavour Please merge this

@flavour Please merge this

I recommend that you explain the urgency rather than repeating your request for merge - although it seems unclear how you would be dependent on a merge?

@flavour thanks for the review...I have applied the suggestions 

Also, please always rebase/compress when fixing PRs - thanks!

I've cleaned things up and addressed all comments. If you let me know where there are specific formatting issues I'll address these too.

@flavour Please merge this

That looks wrong to me. 
- Why include Foundation, but then override it with non-responsive layouts and styles?
- You can not deactivate mandatory modules (gis, pr, org), and surely you should not deactivate "cap", out of all modules?

Experimental code?

I don't think this can be merged at this stage (not functional) - and generally the design should be (seriously!) re-considered. Responsive design is de-facto standard in Sahana, and utilizing the CSS framework when available seems more than obvious.

NB the broken unit-test is in trunk, not caused by your code.

@flavour Please merge this

@flavour Any delay in merging this?

Much better than before ;)

@flavour Please merge this

1. Is it further necessary to notify the user that a multi-sheet workbook is being created? If so, how does Sahana handle error notifications (ie: integrity errors)? Would they be passed through the codec file in python, or through javascript? (I assume the former)
2. The ticket suggests also using xlsxwriter in order to make exporting multiple sheets unnecessary. Is this a worthwhile endeavor? I say this because it may be too much to make the user install two near-identical libraries for a single function in order to bypass a single bug.

This looks good. Small cleanups may be necessary, but nothing serious.

Unit tests would be nice here.

For your questions:

1) Issuing a warning that a multi-sheet workbook has been created is not critical (and not easy either since the exporter window closes immediately after successful export - you would thus have to do some JavaScript acrobatics to make this work, and I don't like that idea).

2) This should not be a replacement, but an alternative per requested format extension. If the requested format says ".xls", then we export a multi-sheet workbook in XLS - and if the requested format is ".xlsx", then we export an XLSX.

Thanks - could you rebase/compress please?
This also has my most recent commits mixed in...many thanks!

@flavour : I believe I rebased just now (maybe not, I'm new to this resolving conflicts thing.) Thanks!

Nope, sorry...I see 16 commits here: https://github.com/flavour/eden/pull/1103
I should be seeing 1
See this doc on compressing commits during the rebase:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#Summaryofcodingworkflowusinggit

done, unless i somehow resolved the conflicts incorrectly.

This looks great, thanks - some very minor comments which I've not just merged/fixed since I wasn't 100% about the totalCols indent.

Bad luck that I happened to be modifying this file at the same time to give conflicts!...ah well, resolving is all good practise ;) 

Done, and as far as I know, it works on my end.
http://a.uguu.se/hwbkam_localhost_ItemsinStock%283%29.xls

In this example, I set the row limit to 4. As we can see, the first page will actually have one less row than the limit (in the real world, 65535).

Great, thanks, merged. Have you filled out a CLA?
http://bit.ly/SSF-eCLA

@flavour Yes, I have.

@flavour Please merge this

@flavour Please merge this 

Please ensure 1 commit per PR (rebase/compress)
Also a request to 'review' is nicer than the request to 'merge'

@flavour I have tried to make changes as per suggestions...Please review

anybody here?

anybody here?

Sorry, I was away when this was submitted & then it got drowned in my InBox.

I just had a check & it seems that the Web2Py Admin interface uses ABOUT & LICENSE but not README, so that doesn't appear to be a blocker, so I guess this is a useful step, thanks :)

thanks

Very hard for me to review this since every line has been changed...I guess this is due to line-endings.
The key things I look for are correct use of variables as this can crash if incorrect.
We have 2 options for proceeding: (A) You resubmit without changing line-endings so I can see what you've changed or (B) I delegate responsibility for this translation to you.
Can I assume that you've done at least partial testing with this new file?
Do you have a live deployment of the software?

I'll fix it soon and then ping you, thanks!

@flavour Please merge this

@flavour Please merge this

@flavour Please review this

Furthermore, that commented out code dealing with title rows right above this section kind of bothers me. How would I access options from either 000_config.py or some other config file so a user can toggle the title row through there? (I apologize for my green-ness, I'm still learning how the Eden codebase is constructed).

@flavour Please merge

Thanks :)
deployment_settings are set in either 000_config.py (for a specific local instance) or a template's config.py
They should have a function in modules/s3cfg.py which accesses this & you then put your caller in the code.
In general we prefer backwards-compatibility, so a settings.get_xls_title_row() should default to False
(I didn't work too hard on the name of the fn so feel free to suggest something better!)

@flavour Please merge

@flavour Please merge this

Thanks - I think this is the kind of setting which would nromally be in a template so we'd prefer the commented example in modules/templates/default.py

@flavour fixed and squashed

Terribly sub-standard, and using unsafe and unnecessary methods. This needs conceptual reworking.

As I see it, this is using completely the wrong framework - or actually: it pretends to use a framework, but then actually bends it and works around it, which is a clear indicator that this is misplaced - and an invalid generalization.

The idea for the user to be able to configure an FTP URL where to get certain CAP alerts published doesn't make this a messaging protocol, IMO. It's just a file system, after all.

It may be a synchronization method (i.e. repository type), where it would not only be easier to implement, but also make a lot more sense - and for example, logging errors in the system log facility is not anyhow useful for the users - as opposed to Sync log, which is accessible through the UI. And since each and every FTP target URL would have to be configured as a separate channel anyway, it could just as easily be treated as a sync peer.

As a Sync adapter, it would also be re-usable for other cases - and could be extended to be two-way.

Sync adapters look like this:
https://github.com/flavour/eden/blob/master/modules/s3/sync_adapter/eden.py
or this:
https://github.com/flavour/eden/blob/master/modules/s3/sync_adapter/wrike.py

...each with its own way of login, pull or push. Shouldn't be difficult to implement one for FTP.

And FTP repositories could then be configured as synchronization peers, including authorization and synchronization schedule etc, for more details about the concept see:
http://eden.sahanafoundation.org/wiki/UserGuidelines/Admin/Synchronization

We don't currently use Sync Adapters for any other Notification method, whereas we do use Messaging Channels which is where it seemed consistent to have FTP be just another Messaging Channel. I'm not sure we need to hold up this merge on this point.

And what is the point with subscriptions here - what is the point with having 1 FTP channel and 100 users subscribing to it? It would only copy the same file 100 times to the same target location.

No, I think this isn't the right concept.

And merging it will only make it harder to pull it out later when we've implemented the right concept of FTP Synchronization.

...which would not only be much cleaner, but also indeed generalizable.

If it would have to become a subscription concept, then this will need to personalize the FTP channel (target location). Otherwise this doesn't make any sense here.

If you wish, I can implement that sync adapter for you so you can meet your deadlines. I'm working in that area at the moment anyway.

I don't think your example of 1 FTP channel with multiple users would ever happen in practise, why would it?
The FTP channel is indeed a personal one for the Subscription.

Currently I see no need for an FTP Sync Adapter...sure it may be useful to have such in general and if we can use Sync Adapters for Subscriptions (which seems reasonable) then we could make use of that here, but I don't see any issue with having FTP as a Messaging Channel for a consistent API from there.

Yeah - I would strongly disagree with that. 

In the CAP context it may appear that this is just another messaging channel, but just because CAP is designed for messaging doesn't mean all possible CAP export paths are now suddenly and necessarily messaging channels. For file export - regardless whether push or pull - this is simply untrue, mixing apples and oranges and then calling it "consistency".

From a technical perspective, FTP is simply not a messaging protocol - and none of the typical subscription/notification features does apply. But the strong generalizable case is on the Sync-side, where we could re-use FTP for many purposes.

I know you have deadlines, but rewriting this as a sync adapter isn't as expensive as it may seem - and hence I don't think it's worth to fight for this PR.

It's bending the specs of the notification framework (more than of the messaging framework), and I am opposed. Especially since it doesn't seem to complicate anything here - adding an FTP channel isn't quite like adding an email address to your user profile, so the inconsistency is already there. And this inconsistency is far greater than the inconsistency with Sync repositories.

All the exporting and sending code can be re-used for a sync adapter, so it's not like re-inventing the whole thing, but rather just moving it where it belongs. And exposing a simple dialog within CAP to configure another FTP repository doesn't seem like a big deal - and you do need to do something similar for FTP subscriptions anyway.

...and would you argue that there is something like a personal FTP channel framework that is anywhere near a normal pr_contact as it is used for regular messaging? I think that this is actually much more inconsistent than Sync is - and I don't quite see a case for re-using FTP "messaging". Very far-fetched.

OK, I'm convinced ;)
So the pr_subscription table should use repository_id instead of channel_id
& s3notiify doesn't have method = "FTP" but rather method = "sync"
(Internally the SAMBRO template can label this as FTP if-desired)

I would simplify that and use the repository name as label.

So, if you had multiple (and they were accessible for you), you could add multiple peer repositories to your subscription - and in fact, it doesn't really matter whether they are FTP or e.g. Wrike as long as they do accept PUSH.

The sync_repository table could have a "subscription" flag to distinguish those which are open for subscriptions from those which have a schedule and those who are inbound. That'd be easy.

Do you want me to implement the Adapter?

> I would simplify that and use the repository name as label.

Instead of repository_id? _shudder_

> So, if you had multiple (and they were accessible for you), you could add multiple peer repositories >to your subscription

Wouldn't each of these be a separate subscription?
hmm, I see that method is a list:string currently so there would indeed just be 1 record if subscribing to the same filter, on the same frequency but via 2 different methods...this does get very ugly for the very rare case where a subscription was coming in via multiple repository_ids.
I would be tempted to remodel this...e.g. what if the user wanted to subscribe via 2 different email addresses? (Seems a much more common usecase than 2 different repository_ids)

> - and in fact, it doesn't really matter whether they are FTP or e.g. Wrike as long as they do accept >PUSH.

This is _exactly_ why I said "use repository_id & just label as 'FTP' in the SAMBRO template"

> The sync_repository table could have a "subscription" flag to distinguish those which are open for >subscriptions from those which have a schedule and those who are inbound. That'd be easy.

I don't see the point of this yet, but I guess could be useful later if we have tons of repos for different purposes...def not required yet.

> Do you want me to implement the Adapter?

This seems to be a ballooning requirement which makes me wary of doing anything...I know that you are very busy with other work so asking you to volunteer to do this seems inappropriate, yet equally it is a lot to push back on us.

Don't worry - I am currently busy with Sunc repositories anyway, so this is my focus area at the moment and not much of a task switch. Better now than some other time - and implementing it is actually less effort than reviewing it ;)

Subscribing via contact address rather than contact method very much +1 (has been discussed before, was just postponed until a case came up), and I do actually see a case where the same user (e.g. a CAP Publisher) would want to subscribe multiple target repositories to the same alert feed. 

That would especially be meaningful if the target repos used different formats (as has been suggested in this discussion).

Using the repository name as label instead of "FTP" would be equivalent to using email addresses instead of just "Email", btw. Don't get your "shudder" here.

The best design would probably be to let the user choose a notification method, and then offer an (Ajax-fetched) list with possible target addresses (email addresses, mobile phone numbers, FTP repositories) for multiple selection.

Extending this with an "Add another one" dialog may be overkill at the moment - but it's an obvious future enhancement.

This is how I imagine subscription to work, but of course there could be other designs in specific use-cases.

However, I would imagine the same FTP URL to be subscribed only exactly once to one particular alert feed - which makes the whole effort to employ the subscription framework /at all/ look a bit inflated. The user would actually enter a new FTP URL for every subscription, no?

And if that is indeed the scenario - then you don't actually need anything in S3Notify, but can push the FTP configuration directly to S3Sync.

...which would be half the effort for twice the value

torsdagen den 13 augusti 2015 09.28.50 skrev  Fran Boon:

> This is exactly why I said "use repository_id & just label as 'FTP' in the
> SAMBRO template"
> Yeah yeah - I get it. Of course - I was just suggesting a generic way to 
> represent it.

In principle I think when you subscribe via FTP, then you wouldn't just choose 
"FTP" from the list, and then want to enter a URL - and most likely a new one 
for each filter.

I don't quite see subscribing one and the same FTP target location to multiple 
filters as the most likely case, nor the most flexible one.

Could happen, sure - but it seems very unlikely that /all/ filters would go the 
one and the same FTP target location (nor all subscriptions to equally to all 
FTP target locations) - what would be the point? I mean - if that is your 
primary scenario, then what's the point with individual per-user subscriptions 
at all?

Dominic

torsdagen den 13 augusti 2015 19.06.36 skrev du:

> Could happen, sure - but it seems very unlikely that all filters would go
> the  one and the same FTP target location (nor all subscriptions to equally
> to all FTP target locations) - what would be the point?

So, in fact - having a drop-down with existing target locations doesn't seem 
to be the most useful thing.

Having an "FTP" method to select for the subscription, and then show an 
(embedded) input dialog to enter the respective FTP target URL and 
credentials, that seems the more common case to me.

Just for the case where you would really want to subscribe the same target URL 
to multiple filters (as I say - I see this as an edge-case), then it may make 
sense to be able to retrieve it. Could just be an autocomplete for the URL?

Like in:

Subscribe to this feed

O EMail
    O myaddress@example.com
    O otheraddress@somethingelse.org
O SMS
    O +4936273564
    O +4973846283
O FTP
    URL: ftp://somewhere.org/path/to/repo
    Username: dumbo
    Password: ****
    Format: CAP | XLS | PDF

(If this looks ugly, copy to monospaced in your editor)

> Subscribing via contact address rather than contact method very much +1 (has been discussed >before, was just postponed until a case came up),

Note that this isn't that usecase...just that it seems like if we're redesigning then this should be taken into consderation.
The downside of this 'hardcoded contact within subscription' is that if the user changes their contact details then they need to either update this subnscription manually or we need to ensure that onaccept does it for us which seems fiddly/unreliable...the decoupling of these 2 does have it's benefits.

> and I do actually see a case where the same user (e.g. a CAP Publisher) would want to subscribe >multiple target repositories to the same alert feed.

This isn't the way the workflow is currently defined, but yes I can imagine that in the real world it could well be like that - the FTP repos aren't belonging to the Publisher but it's easier for them to simply add a subscription directly rather than create the user acount for the real subscriber & then use that to subscribe them.

> I would imagine the same FTP URL to be subscribed only exactly once to one particular alert feed 

For CAP, yes

> which makes the whole effort to employ the subscription framework /at all/ look a bit inflated. The >user would actually enter a new FTP URL for every subscription, no?

Yes, but the point is that from the user perspective this is a Subscription just like for Email/SMS
FTP shouldn't look any different from these - other than the details within the contact/channel/repo..

> then you don't actually need anything in S3Notify, but can push the FTP configuration directly to >S3Sync

I worry this makes the debugging harder - an Admin wanting to debug notifications now has to look at 2 different sets of tables rather than having these in a common place...but I see your point.

> In principle I think when you subscribe via FTP, then you wouldn't just choose
> "FTP" from the list, and then want to enter a URL - and most likely a new one
> for each filter.

yes of course
I was just saying that the label would be 'FTP' not 'Sync'

> (embedded) input dialog to enter the respective FTP target URL and
> credentials, that seems the more common case to me.

Thats exactaly how I was proposing it be done for the Channel method - no difference in UX here

> Format: CAP | XLS | PDF

This could also appy to Email (email of PDF/XLS seems a common usecase)

So, the planned workflow is that every user has a personal FTP channel which he can manage under "Contacts"? Now I should perhaps add a _shudder_ here :D

Yes - uncoupling the contact address and the notification method of subscriptions had exactly that purpose, originally. The subscription could remain the same while you could maintain your email addresses in a central place without having to update every use-case separately. Very much agreed.

On the other hand, you would probably not store the email address itself in the subscription record but rather a reference (pr_contact_id), and if the address (value) for that pr_contact entry would change, it would equally change for all subscriptions.

Surely, if you remove a pr_contact, then you would also remove all subscriptions for that pr_contact entry - but what's wrong with that, actually? I do actually like the idea to be able to remove all subscriptions together with the email address from my account.

The trick would be to make the user aware that a particular of his pr_contact entries is used by subscriptions, and deleting it would also remove these subscriptions, but that should be an easy thing to do.

Hmm - yes, you would have to debug FTP sync in a different place if it did not use subscriptions.

But at the same time, it would be a very convenient place to debug because all the sync adapter stuff is in one place ;) as opposed to the combination of S3Notify+S3Msg+S3Sync which is pretty much spread out.

In any case, I think that trade-off is acceptable - especially if the FTP Sync is additionally also maintained from another perspective (i.e. genuine FTP Sync).

I need to get off this thread for a while and focus on something else - does not mean I've changed my mind or have lost interest ;) If required, we can continue to discuss this on Skype or Hangout tomorrow (or some other day that is convenient for you), but for now I need to get a job done. Sync, that one too ;)

Does this really need a separate menu entry?

I would have thought that the default Alerts list would make sense sorted to have the most recent alerts 1st and that it not being too busy should be sufficient, but can easily have an 'Expired/Unexpired filter on it if-required.

To me the title of the menu entry is misleading compared to the filter applied - this isn't "recent" alerts, but rather "unexpired" alerts...

@flavour  this is as per L64 of https://docs.google.com/spreadsheets/d/1N9xUqZQhignq7QM_7CtrV4zv86sq4lMdJj81IQuch3Y/edit#gid=0
"the expire date of alert less than now" isn't the recent alerts?

I think this is a mistake in the specs: recent alerts would be expires > today, not expires < today.

Saying that because according to the spec item, recent alerts = active alerts - but expires < today selects expired alerts.

It also says "at least" recent alerts, but it doesn't explicitly disallow "all alerts with the most recent on top", which may be more useful.

Meaning: you could list all alerts, with the most recent on top, and set expires >= today as filter default. 

Then the menu item would show only recent alerts at first (and the most recent on top), but the user could modify this filter to select more (or "clear filter" to show all alerts), and also alter the sorting.

By contrast, with s3.filter the user would need to switch to a different page to extend to older alerts.

Filter default example here:
https://github.com/flavour/eden/blob/master/modules/templates/CRMT/config.py#L633

Btw - with this definition it should be "Active Alerts" or "Current Alerts" not "Recent Alerts".

You can also just put the default filter into the menu item analogous to "Active Missions" in RDRT:
https://github.com/flavour/eden/blob/master/modules/templates/IFRC/menus.py#L393

Then you don't need a separate controller, and the user can still modify the filter to also see expired alerts.

Yes, so Dominic is echoing what I am saying, with some further refinements:
- (The menu entry as it stands has the wrong name)
- Rather than having this menu item at all, it would be better to simply have this be the default view for the main Alerts list:
  - Sort with most recent at the top
  - Include a Filter to select expired or not
  - Have this filter default to just showing unexpired (which can be done most easily with the URL filter in the menu link)

This would probably be better posted on the mailing list than put onto GitHub.

Personally I always import using CSV as the XLS/XLSX files are unwrapped to this format, hence can provide additional problems (e.g. XLSX requires a recent version of the xlrd library)
Also spreadsheet programs are notorious for doing unexpected things to your data when trying to be 'helpful', so I look at the CSV file primarily through a text editor, only using a spreadsheet program when I really need the advantages it brings.

Trying to debug your specific issue is almost impossible without the file that you are trying to import.

Here is the .csv to be imported into the Hospital section:

```
"Name","Code","Type","Status","Reopening Date","Power","Services","Beds Total","Beds Available","Organisation","Branch","Country","Building","Address","Postcode","L1","L2","L3","L4","Lat","Lon","Phone Switchboard","Phone Business","Phone Emergency","Email","Website","Fax","KV:XXX"
"Ngelehun",,"CHC",,,,,,,"Ministry of Health and Sanitation",,"Sierra Leone",,"Ngelehun, Badjia, Bo",,,,,,,,,,"+23211123456",,,,
"Njandama",,"MCHP",,,,,,,"Ministry of Health and Sanitation",,"Sierra Leone",,"Njandama, Badjia, Bo",,,,,,,,,,"+23211123456",,,,
```

Anything obvious?
Thank you so much!
Chris

That file imports fine for me here.

NB I always use the 2-letter ISO code for country as smaller & less easy to typo/spell alternately (but this is OK too)

The Address would be better split into the L1, L2, L3 for Reporting & Mapping...

The error in the traceback you show above is in the xlsx handling of the xlrd library, so maybe try upgrading that library or using xls or csv

Following your advice, I am only using .csv, which is the smaller the preferred format anyway. What is happening now is that on any import attempt just nothing happens.
My gut feeling is that the server portion doing imports is hanging. Alas, I have in the current setting no way to play sys admin (but I believe they used Ubuntu), and may have to revert to my own dedicated server to check this out in more detail. It is, however, encouraging to know that you could actually handle the file. 
On my FreeBSD server, I plan to use daemontools to control the Web2Py instance - could this prevent such partial "hangs" , if my hunch is correct?
I will revert as soon as I have more information! Thanks a lot, and bests from Freetown.

I have no experience of Eden on freeBSD or using Web2Py with daemontools.

Our recommended installation guidelines are on the wiki. The one I use mostly is Cherokee/uWSGI but Apache/mod_WSGI is also in-use.

@chlarsen : as it looks your import .xslx has been modified using LibreOffice, and certain LibreOffice versions have a bug which do not properly encode the column range of the document, which then leads up to this crash in xlrd (as xlrd doesn't catch it).

LibreOffice won't fix the issue saying that their xslx output validates properly in Excel (hence it's not their problem), and python-xlrd has an open pull request to solve the problem https://github.com/python-excel/xlrd/pull/107

We can only hope that either side will solve it some day - and until then, you can only either use MS Excel to correct the output xslx (i.e. open it, and save it again), or use CSV format as Fran recommends. Very little else we can do from our side except to document it as a "known problem".

Sorry.

Note that the problem does not exist with .xls format (i.e. binary Excel format not XML), so if you use LibreOffice, you can save as .xls instead of .xlsx to work around the problem.

For the other problem re: "partial hangs" - could you elaborate on "just nothing happens"? Does the form actually get submitted (can you see the POST request go out in firebug)? Does the page remain the same or does it go blank? Can you open any other page in Sahana (e.g. navigating to another menu item)?

There is no known FreeBSD-specific problem with such symptoms, so before you reconfigure your server, I would recommend to first really exclude a client-side problem. Otherwise this could become really frustrating.

Btw - you did not yet mention which versions you are using (both web2py and Sahana). That is always very useful information when you report problems.

Oh sorry, I misread that - you say the current server is Ubuntu, and you are only planning to switch to FreeBSD.

However, the same strategy applies for Ubuntu - no known Ubuntu-specific problem that would cause the web server to "hang", and thus equally important to exclude client-side and transmission problems first.

As for daemontools - I don't see how that would help. Even if you would use supervise to control the web2py server process - the server process does obviously not /die/ but is either busy or waiting, and either situation would just indicate it as "running" - and hence supervise would do nothing.

If Sahana doesn't send a response to a request, then that does not mean it has died. It just means it either didn't receive the request, or processing the request takes so extraordinarily much time that it never produces a result that could be returned to the client. 

If it does send a response, but the response is either empty or wrong, then we do have a bug. But that situation can neither be caught with supervise.

So what we need to find out is: does Sahana receive the request, and does it really not respond or does it just look like it wouldn't respond. My suspicion is the latter: Sahana does receive the request, but responds by resending the import form instead of the import result, which looks in the UI as if nothing would happen.

sorry I closed the earlier PR https://github.com/flavour/eden/pulls?q=is%3Apr+is%3Aclosed
but again it is showing here :(

@flavour Please merge

Fran, Dominic,

Really really appreciate you discussing the engineering intricacies, so we have the most effective and efficient solution. However, we are a bit held up on offering the solution for the workshop. 

Unfortunately, the SMS and Email delivery code is also held up with the FTP code for us to test and ready for the workshop. I've asked Biplov to split the code and merge requests so we can test the individual delivery methods.

Thanks a bunch
Nuwan

Not sure why - this PR and the entire discussion were only about FTP, and didn't contain any SMS/Email-related code. What's the dependency?

Sorry @waidyanatha : I can't see any pending Email/SMS-delivery related code changes, neither in this pull request nor another, and I don't understand what could possibly be the dependency of those delivery methods from the changes discussed here. 

Further I don't see why pending trunk merges should hold up your demo - you can easily demo from any development branch, it does not need to be trunk for that? The other way around, of course, you may need to integrate upstream changes from trunk into your development branch - and may have trouble to resolve conflicts between the two versions. Is that the case?

Else, I'm not sure what you want us to do.

@flavour Please merge

@flavour Please merge

Sure :)

What is the purpose of this separate field?

This is as suggested by Nuwan...beside event type (as parameter in cap XML), a free text field called event (as in CAP 1.2) should be there...if the user doesn't fill in the event value should be same as event type...last time discussed with Nuwan

What exactly is this for?
As I see it, the purpose here is to allow the Alert Editor to set the Event field to something other than an event_type_id.
The reason they need to do this is because they don't have write access to the event_type_id lookup list?
What is the usecase for this? When would event be set to something that shouldn't go into event_type_id?
Note that the list will be filled with junk anyway since we import whatever people put into event into event_type_id for imported alerts...although I guess that not all deployments may import alerts.

The distinction between an eden.event_type and a cap.event is that we have a knowledge base that depends on the event_type. One example, would be the meteorological warning_priorities that are defined on the event_type = "tropical cyclone". We would define a set of warning priorities based on the event_type. Similarly there is other knowledge such as the event_type specific cap.expire (date/time) offset that we would pre-program. Therefore, we need to include the event_type in our design.

cap.event, in general is free text. For example, for an event_type = "terrorist attack", based on the actual incident we would fill the cap.event value as "terrorist bomb explosion". Another could be "terrorist chemical warfare attack". Both of them would be associated with event_type = "terrorist attack" which certain agencies would subscribe to such alert. There might be an a non-terrorist bomb explosion because some factory accidentally diffused a bomb. National security would not care too much about that attack to activate their people and hence would not subscribe to such events (reality they would because they are curious about all bomb explosions, but trying to make a case).

For those alerts, like an asteroid threat would not have a cap template. The user would use the default template to generate an alert. In such instances, we would need to set the event_type, which would be associated with some database relationships (knowledge) as well as define the actual cap.event.

Hope this explains 

Oops, careful what you give away ;)

> 24 aug 2015 kl. 15:02 skrev Nuwan Waidyanatha notifications@github.com:
> 
> National security would not care too much about that attack to activate their people and hence would not subscribe to such events

I think the essence of this is that "event" is a (short) description of the particular event, whereas event_type is a classification of the event. In the very basic form, event would be just a textual representation of event_type, but it could be more elaborate.

If this were to become more formal, a hierarchical taxonomy would be a possible solution - with "event" being the leaf category, and "event_type" the corresponding root category. The advantage of that would be that consumers could subscribe to sub-categories at any arbitrary level (and knowledge-base could link to sub-categories as well) - without giving up the basic CAP data structure.

A bit Sahana-added value, so to speak ;)

This worked then? :)

@flavour Please merge

"This branch has conflicts that must be resolved"

I think I already pushed this anyway

Could you please resolve conflict. I mean remove u and add s3_unicode

I think trunk is correct already - no more action required

@flavour: Just a sec merging one more bug fix :p

The project_Details bug fix is missing ;)

Ah - it's already in trunk, so it doesn't appear in the diff anymore. Ok ok

@nursix : Fran is too fast for a second :D :D 

@flavour Please review and merge

I'm sorry - but this does not follow the relevant standards for REST nor CRUD, which makes it massively inconsistent and risky.
- "Approve" is a method to change the db status, and should therefore be POST not GET. 
- Post-action redirection in S3Methods uses self.next, not redirect. You should never redirect from an S3Method directly
- Error handling should go through r.error to be safe for non-interactive clients
- The target resource can not be concluded from r.tablename (which is the master table) - all S3Methods must use self.resource and self.record_id to work so that they work on both components and link tables
- You should _never_ re-instantiate the target resource for manipulation, that is incorrect. Instead, if you need to operate on unapproved records, you must include them in the first place (REST)

I'm afraid this implementation is completely unacceptable (because it is incorrect).

Note that approval does actually not work from components (obviously can't approve a component without approving the master).

That is why "review" is only available for master requests - and thus it may be sufficient to throw an error for component requests, and otherwise stick with self.resource.

Re-instantiation is actually not necessary, because if you see the record in a list-view (and hence have that "Approve" action button), then you already have "unapproved" in CRUD. If you don't have that, then the user has no review permission anyway, and hence should not be able to use approve in the first place.

GET is not correct in any case, though. As the very minimum it must be caught behind a confirmation dialog - but actually it must be RESTful a POST request, a simple URL GET should not be able to approve a record.

But what is dramatically wrong with that method is that you do not check whether the user is actually permitted to approve the record. You seem to take that for granted. That combined with a GET request is a security hole big like barn door.

With this implementation, anyone who wants to publish an alert just needs to open it and change the URL method into /approve. They do not even need update permission, nor any complicated request construction - read-access and a browser are good enough.

The other weird question is why this is using the "approve" workflow at all.

In an earlier, similar case, we had implemented a "publish" workflow, which is why there is a PUBLISH permission. This simply used a "public" flag in the target record, and imposed a filter for anonymous users that hid all records with public=False.

This would be a lot easier and safer to implement, and all those weird modifications to the approval concept wouldn't be necessary, and interference with security could be avoided.

This publish-workflow was for CMS posts (newsfeed). Very simple resource-specific method, that was exposed for users with auth.has_permission("publish") == True (this permission does exist and can be managed).

If all you need is to hide alerts from anonymous users, then I think all this is effort and complications are way beyond reasonable.

...not everything needs to be implemented at the framework level ;)

Really - this is very confusing. Why do you "publish" by approving?

If approving an alert and publishing it is one and the same workflow step - then why make it complicated and use record approval?

I would have though that these are two independent steps - approval means "authorize it", and publish means "send it out", in which case indeed you need to have both an approval-concept and a publishing workflow.

But now it looks as if that is one and the same thing - so "approving" a record means to make it public at the same time. And if that is the case, then a simple publish-workflow would have been just as good - and all those inconsistent and insecure framework modifications wouldn't have been necessary.

If though "approving" and "publishing" are two independent workflows, as originally argued, then it seems wrong to make the "Publish" button call the "approve" method.

In my memory it was "you can only publish an alert when it has been approved" - without though making publishing mandatory at the moment the alert has been authorized. I would understand if that requirement has changed - but then it seems odd to employ the complexity of record approval for that purpose, and make major framework modifications just for that one case.

# 

Generally I do see a problem with all this:

The normal meaning of record approval (in the sense of the concept that was implemented) is "to allow the record _to enter_ the database" - which is why it has a reject-component. This meaning has been massively undermined by the recent changes, and records are now allowed to enter regular database workflows without first being approved.

But in the alert case it seems that it actually has the meaning "to make a record available for a wider audience" - while the record gets accepted into the database upfront and without further procedure. That is though "publishing" - and not "approval".

Both concepts can co-exist, which is why we do have separate permissions for them (APPROVE/REJECT vs. PUBLISH), and typically would implement separate functionality too.

But if you don't need both, then you should actually stick to the right concept instead of bending the opposite one to fit your needs while breaking it's original meaning - and without need, I must say.

I think this has all been terribly mixed up due to context-specific terminology being mapped to the wrong framework concept - and unfortunately it is causing the loss of that very valuable, and much needed security concept to prevent unwanted records from entering regular workflows.

To make that clearer:

The actual idea behind record approval is (as needed in NYCP and other templates):
General Public => Data Entry => Approval => Application Workflows

You need seems to be (SAMBRO):
Application Workflows => Approval => Publish => General Public

So, it's turning a framework concept completely upside down - so much that it actually gets lost.

And I do actually disagree that both concepts can be lumped together - because in fact they can co-exist and be separate workflows:

General Public => Data Entry => Approval => Application Workflows => Approval => Publish => General Public

...and should therefore be kept separate.

...and since public data entry (e.g. crowdsourcing) is still an aspect in Sahana, we need to retain the workflow entry barrier option as we had it, even if that is not required for SAMBRO.

In all previous cases where we needed controlled publishing (workflow exit barrier) we did not use the approval-workflow, but a "public" flag of some kind. Michael Howden has correctly recognized this as controlled=>uncontrolled transition (=output chain), and that it is different from the record approval concept (which is for the input chain).

However, SAMBRO project terminology seems to suggest that the application environment is uncontrolled while the general public is the controlled area - but even if that is the case from a business logic perspective, it does still not make "publishing alerts" an input chain, because as Fran explained: application workflows come before that.

Unlike what I first expected, SAMBRO doesn't seem to impose any input chain controls other than trusting the users - every workflow input (e.g. a new alert) is automatically trusted and allowed to enter application workflows if the user has permission to create it.

I did expect that alerts published by other sources and automatically imported into SAMBRO would require approval before being processed further in SAMBRO (=input control), and could be rejected if they were not trustworthy.

But instead, SAMBRO aims to impose output chain controls by requiring separate authorization for workflow items to become available beyond the application workflows (e.g. alerts _to_ the general public, not _from_ other sources).

So, I misinterpreted the need - and hence accepted certain modifications to the approval concept even though they appeared incorrect. But now I see that it is actually a completely different kind of thing that is needed :/

@flavour Please merge

This has a merge conflict that needs resolving & should be rebased/compressed down to 1 commit

I made the core DVR change in trunk

@flavour Please merge

I'd prefer a bit less churn, so will merge this with the next substantial change, ok :)

@flavour Please merge

Hello @schlos - please contact me outside GitHub under dominic@aidiq.com

@flavour please close, I'll take care of that.

Beat you to it ;)

Oops ;-)

I fundamentally disagree with "S3ResourceLink" - the name was chosen to clearly document the purpose of this class, and I don't want to hide it for the sake of a single edge-case. You can still add a comment to document the deviation, or assign an alternative class in-place, if you think it would otherwise be confusing, but not rename everywhere else where "S3AddResourceLink" gives clarity and makes the code more understandable.

I can review the FTP Sync Adapter once you've got that out of the way.

@nursix Thank you so much for the review
I would need ftp object in the push once I move the ftp login to login method...How do I retrieve the ftp object on the push?

You can just put it into self no? S3Sync will always use the same adapter instance it has logged in with.
So, during login - set self.ftp_connection

> I fundamentally disagree with "S3ResourceLink" - the name was chosen to clearly document the          purpose of this class, and I don't want to hide it for the sake of a single edge-case. You can still add a comment to document the deviation, or assign an alternative class in-place, if you think it would otherwise be confusing, but not rename everywhere else where "S3AddResourceLink" gives clarity and makes the code more understandable.

hmm...we started with a subclass - but it didn't make sense to me since it was so similar.
We /could/ have an S3ResourceLink base class & then have Add & Update as subclasses, but it really seems overkill to me.
We can have S3AddResourceLink as an alias to S3ResourceLink since that defaults to m="create" & I suggested that to avoid breaking non-trunk templates/modules.

söndagen den 27 september 2015 12.17.57 skrev  Fran Boon:

> hmm...we started with a subclass - but it didn't make sense to me since it
> was so similar. We /could/ have an S3ResourceLink base class & then have
> Add & Update as subclasses, but it really seems overkill to me. We can have
> S3AddResourceLink as an alias to S3ResourceLink since that defaults to
> m="create" & I suggested that to avoid breaking non-trunk
> templates/modules.
> What for?

You can well use the S3AddResourceLink class, and override the method.

My point is about the _name_ of the class, not about the overriding of the 
method - that part is alright.

But using it for an "update" link is an edge case - the normal standard use-
case is to use it for _adding_ a new record, and that is what the class name 
should say.

If in one case it is used for _update_, then that one case can either use 
S3AddResourceLink(method="update") and explain that in a comment, or, if by 
all means it has to be another class name, then import it under an alias.

The "Add" in the class name is what I am after - I want this to be left in 
place in order to make clear what it does.

> The "Add" in the class name is what I am after - I want this to be left in
> place in order to make clear what it does.

For the myriad cases which use this, I'm happy for them to use this alias...but I think the core class should be renamed to allow the use for both create & update.
Update is indeed an edge case right now, but I can see it being reused & I see it as very confusing if it's called Add there...

Right - it is the "Add" in the places where it is used, not in the class definition. But there it is important to really express what the code does _especially_ if it can do multiple things. 

S3ResourceLink is generic, and for people not so familiar with the code, it is not obvious what it would do (again, in the places where it is /used/ - not where the class is defined).

Btw, in my opinion "S3ResourceLink" is a totally misleading name for this class.

You could name it S3PopupLink, which makes it a whole world clearer - and then maybe have S3CreatePopupLink and S3UpdatePopupLink as aliases.

But S3ResourceLink is nonsense, really.

S3AddResourceLink wasn't really my favorite name either - but at least the "Add" made clear the purpose, somehow.

S3PopupLink would make it a lot better, especially because it makes the connection to s3.popup.js.

And with S3PopupLink, maybe we don't need the "Add" alias, if that is the default behavior.

I'm fine with PopupLink...but feel we should keep the S3AddResourceink alias to avoid breaking non-trunk Templates/Modules

Backwards-compatibility is important too, yes. 

I'm using S3AddResourceLink in non-trunk code too - and in a feature branch for a new module I'm currently working on. Though I can deal with that - but maybe others can't as easily.

However, my main concern is that the new name should not be misleading, or become too generic so that you can no longer understand the purpose. People who try to learn from existing models need to be able to make the connection, and "S3AddResourceLink" was already weak - but "S3ResourceLink" is even weaker. "S3PopupLink" is a lot stronger, especially because the corresponding JS script also uses "popup" in the name.

Thanks for updating it - but not quite ready yet, I'm afraid.

No point to review this further until you've resolved the issues indicated so far - will continue after the next update.

Makes a lot more sense now - apart from the small bits indicated above.

Now it needs testing, and it would be ideal if you could implement a bunch of unit tests for it. But I guess now I'm asking too much :/

@flavour Please merge

Looks ok to me - @flavour to do his own review, of course.

Does it work?

Yes :-)

Good work then :) thank you.

@nursix Couple of problems:
1. When I add repo, it does not seem to insert into the "last_push" field as I have specified here https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a048020941cR780
2. When I add FTP repo and disselect it, it removes the repo as intended https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a048020941cR837, but if I add again the same repo, the "owned_by_user" field does not gets updated with the auth.user.id but the deleted_fk field has attribute as {"owned_by_user": xx, "modified_by": xx, "created_by": xx} (deleted field is False ofcourse again after creating it). Do I need to set is_owned_by_user onaccept?

What am I missing here?

onsdagen den 30 september 2015 01.36.43 skrev  Biplov Bhandari:

> @nursix Couple of problems:
> 1. When I add repo, it does not seem to insert into the "last_push" field as
>    I have specified here
>    https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a
>    048020941cR780

I think that is because you end up here:
https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a048020941cR764

> 1. When I add FTP repo and disselect it, it removes the repo as intended
>    https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a
>    048020941cR837, but if I add again the "owned_by_user" field does not gets
>    updated with the auth.user.id but the deleted_fk field has attribute as
>    {"owned_by_user": xx, "modified_by": xx, "created_by": xx} (deleted field
>    is False ofcourse again after creating it). Do I need to set
>    is_owned_by_user onaccept?
>    I'm not sure I understand that. 

When you delete a repo - how can you re-add it? I don't see code that sets the 
deleted-flag to False, so how are you doing it so that deleted is False, yet 
there are deleted_fk?

And no - you don't touch owned_by_user directly, but always call 
set_record_owner.

Dominic

onsdagen den 30 september 2015 01.36.43 skrev  Biplov Bhandari:

> 1. When I add FTP repo and disselect it, it removes the repo as intended
>    https://github.com/flavour/eden/pull/1165/files#diff-8b02f3a5c97483e605769a
>    048020941cR837, but if I add again the "owned_by_user" field does not gets
>    updated with the auth.user.id but the deleted_fk field has attribute as
>    {"owned_by_user": xx, "modified_by": xx, "created_by": xx} (deleted field
>    is False ofcourse again after creating it). Do I need to set
>    is_owned_by_user onaccept?
>    From your code, I don't see that the same repository record is being re-used.

I can't believe that deleted=False in that record. How would that be possible? 
Once a record has been deleted, and deleted_fk has been created, you would 
have to intentionally revert that, i.e. actively set deleted=False - but 
nowhere in your code I can see that happening.

Could it be that you are looking at the deleted record while your code creates 
a new record that you are not aware of?

Dominic

@nursix Let me test again

onsdagen den 30 september 2015 01.36.43 skrev  Biplov Bhandari:

> What am I missing here?
> NB You should run again with a fresh database. 

It could well be that after running the old version of your commit (which 
didn't quite follow framework rules), the database is now corrupt and hence 
the strange behavior.

Wipe the db, and verify again?

Dominic

Ah no - you are right.

I guess you are using the same UUID when re-creating the repo? That indeed makes it an update rather than a create, and wouldn't re-establish the record owner.

Let me see whether I can fix that.

@nursix The first part (last_push insertion) is working...

Yes for second one, for recreating I am giving same UUID, so it basically updates deleted field to False.

First Creation: http://i.imgur.com/ZNVWGtg.jpg

After deletion->Creation: http://i.imgur.com/cweWBt5.jpg

Yes, I can see why.

This is an edge-case where a record update should be treated as a create in CRUD, but isn't. I'll fix it.

The background for this problem is:

A matching UUID (or other unique key) in a CRUD form would reinstate a previously deleted record rather than creating a new one. However, this was (wrongly) treated as "update" in forms, instead of treating it properly as "create":
https://github.com/nursix/eden/commit/1548edc282263e8f43bc81dd6954baee1761ec52

"Update", though, does not set the record owner again.

This is a rare edge-case, however - because the uuid field is editable. However, the uuid is not required for passive repositores - so in the FTP case you could actually hide it.

And if you just leave this field empty when creating a repository, then it will be automatically populated with a real uuid, and then the problem won't occur. 

Well, ok - with this fix ^ it won't occur either way.

Done :) Thanks @nursix so much

@flavour PLEASE MERGE

@flavour Please merge

Just enough here for a last cleanup pre-merge? :)

@flavour Please merge...

"This branch has conflicts that must be resolved"

The comment is also wrong as this is "uncomment dvr_status field" rather than "change represent"

Sorry, my mind is confused. Yes "Uncomment dvr_status field"

It's already been done - hence the conflict ;)

This has already been done - try to update your branch from trunk:
https://github.com/flavour/eden/blob/master/modules/s3db/dvr.py#L248

ok. thanks

There are also other changes for DVR in trunk that may be useful for you:
https://github.com/flavour/eden/commit/f6b46f010daf7435fcc1f5293d1f4d1c524fc98b
https://github.com/flavour/eden/commit/c4e13caf8dbc99b6d3866d254775d8d239ed6048

So, updating your branch may be good.

@flavour Please merge

@nursix and @flavour done

This is the right concept - but a sloppy implementation of it ;)

You should always _test_ your code before submitting a PR - and this code can not work, so you either didn't test it, or you ignored that it doesn't work ;)

Actually @nursix I did tried to test it, but I think they way I tested it is wrong, sorry for that.

@anurag-ks - generally no problem to ask for feedback on the concept by tagging me in a comment to your commit before submitting a PR. But for a PR, stuff should be working.

You could try to write a unit test for this (even if just as an exercise) - this would give you immediate feedback while refactoring things.

@nursix just a doubt, these represent classes/functions are used for custom rendering of data values for data-tables or exporting data, right ? But on enabling the `commit_id` field on `/eden/req/commit` gives me `None`

for req/commit there is no 'commit_id' field, there is an 'id' field which in other  places would be seen as a commit_id

> these represent classes/functions are used for custom rendering of data values for data-tables or exporting data, right ?

yes

Okay so `commit_id` is for components, but it's not there on the data tables.
To be honest I haven't written any unit tests before (only automation stuff), so I was checking out other ways to test it.

A unit test would create a test req_commit record, and then run req_CommitRepresent against the record ID. Then check whether the return value is correct, and finally remove the test record.

That's all there is to it, nothing fancy.

There are over 500 examples of unit tests in modules/unit_tests and plenty of documentation for the Python unittest module. It's not rocket science - the trick is just to understand what you're trying to prove with the test and implement a valid test.

And I said that with the unittest only to spare you the effort of digging for a case where it is visible, because I understood that you couldn't find one. In fact, there may not be one ;)

@flavour Should I add a function in controller to approve as I have done earlier?

> Should I add a function in controller to approve as I have done earlier?

No! ;) The review page is /OK/ (although I prefer to avoid it)...it's just the label I was suggesting to change right now.  This first iteration can be refined with the POST script later (I'm sure it will be necessary as this extra step seems clumsy to me)

I don't think this is about field value representation at all - it's rather to select between two alternative fields in the view.

The elegant solution is therefore to include both fields in the select (as extra_fields), and then have a Field.Method that returns either the name_l10n (if it is not empty) or otherwise the name:

```
local_name = row["cap_area_name.name_l10n"]
return local_name if local_name else row["cap_area.name"]
```

The filtering of the name_l10n by current language can be achieved by adding e.g. cap_area_name as a filtered component "local_name" to cap_area, and use language as filterby. Then specify "local_name.name_l10n" as extra_field (along with "name").

That way, you do not need to conduct any lookup, not write any complicated S3Represent subclass, and yet you get a very efficient mechanism.

I think this is about field value (cap_area.name) representation as I am doing here: https://github.com/flavour/eden/pull/1186/files#diff-deea28c62cb200676ae57b2e1b30a34bR1138 (building representation options)? Isn't it? Or am I missing something here?

You are doing that, yes - but that doesn't mean that is what it is about. 

In principle, you want to show the localized name or, if it is not available, fall back to the original name. And that is simply choosing between two alternative name fields, not representation of the name.

Including both fields, and implementing the fallback as Field.Method is the easiest and most efficient variant. Building a dict of representation options is not required here.

Or am I wrong that in "assign" (=cap_AssignArea), you are showing a list of areas, and in that list you want to show either the local name of the area, or, if that is not available, the original name?

Ok ok, maybe I'm wrong and misinterpreting your code. This is closed anyway, so feel free to disregard.

@flavour Please merge

:+1: 

IMHO this is the wrong concept, and has always been, which is why I recommended to not to use the approval-framework in the first place.

The alert should be copied into a separate table ("published alerts") when it gets approved and published, and that table should generally be locked for all writes except by the publishing-workflow. That extra table can have additional meta-fields (for message tracking), and a different access level.

It _is_ a publishing workflow after all, exactly like I said - and this requirement here shows why that is different from the input-approval.

@nursix The workflow here is that after an alert has been published; at time we want to send the update or error if it is(well we want to minimize this, but we cannot control human error). So in that case we have the same alert(with same identifier small components-info, area and resource) and we update certain fields (like msg_type, instruction, headline etc.)(this depends on country profile so I have commented them out here: https://github.com/flavour/eden/pull/1191/files#diff-deea28c62cb200676ae57b2e1b30a34bR165
So this need of cloning the alert along with its components.

I would rewrite the whole thing, and introduce a cap_published_alert table that holds those alerts that have been published. 

Copy the cap_alert into cap_published_alert when it gets approved for dissemination, and link all published copies per link table to the original cap_alert.

The cap_alert table would then be restricted to alert editors, whilst the cap_published_alert table would be open to everyone, but read-only. And all subscriptions/notifications would work from the cap_published_alert table only.

That is a _much_ cleaner and safer concept, and it allows tracking of all published versions easily. Additionally, the cap_published_alert table can hold the EDXL-DE meta fields for message tracking, if that is still a relevant concept for SAMBRO.

Regardless the concept, though - there are some violations of coding conventions you should fix.

And for making the alert identifier non-unique - I think this is debatable. Is it valid, anyway? I'm not sure it is for CAP - I think alert identifiers are meant to be unique and must not have multiple versions with the same ID.

AFAIK you must send an update referencing the original rather than sending another version of the original - hence you must use a new identifier. Please validate that.

Yup - correct. Re-using the same identifier violates the CAP standard - if you want to send an update, then you must issue a new alert (new identifier) with a _reference_ to the original. Please read in the CAP 1.2 specification about how to rectify alerting errors.

Alert identifiers must be unique - reusing them will give consuming systems a hard time, and they may even refuse to accept the update if it carries the same identifier. Sending multiple versions with the same identifier will also undermine the credibility of the Sahana system as alert source.

This is the minimum you must change.

I would reconsider the whole concept, however.

Like in the example:

```
<alert xmlns = "urn:oasis:names:tc:emergency:cap:1.2">
    <!-- new identifier -->
    <identifier>TRI13970876.2</identifier> 
    <!-- message type "update" -->
    <msgType>Update</msgType>
    <!-- reference to the original (inappropriate) alert -->
    <references>trinet@caltech.edu,TRI13970876.1,2003-06-11T20:30:00-07:00</references>
```

This is what the standard defines how you can update inappropriate alerts - and not by sending out a new version with the same identifier (I like the version-numbering in this example btw.).

I think it is important to adhere to this standard, because consuming systems will expect it.

@nursix I think you are correct, the identifier should be different like http://publicalert.pagasa.dost.gov.ph/output/gfa/29ebde5a-0809-4d75-9866-fb84d11bf42c.cap and http://publicalert.pagasa.dost.gov.ph/output/gfa/45827385-ce01-40ec-87d6-d94fe9d75d79.cap. That way we can fill in the reference field to the earlier alert.

@waidyanatha your thought on this?

The reference field is used if an Alerting Authority relays a CAP message
that was originated by another Alerting Authority. For example, when the
Maldives Met Services issues a CUG Alert that is received by the Maldives
Nat'l Disaster Management Center and then NDMC decides to relay that
message to the public. In this case, the identifier will get replaced with
the NDMC OID and the MMS originated identifier gets added to the
<reference> element.

In general it is a good habit to always refer to the CAP specifications
document when coding:
http://docs.oasis-open.org/emergency/cap/v1.2/CAP-v1.2-os.html

On Tue, Oct 20, 2015 at 3:07 PM, Biplov Bhandari notifications@github.com
wrote:

> @nursix https://github.com/nursix I think you are correct, the
> identifier should be different like
> http://publicalert.pagasa.dost.gov.ph/output/gfa/29ebde5a-0809-4d75-9866-fb84d11bf42c.cap
> and
> http://publicalert.pagasa.dost.gov.ph/output/gfa/45827385-ce01-40ec-87d6-d94fe9d75d79.cap.
> That way we can fill in the reference field to the earlier alert.
> 
> @waidyanatha https://github.com/waidyanatha your thought on this?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149457509.

That does not answer the question, @waidyanatha 

> 2.3.5     Repudiating a False Alarm
> Inadvertently the integrated alerting network has been activated with an inaccurate warning 
> message. This activation comes to officials' attention immediately through their own monitoring 
> facilities (e.g., 2.3.3 above).  Having determined that the alert is, in fact, inappropriate, the officials 
> issue a cancellation message that refers directly to the erroneous prior alert.  Alerting systems that 
> are still in the process of delivering the alert (e.g., telephone dialing systems) stop doing so.  
> Broadcast systems deliver the cancellation message. Other systems (e.g., highway signs) simply 
> reset to their normal state.

I don't think it is correct to just publish an updated version of the original alert using the same identifier - this would contradict the general principles of a messaging protocol, and CAP in particular.

The original alert will have triggered responses, and just re-publishing the alert would not take back those responses. Moreover, as it uses the same identifier, systems will treat it as "already processed" (that is what the identifier is used for!), and hence the update may not trigger anything at all, and all the changes go unnoticed.

Hence, you must issue a new alert of msgType "Update" with a new identifier, that references the original alert, and explicitly triggers response updates.

Additionally, it will undermine the credibility of the alert source if there are multiple versions of the same alert, without explicitly indicating an update. That looks dodgy.

No - sent is sent, you can not re-publish an updated alert under the same identifier. No messaging protocol in the world allows that, and neither does CAP (if it would, it would be fundamentally flawed).

If you want to update an already-published alert, then you must send an update message with a new identifier, and a reference to the original alert.

Using version-numbering like in the example above makes it human-comprehensible, which would provide an additional means for verification - but since CAP is meant to be machine-processed in the first line, this is secondary.

Most, if not all, automated systems will track which alerts they already have responded to, so if we want them to respond to an update (and indeed we do want that), we must use a new identifier and an explicit indication that this is an update of a previous alert. That's how CAP is designed, is it not?

This is why I keep proposing to not just use the Sahana approval-mechanism, but to also explicitly copy any published alert into a separate table (like the "sent messages" box in your email program), and generally lock that table against interactive writes of any kind.

And then, you should only ever assign a unique alert identifier at the moment when you actually publish the alert (=send the message). Perhaps the alert table could hold a base identifier, and when copying/sending it, you would append a version number - that way preventing that there can every be two messages with exactly the same identifier.

But even with the "cloning" concept, you still need to make sure that an update create a new message.

The point is that CAP is a _messaging_ protocol, and unlike with representational protocols (e.g. REST), the sender is not in control of the object - the message is the object you've sent away, not the object you have in the database!

And since you have no control of the message object - you can not update it. You can only ever generate a new message object that overrides the previous one - and being a new message object, it has to carry a new identifier (otherwise it wouldn't be a new object, that's the point with identifiers).

Hi Dominic,

Thanks for these insights and for raising these valid points. Let me
investigate this a bit further.

I get your point but curious whether it is illegal or unethical to send a
massage with the same ID more than once in this world?

Nuwan

On Tue, Oct 20, 2015 at 5:43 PM, Dominic König notifications@github.com
wrote:

> This is why I keep proposing to not just use the Sahana
> approval-mechanism, but to also explicitly copy any published alert into a
> separate table (like the "sent messages" box in your email program), and
> generally lock that table against interactive writes of any kind.
> 
> And then, you should only ever assign a unique alert identifier at the
> moment when you actually publish the alert (=send the message). Perhaps the
> alert table could hold a base identifier, and when copying/sending it, you
> would append a version number - that way preventing that there can every be
> two messages with exactly the same identifier.
> 
> But even with the "cloning" concept, you still need to make sure that an
> update create a new message.
> 
> The point is that CAP is a _messaging_ protocol, and unlike with
> representational protocols (e.g. REST), the sender is not in control of the
> object - the message is the object you've sent away, not the object you
> have in the database!
> 
> And since you have no control of the message object - you can not update
> it. You can only ever generate a new message object that overrides the
> previous one - and being a new message object, it has to carry a new
> identifier (otherwise it wouldn't be a new object, that's the point with
> identifiers).
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149497820.

@waidyanatha : is is neither "illegal" nor "unethical" - it is a protocol violation, and thus an incorrect implementation.

The only question is whether the changed message is still the same message - because only then it can use the same identifier again due to the uniqueness-requirement specified by the CAP standard.

And by definition a message is only ever the same message if all possible responses are invariable to the change (e.g. a different data format, or a different messaging channel) - but the very reason to send an updated version in the first place is _because_ we want to alter responses, and that does make it a new message.

And a new message MUST have a new identifier.

Come on - this is information technology basics, high school level - why the debate?

agree with you, what my worry is that the definition of the identifier
might be wrong if it is supposed to refer to the specific event and not the
message. Specs use the term "this warming message". I need to clarify from
the guru's that it does not refer to the event.

On Tue, Oct 20, 2015 at 8:48 PM, Dominic König notifications@github.com
wrote:

> @waidyanatha https://github.com/waidyanatha : is is neither "illegal"
> nor "unethical" - it is a protocol violation, and thus an incorrect
> implementation.
> 
> The only question is whether the changed message is still the same message
> - because only then it can use the same identifier again due to the
>   uniqueness-requirement specified by the CAP standard.
> 
> And by definition a message is only ever the same message if all possible
> responses are invariable to the change (e.g. a different data format, or a
> different messaging channel) - but the very reason to send an updated
> version in the first place is _because_ we want to alter responses, and
> that does make it a new message.
> 
> And a new message MUST have a new identifier.
> 
> Come on - this is information technology basics, high school level - why
> the debate?
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149554980.

BTW - I skipped high school and went fishing with my friends instead

On Tue, Oct 20, 2015 at 9:03 PM, Nuwan Waidyanatha waidyanatha@gmail.com
wrote:

> agree with you, what my worry is that the definition of the identifier
> might be wrong if it is supposed to refer to the specific event and not the
> message. Specs use the term "this warming message". I need to clarify from
> the guru's that it does not refer to the event.
> 
> On Tue, Oct 20, 2015 at 8:48 PM, Dominic König notifications@github.com
> wrote:
> 
> > @waidyanatha https://github.com/waidyanatha : is is neither "illegal"
> > nor "unethical" - it is a protocol violation, and thus an incorrect
> > implementation.
> > 
> > The only question is whether the changed message is still the same
> > message - because only then it can use the same identifier again due to the
> > uniqueness-requirement specified by the CAP standard.
> > 
> > And by definition a message is only ever the same message if all possible
> > responses are invariable to the change (e.g. a different data format, or a
> > different messaging channel) - but the very reason to send an updated
> > version in the first place is _because_ we want to alter responses, and
> > that does make it a new message.
> > 
> > And a new message MUST have a new identifier.
> > 
> > Come on - this is information technology basics, high school level - why
> > the debate?
> > 
> > —
> > Reply to this email directly or view it on GitHub
> > https://github.com/flavour/eden/pull/1191#issuecomment-149554980.

:D Okay, I see - fishing is bad, because you can indeed catch the same fish twice and each time it's different. So I understand that.

Anyway - CAP is about alerting, not about event management, so does not define any "event" entity, and consequently it does not hold any event object reference. I can tell you as much ;) 

But yes, feel free to double-check with the TC.

This what the Canadians do - We create a new identifier each time.

Every element in that first group of elements, prior to the <info> block,
attributes the same thing and that thing is the Alert Message (not the
Alert).

We know this because for most of the other elements it is obvious they are
attributing the Alert Message (<status>, <sent>, <references>, etc...) so
<identifier> must too. Also, none of those elements are required to be
"persistent" across the series of messages that make up the alert.

Also, the spec says... "A number or string uniquely identifying this
message, assigned by the sender."
On Oct 20, 2015 9:15 PM, "Dominic König" notifications@github.com wrote:

> :D Okay, I see - fishing is bad, because you can indeed catch the same
> fish twice and each time it's different. So I understand that.
> 
> Anyway - CAP is about alerting, not about event management, so does not
> define any "event" entity, and consequently it does not hold any event
> object reference. I can tell you as much ;)
> 
> But yes, feel free to double-check with the TC.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149564108.

I don't have the time right now to review everything, so just commenting on the most critical things.

Will review again once you've fixed these.

Philippines also does the same, Lester said - "We create a new
identifier then reference the previous identifier."

I hope the data structure has another kind of ID that allows us to
bundle the messages that are related to a singe event? This is
necessary for presentation and for audit trails. Dominic or Biplov
might have thought of it or explained the strategy. If you yes, then
good.

On Wed, Oct 21, 2015 at 11:59 AM, Biplov Bhandari
notifications@github.com wrote:

> Closed #1191.
> 
> —
> Reply to this email directly or view it on GitHub.

@waidyanatha CAP does not provide any such identifier, because, as I said before, it doesn't deal with event management at all and hence does not define any event entity.

Sahana, however, does have an event management module, and it seems trivial to me to add an event_incident_id() to cap_alert, so that alerts can a) be filtered by incident, b) appear on a tab under the respective incident and c) can be reported on by incident.

But again - even if we implement that in SAMBRO/Sahana, there will be no way to express the relationship in CAP alerts and hence communicate that to message recipients - because the CAP standard does not define any such thing like an "event".

The reason behind this lack of a CAP data structure is very simple: there is no common understanding of what "event" actually refers to - every country, every organisation use their own definition. That makes it impossible to incorporate that into the CAP standard - apart of course from the fact that it isn't actually relevant for the alerting as such.

Note that what you call "event" is called "incident" in Sahana (whereas a Sahana "event" can have many "incidents").

NB CAP is XML, and like with any XML, you can easily embed additional elements under a separate namespace - and hence it will very well be possible to add the incident reference to the alert message.

Just not with CAP elements.

The CAP module's tables carry more information than a typical cap message
does. For example, we have introduced a table called the warning_priority.
We also use the Incident values from the IRS module (or whatever it is
called). This is for our own controls, presentation, ease-of-use, and
usefulness. Basially, SAMBRO offers a comprehensive multi-agency alerting
system and it is also CAP compliant, meaning we can offer a CAP RSS Feed
that adheres to the CAP standard.

On Wed, Oct 21, 2015 at 7:01 PM, Dominic König notifications@github.com
wrote:

> @waidyanatha https://github.com/waidyanatha CAP does not provide any
> such identifier, because, as I said before, it doesn't deal with event
> management at all and hence does not define any event entity.
> 
> Sahana, however, does have an event management module, and it seems
> trivial to me to add an event_incident_id() to cap_alert, so that alerts
> can a) be filtered by incident, b) appear on a tab under the respective
> incident and c) can be reported on by incident.
> 
> But again - even if we implement that in SAMBRO/Sahana, there will be no
> way to express the relationship in CAP alerts and hence communicate that to
> message recipients - because the CAP standard does not define any such
> thing like an "event".
> 
> The reason behind this lack of a CAP data structure is very simple: there
> is no common understanding of what "event" actually refers to - every
> country, every organisation use their own definition. That makes it
> impossible to incorporate that into the CAP standard - apart of course from
> the fact that it isn't actually relevant for the alerting as such.
> 
> Note that what you call "event" is called "incident" in Sahana (whereas a
> Sahana "event" can have many "incidents").
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149856059.

Correct, that is one approach. The other would be to use the <parameter>
element was introduced for, to embed other data elements and values.

On Wed, Oct 21, 2015 at 7:05 PM, Dominic König notifications@github.com
wrote:

> NB CAP is XML, and like with any XML, you can easily embed additional
> elements under a separate namespace - and hence it will very well be
> possible to add the incident reference to the alert message.
> 
> Just not with CAP elements.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149856758.

Obviously, yes - question is though what purpose it would serve to put the Sahana incident reference into the CAP feed? Are there _any_ consuming systems who would process it, and if yes - what for?

There is no "official" (authoritative) registry of incident identifiers - nor do alert responders normally manage alerts by incidents (but rather responses by alert). I think such a feature would be very specific for individual peer systems - and should maybe only be added if/when actually required for a particular integration.

However, within Sahana it would easily be possible to add a link between alerts and incidents (as described above), with all the standard functionality that would add. And yet - that's a possible solution, now: can you specify the possible problem that it would solve (or would it just be "cool")?

...and are you requesting implementation from me, or are we just discussing Biplov's work?

onsdagen den 21 oktober 2015 04.06.11 skrev  Nuwan Waidyanatha:

> The CAP module's tables carry more information than a typical cap message
> does. For example, we have introduced a table called the warning_priority.
> We also use the Incident values from the IRS module (or whatever it is
> called). This is for our own controls, presentation, ease-of-use, and
> usefulness. Basially, SAMBRO offers a comprehensive multi-agency alerting
> system and it is also CAP compliant, meaning we can offer a CAP RSS Feed
> that adheres to the CAP standard.
> So? Rehearsing the presentation - or is this meant to specify a requirement?

Struggling to understand what you're after here - maybe we should switch to a 
voice channel for better comms.

@waidyanatha As much as I understand the SAMBRO project, event/incident management would be a significant extension of scope - but even if logical, I don't yet see a sufficient use-case definition anywhere in the documentation (...the parts I have visibility of).

Even a simple, workflow-less incident registry would add technical requirements (such as data entry), and right now, that is not described anywhere. Who would register incidents? Where do the data come from? What data exactly? Is filtering by incident the only relevant user task in this regard?

I see the value, but not enough information yet to action it.

​Just as much as I would like you to be involved in the design of SAMBRO,
it is forbidden!. These are simply brainstorming session and I am not
requesting any implementation because that would be a violation.

SAMBRO - it is a vision beyond CAP and warning. The design would serve as
an Early Warning System and an Incident Command System; mainly working
within the response phase of the disaster management cycle. It does bleed
into preparedness with risk mapping because we need to understand the
risks. I have limited the wiki to CAP, for now, to avoid confusing the
principals and developers, and having to explain a lot of the intricacies.
The need for a comprehensive SAMBRO was confirmed during the August
workshop, read the last paragraph:
http://sahanafoundation.org/cap-on-a-map-tot-week-one/ . When I find the
time, I intend to revamp the Blueprint. Here's a set of incomplete slides
that may paint a picture of the full scope:
https://docs.google.com/presentation/d/11GbmMmMJVcp8wGfrjQbm02_eWuFTaTnRuIKAxjCUrI4/edit#slide=id.g7085e25d6_0_0

Incidents - As you know CAP Alert block already carries the Incident
element. Naturally, we thought of using the Sahana Incident model to
provide the look up values for this field. That is how it got linked to the
CAP module. Users would edit the Incident Model, through the views, to
their liking. Unfortunately there is no "authoritative Incident dataset"
defined for CAP, in general. The Australians have their own and the
Canadians/Americans have their own. Canadians and Americans (peer system)
share the Incident values in their CAP cross-border messages. It is mainly
for systems, more so than humans, that use these values (or codes) for
applying system logic. One aspect I'm trying to introduce/test in the next
phase of this project is cross-boarder alerting and peer systems. I don't
think our partners understand the importance of it or the concept.

On Wed, Oct 21, 2015 at 7:45 PM, Dominic König notifications@github.com
wrote:

> @waidyanatha https://github.com/waidyanatha As much as I understand the
> SAMBRO project, event/incident management would be a significant extension
> of scope - but even if logical, I don't yet see a sufficient use-case
> definition anywhere in the documentation (...the parts I have visibility
> of).
> 
> Even a simple, workflow-less incident registry would add technical
> requirements (such as data entry), and right now, that is not described
> anywhere. Who would register incidents? Where do the data come from? What
> data exactly? Is filtering by incident the only relevant user task in this
> regard?
> 
> I see the value, but not enough information yet to action it.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1191#issuecomment-149863746.

CAP refers to incident /types/, not to individual incidents - and that part is indeed implemented using the Sahana event management module.

The question is whether we additionally need to reference individual incidents - which in turn would require to also _track_ those individual incidents in SAMBRO. 

And this tracking of individual incidents is not currently described as a SAMBRO requirement, and in fact, not in these overview documents either. It seems that the documentation simply /assumes/ that such incident tracking is happening - and doesn't define whether that happens within SAMBRO or outside of it.

If it was to happen within SAMBRO, it should use the event_incident entity - which is part of the "event" module (not IRS). The "event" module is already used by SAMBRO (cap_alert references the event_incident_type taxonomy, which is the same taxonomy used by event_incident), so it would more or less just mean to:

a) expose the incident tracking views (menu item, user permissions)
b) link cap_alert to event_incident (instead of or in addition to event_incident_type)
c) add the incident tracking workflow to the specs

This link would add all the CRUD and mapping functionality around incidents, and, the cool thing is that this easily extends into both sitreps (which are attached to event_incident) and dispatch (also attached to event_incident), thereby providing the full cycle you're after.

And yet - nowhere in the documentation or presentations it is actually mentioned that SAMBRO would need to track incidents. 

This is simply _the_ missing link between all the components, and yet it's not mentioned anywhere. Almost as if it would happen outside of SAMBRO. Does it?

It will be obvious to you that if you want to reference individual incidents, then you will have to track incidents. As a very minimum, you need to register them.

But SAMBRO, so far, has been built around alerts - all workflows start and end at alerts, and no individual incidents are even recorded.

Generally, as I understand it, SAMBRO is supposed to be a comprehensive messaging and alerting system - but not response management. But incident tracking is actually about response management rather than messaging/alerting, so I still wonder how this would fit into the scope.

It is very well possible that the incident tracking happens outside of SAMBRO (e.g. in a separate ICS), we have that situation in other places. And if that is the case, then the question goes to how to integrate that separate response management.

If you, however, envisage response management to be integrated in SAMBRO, then incident tracking is, obviously, not the end of the story - it will also require resource management. For instance, if you want to dispatch a unit (e.g. a fire engine) to an incident, then you must track both - the incident, and obviously also the unit.

So, this is a bit unclear still.

Doesn't mean a simple incident tracking couldn't just be enabled for SAMBRO ;)

If you are not involved with the SAMBRO design, then who is? Who does specify the requirements?

> CAP refers to incident /types/, not to individual incidents - and that
> part is indeed implemented using the Sahana event management module.

​That is correct, I was loosely referring to this as incident​

​but we are using the incident types or something of that order.​

The current implementation or developments of SAMBRO does not imply it is
using any incident management work flows. These are yet to be designed and
developed; i.e. a
s mentioned I have yet to define the incident tracking.

As of now my knowledge in
​the incident management aspects are
 based on the SITREP research work we did in 2012
​. It involved​
integrating
​the Freedom Fone
IVR with
​ ​
Sahana-Eden
​ (integration was not from an engineering prospective but a work flow
prospective)​
.​

In these workflows we experimented how we would first alert CERT of an
event
​(using EDXL-CAP messages) ​
and then have the CERT
​respond to the event to ​
provide incident reports
​. For example, we alert the CERT of a Landslide and then they visit the
site to provide the ground situation.; i.e. registering incidents.

Registering Incidents was ​
namely
​ sending​
​EDXL-SITREP ​
field-observation and casualty-illness reports
​ to the EOC​
. Then
​ the EOC would extend
those reports
​to
situational-information reports. Emergency managers use
​d​
the situational-information to derive the response resources
​ reports​
. That is where we stopped
​our
workflow
​s​
.
​Subsequently, the workflow
would extend to resource messaging to dispatch the required resources to
respond to those incidents.

If it was to happen within SAMBRO, it should use the event_incident entity

> - which is part of the "event" module (not IRS). The "event" module is
>   already used by SAMBRO (cap_alert references the event_incident_type
>   taxonomy, which is the same taxonomy used by event_incident), so it would
>   more or less just mean to:
> 
> a) expose the incident tracking views (menu item, user permissions)
> b) link cap_alert to event_incident (instead of or in addition to
> event_incident_type)
> c) add the incident tracking workflow to the specs

​Thanks for lining this out.​

> This link would add all the CRUD and mapping functionality around
> incidents, and, the cool thing is that this easily extends into both
> sitreps (which are attached to event_incident) and dispatch (also attached
> to event_incident), thereby providing the full cycle you're after.

​Superb! Does this mean there is already a EDXL-SITREP API that can
generate SITREP messages from the Event-Incident?​

And yet - nowhere in the documentation or presentations it is actually

> mentioned that SAMBRO would need to track incidents.
> 
> This is simply _the_ missing link between all the components, and yet
> it's not mentioned anywhere. Almost as if it would happen outside of
> SAMBRO. Does it?
> 
> ​For now I only have this image describing the essential components of
> SAMBRO: http://eden.sahanafoundation.org/wiki/Deployments/SAMBRO#DESIGN ​
> ​But it does not spell out the actual design using Sahana language.​

Incident tracking would be distinct from early warning. They are somewhat
intertwined. An incident tracking workflow may originate from an alert
(e.g. landslide alert instigates responding to the incident) and an alert
may originate from an incident (reporting a train derailment incident may
trigger alerting all First-Responders).

The separation may occur by distinguishing Alerting Authorities from
Incident Managers. Police, for example, could be both an Alerting Authority
reporting of some civil unrest and also a Incident Mangers responding to
the civil unrest to contain the situation. Until such time I come across a
real situation, I am not sure whether we want to assign the roles
associated with alerting and incident management to a single user?

​Regarding the scope of SAMBRO and the terminology of "alerting and
messaging" - life is event driven. We make plans but certain events shape
the course of our lives. Similarly SAMBRO is also event driven. When I
first coined the term it was inclined towards alerting. But now I want to
extend that to incident command and control. In a very non-technical and
way I am associating the word messaging with Incident Command and Control
messaging. Once we mature we might change the term from SAMBRO to something
else. For now that is what the users are familiar with and would stick to
it for a while.​

​Regarding the SAMBRO specification, it is very much a research and
development approach. Developing countries in Asia are slowly developing
their disaster management systems. They have an idea what to do but don't
always know how to do it. What I am offering is a simple and basic platform
that allows them to build on. Strategy is to start with an EWS. Then slowly
migrate them in to ​ICS. The initial requirements comes from my research
experience. With that we have developed an egg. We will slowly mature the
egg into a chicken through a community-centric participatory design and
development approach. The subsequent set of requirements will come from the
users (or adopting community).

> Does this mean there is already a EDXL-SITREP API that can
> generate SITREP messages from the Event-Incident?​

No...supporting a workflow doesn't mean being able to expose that via a specific Standard without additional work....experience of EDXL standards suggests significant work ;)

For some reason your multi-commit PRs always send up with just the commit message of the last one which is not ideal
This commit says "changed label" which isn't what it does at all (that was just an interim step).
The actual change is "Add site to dvr_case"

Thanks @flavour will work on the suggestions :)

@flavour Done...Please merge

I see no need to add this extra variable

I see no extra variable here?

ok, this is even 2 less :)

Yup, and it looks cleaner than before - now all variables are initialized for all branches.

May have been a bit premature to close this.

Other than the relatively small tweaks suggested, this looks good - nice and DRY :)
I assume it all works when tested?

@flavour Why the check has failed? Any error in my code?

raise ValueError("User not found")
This is admin@example.com
I did make changes in roughly this area, but I wouldn't have thought this could happen...am digging.

Doesn't appear to be your code

User works fine when I prepop here - no idea why Travis env is different

@flavour Yes works fine for me too

Travis wasn't updated for the new prepop pattern, so didn't configure correctly.
Fixed.

> Fran Boon notifications@github.com hat am 3. November 2015 um 09:20
> geschrieben:
> 
>  raise ValueError("User not found")
>  This is admin@example.com mailto:admin@example.com
>  I did make changes in roughly this area, but I wouldn't have thought this
> could happen...am digging.
> 
>  Doesn't appear to be your code
> 
>  —
>  Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1201#issuecomment-153285542 .

@flavour Please merge

@flavour Please merge

@flavour  Is it possible to allow to add more records as below in the custom form of subscriptions? This would then allow different subscriptions for different users...I mean after setting subscription for one user, then need to set subscriptions for next user.
![ss](https://cloud.githubusercontent.com/assets/4207677/11014317/27ba58e6-8563-11e5-90ea-b8c7a714bb87.PNG)

I think you'll have to do something like this indeed...the create/update form should look like what you have already, but you also need a list view

@flavour Custom Listview? Any examples in trunk?

Why 'custom'?
Make it a std one - i.e. use the /eden/pr/subscription REST controller
You can make a little custom wrapper around it to filter to just admin subscriptions & patch the create button to the custom form (postp)
Simple wrappers abound:
https://github.com/flavour/eden/blob/master/controllers/vol.py#L30
https://github.com/flavour/eden/blob/master/controllers/vol.py#L56

@flavour Please review

@biplovbhandari please be patient...A pull request goes into my queue without any need to ask me to merge & chasing it after a day at the weekend isn't helpful...

@flavour Please REVIEW

I updated the Import XSL - see next commit

Is this to hold the relationship in the family?
Please can you rebase/compress to single commit?

Looking a lot better now...some minor tweaking to do & then we can merge & try it out :)

I think you'll need to give a _lot_ more information.
Consult the documentation for the different permutations of what is required for permissions:
http://eden.sahanafoundation.org/wiki/UserGuidelines/Admin/Permissions

That is the expected behaviour, yes.

The default configuration applies single-tier authorization (i.e. whether the user is logged-in or not logged-in), no roles or permission rules are applied. Anonymous users can read, authenticated users can write everything.

If you want to use role-based authorization, you must switch to a role-based security policy (3 or higher, in 000_config.py). For what you want to achieve, policy 5 is the recommended  setting.

> 18 dec. 2015 kl. 11:44 skrev Michele Basile notifications@github.com:
> 
> I tried to create several roles in the Administration section, but it appears that the permissions are not properly applied For example, when I create an user and associate to him a role with no CREATE permission on Organisation module and then log in with that user, I can still add new record to the Organisation resource
> 
> I encountered this problem is in an old commit in November, and in the latest version
> 
> —
> Reply to this email directly or view it on GitHub.

I missed that page on the wiki, I'm sorry. Thank you guys :)

@flavour I have made the corrections you pointed out...Added the Event Checklist Model...

A few minor tweaks& then this can go in finally ;)

@flavour Done :) Please merge

I agree with Fran - this is a simple read action, so GET it should be.

There is no need to send any POST data to the server here - the HTTP BasicAuth header will trigger proper validation, and all you need to check in the custom controller is whether there is a current.auth.user. If that is the case, then return the data for _that_ user (i.e. current.auth.user), and that's it. If there is no current.auth.user, return nothing - or if absolutely necessary, return a 401 challenge using current.auth.permission.fail() (not a 400 status - that's incorrect!).

Instead of user roles, you should send concrete permissions as booleans, like:

{...., "create_alerts": true, "approve_alerts": false, ...}

or a bitmap that encodes all relevant permissions in a single integer:

{..., "permissions": 428, ...}

This is more flexible and doesn't need to be adapted in case the role names/ids/uuids change. And anyway - the client doesn't need to know about roles, it needs to know about concrete permissions only. Hence, send only permissions - not roles.

If you have doubts: there is nothing you need to do about the BasicAuth header on the server-side, that happens automatically. If the header is valid (i.e. username and password correct), then at the time when the custom controller is executed that user will be the current.auth.user.

If the header is not valid, then current.auth.user is None, and you can simply respond to that with a 401 challenge (auth.permission.fail()).

You do not need to implement anything else in this regard - no password check. And you shouldn't.

> Instead of user roles, you should send concrete permissions

Actually I don't think that is needed for this particular usecase...it's about workflow rather than permissions really (the server will enforce permission checks)

Oh ok - how do you know that? The original question said that the client application needed to know whether the user has permission to create alerts - it said nothing about roles.

And indeed if the mobile app is meant to align its workflows with what the user could do on the server, then necessarily you can not assume that a role will always mean the same if it is possible to change it in a live system.

You can very well deny a role permission to create alerts through the admin UI, but that wouldn't have any effect on the mobile app - and woops, the whole idea /why/ you request the user info is suddenly pointless because your mobile knows just as much without it :P

> Oh ok - how do you know that?

Because I have reviewed the code in depth multiple times

> you can not assume that a role will always mean the same if it is possible to change it in a live system.

No-one will be doing that in this usecase

Ok, so where is the code of the mobile app so that it can be reviewed in context?

And since when are roles fix for a use-case? For a deployment, maybe - or even for a certain organisational context. But for an entire use-case? Hardly.

I think that is simply inconsistent design that I can not really agree with - and you wouldn't either if I'd committed this. It's simply a breach of concept, confusing for developers, and a barrier for future changes if all server-side functionality checks permissions not roles, but a mobile client checks roles not permissions.

If that is meant to be a permanent solution, then -1 from me. Not a blocker, but strong disagreement.

The more important point was though about using a regular authentication mechanism instead of implementing a new one in that custom controller - that is more something I would insist on.

Just out of curiousity: what does a role mean for that particular mobile workflow that is not reflected by server-side permissions? And if so, then why do the web GUI workflows not check roles, but permissions?

> The more important point was though about using a regular authentication mechanism instead of implementing a new one in that custom controller - that is more something I would insist on.

& one I had already suggested in my review

The roles for the mobile are just to determine whether the particular UI should be visible in mobile or not. Anyway the real permission check is always done in the server side.

@flavour Please merge...

@flavour Done :) Please merge

@flavour Done :) Please merge

Looks good - 3 minors to fix which I can do after merge. Thanks Armin.

 @armin11 : seems GitHub worked just fine for you, hopefully we see more from you here? If you are interested to work on the DRK code - I do have a couple of open requirements for that which I could share with you. Pls contact me off-list for that.

@flavour Please merge

@flavour Please merge

Looks ok to me.

Regarding that "P0 Number" string: can you tell where you see that in the UI? It's not in the code, so it would be in a database - maybe we can fix it if we understand where to look.

Thanks, but no need for this micro-commit. Will include it in my next commit.

Coming in the next update anyway, thanks

:D Ok, you fix it @flavour 

@flavour hope this is okey now

@flavour Please MERGE

@tudorian Did you see this: https://groups.google.com/forum/#!topic/sahana-eden/KS96vLuJXD0

Was fixed in June 2015
Please report bugs only against latest release

@flavour Done please merge

Can you provide higher-resolution images - or is this just to demonstrate how issue reporting on GitHub works?

JavaScript not needed to hide the images for small devices, just add a class "hide-for-small" to the HTML (it's static HTML)

There's the corresponding HTML:
https://github.com/sahana/eden/blob/master/modules/templates/CRMT/views/index.html#L13

If you want to hide them on small devices, add an attribute class="hide-for-small" - probably best to add it for the entire surrounding `<div class="row">`. I can't judge whether that gives an acceptable design, and since the CRMT project isn't currently active, there won't be user feedback available either.

I'm not going to fix this for now - if/when someone is actively using it, we can talk to them.

anurag029 said: 

I have tried to implement the multi-sheet workbook export using xlwt -  https://github.com/anurag-ks/eden/commit/926c0d300b61306ea2b42e608cc67512082ef0ff 
Need a review on it.  

I'll merge to ease Nuwan's review (although really I would much prefer not to be pressured that way: the reviews should be able to happen independently of merges...by having the demo server run off your branch).
Please do go back & do the tweaks though...especially that inefficient loop-in-loop

@flavour Hope this is ok to merge

@flavour Please merge

@flavour Please merge...

@flavour Please merge...

Looks good now - nice enhancements :)

@avni510 did you forked/cloned the latest eden repository? This branch has conflicts with the master branch of eden. Besides these are not internationalisation.
See the wiki for git at http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git and for internationalisation at http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Internationalisation

If you look at https://github.com/avni510/eden/tree/disease_mod_translatable_labels, you can see that it is 125 commits behind sahana/eden. That means you need to rebase it on the latest sahana/eden before it can be merged.

It is recommendable that you always rebase before you push to GitHub - making that a habit prevents accumulation of merge conflicts, keeps you up-to-date with the latest development and saves us the extra round of comms to point you to that ;)

Generally speaking, you always need to test whether your changes have the desired effect before you send a pull request.

In this case, the desired effect is that by changing the GUI language (using the language selector), the labels for these fields should appear translated in the corresponding forms.

Getting you to run the GUI in order to verify the effect of your changes was the actual idea behind this exercise ;) - the required changes are trivial, but they are not the point here.

Ok thank you for the feedback. My apologies! And thank you for your patience. After editing the code based on suggestions ex: Field("description", "text", label = T("Description"))
and running it locally, I found that some of the text was not translated. Ex: description and short name but some fields were translated ex: Name and Acronym. 

Is this something that I can fix?

This depends on which language you selected & whether there is a complete translation available.
If you can speak the language then you can add missing translations to the appropriate file in the languages folder.

@flavour Please merge...

Basically correct now, however if you look at how the formatting is done in other models, you could adjust to match :)

Cristian -- please see the other thread. Use web2py 2.14.5 to solve this problem.

> 26 apr. 2016 kl. 06:20 skrev Cristian Salamea notifications@github.com:
> 
> With a fresh installation, in Debian 7 i change to use postgresql as DB using this to deploy from our fork but i got the error:
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly or view it on GitHub

Copying from the other thread:

Please revert to web2py 2.14.5 to solve this problem. 

```
cd /home/web2py 
git reset --hard 81d0291 
```

The PyDAL component of web2py is currently undergoing a major restructuring, breaking backwards-compatibility and thereby loads of our code. Until this is fixed, and our code adapted accordingly please use 2.14.5.

Web2py still declares the new PyDAL as experimental - and since this is an incompatible change, we won't adapt Sahana just yet.

@nursix ok i will try and comment

@nursix i still get the error

`AttributeError: 'PostgrePsyco' object has no attribute 'INVERT'`

Here full traceback https://gist.github.com/ovnicraft/2b236bd612ccc2402ef2a578d034c51f

I dont know if pydal submodule must be revert to some version ? 

Yeah - correct. Sorry, I forgot that one.

```
git submodule update
```

...in the web2py folder

@nursix ok, i did it so when try to access to platform now i get this https://gist.github.com/ovnicraft/b43bf3e55576fb3dba003da6f263d8c3

`<class 'psycopg2.ProgrammingError'> la columna «worker_stats__tmp» es de tipo json pero la expresión es de tipo text LINE 1: UPDATE scheduler_worker SET worker_stats__tmp=worker_stats;`

Could you try to clean the database (=drop it, then create it new), and then try running it again?

Don't forget to delete everything in the databases/ subfolder after you dropped the database ;)

i did it but now get `Cannot connect to postgres Database: localhost:5432/sahana`

I create it new and sahana user is the owner ?

how i can debug it from console ? 

i got this with `psql -l`

```
csalamea@prod-desastre-eden:/home/web2py$ psql -l 
                                  List of databases
   Name    |  Owner   | Encoding |   Collate   |    Ctype    |   Access privileges   
-----------+----------+----------+-------------+-------------+-----------------------
 postgres  | postgres | UTF8     | es_EC.UTF-8 | es_EC.UTF-8 | 
 sahana    | sahana   | UTF8     | es_EC.UTF-8 | es_EC.UTF-8 | 
```

So, you dropped the "sahana" database, created it new, and after that it says "cannot connect to postgres database"? Are you sure you restarted Sahana after that?

If it could access it before, it should also be able to access it afterwards.

Console won't give you any other error, but you can do something like this:

```
python web2py.py -S eden -M -R applications/eden/static/script/tools/noop.py
```

...from the web2py folder. If this crashes with the same error, then we need to try again with the database reset...

Now its populating database, i hope this works and we can deploy eden ASAP.

Hi - you shouldn't change the order of the day names, this creates an inconsistency with the minified names, and accidentally changes the first day of the week.

> 7 maj 2016 kl. 11:52 skrev mohibullahiqbal111 notifications@github.com:
> 
> Hi Fran
> i just made change in names of months and days of the week but i really try to delete the English names but i cant so please delete the English names also
> 
> in the calendar we are not using short names so please use full names
> 
> thank you
> 
> You can view, comment on, or merge this pull request online at:
> 
>   https://github.com/sahana/eden/pull/1283
> 
> Commit Summary
> 
> Update jquery.calendars.afghan-ps.js
> File Changes
> 
> M static/scripts/calendars/i18n/jquery.calendars.afghan-ps.js (14)
> Patch Links:
> 
> https://github.com/sahana/eden/pull/1283.patch
> https://github.com/sahana/eden/pull/1283.diff
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly or view it on GitHub

Hi - so i will edit again and send you new pull request and also there are some language wise problem also i will edit day by day 

thank you for your kindly reply 

Shouldn't use inspect.isfunction, but just callable(subject) - it ain't wrong to pass any callable object, doesn't have to be a function (and just using callable saves one import).

> 19 maj 2016 kl. 06:41 skrev Biplov Bhandari notifications@github.com:
> 
> You can view, comment on, or merge this pull request online at:
> 
>   https://github.com/sahana/eden/pull/1286
> 
> Commit Summary
> 
> SAMBRO: alert history + SAMBRO: allow templates to be deleted + SAMBRO: send email about new priority options + email subject fix + SAMBRO: tweaks
> File Changes
> 
> M controllers/cap.py (117)
> M modules/s3/s3notify.py (3)
> M modules/s3db/cap.py (1249)
> M modules/templates/SAMBRO/config.py (67)
> M modules/templates/SAMBRO/controllers.py (27)
> M modules/templates/SAMBRO/menus.py (5)
> A views/cap/_compose.html (4)
> A views/cap/compose.html (2)
> Patch Links:
> 
> https://github.com/sahana/eden/pull/1286.patch
> https://github.com/sahana/eden/pull/1286.diff
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly or view it on GitHub

All seems fine other than the query above :)

"This branch has conflicts that must be resolved"

@flavour corrected! Please merge

Merging - can answer/cleanup afterwards

@flavour Please MERGE

@flavour please merge

Great, thanks :)
2 minor enhancements I will do after the merge:
Remove comment from 'Profile' now that it has a translation
Remove extra space at the right of one of the strings

@flavour corrected..Please merge

@flavour please merge..

I will merge even with the little cleanups left to do

@flavour corrected! Please merge

@flavour How can I not apply the gis configuration for the imported alert area because for country instance it will give validation error? Or apply default one?
Also can you please minify the js files? Many thanks!

Minifying now

If you need an instance to support Alert Areas outside of the country then don't have any restricted boundary in the default config for that instance.

@flavour What is the proper way to change the length of the column event_event_type.name (https://github.com/sahana/eden/blob/master/modules/s3db/event.py#L106)? This is required for the imported alerts as some event name are longer than that. If I try to change that value to other value, it generates a null value error (error ticket: http://pastebin.com/QJkz4pz0)

@flavour Done...Please merge

This appears wrong, but must have come from somewhere.
Why would we notify all approvers whenever anyone reviews an alert?
This has the potential for many copies of a 'please review x alert' message.
I've not investigated where it should happen instead, but think it really should have been an earlier stage which sent the notifications...there should never be a need to send notifications when this button is pressed?

Assuming that this refers to the [file] link for the organisation logo in the organisation form, this appears to have already been fixed in trunk.

This problem can no longer be reproduced with the new default theme.

This problem has been solved in the new default homepage design.

Fixed in trunk.

Fixed in new default homepage design.

Fixed in trunk.

Anaurag's multi-sheet export is now in trunk, which prevents the crash. The implementation of the xslx export options is still desirable, however - even though such massive exports are rather rare (and super-size spreadsheets of questionable value).

Downgrading to minor enhancement.

@flavour This is the requirement from Myanmar. Even though the Approver can approve the alert without consent with others, they want to know that someone is approving the alert. 

I am not arguing the requirement.
I am arguing the proposed workflow to meet this.
(1) It doesn't seem to actually do what Myanmar want:
- The solution as-proposed sends them a notification to reviw an alert when an alert is reviewed
- What they seem to want is a notification saying that an Alert has been approved (onapprove hook)

(2) There is a danger that users will be flooded with multiple copies of a 'Please review x alert' message

@flavour Corrected please merge

Superseded by:
https://github.com/nursix/eden/commit/656045f74ef5ccfacf86cf722a58ea9683c4759b
...hence closing this one.

Thanks Matt :)

Nice. Could you make the two additional changes (see my comments)?

Yea done 👍 

:+1: 

As per mailing list thread, we currently only support the latest stable web2py:
https://groups.google.com/forum/#!searchin/sahana-eden/portalocker%7Csort:relevance/sahana-eden/3NmgZrCTdU0/Ak0SfqmWAwAJ

Thanks - all tests failed, but not your fault (problem in trunk).

I don't like the change to core RSS handler here for the 2 reasons given inline...which cases does the old system not work with?

@flavour For http://www.dmhwarning.gov.mm/eden/cap/alert.rss, this method gives me '`bozo_exception': SAXParseException('not well-formed (invalid token)')`.

google search gives this error may be because of character-encoding. The myanmar characters are entered by the user themselves. However it works fine for public feed,  http://www.dmhwarning.gov.mm/eden/cap/public.rss, ie there is no bozo exception.

@flavour Myanmar wants to have new line between English and Myanmar content. Is there a way I can join two values using newline. I am combining values in different language here: https://github.com/sahana/eden/blob/master/modules/templates/SAMBRO/config.py#L1328

`"\n".join` won't work until we print the value.

> For http://www.dmhwarning.gov.mm/eden/cap/alert.rss, this method gives me 'bozo_exception':  SAXParseException('not well-formed (invalid token)'). google search gives this error may be because of character-encoding.

I don't have a login so can't see the original document...the public version correctly encodes the XML as utf-8. The myanmar char isn't in the username/password is it?

> For http://www.dmhwarning.gov.mm/eden/cap/alert.rss, this method gives me 'bozo_exception': SAXParseException('not well-formed (invalid token)')

I fixed this in current trunk. The issue was that feedparser wasn't doing pre-emptive authentication & was crashing trying to parse the 401 response (which in this case was in Burmese).
I have therefore added the header manually.

@flavour Please merge

@flavour Please merge

We definitely shouldn't duplicate core stylesheets just for the sake of paths - that is absolutely unmaintainable.

Since the problem is only with eden.min.css, I think either the minifier should adjust any relative paths in the concatenated CSS, or place the eden.min.css into a folder at the right level (with a different name, maybe).

But no replicating of core stylesheets please - this is just....irrrgh, no go.

I'd favor the build script to adjust any relative URLs in eden.min.css - this seems relatively easy to do: if the target location of eden.min.css is not top-level themes/*, then scan eden.min.css for url() => adjust any relative paths => rewrite eden.min.css. Shouldn't be hard to do in Python.

how do i debug build.sahana.py? I am in Windows. I tried new Debug Configuration in Eclipse, and the main module to run as the path to build.sahana.py. My arguments tab has -A css for min css. The process starts and I meet this error: https://github.com/sahana/eden/blob/master/static/scripts/tools/build.sahana.py#L16

main module needs to be web2py.py
arguments -S eden -M -R /path/to/build.sahana.py

@flavour Please merge

@biplovbhandari Do you really need a full custom theme per country if all you need to customise is the menu logo and favicon? Seems a bit over the top to me.

Check the RMSAmericas theme how things can be made dynamic:
https://github.com/sahana/eden/blob/master/modules/templates/RMSAmericas/views/layout.html#L78
https://github.com/sahana/eden/blob/master/modules/templates/RMSAmericas/layouts.py#L256

Should be easy enough to implement something similar to change the menu logo (and favicon) per settings.template - and minimal style differences can be caught by CSS classes.

@nursix : Why not make this the default then?
Currently this is the docs which you are well aware I was writing as I just did exactly this for SCPHIMS:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Themes#Simplemodifications

@flavour Making the menu logo of the default layout configurable is already on my list (we discussed this before). However, SAMBRO is using a custom theme/layout, so this wouldn't immediately benefit from the enhancement - and the question here was about the need for sub-themes.

And anyway @flavour, my standpoint is that menu logo and favicon are actually contents (i.e. template), not styles (theme) - hence having the logo in the theme isn't quite right.

@flavour Please merge

@flavour Please merge

@flavour Please merge

Proposed fix:
https://github.com/nursix/eden/commit/dbedc5f1f699ea6f5c08f7b700845b5453a500cb

@flavour Please merge

Can easily modify the UI for a single record by either setting the form's
inline component to multiple=False or even redefining the component as
signle in this view

On 12 November 2016 at 10:04, Biplov Bhandari notifications@github.com
wrote:

> ## _@biplovbhandari_ commented on this pull request.
> 
> In modules/templates/SAMBRO/config.py
> https://github.com/sahana/eden/pull/1330:
> 
> > @@ -1349,4 +1358,62 @@ def get_formatted_value(value, represent=None, system=True):
> 
> ```
>              return nvalue
> ```
> -    # -------------------------------------------------------------------------
> -    def _get_or_create_attachment(alert_id):
> -        """
> -            Retrieve the CAP attachment for the alert_id if present
> -            else creates CAP file as attachment to be sent with the email
> -            returns the doc_id for the CAP file
> -        """
>   +
> -        s3db = current.s3db
> -        atable = s3db.cap_attachment
> -        query = (atable.alert_id == alert_id) & (atable.deleted != True)
> 
> but then we can upload multiple doc for a alert from cap_resource UI. SO I
> created new table to store the cap xml only
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> https://github.com/sahana/eden/pull/1330, or mute the thread
> https://github.com/notifications/unsubscribe-auth/AAXx2Bk14Sf0U8313Nb6VMVUlXqWFxktks5q9Y8ZgaJpZM4Ktbh4
> .

@flavour Please merge

This bug seems to be resolved. Can this be closed?

Following steps were done to verify:
1. Un-commented OCR module section in /module/templates/default/config.py
2. Navigated to admin/translate/create?opt=1
3. OCR was found in list of modules for selection.
4. Re-commented OCR module section in /module/templates/default/config.py
5. Navigated to admin/translate/create?opt=1
6. OCR was **not** found in list of modules for selection.
What I think is still needed is to exclude at least some of modules/s3/s3pdf.py

To Test, you need to export a translation file for a new language code (even a dummy one) & you'll probably see some strings which relate to OCR even if the OCR module is disabled
Two tests were done with OCR module disabled and on each occasion, OCR related strings were found to be present when core was included ( i.e. include core was checked ). When core was not included, OCR strings were not found in the exported file.

Another observation was that the OCR related strings found were independent of the language and module selected. On both instances when core was included, the same OCR strings were found in the exported files.

Test 1: 
1. Navigated to admin/translate/create?opt=1
2. Selected module - organizations
3. Selected language code - es 
4. Checked and unchecked "include core" and exported for each instance.

Test 2:
1. Navigated to admin/translate/create?opt=1
2. Selected module - hospitals
3. Selected language code - fr 
4. Checked and unchecked "include core" and exported for each instance.
Exactly what I'd expect.
OCR strings in s3pdf currently are included in 'core' but should be included in the 'ocr' module from a translation perspective
Why can't this use the standard supply/asset modules to manage the UAVs? I don't see anything special here that can not be handled with the existing data models.
I am thinking of putting the images coming from UAV, reading EXIF data in the model along with visualization and other
So? I still don't see why this can not use the supply/asset module to manage the devices. And images would be doc, so they can easily be linked to context models.
I don't think that we want to introduce a separate module for each type of sensor/observation equipment.

The devices themselves are just assets, and would typically be managed together with all other assets of an organization.

The data they produce are either context-specific (e.g. incident data) and should hence go into the respective context modules - or they are generic (e.g. weather data, areal imagery) and then should go into a generic module like doc, gis or the like so that they can be linked to context data.

And /if/ the data are only linked to the UAVs themselves (and not any humanitarian/emergency management operation), then we need to ask whether that should be in Sahana at all. Otherwise I might want a lego module to manage the bricks for the local kindergarten.
Yes the data are context-specific (mostly damage assessment, mapping and sometimes incident data). I will try to play with assests module. For images, I was thinking of using gis and doc modules.
Okay, I think this will be a better approach. You may want to close this while you're working on it? Or do you want a complete review now?
Note that the core Assets module can  be extended with UAV-specifics if-required, just like for Vehicles (& there are stubs for Telephone/Radios)...in which case a UAV module may still develop, but just not to repeat the core stuff like Manufacturer.
Which template uses Vehicle specific assets?
Not a template, but a module:
https://github.com/sahana/eden/blob/master/modules/s3db/vehicle.py
https://github.com/sahana/eden/blob/master/modules/s3db/asset.py#L130
@flavour fixed...please merge
Seems fine, but I see no pressure to merge this WiP?
@flavour Please merge
No files changed
Thankyou, silly mistake indeed!
I will fix but not as a merge since you also have a bunch of changes within the locale file here that I cannot easily verify. Thanks again :)
Overall this is premature for a Pull Request: This breaks a lot of functionality for other pages & even within this page it replaces a lot of dynamic, working content with static dummy data....so overall is quite a major step backwards.
In general, smaller pull requests are better than larger ones...easier to review & less likely to give problems.
For providing desired styling updates to dynamic contents, we need to use a different system to a Pull Request. It can certainly be flat HTML with dummy data, like this, and it can even be code in GitHub, but then probably a different branch to the one being used to submit Pull Requests so they don't get muddled up.
ok, I merged, but I see an issue in that the 'Add Update' button is visible to all, which I believe is incorrect?
This should only show to those people who have permission to do this?
Which for this usecase is all AUTHENTICATED users, so we could just hide this in the view with {{if auth.is_logged_in():}}BUTTON{{}} or we could be more generic & do the permissions check that we have already in the controller & so currently that would be hiding it behind the {{if create_post_form:}}
I think we should be trying to be generic where possible to make it easier to build SAFIRE.

For the Modal create form, I am assuming that we will use a std jQueryUI popup instead of this one? (Foundation I assume?)
NB I can make the change, but would rather do with the Popup change, so will wait a mo...just want to confirm it all with you first.
re: add update, yes the generic method of hiding that button sounds like the right choice

re: modal, it seems to me that it makes sense to keep all pop-ups as jQueryUI for consistency. I'm not clear on *how* to achieve this, if you can replace the foundation modal with a jQueryUI implementation that should be enough to get me clear so I can execute in the future.

Thanks @flavour 
I noticed that I've left a few double quotes in my HTML, sorry! Auto complete...
Thankyou, unfortunately this is very hard to review.
is it possible for you to resubmit with a single commit & with the new translation file alphasorted like the original?
i.e. All Capital letters 1st & then lower-case after that.
This way I can review it more easily...many thanks!
I'm sorry! Apparently editing the locales via the web interface is not a good idea. I will make a new pull request.
Great, many thanks, was easy to review this time so merged & reverted that incorrect fix :)
I'll cleanup the issues post-merge
I left it as 'column' btw as not 100% this is a bug
@flavour Please merge
I find this rather unclear I'm afraid. I think the deployment_setting could use a summary of what it does in the docstring...can you add that?
@flavour please review
@flavour Please merge
@flavour Please merge
@flavour please merge
Moving all the tabs to the top-level instead of nested is a definite improvement I think :)
The nested was clever but confusing...
This is not a bug, but a recommendation. For such, please use the mailing list, not the issue tracker.
Thanks!
For point 1:

The default/config.py file shall not have any settings uncommented - these are rather just examples to illustrate the usage in other templates or models/000_config.py (i.e. they are copy+paste templates, or documentation, if you will).

In the default template, they shall (it's in the name) always *default*. And consequently, there shall be no imports of anything either - those would just cause unnecessary processing.

So, these issues are not /bugs/ but incorrect examples/comments/documentation.

As for point 2: this seems like a typo - easy enough to correct this example
As for point 3: indeed you can not use current.messages in the config() function itself (because it is only defined afterwards), it must be wrapped into a callback - so this observation is correct. The example should be corrected
Correct would be:

    orderby = "delphi_problem.code"

Correct analysis, this module was written for NZ Canterbury EQ and hasn't been touched since other than a very simple rough migration through 1 evolution of code.
The yes_no_represent is easy to fix indeed.
S3Search had been replaced by S3Filter, which is a bit more work to migrate to, but still fairly easy for anyone who wishes to make use of this module :)
Actually, it's inconsistent of openid_auth.py to return a DIV rather than a FORM when requesting a login_form() - this can't be expected.

And I'm not sure whether catching this in the default controller before checking for form.errors would actually help - but it may be a workaround for /this/ problem.

However, I'm not aware of an active use-case (which template uses openID?).
Deletion hasn't been tested for ages - since nobody is actually using it ;)

However - clearly a bug, albeit easy to fix: 
Record deletion (unlike record archiving) assumes deletable=len(rows), and for every failure ("Row is not deletable") would subtract 1. If that gives zero, then that means "no deletable rows found".

Will fix this.
I don't think it's a web2py error - it may well be an error in the client-side form processing.
Btw - instead of posting the corrected code into the issue report (point 2), you could as well have sent a pull request.
Nah - more like this:
https://github.com/nursix/eden/commit/634531a631b7d3d0510ec95230dcd0b4bbb4ef7d

Fix provided:
https://github.com/nursix/eden/commit/e4698399de6c5b9540a5850e9576d0be9baf7180

Fixed:
https://github.com/nursix/eden/commit/e4698399de6c5b9540a5850e9576d0be9baf7180#diff-e4dc3e671d97369fd4c835a324918839
NB It only /seems/ that there are many undefined variables and function calls throughout the code - but you have been analyzing a lot of unused/outdated code (which is either kept as historic reference, or as c/p templates).

That's the downside of running pylint against the entire code base ;) you will find quite a lot of ghosts.

However, running pylint (or jshint, for the JS parts) is indeed part of my routine, so I would second your recommendation - it is very helpful indeed *if* you know what you're looking at.

It is though /not/ so very helpful to publish the output here with the suggestion that there are tons of bugs - either you verify every single one of them (and check that they are in active code), or you put in a disclaimer (...although then it doesn't belong on the issue tracker, but I said that already).

Nevertheless - good digging.
No template yet. We're evaluating Sahana Eden for possible deployments on our use cases. OpenID is one of the features which would be nice to have, as it seemed that it's already implemented.
Well, as it seems, the framework for that exists - but the use-case isn't currently part of the default template (maybe it never was).

That's actually the case with many features - they may be (or have been) part of specific templates, and wouldn't work in others. This one seems useful for default, though, and should thus be fixed for it.

However, you may eventually want to develop a specific template for your case - and then only fix the problem there. If/when you do, then maybe remember this report of yours, and port your fix to default ;)
Confirmed. Initialization works now. Thanks.
I should put this right:

Many of the config switches (particularly of framework-level features), require the respective template to support them - but most templates only expose/support a subset of the functionality. In most templates, therefore, switches can have adverse side-effects or no effect at all.

Surely "default" is meant to be the "kitchen sink", and expose sort-of everything - but then again it doesn't because some of the features actually conflict with each other (so it would only support the most common case), and other features are untested and may indeed not work (and are therefore not be exposed by default). For exactly such reasons, a number of modules is disabled by default.

For your evaluation that means that everything you get in /any/ template without modifying its config switches is what is supposed to work in this template - and everything else /could/ work, but requires testing and maybe some hands-on to make it work. 

Also take into account that the default template is currently one of the least maintained ones - simply because nobody is actually using it in a deployment - so that's a natural effect of us focusing on specific cases much more than the "kitchen sink" (in fact, it may be that nobody has been working on the default template for the past 2-3 years).

The best strategy for an evaluation for deployment may be to discuss your case on the mailing list. That way you can get a much better idea of how much effort it would be to support your requirements.
Organisation tags work now. Thanks.  
Also, 10,000th commit, congratulations. 🎉
Nah - nobody is trying to break records here ;) And it's only 10,000 commits in this repo, but thousands more in previous/other repos (Sahana used to be on Launchpad before), so nothing new really ;)
Hard-deleting organisations which are referenced now gracefully fails with user-friendly error in popup box. Thanks.
NB "hard-deleting" is not recommended for production deployments, and it will not work effectively if you have multiple synchronized instances (peers can't see hard-deletions, so they would restore what you delete). It is also not sufficiently tested across the board.

If there is a specific reason to deploy with deletion instead of archiving, then it would be interesting to learn about it - this requirement hasn't come up in a decade (if-ever).
Fix provided in:
https://github.com/sahana/eden/commit/35d1b3e4c54838fc1f7664ab85d7fdb9904300b2#diff-21a13ac928a047a2dea91a8728413638L139
Confirmed. Both *Assets* and *Facilities* tabs now display properly. Thanks.
Clarification: The stack trace above is reported when SE runs directly via web2py server. When running via nginx+uwsgi, following stack trace is shown in SE ticket instead.
```
Traceback (most recent call last):
  File "/srv/sahana/gluon/restricted.py", line 227, in restricted
    exec ccode in environment
  File "/srv/sahana/applications/eden/controllers/default.py", line 1547, in <module>
  File "/srv/sahana/gluon/globals.py", line 417, in <lambda>
    self._caller = lambda f: f()
  File "/srv/sahana/applications/eden/controllers/default.py", line 298, in index
    login_form = auth.login(inline=True)
  File "applications/eden/modules/s3/s3aaa.py", line 759, in login
    self.login_user(user)
  File "applications/eden/modules/s3/s3aaa.py", line 994, in login_user
    locations = gis.get_features_in_radius(userlat, userlon, accuracy)
  File "applications/eden/modules/s3/s3gis.py", line 2088, in get_features_in_radius
    connection = psycopg2.connect("dbname=%s user=%s password=%s host=%s port=%s" % (dbname, username, password, host, port))
  File "/usr/lib/python2.7/dist-packages/psycopg2/__init__.py", line 164, in connect
    conn = _connect(dsn, connection_factory=connection_factory, async=async)
OperationalError: could not translate host name "None" to address: Name or service not known
```
There is no need for this: the Messages structure is already localisable by default
Thankyou, have you signed a CLA?
I was told by the rightful owner of this account that the CLA has been signed :)
Hi Fran, 
yes, I have signed CLA a months ago. 
this account shared with my developer and I very welcome his help. 

Thanks, Jiri Podhorecky
The s3_str method is exactly what is used elsewhere.
Am not sure how we can be more systematic without patching web2py
Yeah - the unicode mess!

I agree, just patching in s3_str is cheap and effective - but it's not really systematic.

Some background:
- we shall try to normalize any handover (parameter or return) of strings to utf-8 encoded str
- avoid unicode unless you need it (temporarily)
- unicode is needed when you parse, split, replace, lower/upper etc - and then it is a *must*!
- we have "safe" converters for both directions: s3_str and s3_unicode (both assuming utf-8)

For represented values, however, character-operations are extremely rare, so returning unicode from a representation function doesn't normally make sense. It's the easy way, though, because the DAL delivers unicode and just returning that is the obvious thing to do.

Now, there is already a general requirement for all representation functions to always return utf-8 encoded str - and it's been implemented in S3Represent (so much for "systematic" approaches).

And the point with that is exactly this: the HTML construction helpers apply str() on everything (i.e. using ASCII codec), so they will almost always crash with unicodes beyond ASCII. Represented values almost always go into HTML (what else is the point?), hence we want str from all represents.

Now...one systematic violation of this rule is the default renderer in S3ResourceData (my fault, sorry, fix pushed).

But note: even if that fixes a whole bunch of cases, it doesn't mean it fixes /all/ cases. This problem will probably haunt us as long as we use Py-2.7 ;)
@trendspotter 

You may want to test again once this is merged:
https://github.com/nursix/eden/commit/0df0a3aaf3e78b72fc674dc8b45c69e353cf6b23

...before you put in that s3_str. Maybe (hopefully) you don't need it anymore then.

Confirmed. Alert hub is now displayed properly even without the explicit *s3_str()*. Thanks.
Cool, so I dare closing this then...
Thankyou, yes, have had to do a couple of those in the past :)
Mergeed but I have no idea what the 'RSS feed goes here is all about?
During import, CSV sheets are converted to XML using an XSLT transformation stylesheet.

XSLT stylesheets cannot see Python configuration settings, so changing the UI label of "Staff" to "Contact" in the deployment settings has no effect on the interpretation of CSV sheets (and cannot have).

If you need to use an alternative label in imports, then the only way is to add it as an alternative for the value of 1 here:
https://github.com/sahana/eden/blob/master/static/formats/s3csv/labels.xml#L119

Like this:
```
<option value="1" name="staff">
            <label>Staff</label>
            <label>staff</label>
            <!-- also recognize "Contact" as type 1 -->
            <label>Contact</label>
            <label>contact</label>
</option>
```

...however, this could be ambiguous: contact persons can be volunteers in other contexts. So I'd be very wary of making this change, and wouldn't necessarily support such a fix.

Instead, I would highly recommend that you change your CSV instead - and indicate clearly whether these are volunteers or staff members (because that's the distinction that matters, technically).

As for your other note:
The limitation of string fields is both for efficiency and compatibility reasons. The latter has become less important, however that doesn't change the fact that lengthy labels are a nightmare.

They are barely readable for users (it takes much more time to understand the information on the screen), massively clutter up UI representations (tables, forms, charts) and they make search queries significantly slower. 

Contrasting that with the value they add, I'm inclined to insist on the length limitation.

And honestly, tell me the value-add of

"Department of Civil Emergency Planning, Protection of Classified Information, Defense and Defense Planning"

over 

"Department of Civil Emergency Planning"

...in the Sahana-context. Is the latter anyhow ambiguous (do you have multiple departments whose names start like that?)?

Your government should perhaps issue short names for ministries ;)

NB the header of the corresponding XSLT clearly documents the accepted options for this column:

https://github.com/sahana/eden/blob/master/static/formats/s3csv/hrm/person.xsl#L15

Okay. The template CSV does not contain the *Type* column and it didn't occur to me to check also XSLT.

As for the long names - understood and agreed. Let's see what can we abbreviate.

Thanks.
Moved to the end as requested.
Yeah, CSV/XLS formats are a common point of contention - simply because everybody want something else. But exactly that is the problem with Spreadsheets in general ;)

Whilst there is some flexibility in the CSV formats, our standpoint tends to be that it is easier to fix CSV/XLS sheets to meet a standard format, than it is to implement complex data analysis/interpretation in the importer....which is only bound to fail again with the next user who wants something differently.

But you're right, it's not obvious that you should look into the XSLT to see the documentation for the CSV format ;) that's just something you need to know. The XSLT files are easy to find - they have the same name as the CSV template, and are in the same folder.

It might be possible to write a function that extracts the documentation from the XSLT and shows it as a "Help" link beside the download-link for the CSV template - if you like the idea, then feel free to add it as a new issue. Or else - make a better proposal ;)
Both, sort-of.

For one, cap.py should configure a mutable list, but then also S3CRUD should convert to a list if it isn't a list. Can you do that and send a PR?

> 24 sep. 2017 kl. 08:54 skrev trendspotter <notifications@github.com>:
> 
> When using CAP module along with settings.ui.interim_save = True, Alerts die with following traceback
> 
> Traceback (most recent call last):
>   File "/srv/sambro/gluon/restricted.py", line 227, in restricted
>     exec ccode in environment
>   File "/srv/sambro/applications/eden/controllers/cap.py", line 1515, in <module>
>   File "/srv/sambro/gluon/globals.py", line 417, in <lambda>
>     self._caller = lambda f: f()
>   File "/srv/sambro/applications/eden/controllers/cap.py", line 1032, in alert
>     rheader = s3db.cap_rheader,
>   File "/srv/sambro/applications/eden/models/00_utils.py", line 243, in s3_rest_controller
>     output = r(**attr)
>   File "applications/eden/modules/s3/s3rest.py", line 691, in __call__
>     output = self.resource.crud(self, **attr)
>   File "applications/eden/modules/s3/s3rest.py", line 1774, in __call__
>     output = self.apply_method(r, **attr)
>   File "applications/eden/modules/s3/s3crud.py", line 110, in apply_method
>     output = self.select(r, **attr)
>   File "applications/eden/modules/s3/s3crud.py", line 1239, in select
>     form = self.create(r, **attr).get("form", None)
>   File "applications/eden/modules/s3/s3crud.py", line 372, in create
>     self._interim_save_button()
>   File "applications/eden/modules/s3/s3crud.py", line 3130, in _interim_save_button
>     settings.custom_submit.insert(0, item)
> AttributeError: 'tuple' object has no attribute 'insert'
> This is caused by the fact that Alerts define their own custom_submit which is immutable (a tuple). I see two approaches.
> 
> Either make the custom_submit mutable (list instead of tuple), which I have in 21beef1
> Or, since the Save and edit information button has pretty much the same functionality as interim save, there can be a check in S3CRUD which determines if the custom_submit is mutable (resp. has insert property) and if it's not, it doesn't add the interim save button. This I have in 6523bba.
> Which one would you like to see as PR?
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.
> 

Yeah - that looks good now.

Now, as an exercise - could you please squash the commits into one?
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/Git#Squashingcommits
Easiest way is probably to soft-reset to the commit before the first in this PR, then commit again, and then force-push (this will update the PR accordingly).

Thanks.
GitHub allows squashing when accepting PR in the dropdown menu. But OK, lets's see how it works if I try to squash them on my side.
About the comment "*cap.py setting tuples is a good thing*". Should I revert the changes for CAP and CRMT and leave just S3CRUD?
> GitHub allows squashing when accepting PR in the dropdown menu

So it does :)
Wonder how long that feature has been there without me noticing ;)
Yeah, I know - but I'm not the one to merge it, and Fran would normally request multiple commits on the same issue to be squashed to make it easier to review. Never really an issue, that's why I said "as an exercise" ;)
Yes, that's what I said: the changes in cap.py can be reverted - tuples are actually good since faster to instantiate than lists, and the CRUD change is performance-neutral yet makes it robust for tuples.
Perfect :) Sorry for the extended conversation - I'm a bit slow thinking on Sunday mornings. How do you manage? *lol*
This can probably be fixed by changing this:
https://github.com/sahana/eden/blob/master/modules/s3/s3gis.py#L2082

into:

    host = settings.database.host or "localhost"

If you have a test environment ready, could you check if this would fix it, and send a PR if so?
To explain it: settings.database.host is usually None to indicate that it should default, but get_features_in_radius doesn't apply any default. This would add it.

Alternatively, we could have a S3Config.get_database_host() that returns the default "localhost" for None, and then call that in get_features_in_radius (in fact, that would be the "correct" way - the settings dict shouldn't be accessed directly to prevent regression).
```
host = settings.database.host or "localhost"
```
Changes the traceback to 
```
Traceback (most recent call last):
  File "/srv/sahana/gluon/restricted.py", line 227, in restricted
    exec ccode in environment
  File "/srv/sahana/applications/eden/controllers/default.py", line 1547, in <module>
  File "/srv/sahana/gluon/globals.py", line 417, in <lambda>
    self._caller = lambda f: f()
  File "/srv/sahana/applications/eden/controllers/default.py", line 298, in index
    login_form = auth.login(inline=True)
  File "applications/eden/modules/s3/s3aaa.py", line 759, in login
    self.login_user(user)
  File "applications/eden/modules/s3/s3aaa.py", line 994, in login_user
    locations = gis.get_features_in_radius(userlat, userlon, accuracy)
  File "applications/eden/modules/s3/s3gis.py", line 2088, in get_features_in_radius
    connection = psycopg2.connect("dbname=%s user=%s password=%s host=%s port=%s" % (dbname, username, password, host, port))
  File "/usr/lib/python2.7/dist-packages/psycopg2/__init__.py", line 164, in connect
    conn = _connect(dsn, connection_factory=connection_factory, async=async)
OperationalError: FATAL:  password authentication failed for user "None"
```

So it seems that none of the database information are getting populated here.
Aaa, yeah.. because I don't have any `settings.database.username` and I'm relying on the *S3Config* to give me the default string. So your suggestion about `S3Config.get_database_*` applies also here.
Same problem there - even settings.database.user is None to indicate the default "sahana".

The correct way to solve it is to not access the settings dict directly, but have a getter-function in S3Config that applies the defaults (you can see the default in the modules/templates/000_config.py template).

A quick workaround would be to "or" the defaults here in the settings-lookups. But this wouldn't be robust for future changes of the defaults then, so I'd recommend the former.

However, your test confirms at least that the missing default is the problem.
:D right
I think, instead of having individual getters, we should have something similar to:
https://github.com/sahana/eden/blob/master/modules/s3cfg.py#L979

...which returns a dict with the database settings instead of a string.

This could then be used in get_database_string (i.e. DRY).

What do you think? Do you want to do this, or shall I?
E.g. S3Config.get_database_parameters() => takes the settings.database.*, applies all defaults (...which depend on the DB type), and then returns a dict with the parameters.

S3Config.get_database_string() would call get_database_parameters() and then construct the string from that dict rather than applying the defaults itself.

S3GIS.get_features_in_radius would also call settings.get_database_parameters(), but construct a different string from it.
> What do you think? Do you want to do this, or shall I?

Go for it. You know the codebase incomparably better than me. :) There's also similar approach as the GIS uses (this time with defaults) here: https://github.com/sahana/eden/blob/master/controllers/default.py#L1119 and few lines below that for PgSQL
Like this, maybe:
https://github.com/nursix/eden/commit/385b3de74d2da6627386c25fae0485039d3959e7

Now I don't currently have an active PostGIS installation locally - so I can only verify that it prevents the crash you described above, but not whether the setting of presence on login actually works. Could you maybe check that and confirm?
Following traceback during DB population. I guess the same thing as in [44cc117](https://github.com/nursix/eden/commit/44cc11731c0d9cee36a08b0bc7baf4d09200d669) has to be fixed
```
Traceback (most recent call last):
  File "/srv/sahana/gluon/restricted.py", line 227, in restricted
    exec ccode in environment
  File "applications/eden/models/00_db.py", line 53, in <module>
    if settings.get_base_session_db():
  File "applications/eden/modules/s3cfg.py", line 909, in get_base_session_db
    (db_string, pool_size) = self.get_database_string()
ValueError: too many values to unpack
```
Okay, fixing it again...hang on...
This makes more sense then:
https://github.com/nursix/eden/commit/2d9254f416bd9f1cd9c6c84e0b090d3852cdd322
@trendspotter wait for the unit tests to complete - they actually caught the issue.
Okay, passing now:
https://travis-ci.org/nursix/eden/builds/279191755

NB I updated the original commit rather than adding on top of it, so you may need to rewind a little bit.
Btw - maybe we should have live conversation on IRC freenode/#sahana-eden. Otherwise I will get whipped for spamming people here :$
DB population works, login works and `auth_user_clientlocation` has correct data, so these are definitely OK.  `gis.get_features_in_radius()` doesn't seem to return anything even though I have a feature right on my coords, but that can already be a problem with my data (and if not, it didn't work up until now anyway).

So.. nice job here, I think it can go to the master.
Cool, so let's wait for the merge, then close the issue. Thanks for checking.
Try replacing ```S3.autocomplete``` with ```S3.autocomplete.normal``` in s3.gis.js
JS trace is gone but the *Layer Properties* tab is still empty.
FWIW, the tab tries to get content from URL like `http://<host>/eden/gis/layer_feature.plain?layer_feature.layer_id=15&update=1&_dc=1506434920847` but gets only this as response body (including blank lines):
```







<div id='plain'>

</div>
```

It has been brought to my attention that the same issue exists also on <http://rmsdemo.aidiq.com/eden/gis/index> which I personally can't confirm since I don't have access there (yet).
https://github.com/nursix/eden/commit/270108e9f0c4e4f1b1ef1346257b2fe6659bcb29

should solve that.
And it does. One character and so much damage :)  
Thanks
Btw. what about the *Filter* tab? Currently it seems to render whole SE GIS window again, as it sends AJAX request to `https://<host>/eden/gis/index`.
Pass...I'm not sure this has ever been migrated to the current framework, and this may also be beyond this issue.

Make sure to send a PR with the s3.gis.js fix ;)
Yes, as it says here:
https://github.com/sahana/eden/blob/master/static/scripts/S3/s3.gis.js#L6056

@ToDo: Migrate to S3Filter!

It used the old S3Search framework when originally written and hasn't been updated to use S3Filter
Seems that the URL in table in step 6. is created with wrong ID.

Eg with default data in RMS template, it leads to `http://<host>/eden/survey/series/Ms.%20Mario%20Moniz/summary`. In default template it leads to `http://<host>/eden/survey/series//summary` (the ID is missing entirely there).
Note that the Survey module is being deprecated & replaced by the DC module (Data Collection)
This can be seen using the SCPHIMS template where itis called 'Assessments'
DC uses the dynamic tables back-end & so will be fully integrated into the framework, usable on Mobiles, etc.
However there are a few features that are unlikely to be ported from the old Survey module, so it would be good to get this fixed still.
ok, there shouldn't be any Open button at all...this is being automated which the page isn't expecting...it just wants a formatted table!
Fixed: https://github.com/sahana/eden/commit/978f0c25c8d85bef6c4a7d535dd7481784a773b7
Unfortunately mixed with my other work...but no time to unpick
Yes, very easy for simple fields like this :)
Good to add to the top of the XSLT too, which is a place for documentation, but can come with anything else you push :)
Seems a little early to add the 280 char support if still being test-driven?
Perhaps have this commented ready to go?

Also this will trigger a database migration, which may not be automatic for some databases.
Ideally test that for all 3 supported dbs & come with a migration script for any platform which it doesn't work automatically for (the whole process of migration scripts isn't supported well currently...we do have some back-end support in s3migration.py & plan to build front-end support into WebSetup but this will focus on moving between stable releases: 1.0->1.1 etc)
This case /might/ be straightforward, but good practise to be aware of it
OK, not really *test driven* but slowly *rolled out to public*. There already are accounts tweeting with the new length, see also related [post on Twitter blog](https://blog.twitter.com/official/en_us/topics/product/2017/Giving-you-more-characters-to-express-yourself.html).

Anyway, for the time being, I've rolled back those changes and I'll push them again when I have the opportunity to test. Could you please give me some hints about the migration (either here or in the Google Groups thread)? Thanks.
Looks good to me. If vehicle_report is now unused, that should be indicated in its docstring.
...probably with a todo to clarify why it's unused, and what should be done to make it useful again (e.g. re-implementing the same based on event-module?)
Is `@ToDo: Currently unused, requires deprecated irs module` good enough?
Well, just imagine you were new to this code base, had a requirement that would suggest using this function, and would find that docstring: would it help you to understand the purpose of the function, and what you can do in order to make use of it?

If that's a yes, then it's good enough.
Don't mean to be disrespectful, but I don't have to imagine. I *am* new to the codebase I and *have* the requirement (resp. my employer has the intention) to use pretty much every functionality which has been already written. I'm chewing through the codebase since mid-June and looking at the number of ticket in our internal system, I'm barely half-way there. So yes, pretty much *any* comment is good enough. Definitely better than no comment at all. :)  
And yes, I'm aware that this isn't how SE is intended to be used, but that's not a topic for discussion on GitHub.

Anyway, added the remark about reimplementation in event module.
Yup, that was exactly my point: from your perspective you can better judge what is "good enough" a comment, whilst I can only name the general requirement and make suggestions. Thus, if you deem your comment useful for others in the same situation as yours, then I'd rely on that.
Can I get a hint for one extra fix, please? In the *Fire Zone* creation form, there is a *Create Zone Type* popup link. It opens and loads the popup content as expected, but it doesn't assign `display: block` to the form element, so the form remains invisible. Which piece of magic handles this?
Why is the form hidden in the first place? It shouldn't be.
Apparently all `/create?format=popup` forms are implicitly hidden and then shown via JS. Or at least this is what I see from my observation.
You're right - I think it's a timing problem with S3.popup_loaded (in S3.js). Apparently it's called before the DOM of the popup is ready, so I' trying to fix that now.
Timing seems to be OK. Strangely enough, that form simply doesn't do anything on jQuery `show()` method.

These don't work:
```
$('#' + id).contents().find('#popup form').show()
$('#' + id).contents().find('#popup form').css('display', 'block')
// ^- This is pretty much what show() does internally
```

This works:
```
$('#' + id).contents().find('#popup form').attr('style', 'display: block')
```

I also find strange that *Fire Stations* is the only module where the problem exists.

//Edit: It actually exhibits the same behavior also when directly opened in new window. Even there the `$('#popup form').show()` doesn't work.
OK, found the reason. The form contains a textarea with `name="style"`. DOM unhelpfully overwrites the original `style` property of the form element, which is supposed to be a `CSSStyleDeclaration` object, with the textarea object. jQuery then tries to change the value of `this.style.display` which doesn't exist anymore. Now to find the easiest way out :)
Well,

this took me a while to grasp...although in hindsight it's plain obvious:

The name-attributes of input elements in a form set properties for the DOM Element. E.g. if you have an input with the name "example", then the form Element has a property ```form.example```.

So far, so good. And when you now have an input with the name "style", then that would obviously become form.style. 

But that overwrites the Element.style property of the form - which is just exactly the handle that is needed for JavaScript to set Element.style.display='block'.

And therefore, jQuery.show for the form will never succeed as long as there is a field "style" in that table.

It would of course work if, instead of having a global CSS ```#popup form {display:none}``` in widget.css, we would add a class "hide", and then remove that class in S3.popup_loaded. That'd be one way to fix it - although it would still leave the form's style inaccessible for JavaScript.

The other way to fix it is to avoid fields with the name "style" (and thereby inputs with name="style"). This is what I did for this case now, for one, because "mapstyle" is more self-explaining anyway, and for another, the field is currently unused.

However, there are other tables with fields "style" (s3db/gis.py), and those can not easily be changed in this way. Nor is it so striking obvious that you shouldn't use "style" as a field name or why.

So I think, this needs yet another round of tweaking to make it more robust - namely, to not hide/show the popup form, but rather the form container. That though requires it to be present in all templates, and in all templates equally, so I need to investigate that first.

Hence, for now, the fix:
https://github.com/nursix/eden/commit/a9c26309823b04f2fccb5845eecd0c3df5b9b510
(Note that it's not minified yet, since I'm looking to tweak further)
So...now I additionally changed it to initially hide the container DIV rather than the FORM, because DIVs don't have that vulnerability.
https://github.com/nursix/eden/commit/73fcee5c8c09250ed493c8210472c082d0a140cb#diff-8191c7ac5c7dc0f5704f2b8a3879305fL279
With that, the modals should now work even when there is a "style" field in the form - it would still break the form.style property, but not prevent the showing of the popup contents.

It's not the easiest change as touching widgets.css always requires to re-minify each and every theme. I already did a bunch, but I'm growing very tired now, so need to leave the rest for tomorrow to avoid mistakes.

Can you confirm whether that solves the problem?
Ah, you found the root cause before me - saw that only now! (sorry it's really late...)
I confirm that the *Fire Station* popup is now popping up correctly along with all the others :) Nice job.  
The popup is missing a title however, but I know ho to fix that one, so let's first merge your changes and I'll rebase mine afterwards.
Rebased and squashed.
Devin requested an RSS feed but didn't specify what it is going to be.
The actual function at fault is this:
https://github.com/sahana/eden/blob/master/modules/s3db/org.py#L5504

Correct is, however, that custom_lookup_rows must return exactly one row per site_id - it is not allowed to have multiple result rows (=multiple representations) per site_id.

And yet, that one row should contain all facility type IDs for that site_id, not just the first one.

Best option is to
- not left-join the facility type at all, but
- run a secondary query for the type links, then collect the facility_type_ids per site_id
- use a the facility_type_id representation function to bulk-represent the facility_type_ids
- add the list of facility_type_ids to each site row, so that represent_row can pick it up
- represent_row  then renders a comma-separated type name list in the brackets

This would also be more efficient than the double-join.

This seems like an easy fix, do you want to go for it?
My initial idea was to add a `GROUP_CONCAT()` to the SQL query, but I have no idea if that's even within realm of possibilities. The database object model (and by extension whole Web2py's pyDAL) is one of the few things where I'm still completely lost, as it doesn't resemble anything I've worked with so far (which was mostly C# and PHP... plus, I'm primarily a sysadmin, not a programmer :) ), so if you don't mind, until I have at least a notion about this whole abstraction thing, I'd rather not push any PR where DB relations come into play yet. 
Okay, no problem. I can fix it - and optimize it along the way. Give me an hour.
You could try this:
https://github.com/nursix/eden/commit/282f45b186298c891e0ac9658111b4e9064895f8

Let me know if it works.
Works like a charm. Thanks.
And to answer your doubt about GROUP_CONCAT - you're right, this is rather remote. 

GROUP_CONCAT is pretty much a MySQL invention. There are similar functions in a few other SQL implementations - but no defined standard, and so we would need a different solution for each DBMS that supports something of that kind plus a Python-side alternative for those which don't.

That would certainly be /possible/, but not very smart from a code maintenance perspective - and given that the Python-side alternative is needed anyway, we can settle for just that.

Updated and squashed.  
The PR now also resolves conflicts introduced for vehicle imports in *ARC* template (Actually, most of them were magically resolved by themselves simply by removing the old stuff).  
The *represents* line referenced in the question above is no longer needed, as the field doesn't exist anymore and the `supply_item`-provided type is represented nicely by default.
Thanks for doing this, however whilst it's true that Vehicles are a specialised type of Asset, and hence a Supply Item, the Supply Item Categories don't contain all the specialised details that Vehicle Types do, nor would I expect them to do so.
I have pushed a fix sufficient for the old demo ARC template: https://github.com/sahana/eden/commit/dddcd0c3005362a76dc83ffc4d7247c0445bf4e4
The point of this PR was to fix the vehicle modules relations. The need for modification of ARC template was just a side effect triggered by that change. The original problem mentioned in the [Google groups thread](https://groups.google.com/forum/#!topic/sahana-eden/yQzpvlTIPNU) still remains unresolved.

Just to reiterate:
Currently, the *Vehicle Types* menu link leads to `/eden/vehicle/vehicle_type`, however when I'm creating a new vehicle record manually, the options I'm given in the *Vehicle Type* dropdown and the *Create Vehicle Type* link are using `/eden/vehicle/item` instead. This was the *duplicit and slightly confusing* part I mentioned above.

> Supply Item Categories don't contain all the specialised details that Vehicle Types do

I don't think so. That's why you have `supply_item_category.is_vehicle` flag in supply/assets. When an item is in category which has this flag set, the specialized details you're talking about are shown on a separate *Vehicle Details* tab in asset detail. 

It seems that you've decided to migrate the vehicles to assets completely in the past and this PR was just to clean up the remaining skeleton in the closet.
Updated to work with nursix/eden@c972e9c. This whole S3 thingy seems neat, but there is too much going on in the background so for people unacquainted with the code, it seems like witchcraft. Little by little, example by example it's getting clearer . Is there any documentation for all these `S3Whatever` classes other than docstrings?
Some: http://eden.sahanafoundation.org/wiki/S3
However, examples in core modules (pr, org, gis, hrm, dvr) are a better source.

S3 represents the generic standard functionality of Sahana Eden, and it is meant to reduce efforts for implementing that standard functionality for new models (RAD).

Beyond the S3* programming interfaces lies the more complex stuff that use-case development should be able to treat as black box, ignoring how exactly things happen, so that you can focus on getting the models and UI work flows right.

When you do things the S3 way, you can almost always expect that to fulfill our standard functional requirements without needing to be aware of every detail about those requirements - let alone having to implement them again and again.

S3Represent, in particular, is one of the examples where our standard requirements are complex enough to make it nearly impossible to implement new models quickly, especially when you are new to the code base. 

Therefore, using S3Represent saves you a lot of headaches ;)
Btw, the core principle of S3 is introspection - and that is what makes it sometimes hard to figure out why things happen the way they do: S3 function calls seem to lack many parameters, so seemingly you have little control.

Awareness of the introspective principle helps, though: those "missing" or "hidden" parameters are, in the vast majority of cases, either 
- taken from configuration settings (s3db.configure or deployment_settings), or
- derived directly from the data model, or
- looked up from the global request object (i.e. the HTTP request context)

And there's where you can influence the behavior.

To some extent, you can sometimes override parameter sources (or defaults) at function call - but the general idea is indeed that S3 shall find the right parameters itself.

Admittedly, that can lead to confusion if you are unaware of those parameter sources - but once you are acquainted with those, it will quickly loose it's "witchcraft" appearance ;)
This also drops the 4x pipeline - which I think should be restored.
Simpler fix where just the proper `GET` variables are extracted and the pipeline is retained, however after first 4 pages, the `limit` variable is set to double the amount of items per page, effectively making it 8x pipeline. Not sure why.
Well - why :) because you tell it to :P

...the ```limit = 4*display_length``` should obviously be behind an ```if representation != "aadata"```.

By the way - this pagination beyond 40 is really a non-feature ;) 

People who need to go that far to find an organization typically switch to Search after the second or at most third page, so retrieving 40 upfront will effectively prevent org box pagination from ever being used.

That's why you are the first to find it broken - after it's been out there for several years :D real-world user behavior.
Not sure why would the retrieval of 2x the amount of record in single request be obvious.

Moreover, if the default limit is 10, in `if representation != "aadata"` it'll be always 40 and will work only on the first page load, when the data are loaded as html. As soon as you start filtering, the responses will be already be represented via aadata, which results in "standard" two-page response even for the first page. I don't really see the point of having 4x the amount in that one particular case (other than that "*~~640 K~~ 40 records ought to be enough for anybody*").
Well, that's simply to cover the majority of cases without any additional requests.

The point is that in most deployments, the average user can see fewer than 40 organizations - so the initial request can fetch them all. That's by far the majority of cases.

When a user really can manage more than 40 organizations (rare case), then the org box is only useful when they can find the org they want on the first 3-4 pages. If not, then the org box is fairly useless for them anyway - and most deployments (all, actually) that have too many organizations, disable the org box anyway or at most replace it by a search-only feature.

Therefore, fetching all (=up to 40) organizations in the initial page request covers the majority of cases without requiring another pagination request, and that is why that 4x pipeline was there and should remain there.
Remember that the org box is intended as a shortcut.

If you need to browse through many pages, or use the Search-feature to find a particular org, then that's actually no longer a shortcut, and then you are better off navigating to org/organisation right away.

And that's exactly how it happens in most actual deployments - few orgs=>org box for faster navigation, many orgs=>org/organisation as first stop.

Although I understand what you're saying and also understand that the PR resolves pettiness rather than an actual issue, I still think that if the feature is there and is considered default, it should work without any defects, even such which are triggered by edge cases.

My confusion in the implementation stems from inconsistency. *Obvious* would be:  
"Load *n* records in initial request, display *n* records, load *n* records in subsequent requests (one request per page)"

Less obvious but still pretty consistent would be:  
"Load *n×k* records in initial request, display *n* records, load *n×k* records in subsequent requests"

However current behaviour was not obvious as there was again some implicit logic involved (aka *witchcraft*)  
"Load *n×k* records in initial request, display *n* records, load *n×k**×2*** records in subsequent requests"

Since you made clear that those 40 records should be loaded right of the bat, then the solution can be simplified either as this (less `if`s):

```python
    display_start = int(get_vars.start) if get_vars.start else 0
    if get_vars.limit:
        display_length = int(get_vars.limit)
        limit = display_length
    else:
        display_length = 10
        limit = 4 * display_length
```

Or as this (less lines):
```python
    display_start = int(get_vars.start) if get_vars.start else 0
    display_length = int(get_vars.limit) if get_vars.limit else 10
    lengts = int(get_vars.limit) if get_vars.limit else 4 * display_length
```

(Or the [current fix](https://github.com/sahana/eden/pull/1402/commits/9dc74ccc31bed44ca8941bab75e78144b0bf485b) (ab)using `else` branch can remain)

Which one would you prefer?
Neither. My point was:

The original version loaded 40 records (4 x default page size) in the initial page request. The idea with that was that this number eliminates the need for any subsequent requests in the majority of use-cases.

The issue you found was that the pagination requests were reading the wrong parameters. You fixed that perfectly, but you also removed that initial loading of 4 pages - apparently as an unintended side effect of your fix.

So I asked you to restore that initial 4-page loading, as it is obviously orthogonal to the problem you intended to fix. There is no need for you to change it, so - don't.

That is in no way pettiness. The person who originally implemented the initial 4-page pipeline had convinced me of the good reasons behind it, so I'm defending it while you have no obvious need to remove it.
I got your point. The last question was purely about the best practices used in codebase as all 3 methods achieve the same result (restoring the initial 4 pages), only the code look a little bit different.

Current method may not be obvious at first glance when the `limit = display_length` is 10 lines above the  `else` branch, but it gets the work done, so I'll leave it.

(And by the "pettiness" I meant the pagination issue which I came to originally fix - as you said, it's nothing groundbreaking or hugely beneficial. More or less just a cosmetic issue.)
Nah,

I didn't see your fixing of the regression problem in the pagination request (which came about due to the datatables 9=>10 migration) as "pettiness". It is absolutely so that this mistake should be corrected - although the real reason may not be as obvious.

It is indeed so that the pagination beyond 4 pages of orgs is an edge-case - but that only applies to /this/ particular box. This box was though originally invented as a pattern, i.e. its primary purpose (and that of the fac-box too) is to illustrate how such boxes can be implemented - and for the users, how they would look+feel like.

So, think RAD: A deployment could need "My Requests", "My Tasks" or "My Projects" - so what you (or say: the average Sahana developer) would do is to take this default homepage controller, copy+paste it into modules/templates/XYZ/controllers.py, and tweak this function to deliver the resource(s) they need.

And then, it absolutely matters that things are correct with default/index - so your fix isn't pettiness or cosmetic at all, but indeed preventing the proliferation of a regression issue.

Pettiness, though, is my role here ;) - I'm the reviewer.
After some more tests it seems that the current 140 char limit in code can cope with longer messages fairly well, so let's revisit that once it's really needed.

Instead, I have reworked the code around TwitterSearch to support version 1.0 and newer. Works the same, but uses mostly PEP-8 compliant function and property names. The other solution would be to limit the requirements to
```
TwitterSearch>=0.78.4,<1.0
```
but since the changes in code are minor, I figured it would be better not to introduce unnecessary legacy dependencies but to update instead.
Thankyou :)
That is correct - req interprets the type in the req context, and asset in the asset context. Both have type and status, so naturally that will collide.

IMHO neither model should make assumptions here, since both can be called cross-module. Ideally, req should look for reqtype/reqstatus and asset should look for assigntype/assignstatus or something like that. However, such a change would require quite a number of use-case migrations.

An alternative could be to check for the context (controller/function) to see if the type/status applies for asset or req - that would be a simpler fix, but it would also be less robust.
Actually, it's rather a bad thing to have model defaults or onaccept functions look for GET vars at all. They can be called from everywhere (including non-interactive, e.g. sync), and nothing that says that the current request context is addressed at them.

So maybe you can find a way to eliminate the GET vars here completely?
If that's supposed to be a prompt for brainstorming, then:

Option 1) Call URLs like `/eden/asset/asset/1/log/assignperson` instead of `/asset/asset/1/log/create?status=2&type=person` and have that `assignperson` method call `asset_log_prep()` with the extra parameters which are now in GET (status, type). Or have separate `prep()` and `onaccept()` until the end.

Option 2) Don't parametrize the form using variables at all and have a unified one, then decide in onaccept() based on the form data.

Option 3) Same as 2 and additionally have the fields shown/hidden using JS, which can get the data from fragment in the same manner as the GET does. (ie. `/asset/asset/1/log/create#status=2&type=person`

No idea if any of those qualify for an elegant solution.

Also note that it's probably not a good idea to have a [variable called `type`](https://github.com/sahana/eden/blob/master/modules/s3db/asset.py#L1041) as `type()` is a python builtin function.
It was a prompt for brainstorming ;)

I like option (1) best - and it doesn't even need any GET vars. Because:

When you call the asset/asset controller like ```/asset/asset/1/log/assignperson```, then the ```asset_log_prep``` can see that from ```r.method``` and thus decide the defaults for ```status``` and ```type``` itself (there is only one status/type combination for that method).

Then, after configuring the defaults for the fields, ```asset_log_prep``` can re-route the request to create by setting ```r.method``` (we've done that in other places, too).

And yes, naming variables like built-in functions is discouraged - we're routinely cleaning up those where they cross our paths, so probably a good thing for you to get into that habit too.

OK, I'm done with the first part in `asset_log_prep()`. As you've suggested I'm checking `r.method`, setting appropriate variables, then rerouting to `r.method = "create"`. Everything is nice and green and I see the proper forms.

Now, how can I get the values propagated also to `asset_log_onaccept()`? I don't see `r` in its context and  even though the form_vars provide distinct sets, I don't think building the logic around which fields get passed back is wise. Is there simple any way how can I get either `r` or smuggle some hidden fields into the form which won't affect the actual user input?
The standard way would be current.response.s3 - but I don't think that's necessary.

Both type and status are in the record - so they can be looked up from there.
Nope, the type is completely arbitrary and it's not stored anywhere. However `r = S3Request("asset", "asset", request)` seems to do the trick to get the proper `r.method` back, so I'll try with that one and you can give me some more pointers when I submit the PR.
Oh, you shouldn't try to re-instate the S3Request - that will trigger a lot of unnecessary processing.

Then better pass the method via current.response.s3.asset_log_method (i.e. set it in asset_log_prep, and inspect it in asset_log_onaccept).
Another option could be to decorate ```asset_log_onaccept``` and configure it in the ```asset_log_prep```, passing the method as parameter via the decorator. That would make more obvious /where/ you pass the parameter to.
I think this works well eliminating the vulnerability caused by GET vars inspection far away from the controller, and prettifying further goes beyond the problem at hand.

Passing parameters from the controller to the onaccept via response.s3 is fragile (still better than inspecting GET vars in the onaccept, though), and requires proper documentation, which you have done.

What's really wrong here is that the entity type of the assignment can't be inferred from the asset log record, which is a glaring weakness of the data model. So, any further improvement should try to solve that, so that the onaccept can inspect the record instead of requiring a hint from the controller.

Aliasing/overriding URL methods, on the other hand, is absolutely a valid pattern - we're using that elsewhere (e.g. deploy), it is allowed and intended in the framework.
...and when I say "glaring weakness" then I mean it: 

There is no way to reconstruct the current or any historic status of the asset from the log - because you always need the "type" (explicit or implicit) from the request that created the log entry, which is lost as soon as the call is over.

That's quite a concept flaw if you ask me - what kind of a "log" is that if you can't reconstruct the current/historic statuses from the trail of log entries?

So if you really wanted to fix it, then you should add the entity type to the log record - and then make the onaccept inspect the log trail to determine status and location of the asset.
Imagine the situation where the assignment happens in an offline instance, and then you sync two or three log entries to the master - how can you determine the current assignment type?

Or, how can the log answer the question to what or whom the asset was assigned at time X somewhere in the past (and I mean: that's the whole point with a log, isn't it?).

One option could be to assign via super-entities (=key tables), i.e. pe_id and site_id. Then, we apply the simple yet intuitive logic that when no site_id is set, the asset is to be tracked with with the person entity identified by the pe_id (organisation, person, team via pe_id) - otherwise it is located at the site specified by site_id.
Debug code removed, comments slightly adjusted to be a bit more clear (there's no point of mentioning GET variables if the reader doesn't know the history behind it)

> So if you really wanted to fix it, then you should add the entity type to the log record - and then make the onaccept inspect the log trail to determine status and location of the asset.

That's kinda is what I was thinking by [option 2](https://github.com/sahana/eden/issues/1405#issuecomment-335022906) - ie. not to explicitly *require* any of the values by data model based on which method was used, but instead use generic form and check which fields did the user filled in. If they filled in person, then assign to person, if they filled in site, then assign to site etc. I imagine this may get more complicated when the user sets eg. an organization AND person who has nothing to do with the org, but it *should* still be fairly easy to catch in data model validation.

Anyway I think there's more history behind the assignments then it's visible from the code. E.g. the disabled `ASSET_LOG_RETURN`, so ultimately, some deeper modifications may be in order. But that's stage 2. Stage 1 is to make the things work without errors so we can see what they were supposed to do. And once they do, we can ~~break them again~~ improve them.
Sure Sure - you were asking for suggestions how this could be made "prettier", so that is why I made suggestions.

Apart from that, I think this PR resolves the original issue - so stage 1 is good to go ;)
Thanks for this - some definite enhancements here :)
Please don't remove the ASSET_LOG_RETURN though & a suggestion for slight enhancement of docs.
That `ASSET_LOG_RETURN` comment has been just copied from [here](https://github.com/sahana/eden/blob/c1da768eb804d55cdc988512cadeeeb650b0ab98/modules/s3db/asset.py#L1143) as the functionality is anyway disabled there. I've disabled it even in the `elif` to not confuse the next person reading that code. The `status` is now set either via custom method or via the form and there are no circumstances under which it could be  `ASSET_LOG_RETURN` (unless there is again some witchcraft possible in imports or sync) . Anyway, I've uncommented it again, but It'll be just another piece of dead code.

Added the comment about `prep` in `onaccept`.
If modifying css.cfg should we not also rebuild all the minified CSS?
Otherwise looks fine :)
Actually, the minified CSS already has this CSS. Wondering was the path changed recently?
I don't think path changed, but you can check via GitHub history, anyway will merge if you're happy :)
this is working fine for me on my local machine. Also @flavour if I want to use a cascading template, how do I give the template name in the configure script? Now I do SAMBRO first and later manually include the cascade.
Not the right place for this query...do you mean Installation script?
Don't know, would need to look at the script to see how it works & potentially modify it
Sorry this was a mistake
