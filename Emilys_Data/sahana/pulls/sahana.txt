Nah - certainly not resource.name. Perhaps like: record[str(resource._id)] ?

Why is this hash[i-1][j-1] + 1 ? I thought that it should be hash[i][j-1] + 1

So if you have no match then this will return the first option. Is that correct?

would this work with just if j!=0: ?
Also would the meaning be clearer with a
if j==0:
  hash[i][j] = 1
else:
 hash[i][j] = hash[i][j-1]+1;

I'm not convinced that this is the best solution. If feels over engineered, and on top of that I'm not convinced that the solution provided is correct. Did you have any unit tests which I could go over with your function?

This is the dynamic programming solution for longest common substring.

Please refer to this page - http://en.wikipedia.org/wiki/Longest_common_substring_problem#Pseudocode

This explains why it should be hash[i-1][j-1] + 1

Yes, say we have just one option and it has no match with el_value. 
In this case, the matched_len will be 0 and hence, the first(and only) option will get selected.

This is why I have initialised the max_len as -1

No, it could work with - 

if i==0 or j==0 :
    hash[i][j] = 1;
else:
    hash[i][j] = hash[i-1][j-1]+1;

Again, this is because of the DP of LCS.
Refer - http://en.wikipedia.org/wiki/Longest_common_substring_problem#Pseudocode

I don't have them right now. Please see my comments above. If you are still not convinced, then I will write some.

When i'th character of el_value is equal to the j'th character of text, we take the matched length of el_value[0 : i -1] and text[0 : j -1] which is equal to hash[i-1][j-1]  and add 1 to it. Hence, it is hash[i-1][j-1] + 1.

I hope this is clear

So if you don't have any match you're happy to just return the first option. In which case why not look for an exact match and if there is no exact match then return the first option. As I said before it looks to be an over engineered solution.

What I mean by no match is that not even a single character is common, say "abcd" and "efgh". In cases like these, it will return the first option.

So, if there is no match, it is guranteed that there is no exact match, it simply means that not even a single character is same. 
It is not over engineered, it simply returns that option in which the maximum length of characters match.

My point about over-engineered is that whilst your solution may be a good one for substring matches, is that what is required? If the problem is that you need an option to be selected from the drop-down and without an option then the tests fail. Then you have a number of solutions, for example you could use the following approach.
  1) Exact match
  2) if no match then compare strings trimming the longer string ensuring that both are of the same length before comparing
  3) if no match then return the first string
This may not be an appropriate solution but I'm sure that a simpler solution could be found. So what is the problem that you are trying to solve?

The problem that I am trying to solve is - 
Say there is a test which has an autocomplete field with data "International Federation of Red Cross and Red Crescent Societies".
This test runs successfully, it fills in "International Federation of Red Cross and Red Crescent Societies (IFRC)" in the field. 
Now, I wish to find the widget used in the form, say in the "default" template. Here, the organisation name is a dropdown. I want the same test to successfully run on both autocomplete and dropdown.

Note that I have given test data as "International Federation of Red Cross and Red Crescent Societies" and it "International Federation of Red Cross and Red Crescent Societies (IFRC)" is present in the dropdown option.

So, here the test will fail just because of missing (IFRC). 

Let len = length("International Federation of Red Cross and Red Crescent Societies")

This commit does the following - 
1. Looks for "International Federation of Red Cross and Red Crescent Societies". (Because this is the longest possible match - exact match - automatically handled by LCS)
2. Looks for "International Federation of Red Cross and Red Crescent Societie" and "nternational Federation of Red Cross and Red Crescent Societies" (because these are the substrings with length = len-1)
3. Looks for substrings with length = len - 2...
   ... so on.

It stops wherever it gets the best match. (In this case, at step 1).

It is assumed that the test data is written correctly and should match fully with the options field, but with moving development, if some minor changes are added, then the tests would not fail. Eg - This happens with tests with data "Lospalos Warehouse (Warehouse)". In some templates, (Warehouse) might not be present. Also, in SendItem test, "Blankets - Australian Red Cross" is used in the test data whereas "Blankets - 123457 - Australian Red Cross" is present in the options.

SendItem used to pass before, but as I said, with minor changes in the options, this has started to fail.

Okay thanks for the examples.

My suggestion that you look for matched using trimmed strings would find a
match of "International Federation of Red Cross and Red Crescent Societies"
with "International Federation of Red Cross and Red Crescent Societies
(IFRC)" the same for the warehouse example that you gave.

The last example is a little more problematic since the extra field has
been inserted in the middle of the string. First, how does the
find_max_match function do with this scenario? Well it will most likely
find goods donated by the "Australian Red Cross" but it will have
difficulty distinguishing between Blankets and Buckets which may have both
been donated by the Australian Red Cross. Maybe a better approach would be
to split the two strings are word boundaries and match all non trivial
strings (any word longer than length 1 so we don't match hyphens) Thus you
match the word set ["Blankets", "Australian", "Red", "Cross"] with ["
Blankets", "123457", "Australian", "Red", "Cross"] and get 4 exact word
matches which would be better than ["Buckets", "123458", "Australian", "Red",
"Cross"] which gives 3 exact word matches.

A strategy like this would be done in parts. If any part passes then the
result is returned. So any exact match would be done first on the whole
string if that passes no need to look for matches on trimmed strings, and
so on.

Graeme.

On 4 June 2013 17:34, Somay Jain notifications@github.com wrote:

> In modules/tests/web2unittest.py:
> 
> > -            for i in range(n):
> > -                for j in range(m):
> > -                    if el_value[i] == text[j]:
> > -                        if i!=0 and j!=0:
> > -                            hash[i][j] = hash[i-1][j-1] + 1;
> > -                        else:
> > -                            hash[i][j] = 1
> > -                        if matched_len < hash[i][j]:
> > -                            matched_len = hash[i][j]
> >   +
> > -            # Save the maximum matched option in matched_option.
> > -            # matched_len is the maximum matching length for the current option.
> > -            if matched_option == None or matched_len > max_len:
> > -                matched_option = option
> > -                max_len = matched_len
> >   +
> 
> The problem that I am trying to solve is -
> Say there is a test which has an autocomplete field with data
> "International Federation of Red Cross and Red Crescent Societies".
> This test runs successfully, it fills in "International Federation of Red
> Cross and Red Crescent Societies (IFRC)" in the field.
> Now, I wish to find the widget used in the form, say in the "default"
> template. Here, the organisation name is a dropdown. I want the same test
> to successfully run on both autocomplete and dropdown.
> 
> Note that I have given test data as "International Federation of Red Cross
> and Red Crescent Societies" and it "International Federation of Red Cross
> and Red Crescent Societies (IFRC)" is present in the dropdown option.
> 
> So, here the test will fail just because of missing (IFRC).
> 
> Let len = length("International Federation of Red Cross and Red Crescent
> Societies")
> 
> This commit does the following -
> 1. Looks for "International Federation of Red Cross and Red Crescent
>    Societies". (Because this is the longest possible match - exact match -
>    automatically handled by LCS)
> 2. Looks for "International Federation of Red Cross and Red Crescent
>    Societie" and "nternational Federation of Red Cross and Red Crescent
>    Societies" (because these are the substrings with length = len-1)
> 3. Looks for substrings with length = len - 2... ... so on.
> 
> It stops wherever it gets the best match. (In this case, at step 1).
> 
> It is assumed that the test data is written correctly and should match
> fully with the options field, but with moving development, if some minor
> changes are added, then the tests would not fail. Eg - This happens with
> tests with data "Lospalos Warehouse (Warehouse)". In some templates,
> (Warehouse) might not be present. Also, in SendItem test, "Blankets -
> Australian Red Cross" is used in the test data whereas "Blankets - 123457 -
> Australian Red Cross" is present in the options.
> 
> SendItem used to pass before, but as I said, with minor changes in the
> options, this has started to fail.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/498/files#r4519519
> .

Yes, this is a good approach too.

Or we can do a Longest Common Subsequence also, which is more refined than this approach.
Refer this - http://en.wikipedia.org/wiki/Longest_common_subsequence_problem

I think this is a better approach.

When comparing, it can jump some characters to find the max match. 

So, on comparing "Blankets - Australian Red Cross" and "Blankets - 123457 - Australian Red Cross", it will give the result as "Blankets - Australian Red Cross"

Also, "Blanket - Australian Red Cross" and "Blankets - 123457 - Australian Red Cross" will give "Blanket - Australian Red Cross". So, there is no strict word matches. It can match any SUBSEQUENCES of the given strings.

Also, "Buckets - Australian Red Cross" and "Blankets - 123457 - Australian Red Cross" would give "Bkets - Australian Red Cross" which is shorter than match of "Blankets - Australian Red Cross" and "Blankets - 123457 - Australian Red Cross".

This scores over in cases like - 
Test Data : "Blanket - Australian Red Cross"
Options : 
"Buckets - 123457 - Australian Red Cross"
"Blankets - 123457 - Australian Red Cross"

In this case, max substring matching is with "Blankets - 123457 - Australian Red Cross". So, this will correctly get selected.

The other cases will work as before.

Given the problem definition that you outlined I don't see any advantage in
using the Longest Common Subsequence to just splitting the string at word
boundaries. The advantage of the approach that I have suggested is that the
code is far simpler. However maybe you could ask Michael for his take on
this. Personally I'd rather have easier to understand algorithms which are
good enough rather than complex algorithms which can handle edge cases we
haven't thought of. In my opinion this is particularly true for this case
where a false positive Selenium test is a minor irritant, there would be
places for this approach I just don't believe that it is necessary in the
test suite.

On 4 June 2013 19:16, Somay Jain notifications@github.com wrote:

> In modules/tests/web2unittest.py:
> 
> > -            for i in range(n):
> > -                for j in range(m):
> > -                    if el_value[i] == text[j]:
> > -                        if i!=0 and j!=0:
> > -                            hash[i][j] = hash[i-1][j-1] + 1;
> > -                        else:
> > -                            hash[i][j] = 1
> > -                        if matched_len < hash[i][j]:
> > -                            matched_len = hash[i][j]
> >   +
> > -            # Save the maximum matched option in matched_option.
> > -            # matched_len is the maximum matching length for the current option.
> > -            if matched_option == None or matched_len > max_len:
> > -                matched_option = option
> > -                max_len = matched_len
> >   +
> 
> Yes, this is a good approach too.
> 
> Or we can do a Longest Common Subsequence also, which is more refined than
> this approach.
> Refer this -
> http://en.wikipedia.org/wiki/Longest_common_subsequence_problem
> 
> I think this is a better approach.
> 
> When comparing, it can jump some characters to find the max match.
> 
> So, on comparing "Blankets - Australian Red Cross" and "Blankets - 123457
> - Australian Red Cross", it will give the result as "Blankets - Australian
>   Red Cross"
> 
> Also, "Blanket - Australian Red Cross" and "Blankets - 123457 - Australian
> Red Cross" will give "Blanket - Australian Red Cross". So, there is no
> strict word matches. It can match any SUBSEQUENCES of the given strings.
> 
> Also, "Buckets - Australian Red Cross" and "Blankets - 123457 - Australian
> Red Cross" would give "Bkets - Australian Red Cross" which is shorter than
> match of "Blankets - Australian Red Cross" and "Blankets - 123457 -
> Australian Red Cross".
> 
> The other cases will work as before.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/498/files#r4520817
> .

I agree that the code for your approach is far simpler.

But, Longest Common Subsequence is not too difficult either. It is just a small DP, which can be implemented easily and handles all edge cases that I can think of now.

Also, the longest common subsequence might be of use in future. 

Right, let's ask Michael to review.

" Personally I'd rather have easier to understand algorithms which are good enough rather than complex algorithms which can handle edge cases we haven't thought of. "
+1
"But, Longest Common Subsequence is not too difficult either. "
It seems pretty difficult to me! Maybe it's time I went back to university! :)

I would suggest that we just trim the options strings to the length of the lookup string, and then look for a match. Does that make sense? Then we just have to make sure that the option in the test is the shorter string.

I wonder why this is relevant at all - sure, I understand that with this algorithm you can have option strings hardcoded in tests and the test still succeed even if the respective strings change in the system.

But why hardcode strings in tests in the first place?

Furthermore, you've now spent a hell of a thread on an algorithm that has thousands of examples and discussions all over the internet - i.e. it seems neither a new problem nor a new solution here, so all you need to do is to check whether you copied it correctly, and then move on to the real problem - i.e. do the tests now actually work reliably across templates?

My first thought was though that this is "just" a test helper function, and the idea was to _simplify_ those, not to complicate them even further - it must be obvious what it does, it must be easy to find and resolve bugs in these test helper functions - otherwise they are definitely not suitable a means to help us to detect and diagnose bugs in our production code.

Right now, the problem is that the test framework is too complicated, nested with too many levels of helpers and helper-helpers, no consistent pattern and difficult-to-understand code.

Are you sure this here is a good idea?
Dominic

"the problem is that the test framework is too complicated, nested with too many levels of helpers and helper-helpers, no consistent pattern and difficult-to-understand code"
Somay - take note of this.
1) Where possible avoid complexity
2) You need to put some more effort into the overall design (I was expecting this by the end of yesterday). If you start with a good design you end up with consistent patterns which are easy to follow. If not you end up with a bits and pieces stuck together which are hard for others to follow.

"so all you need to do is to check whether you copied it correctly, and then move on to the real problem - i.e. do the tests now actually work reliably across templates?"
Yes, I had tested that it ran reliably. Using this, SendItem, SendReceiveItem which were failing before would not fail. Also, the automatic option in the suite will also work more reliably, since we would not worry about slight changes in the options text across templates. Sure, I know that this algorithm is slightly difficult to understand.

I see that breaking the strings into individual words and matching all non trivial strings (any word longer than length 1 so we don't match hyphens) is much easier to understand, so I should change the LCS algorithm to this algorithm.

Is that fine?

What about:
"I would suggest that we just trim the options strings to the length of the lookup string, and then look for a match. Does that make sense? Then we just have to make sure that the option in the test is the shorter string."
What's wrong with this approach?

This would not work in cases like which is the current situation in SendItem - 

Test/Lookup Data : "Blankets - Australian Red Cross"
Options :
"Buckets - 123457 - Australian Red Cross"
"Blankets - 123457 - Australian Red Cross"

Here, the extra part of the string occurs in the middle of the string.

Does this actually occur? In this case I would recommend changing the represent

That can be done, but I fear that this is just a temporary solution, in future, if something is added to the middle of the string, then it would break again

There's a balance between ensuring that the test suite is robust and it's simple. I think this code makes it too complex. I don't think that we need to be afraid of setting rules (and documenting them) about how the tests can work

I just saw another case when the change has been made in the starting of the string.
In inv/create_category.py test, "Standard > Food" used in test data. Dropdown options include "Food" which ought to be selected. Hence, this test is failing. It used to work fine before, but there was some change in code which made the options change from "Standard > Food" to "Food".

Even if we set rules about how the tests can work, these minor changes will keep giving false negatives and we cannot take for granted that the minor changes in the options strings will always happen in the end.

Hence, given that the algorithm which Graeme suggested is not too complex, I think it fits more in this situation.

However, I am also fine with changing the test data. I just worry that this does not keep on happening and hence, we need to make it a bit more flexible.

On 5 June 2013 20:21, Somay Jain notifications@github.com wrote:

> Hence, given that the algorithm which Graeme suggested is not too complex,
> I think it fits more in this situation.
> 
> However, I am also fine with changing the test data. I just worry that
> this does not keep on happening and hence, we need to make it a bit more
> flexible.

I'm +1 to some simple processing to make the tests less fragile like this.
Sure we /can/ use introspection to determine what we should see, but this
is a lot more complex (although definitely right where we can)

F

Still -  the problem I see is that it makes it harder to understand which option is chosen and why, and if this picks the wrong option, then it will be very difficult to correct this behavior.

The idea of using LCS already indicates that the appearance of the representation string is actually irrelevant for the test (this is not what's being tested) - but the goal is to pick the right option. Thus, if you introspect the option value and then either select by value or lookup the actual representation and force an exact match, you're always on the safe side - whatever the represent method delivers.

And here we know the option field, we know the identity of the referenced record (e.g. the "name") resp. of the raw option - so looking up the value for the option is totally easy - and represent-safe. And easy to understand, too.

This solution seems to be a good compromise to move forward with.

@graeme-f : I have updated the code to what you suggested, please review

It looks okay, I would change some of the comments. It's no longer
substrings but words that you are comparing so it would be better to change
the comments to reflect that.

On 11 June 2013 15:46, Somay Jain notifications@github.com wrote:

> In modules/tests/web2unittest.py:
> 
> > @@ -364,28 +364,29 @@ def create(self,
> >                      except NoSuchElementException:
> >                          el = browser.find_element_by_id(el_id)
> >                          raw_value = False
> > -                        for option in el.find_elements_by_tag_name("option"):
> > -                            if option.text == el_value:
> > -                                option.click()
> > -                                raw_value = option.get_attribute("value")
> > -                                try:
> > -                                    raw_value = int(raw_value)
> > -                                except:
> > -                                    pass
> > -                                break
> > -                        options_list = el.find_elements_by_tag_name("option")
> > -                        # Find the Longest Common Substring that matches with el_value
> > -                        option = self.find_max_match(options_list, el_value)
> 
> @graeme-f https://github.com/graeme-f : I have updated the code to what
> you suggested, please review
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/498/files#r4629550
> .

I have changed the comments

@flavour : Good to merge?

Fran, please review - I have removed the try/except block.

Sorry should have caught this before.  The plural of index is "indices".

You're changing this to have explicit keyword args, right?

Doublequotes. ;-)

Good fallback!

Doublequotes.
Maybe better substitute space for control chars, as control chars are word separators, and removing them may concatenate adjacent words.  E.g.:

```
data = "".join(c if ord(c) >= 32 else " " for c in data)
```

What about calling this "indexing_done" or "has_been_indexed" or something like that, that indicates it's been indexed? Can this be a boolean field with True / False values?

Same here re. explicit keywords.

As above, could this be something like "indexing_done" or "has_been_indexed", and boolean rather than integer?

"Has Been Indexed" maybe?

Just the dict, passed as vars.

Just the dict, passed as vars.

Do they need to specify the Solr URL here too?

@ptressel I have set the default url in the deployment setting, if you want me to add here the same, then i could. ??

We should have just a single setting: get_base_solr_url
False for disabled or the URL for the server.

There should be no need for a 2nd setting since this once setting covers both needs...

Might be better to say None than False. But usually the commented-out settings here are examples. E.g. you might have something like:
#setting.base.solr_url = "http://example.com/solr/"

I am checking for self.post_vars and "wf_id" in self.get_vars here-
Because redirection will happen when some action is performed by the user i.e a form is submitted or there is some post vars and "wf_id" in the get vars.
Using self.vars will initiate a redirection loop.

Just for now I am storing this in sessions and You won't see this in the next review.
I have plans to store Json serialised data database only.

skill() and group() will only work when we are trying to create and when there is format=popup in the arguments of the URL, i.e when it is from the inline form

-- [2] is sample data, the output ids of documents 

@nursix : I plan to update it once the csv and xsl are ready and we are able to pre populate the database with some sample files.

@flavour : Updated

better thanks, although I don't see why the interim variable 'settings' is defined only to be used once...?

Not for unit tests, no. Please create fake data, and remove them afterwards.

@flavour : Done, any other thing. and for the unit test i will ad the csv and xsl when they are ready. The will update them.

Why is this part commented?

Ah - I forgot: you would need to add it to the document index :/ so not really possible to create temporary test data.

Ok, but then I need a prepop with some test data.

PEP8? :D

@nursix It was just to check when solr is not available then i will return false. I am going to change it, as at first i will check if solr is running, if not it will return false, else it will return expected..

@nursix : Yeah, That is why i need to create a csv/xsl . I dont know how to make xsl. So will have to look into other .xsl and then copy them. So will upload the csv/xsl and around 4-5 sample files(pdf, rtf, text, etc) in this commit too.

@nursix : but till then u can test it by uploading 2-3 files manually and check them, till then will create try to prepare the prepops

@nursix will correct it

@nursix  : like this

Whoops, testing artifact. it should be else 10 (not else 1)

RDBMS will raise an error if you use LIKE with a non-char field type.

Question is whether you need to catch this or not - please just think about it, don't fix anything in this regard yet.

This is still not equivalent!

The ~.name sub-query is executable even if Solr is not available, i.e. it can be True. And since this is an OR, the whole query would become True for all records which match it, so can not assume False for the whole query.

And whether you can assume False for the ~.document.file sub-query is yet another question. In principle, you don't know - i.e. if Solr is not available, then there is no equivalent query and hence the transformation should give None and not False. That again would be True for all records (i.e. all records match no query).

This one is correct - fully equivalent.

Why is it different from the other unavailable-case??

Same here: false is not equivalent.

Where are these rows created?

This should not rely on a specific prepop - and especially not on a particular order of records!

Make sure you create the respective records _right here_ within this test case, and remove them afterwards (rollback).

This is a general recommendation for unit tests - define a setUp() or setUpClass() function which creates the records (you can even import files and Solr-index them here - you don't need to call any onaccept or something, just hardcode all necessary steps to create the data), and a tearDown()/tearDownClass() function to remove them afterwards.

For quick drafting up of unit tests, prepop data are ok - but eventually all data you're testing against should be created by the unit test itself. 

if l is None: return r
elif r is None: return l
elif l is None and r is None: return None
else: return l & r

=> fulltext() should never return False. It should either return an S3ResourceQuery or None.

Should not return False as that is not an S3ResourceQuery, yet methods like query() or joins() or split() expect it to be.

If you're using record ids, you can do:
if len(filename) < 1: return l == None

Err...why so complicated?

query_transform = l.belongs(filename)

Yet easier - you can actually just remove this check, and return the l.belongs(filename) with an empty list.

Totally ok - it will always fail, but is a valid resource query.

I have the feeling that "filename" isn't quite the right variable name here, is it?

@nursix  We are returning False from fulltext() function and we also need it, when solr is disabled or unavailable in those cases.
If suppose i return None in fulltext() function when solr is unavailabe - then  for this ((S3FieldSelector("~.name").text("test")) | (S3FieldSelector("~.document.file").text("test")) 
the query will whole become None
But the expected output we would want is : (project_project.name like "_test_")
So, I had kept the above condition.

@nursix  We had discussed it before also, and yeah i know for unit tests its better to create the data. But here we want files to be added. So its better to use pre populated data here.

@nursix fixed the rest.

You can add files from the unit test as well, I don't see the problem. And no - it is better to do this in the unit test andnot rely on prepop data.

Hmm, no - that's how you implemented it, not how it needs to be.

fulltext() should never return False, nor should transform (but that's what it does).

@nursix  Okay, I thought about it. I think we dont need to catch this. Because thinking about it, user is not going to use fields like id,etc which will have integers

@nursix So If the fulltext() returns None and then transforms() return None, then the whole query will become None, Do you want that ?

Really not? We have a problem here: how would the user know?

@nursix  User know what ?? 
And yeah i will close this pull request and send a new to you later tonight

@nursix Can we have an IRC chat now, if you are free for some time ?

No, see how I outlined it above.

You need to adapt both functions, transform and fulltext - so that transform _never_ returns False. It must return either an S3ResourceQuery or None, and so should fulltext() - can't you see that False breaks it?

@nursix  Okay, got it, I would then need to make some changes in unit tests also then.

Certainly, we can have an IRC chat - let me just finish my breakfast.

@nursix I removed False wherever it was and tested it. Working both ways when Solr available and unavailable.
Okay, take your time, I will be there on IRC. 

Spelling

This is duplicated in default/widgets.css, so no need to repeat here?

Has a performance hit

Has a performance hit

auth_\* tables always loaded - using db.xx is a little faster

Why groupby?

I guess this is currently left-in deliberately?

Undocumented & unused?

PEP8 spacing

Very confusing logic!
Can we have the positive match first?
if series == "Event" and "newsfeed" not in current.request.args:

Although personally I prefer a separate render controller as this is more robust & performant 

Incase a users is given admin twice. A bit of a precaution - could be removed

Kinda - now gone - not critical if this goes on server though

distinct = True is what you're after?

Switched logic - separate rendered would be too much repetition or too much refactoring

Correct - could you update  - getting to late for another rebase :(

The username and password will need to be taken from the config file. You will need to set these configurations up in (I suspect) models/000_config.py. If these settings don't exist then don't try and upload to pootle.

Do we want to hardcode this here or have a configuration setting? A configuration setting would allow an instance to use their own pootle url, rather than the ssf one.

Variables should be lowercase so url not Url

See my comment earlier about having the url as a configuration setting. The setting might just be, "http://pootle.sahanafoundation.org". Now eden is that the template? If so it might be necessary to have that configurable.

X - lowercase please

Are variable names of X and z the most self-explanatory names you could come up with ;)

oh look another variable called z, is this the same as the last one? (maybe "zip" would be better)

file rather than X ?

file rather than C ?

or possibly have a csv_file and temp_file variables

+1
We need a pair of config options (or a single tuple) in modules/s3cfg.py & read those here.
The settings should be in 000_config & not the template as these are personal, not template 

+1
Another setting in modules/s3cfg.py set in <template>/config.py if needing to override (as this is likely to be a template setting).
This should default to the SSF pootle, so no need for user to specify normally.

Default to the ssf pootle url (not False), then use get_base_pootle_url() in the code to get the URL. This way only systems that are going to use a different pootle URL: need to set up the details in the config file.

Probably better to use settings.i18n.### rather than settings.base.###

How easy is it to replace this system call with a function call by adding the relevant code from the toolkit into trunk?

L10n actually (I made this error above)

Yes, that's more appropriate.

Ahm - actually summary config is per resource (settings is the fallback):

s3db.configure("org_organisation", summary=...)

It isn't really good to use indices here - as that relies on the specific order of something in a different place. The sections have names, so they should probably be selected by names:

s3db.configure("org_organisation", summary = [s for s in settings.ui.summary if ...])

You know what I mean? This retains the original order, yet doesn't depend on it.

Yep - makes perfect sense. Thanks for the guidance - much appreciated. I've made the changes to the code - I'll push a new commit. I'll wait a bit first incase there are any other changes to be made...

What does s3.filter =True do?
I've never seen that construction...I think it would be better to just not set s3.filter in this case?

Sure, I'll change it and push again. 
Thanks

Sorry, but that doesn't make much sense.

We have a function (s3_has_role) that accepts UUIDs, but even better is to use the system roles IDs from session. A DB lookup is neither necessary here nor is it desirable to spread out Auth table queries.

@nursix i changed it and sent a new pull request https://github.com/flavour/eden/pull/638

;-)  Still says Course...

We already have things called reports, and report isn't very specific. Maybe call this bug?

The bug won't always be new -- people are going to review it and comment on it and set its status, etc., after it is created. The second part of the table name tells what the "resource" is, not what the action is, so this could be bug as well, i.e. the table name would be bug_bug. The CRUD operations are specified on the URL separately, e.g. if you change this to bug_bug, the URL for making a new one would be bug/bug/create.

These would be better in order, I think.

Should this select from a list? And can you move it next to priority so all the options are together?

Read through the comments on the original Trac ticket -- they discuss what options would be good for status.

It would also be good to have a short summary or title field above this. The summary line should be one line, but the description should be a larger text box -- look for comments and see how they're done.

And add a field for who is working on it -- maybe "assigned to".

Add a comment field down at the end -- look at other tables with comments. We have threaded comments available, so would be nice to use that. I'm not sure if that's the generic comment field or a special one -- can ask Fran.

Move this to modules/s3db -- that's where models go now. We need to change the book...

Look at other modules there to see how they define a class for the model that is a subclass of S3Model, and tables inside the class.

Add a descriptive comment at the top.

Move this file into modules/s3db -- let's see if that changes anything...

Although indents inside ( ) and other brackets don't matter, people still like things to line up.
I set my editor to convert any tabs to spaces -- see if your editor allows that.  That helps when multiple people are editing the file, and they have different settings for how many spaces a tab is worth -- if everyone uses only spaces, tab settings won't matter.

You already added the self.configure(tablename) to your local repository, so I'm just making a note of it here.

Look at one of the other controllers -- there are a few lines they all have at the top to complain if anyone tries to visit a disabled module.

Little tiny silly thing, but folks here have been using four spaces for indents, so it looks nice to make them the same.

PEP8

tsumani -> tsunami

tsumani -> tsunami
If this is in the current code spelled like this, then it may be misspelled elsewhere. If it's just in your new code, then we don't have to go hunting. ;-)

tsumani -> tsunami

tsumani -> tsunami

This isn't clever - pr_pentity_represent has a bulk option, but this reverts it to row-by-row representation even when pr_RoleRepresent is called in bulk.

Okay , So how would i also represent the pr_pentity table  also with the pr_role . ??

What's this supposed to be used for, anyway?

lördagen den 14 december 2013 05.34.21 skrev  Anurag Sharma:

> > -                      "entity_type",
> > -                      "sub_type"]
> > -            super(pr_RoleRepresent,
> > -                  self).**init**(lookup="pr_role",
> > -                                 key="pe_id",
> > -                                 fields=fields,
> > -                                 show_link=show_link,
> > -                                 translate=translate,
> > -                                 multiple=multiple )
> > -        def represent_row(self,row):
> > -            """
> > -                Represent a Row
> > -                @param: the Row
> > -            """
> > -            show_label = self.show_label
> > -            entity = current.s3db.pr_pentity_represent(row.pe_id)
> 
> Okay , So how would i also represent the pr_pentity table  also with the
> pr_role . ??
> 
> ---
> 
> Reply to this email directly or view it on GitHub:
> https://github.com/flavour/eden/pull/676/files#r8351732

The pr_role_represent function displays the entity table as well along with the pr_role , so I'm asking how would I do that in this class .
As the whole purpose of this class is to replace the old function of pr_role_represent . 

Why would you want to replace this function?

And where is this function relevant, i.e. which views?

I am asking for the purpose of the /change/ not the purpose of the function ;)

Well the purpose of the change  - http://www.google-melange.com/gci/task/view/google/gci2013/5859120699670528 . 

This doesn't explain the purpose of the change, but just suggests the change.

Why would we want to replace this function with a subclass of S3Represent? Who created this task - and what was the incentive?

For the creator and incentive of task , i think you should ask Fran . ,

I'm asking that because I'm not aware of any relevant use-case that would require the use of S3Represent here. Currently, these tables are completely automated - no user is looking at a list of role_ids at the moment. 

The only reason for this to be there at all was to be able to investigate issues with the functionality, i.e. as an easy means to identify objects from the CLI - and for that, pr_role_represent is absolutely good enough (as you always only look at a single row).

So I wonder: what has changed? Is there a new view that I am not aware of which displays multiple role_ids? Where? What is it being used for?

If there is not, I see this task of yours as an exercise, and for that it may be good enough as it is - but no need to merge it into trunk (it only complicated a simple case).

but still , how would i represent two tables together using the S3Represent class . 

I doubt that you need to ;) that's why I'm asking for the case.

Generally - if you want to nest two bulk representations, then you need to implement the bulk-method in the outer class. But this is going to become relatively complicated I'm afraid. I wouldn't make this effort unless you have a case.

But up to now, I can not see the case.

So what do you think i should do to replace the "pr_role_represent()" with this subclass ?, assuming  this task is an exercise .

Checkout pr_PersonEntityRepresent itself - it is a nested represent method itself: pr_pentity is a super-entity and hence needs to load the instance records in order to represent the pe_ids. It implements lookup_rows() in order to avoid unnecessary lookups.

But your pr_RoleRepresent calls it row-by-row, so this lookup_rows() function is always called with a single ID instead of all pe_ids.

To overcome this, you need to implement a lookup_rows method in pr_RoleRepresent which performs the pr_entity lookup for /all/ roles at once, and then remove the additional call to pr_pentity_represent in represent_row().

Apart from that: you're not dealing with just 2 tables here - since pr_pentity is a super-entity, you have to deal with >10 different tables here, so optimizing this requires some more insight. I wonder whether it is worth it - so I do need to understand the case.

Or let me put it more drastically:

The question is whether it is worth to guide you through this and develop a bulk-represent for role_ids - or whether to see it as an exercise and hence accept your solution as "task accomplished", but don't merge it into trunk as it unnecessarily complicates a simple case.

The problem is that this is a lot of effort - both from your side and from my side if I guide you through it - it could take days. But if we don't have a case, then this time is probably better spent on other tasks - with less grief and more points.

So, now - what is the case?

I am getting  confused about it so i have asked Fran , on the melange , and if can contact him so please do it . 

The function had no comment explaining that it didn't need to be made bulk. I proposed a task to make all represents bulk, so that included this one, No immediate usecase doesn't completely obviate the value in doing it just lowers the priority if this particular one.
If you have higher priority tasks, please propose them for GCI rather than simply denying the value of existing ones. I was asked to find tasks so I found some.

No, I'm not judging the value of the task here - but of the solution.

I'm wary of the complexity that is involved in this particular case - and whether the student will be able to accomplish it within the given time frame. For an exercise I think what the student provided here is good enough, but for a real improvement it is too little - yet asking the student to provide a comprehensive solution is probably overcharging him?

Just trying to be fair here.

I think it is better to leave further review and mentoring of this effort to you then, flavour. I don't want to be ranted at for trying to help.

This is how I meant it:
http://pastebin.ubuntu.com/6573926

I've put in some comments to explain the strategy, and hope this explains it a little. I'm happy to discuss this solution with you, but I'm afraid it would take longer than the 24 hours you have left to wrestle with this task, and yet your bravery to take this on should be rewarded.

Suggest you test this.

Please help me implement the link function of S3Represent in it . That's what Fran recommends .  

What he means is that the link() function is called from the renderer when you set linkto=True, and thus it should not be called separately from represent_row. 

Instead, you should implement a link function which takes (layer_id, represent, row=None) as input and returns a link - it would basically do the same as the "if showlink" branch.

Can't help you so much more than that - otherwise there's no point in having you just retype what I type.

the "if showlink " for this version or the previous version of my code . 

Hey Dominic updated the code .

On Tue, Dec 24, 2013 at 6:48 PM, Dominic König notifications@github.comwrote:

> In modules/s3db/gis.py:
> 
> > -                                                 show_link=show_link)
> >   +
> >   +
> > -        def represent_row(self,row):
> > -            """
> > -                Represent a Row
> > -                @param row: The Row
> > -            """
> >   +
> > -            instance_type = row.instance_type
> > -            instance_type_nice = s3db.gis_layer_entity.instance_type.represent(instance_type)
> > -            represent = "%s (%s)" % (row.name, instance_type_nice)
> > -            if show_link:
> > -                represent = self.link("layer_id",row.layer_id,row)
> >   +
> > -            return represent
> >   # =============================================================================
> 
> What he means is that the link() function is called from the renderer when
> you set linkto=True, and thus it should not be called separately from
> represent_row.
> 
> Instead, you should implement a link function which takes (layer_id,
> represent, row=None) as input and returns a link - it would basically do
> the same as the "if showlink" branch.
> 
> Can't help you so much more than that - otherwise there's no point in
> having you just retype what I type.
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/683/files#r8543101
> .

No need to create your own head section, you can just extend layout.html.

Please do not hard code the orgs. Pat also suggested to truncate the org list.

Why are you removing all this? It doesn't have anything to do with the bug. Also, do not hardcode links and forms

18px looks good, but then it will be like the same size as the headers like 'Latest Project'

This only changes the font of the date. To change it for all, add it to front-latest-desc, and front-latest-info.

You still need the font-family.

You have no semi-colon at the end of the statements. Also, you change them into id's instead of classes. There is also a space in the front-latest-info, and a line separating desc and info.

You have even 3 different instances of the class! Really better to have as few as possible.

I don't think this is sufficient - you won't get supply_item details by this.

no supply_item in row

NONE is not defined.

The string construction looks cumbersome - that can definitely be improved.

exp_date or expiry_date?

Somewhat superfluous to define a lambda here if it's used in just one place?

I have defined exp_date
On 26-Dec-2013 7:51 PM, "Dominic König" notifications@github.com wrote:

> In modules/s3db/inv.py:
> 
> > -        """
> > -            Represents a row
> > -            @param row: the row
> > -        """
> > -        s3_date_represent = lambda dt: \
> > -            S3DateTime.date_represent(dt, utc=True)
> > -        ctn = row.item_source_no
> > -        org = current.s3db.org_organisation_represent(row.owner_org_id)
> > -        if row.expiry_date:
> > -            exp_date = "expires:%s" % \
> > -                s3_date_represent(row.expiry_date)
> > -        else:
> > -            exp_date = ""
> > -        bin = row.bin
> > -        rep_strings = [str for str in [row.supply_item.name,
> > -                                       exp_date,
> 
> exp_date or expiry_date?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/690/files#r8555996
> .

Why expose a fresh instance to the global scope instead of the one you already use?

I could not get this ? , the supply_item has no represent that is being used by this class , then how would I get the info in bulk.
And also how is this being used - record.supply_item.name #line 911

What should i do here ? 

Dominic I have done some changes in my code but i will be only be able to push the code after you explain me what should i do to get the supply_item.name info in bulk .

Dominic I have done some changes (https://github.com/flavour/eden/pull/690)
, but i still have doubts of supply items :(

On Thu, Dec 26, 2013 at 7:54 PM, Dominic König notifications@github.comwrote:

> In modules/s3db/inv.py:
> 
> > @@ -726,7 +726,7 @@ def model(self):
> >          # Pass names back to global scope (s3.*)
> >          #
> >          return dict(inv_item_id = inv_item_id,
> > -                    inv_item_represent = self.inv_item_represent,
> > -                    inv_item_represent = inv_ItemRepresent(),
> 
> Why expose a fresh instance to the global scope instead of the one you
> already use?
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/690/files#r8556015
> .

I think there is no reason for this change here - but you've got to test it for yourself, of course.

You don't mean this seriously, do you? It was in the original function, so why would you not know how to do it?

It is really important that you test your code and confirm that it works before submitting a pull request. If you just want to discuss a design or draft implementation, please do so on the mailing list or in our IRC channel, and use pastebin tools or story branches in your own repo to share your code.

Pull requests are not to share your code in order to get advice, but to request it to be merged into trunk. All these conversations are difficult to reference or access later, there is no comprehensive archive, nor a search function - where as our mailing list provides both.

This sets l10n_languages twice -- you only need the first one, don't you?

Add a blank line above.

Add a blank line above.

If there's no material change between the old and new default lists, we would typically leave the old one alone, even if there is some issue with whitespace or misspelled comments or other "cosmetic" problem. If the old lines are shorter than 80 chars, then we should switch back to the old ones to avoid an unnecessary diff in the pull request. If the old lines are > 80 chars, then this is probably an ok time to fix that. Checking...only Brazilian Portuguese extends past 80 chars, so that criterion is somewhat ambivalent.

You should only call check_python_libraries once. You can assign the return value into a list.

You don't need to loop through assigning the values into the two lists, errors and warnings. It should be possible to assign them directly into the lists. If that means that you need to adjust (slightly) how check_python_libraries() returns the value then do so here and then adjust how edenStart works. This change should impact eden as minimally as possible.

But in the end there are two different lists (error , warnings) into which the values need to go , so how would i call it once. 

removed the loops .

Look to see what is being returned, one variable, a dictionary. So you don't need two calls. With care you can construct the code so that you do the function call and assignment into the two lists in a single call. This is a fairly common python technique so see if you can find a solution to doing this in a single step on the web.

Test the code. I think that this should run each time that you restart web2py. It will then display on the command line any missing libraries. Check what you are returning.

graeme-f , i think it is working well , but i did not get any error message as i had all the mandatory libraries installed

this behavior is the same as before , i used to start Eden . 

I'd rather that the return was (errors, warnings) rather than a dictionary since you are putting it directly into two lists. That will then be much clearer when others come across this code.

Still not sufficient. This function does not "check for all python libraries" - please find a better description, and ideally also describe the return value (see my comments in https://github.com/Anurag-Ans/eden/commit/386538c1afed2cbef292d50ee65e76774517bc3f#commitcomment-4961376)

Maximum line length exceeded.

These widely-used shortcuts shouldn't be changed?

This should only be changed for rtl - not in general.

I'm not sure even then? May work sometimes, but I'm sure it'll screw up other things...

Shouldn't this use hrm_human_resource.job_title_id.represent as you have it for organisation_ids?

Could this please be moved out of the constructor into the widget-function? The filter widget constructors are intentionally kept to a minimum to avoid any unnecessary load during model loading.

It is possible to use the string field yet have an options list to select from. I don't think the additional field is needed.
A @todo would do here, though.

Meaning: filter = 0 will be treated like False? Else I see no difference between the two - and who would set it to 0?

Oversight? Why are they still here?

Shouldn't be CASCADE - I understand that you want link tables to be auto-deleted if the person record gets deleted, but in principle, we don't want person records to get deleted.

You can though override this in the s3db.pr_person_id() call - just make it s3db.pr_person_id(ondelete="CASCADE") there.

You made this change :)
https://github.com/oidualc/eden/commit/2fdb962c41173235f8e7accf9f3e73038c99dbca#diff-13b9b810990ca443f4e14e7de07952baR4694

True - but why did I? :D 

There must have been a problem with the previous formulation, which I can however not see at the moment. Let me look at the spec again.

Obviously this is indeed to invert the logic of filter=0. 

In the original version it meant "activate the filter if there is at least one option in the list", now it means "turn off the filter".

I'm not so sure I didn't make a mistake here - but ok, leave it as-is until it makes problems.

Anurag Sharma sent you an invitation

Twitter helps you stay connected with what's happening right now and with the people and organizations you care about.

```
Accept invitation
```

https://twitter.com/i/4b44f3d3-b68a-4a17-9a90-5df4da938a4c

## 

You can unsubscribe from receiving email notifications from Twitter at anytime. For general inquiries, please visit us at Twitter Support.
Unsubscribe: https://twitter.com/i/o?t=1&iid=92480d2907da44ad8f0b3261dec4d357&uid=0&c=rcl%2FV7ewzObMCnyzgY892rnjbhZ%2BgQ2yP6g4W%2FQq6RlXK6W3bSvp9%2BDAQZ3r%2BZ%2FICWOJrCGHRxa5N58ZRX1xNnB9l%2FACYpBkj7CEtTR7MSPU9MDqlF5kQg%3D%3D&nid=9+26

Need help?
https://support.twitter.com

Anurag Sharma sent you an invitation

Twitter helps you stay connected with what's happening right now and with the people and organizations you care about.

```
Accept invitation
```

https://twitter.com/i/39a889b9-c6ff-4989-9795-9bea74fa2513

## 

You can unsubscribe from receiving email notifications from Twitter at anytime. For general inquiries, please visit us at Twitter Support.
Unsubscribe: https://twitter.com/i/o?t=1&iid=fd141e6020ee478aab1f50310b5a46d3&uid=0&c=rcl%2FV7ewzOZAEf89NlChe8BOCJtH4mxojowQY9%2Fm3O0zia1zW5W8pUOXQ5fN6pf8GqU%2BgKN%2BMAgDpvpYDD5Vku434Q94aTA%2Faw4qQjLm1LXBMCkgSgeAdg%3D%3D&nid=9+26

Need help?
https://support.twitter.com

Anurag Sharma sent you an invitation

Twitter helps you stay connected with what's happening right now and with the people and organizations you care about.

```
Accept invitation
```

https://twitter.com/i/732645ba-8c44-405d-914a-5b5fb0f30ed0

## 

You can unsubscribe from receiving email notifications from Twitter at anytime. For general inquiries, please visit us at Twitter Support.
Unsubscribe: https://twitter.com/i/o?t=1&iid=226a3d91647f4ab58147ea27000dd491&uid=0&c=rcl%2FV7ewzOZ%2Ft8RA5NP0R3%2FPJNfw0YNB4ikInlVZgEFwV1PmYwcFOB6v859roFmBfKY0BSoZ9dsLauql2VuHIUL5PTp2ko%2FYCr%2Bz7UKPz3c5s%2FoP7ypfnA%3D%3D&nid=9+26

Need help?
https://support.twitter.com

Do you really think these are widely-useful in Trunk?
They're small, so OK, but real sites (& devs) will install the Polygons via Postpop so why bother adding these files here?

Try to avoid extra blank lines

Yes, exactly - we then have to add the names here which is confusing!
Are we going to have the UI translated into these languages?
I suspect not, so this doesn't make sense....I know that this template currently doesn't make use of these languages, but it's awkward & could bite us in future.
I see no need to include the Location data without-Polygons in trunk, the files are available for Postpop from the wiki & these will be required for any real sites & devs, so the duplication is unnecessary overheads...can we remove?

The data which has no Data is Modelled data which can occur at any time, right?
I think this is a useful meaning for the value date is None
I therefore think that we should move this into the base model....templates which don't use modelled data & hence wish the data to be mandatory should then override in their template (IFRC currently)

If the widget="date" as default in the model, then this should definitely be too.

But this would definitely not be a model default ;)
I think perhaps we may find value in separating Impact from other tags & this would be one such differentiator.
Others would be in linking Impacts to Needs, etc...really hard if some tags are Impacts & some are not...we'd want to start adding a tag for the tags ;) We /could/ use Comments for that but this is a poor man's version...I think Impact is sufficiently required an idea that it should be separated out.

Why is L0 not included here? This is a multi-country template...

magically fixed if Impact is a separate table...which I think should also be a stats_data instance...

;)

...

if value is a prop then we need it in Attributes

+1

As I said in email - I had issues importing Country polygons via the terminal (not browser - which was fine) without existing records for the countries. 

Yes - if you can ensure that the loc data with polygons can be imported without the initial imports...

Are you getting date and data mixed up?
There is no modelled(?) datA
Often the datA source doesn't have a datE - or the datE is a mess and I haven't bothered to format it.
-1 to giving a special meaning to datE = None

I can see the logic here - but there should have been opportunity to discuss this before it was actioned.

Gotcha - poor copy paste on my behalf

Currently this will be sufficient - no need for logging of time/location. Could this be a link field to the log table? I would want to avoid having to tackle an inline location widget.

Changing to a bigger title in the body: 
![screen shot 2014-04-29 at 5 24 20 pm](https://cloud.githubusercontent.com/assets/1373438/2825947/bffcd1fc-cf60-11e3-838f-7ec9be4dbcdd.png)
Can move supporting CSS into bootstrap sytle - but all this is going to be redone shortly anyway
What other templates are task cards used in?

Nowhere else yet...Sunflower shortly I'd guess

I'm presuming that this will all be re-write with the new FW for HTML card layouts soon anyway

Pointless variable?

We have also agreed on "create" instead of "add".

Okay i will change those.

On Sun, May 25, 2014 at 2:17 PM, Dominic König notifications@github.comwrote:

> In modules/s3db/budget.py:
> 
> > @@ -1072,7 +1098,20 @@ def model(self):
> >                             ),
> >                       *s3_meta_fields())
> > -        # @todo: CRUD Strings
> > -        # CRUD Strings
> > -        ADD_BUDGET_BUNDLE = T("Add Budget Bundle")
> 
> Pointless variable?
> 
> We have also agreed on "create" instead of "add".
> 
> —
> Reply to this email directly or view it on GitHubhttps://github.com/flavour/eden/pull/773/files#r13029875
> .

 nursix added a note on May 7
These don't yet make sense to me - if you just want to customize the label, then you should make a deployment setting for that instead (the fields themselves have no unit).

I deleted all measurement configurations previously introduced. these were really useless requirement asked us. 

 nursix added a note on May 7
no point without module prefix - must be cr_notification_dispatcher if it shall be accessed from outside this model.

I added prefix

 nursix added a note Wednesday at 12:43pm
Yet a classic case to DRY?

I think this method is logically similar to event_notification_dispatcher but it should be defined because it refers to specific database fields 

 nursix added a note on May 7
Important to get this ToDo done before trunk merge.

I added other types to EVASS template. I  made it a configuration parameter.

New configuration settings

Fields "available_capacity_day", "available_capacity_night", "population_night","population_day" and "population" (Field already available in Eden previous versions) refer to the same thing. Field "population" define the shelter population in a static way, others define it in a dynamic way. Probably using them together doesn't make sense....

I left the previous behavior as default. I customized the EVASS config file with a customise_cr_shelter_resource method to  activate dynamic fields.

Note that there is a lot of hardcoding in the application around these numbers, especially 3 (Relief Team) - changing these is a recipe for trouble

There shouldn't be spaces around assignment operator in arguments.

You may want to remove these whitespaces.

A newline here.

Yes - we prefer spaces around keyword assignments.

No newline needed at the end of the file - XML parsing works from character stream.

Oh, then it's ok.

Got that.

Move into separate view template and include?

+1

That's a lot of CSS to include routinely even if chat is off

A newline here?

A space after `,` according to PEP8.
`"chat_enabled",False` -> `"chat_enabled", False`

That's not really smarter than before - the stylesheet is fairly big, and if linked like this it's not even getting minified.

Couldn't it be made conditional? So that at least if chat is disabled it doesn't get downloaded unnecessarily? Maybe it's asking too much at this stage - but if it's included unconditionally, then it should be in the minify-config.

I suggested moving this into the conditionally-included View template.
It can be made to load after page load into HEAD using JS (like is done for Ext's CSS)

& yes, we should have debug & minified versions of the CSS

comment should include that the positive isn't True but rather the IP of the XMPP server

I will look into how to do it like EXT's and rebase it :)

Would be better to have this in static (so it's minified, cached & not server-side processed)

will do it :)

I would minify this with the main converse.js

This seems an odd way to pass the config. Instead I would suggest having it put into S3 global
So the view template would have:
s3.js_global.append('''S3.chat_url={{{settings.get_chat_server()}}}'''
& the static would have:
bosh_service_url: S3.chat_url

& therefore the name of the setting & API call should change:
settings.base.chat_server
settings.get_chat_server()

Arnav and I are chatting -- we think we're getting closer.  Arnav is just trying this:
{{s3.js_global.append(”'S3.chat_url=http://%s/http-bind”' % settings.get_chat_server())}}

You don't use request, or appname so little point in declaring them
Likewise chat_server is only referenced once so it would be better to do away with that variable.
Similarly with s3, it's only used once.

Is this still needed, it looks like a testing leftover?

The other way around would be more adequate, wouldn't it?

i.e. leave it as opt_in_to_mail and fix be typo in the line below

Yes, but it is used once again down in the code. So, I thought that typo would have been only once ;)
However, I would change and rebase 

Go ahead and take this all the way out. ;-)

Priority isn't in the spec, so probably will not receive it.  It's an Eden addition, computed from other fields, so it's redundant to specify it separately.  Better to comment this out or remove it.

I'm wondering if it would be better to call this field "chatname" rather then "username". Unless you are planning to use the field for something else this name would make it clearer as to what it is being used for.

You should move your code after this line. The check on user_id is important for your code.

You don't need to have the two assignments into intermediate variables. You could get away with a single statement.

I'd prefer to generally use 2 blanks to separate keywords, rather than table-style alignment.

New login for every case makes suites slow - one login per run should be enough.

Ideally this would check per test whether already logged in, and skip the keyword in that case.

This should check whether already logged in, and only login if not otherwise skip. One logout after the end of all tests in this run (tearDown), or otherwise if explicitly requested by the test. Repeated logins make testing very slow, and don't add any value.

Check for success? (i.e. confirmation message)

Check whether logged in, otherwise skip?

Sure. :)

Will add it.

I can check if 'logout' or 'default/user/logout' is present in the page to see if the user is logged in or not. Is it good or there is a better way?

@nursix 
Different templates have different registration mechanisms. Some send a verification email, some register directly. Is there any way I can check for success across them?

I'm sure there is.

Depending on the template registration might require - 
Admin approval
Email verification

How do I incorporate them in the keyword? I can do something like `wait till the keyword succeed`  but that would make the keyword dependent on some user action.

My general advise is: stick with the case!

IMHO the story is "new user self-registers at the site". Not: "new user confirms his email address", nor "new user gets approved". So, what is required for the /user/ to successfully self-register, in any of those cases? 

As far as I know, the story goes:
- user enters user data
- user submits the registration form
- user gets redirected to the home page
- user sees a confirmation message

...where the confirmation message may differ between the three cases. 

The deployment settings may extend this story with:
- user can /not/ login until he has confirmed his email address (if email confirmation is required)
- user can /not/ login until his account has been approved

You could login as Admin afterwards and check whether the new user appears in the respective list and whether his registration is pending, because that's also an extension of that story:
- admin can see a list of pending registations

Approving a new user is a different story and hence a different test - and a different user (perspective). But possible: surely you can login as admin and approve a new user to test that? And then again login as the user to see whether you can login after approval? But not before approval! This is again part of the story:
- user can login after approval (if approval is required)
- user can login after email confirmation (if email confirmation required, and no approval required)

Similar, you could test email confirmation as a separate case, although that may be harder as you'd need to intercept the confirmation request (or fake one, which may be easier). But opening the URL in the confirmation email to see whether it succeeds makes for a nice test case.

So - stick with the case! Make sure you test the /requirements/ - and for that make clear the requirements to yourself. Try to tell the story as it really is.

Don't make the same stupid mistakes as in the old test suite.

1. Changed the name of login functions
2. Changed the assertion criteria

Should Show Confirmation with a variable argument - message in the confirmation 

I find this double-negation very cryptic - surely there's a better way to do that?

Removed the cryptic double negation
@nursix: Please review

The ToDo suggested a deployment_setting to require uniqueness, not just the validator. 

Bootstrap-specific change in core?

Huh? Safer? Seems less safe to me to have DELETE closer to Submit than above the form!

Happy to revert if others agree

Technically FontAwesome specific stuff - which we kinda already have (although "plus" is way more generic than "folder-open-o") We do have aliases for icons already - but those are in the DRMP font - and I have no idea to change this. I agree with introducing an ICON widget to render icons as discussed would be a good solution - but this would require a fair bit of work (these icons get rendered in JS) - so I'm hoping that this can be implemented later

I agree with Dominic that Delete next to Submit seems very dangerous & hence undesirable.

ICON class doesn't change the HTML rendering in any way, it just centralises the class names to make it easier to move between frameworks/versions. +1 to this approach. Introducing it is very low effort. Migrating all existing instances will take longer but does't need to be done all at once.

Storage isn't used here?

That happens automatically, no?

Why import s3forms, but then S3SQLInlineComponent separately? Either, or.

Consider using S3SQLInlineLink instead of making the link table a component!

Better use S3SQLInlineLink than making the link table a component!

Same here - better use S3SQLInlineLink than making the link table a component.

No need to remove the label when using S3SQLInlineLink

Be careful not to overuse "deployment" as variable name - as we do have a "deploy" module where this has a completely different meaning. I'd stick with "project".

Interesting choice for Sunflower. Isn't that a bit beyond scope for a community management tool?

Or even with InlineComponent: better there to use fields = [("", "theme_id")] since otherwise you tend to find knock-on problems elsewhere & need to surround statements by lots of 'if method' which becomes nightmarish to maintain

Wow - that makes it really complex :S Wonder who's going to maintain all those data.

Which Classification of regions/sub-regions are we planning to use?
(Every org has their own way of cutting this up...)
I'm surprised that SSF thinks it needs to split regions into a hierarchy as we're rather a small org ;)

Oh, I forgot to remove that. Included it when trying out some stuff

I was not too sure of what mode_3w meant. Some documentation would be good :)

Thanks for volunteering to write it :D

Right, I think we would need only org branches (or not?). What are regions and region hierarchies for?

Umm. I still dont know what mode_3w means, I was asking for documentation, if there is any 

Use the source Luke

Use the source Luke

For the zones/regions of the world that organisations belong into. That is if we consider to map all orgs to e.g. continents, or sub-continent regions in order to filter by them.
The original purpose was to be able to send out alerts to a specific zone/region of the world without selecting a particular org (IFRC) - I don't see the point in Sunflower, though.

3W = who what where, that is if we want to track information on what which of our users (=organisations) are doing where. However, I thought Sunflower is a community management tool, so the focus would be who of the contributors does what. Do we really want to track 3W information on user organisations, and if yes - who's going to maintain that data? Do we at all have a mandate to track such information? (Doesn't seem right to me, to be honest - especially not if we don't continuously maintain those data on behalf of the user orgs). Too me, it's too much data. Too much complexity.

Just to make that clear: a "project" of a humanitarian org is related to certain hazards, so you can say "this organisation is doing something about this hazard at this location".

But what has that to do with Sunflower? Sunflower projects (="deployments" in the wider sense) are not about hazards, but about deploying a tool for a either project or an event.

Sunflower itself is a deployment - but what's the hazard? What's the location? The 3W theme?

It seems that by making this 3W, we're actually managing information about the user organisations and what they do - rather than about our community and what we do. Yet the latter was the actual purpose of Sunflower, wasn't it?

Very confusing.

I mean - we're not doing anything about the "risk of floods". But we give people a tool to manage information about organisations doing something about the "risk of floods".

So, the hazard of Sunflower deployments is always "lack of a proper tool to manage information", and the theme is always "Information Management". Why not hardcode it?

These aren't Sunflower deployments but Sahana deployments.
We /might/ wish to track the Event Type they've been deployed in response to...not high on my personal priority list but I'm OK about tracking it. (I'm not sure what use it would get put to beyond simply a 'report')
Likewise for themes, how many deployments are for 'DRR' vs 'Response' etc This has more relevance to the direction that we design the system for....although of course resources speak loudest. Paying people or motivating volunteers to do something will be what makes things happen... a vague 'x deployments (of what type? How large an impact, etc, etc) in sector x vs y deployments in sector y' /might/ provide a vague steer, but not significantly I don't think.....still at least there's the possibility of it being used beyond just a 'report'

But still, the "themes" for the deployment of a software are very different from the themes of humanitarian projects, aren't they? I mean, Sahana doesn't get used to improve sanitation, or to reduce child mortality...I see this rather limited to a subset (or even a specific set), otherwise it will be hard to analyse even that.

It is indeed about the "purpose of the deployment" rather than about the themes of the projects the user organisation is working with - or am I wrong?

Seeing what we are helping users with is certainly interesting - but most 3W data is about what users are helping others with, not what they use our software for. If they are using our software to manage volunteers, then the theme of the "Sahana deployment" can be pretty much everything they are engaged in, and yet not telling us what they use Sahana for in their work. A theme "volunteer management" plus a sector "disaster response" would be much more enlightening.

Hence...the "theme" should be the functionality they use (or the sort of user tasks they are doing with it), whilst the sector could describe the area of /their/ activity where they use the software.

This would give us a good basis for use-case statistics - i.e. see which "modules" (or sets of functionality) are being used by whom and where.

I would be interested in their use-cases yes: which modules & the way in which they're using them (preparedness vs response, long-term community building? Is this crowd sourcing? etc)
The 'what sector/themes are the users working in' is only useful for a 'report', not practical action & I am only after the practical bits. 

NB this would imply that we track which software they have deployed (Eden or Vesuvius), and potentially whether they are self-hosted or managed, have their own vendor team (e.g. AidIQ) or are based on SSF/community support, whether they use custom functionality (e.g. RGIMS), or a community template etc etc...

I still do not necessarily see the point in tracking this level of detail about the user org activities, while we rather need a basis for use-case statistics as you suggest?

No disagreement from me...I'm vaguely OK with capturing the stuff for 'Reports' but it seems rather a distraction as it's not actionable & I'd rather both users filling out these forms & the developers writing the software focussed on stuff which can actually provide meaningful results as opposed to mere 'reports'

Err - right. That's what I meant with "who's going to maintain all this information?". Starts with investigating it, entering it, reviewing and updating it, and correcting it if the respective organisation wants it changed.

I highly doubt that the user organisations would take responsibility for that - so it's on us, thus we should only do that /if/ it helps /us/ with what we do. 

Surely I can smell the "marketing" argument lurking around the corner? Fancy statistics are good for marketing, especially in picture-form. Remember the gizmodo chart?
http://gizmodo.com/5977989/internet-explorer-vs-murder-rate-will-be-your-favorite-chart-today

I'm sure we could do something similar. I'm also sure we most likely need to be more restrictive with what we spend our resources on. So I see a lot of dead data in the Sunflower database, unmaintained and unused.

Maybe we should abstain for now, and activate once we feel an urgent need to track this and a realistic maintenance process?

I checked just now. It does not happen automatically

If so, then you're (wrongly) working around the framework somewhere because CRUD does definitely hide the uplink.

I don't understand why you run CRUD on the link table anyway - project_task_project. Never should the user create a record in this table manually.

The form should be for project_task (not project_task_project) - and since project_task is a component, it will definitely auto-populate and hide the parent field, I am 120% certain it does because it does this in _every_ component form all across the place.

This here is definitely wrong - what are you trying to do?

When a user access the tasks under a project by going to project/project/[project_id]/task , the user can add a task under that project by clicking on the 'Create Task' button, given that the he/she has the permission. 

With projects enabled for tasks (settings.project.projects = True), if the user creates a task from within a project, a project field appears, which is not set to the current project. I wanted to make this field non writable and default to the current project.

So, obviously that's a bug in the project module then - the project field should not appear if in a component view.

Better to fix that issue than to work around it in your template.

Most likely that is an injected field - but it shouldn't be injected if we are in a component view.

Yup - this one: 
https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L4114
...should obviously not be added if we are in a component view. It's pointless anyway - in the component view, the links gets automatically created by CRUD, no need to have an additional inline-field for that.

Right. That shouldn't have been there. 
Thanks for pointing that out :)

I just pulled the latest code. Enabling projects in tasks and going to project/project/[project_id]/task is giving the following traceback - http://paste.ubuntu.com/7628001/

Commenting this line does not generate the traceback - https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L4110

Any idea what is happening here?

I'd need to investigate your code - it doesn't happen in trunk.

Can not reproduce that in trunk, sorry.

Nevermind, I will investigate 

Neither can I reproduce the issue with the "Project" field when creating a task under project/project/X/task/create.

I'm not sure whether you have all your sources right?

What database are you using?

So I did this - 
pulled the lastest code, and on the default template, did settings.project.mode_task = True and settings.project.projects = True.
I could then reproduce the bug on eden/project/project/1/task

I am using sqlite

Gotcha - that's a repeated join due to a filter query.

I can fix that - hang on.

Great :)

@nursix : Can we check whether we are in the component view here - https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L4114 ?

Simply removing it will remove the project field from a normal project/task/create form also.

Case is here: 
https://github.com/nursix/eden/commit/8660e4dcd673f3a13eec67a86c0f670b5ac3b344#diff-9bd6b33d7420bb7d9e0c2c7e2f2cd606R1785

...and fix is here:
https://github.com/nursix/eden/commit/8660e4dcd673f3a13eec67a86c0f670b5ac3b344#diff-66e8d33b478f010c26ff8902d41845a1R976

With settings.project.projects=False, this could not happen (since no join to project_project needed in that case).

Thanks for the nice test case!!

onsdagen den 11 juni 2014 04.20.12 skrev  Somay Jain:

> @nursix : Can we check whether we are in the component view here -
> https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L4114 ?
> 
> Simply removing it will remove the project field from a normal
> project/task/create form also.
> I /think/ that is a case to move into a function and then call it from prep() 
> in the respective controllers.

The challenge would be to find all relevant controllers - and their custom 
variants.

Dominic

No, you completely misunderstood this.

I said it is better to not add this field in the first place if it's not needed.

And if that can not be done for some reason (I don't see why it couldn't), then you should use a remover - which is a method of the object that you want to manipulate and not an external function! - to remove change the fields.

I don't think this is going to work - requires.other.set_filter may. Thou shalt test the code!

It is added in the modules. Is it needed only in the task controller? If so, I could add it only there.

Or, if it is needed at other places too (I can't think of them), then we should have a remover for it in the project controller, when the component is task. Now, I want to manipulate the crud_form, so is there is a remover implemented for crud form?

It does work, I wouldnt have pushed the code without testing. 
s3db.project_task_milestone.milestone_id.requires and s3db.project_task_activity.activity_id.requires are IS_ONE_OF objects. They do filter the activities and milestones.

As I said, a "remover" is a method of the object to be manipulated, i.e. it belongs into the S3SQLCustomForm class and not anywhere else. No manipulations on the internals of an object should be implemented anywhere outside of the object class (=encapsulation principle of OOP).

But it breaks as soon as there is an IS_EMPTY_OR, no?

yes, requires.set_filter would break when it is IS_EMPTY_OR
but requires.other.set_filter would break when it is just IS_ONE_OF (as it is now)

So, best would be to define the requires here, as it is done for others - https://github.com/flavour/eden/blob/master/controllers/project.py#L170

What do you think?

I get it now, i'll have a remove_element(self, selector) function in S3SQLCustomForm class which removes the element with the selector name given as argument and then call crud_form.remove_element("task_project") from the controller. Is this correct?

It is correct, but not the optimal solution. I've said several times now that the right solution would be to not add the form element in the first place rather than removing it afterwards.

If you say so. You could simply check for IS_EMPTY_OR, though - which is still less than instantiating a whole new requires. However, maybe just leave as you have it now (i.e. assuming that it is IS_ONE_OF): this is a link table, and IS_EMPTY_OR is de facto wrong.

However - what's this actually trying to achieve? Isn't it actually about the widget - that it only provides the options that are linked to the same project as the task. Are you aware that the widget can lookup this itself, i.e. that there is an option for the inline link to filter the options for exactly that - so you do not need to manipulate the validator at all?

In S3SQLInlineLink, for example, it's like 

filterby="activity_id:project_activity_project.project_id", 
match="task_id:project_task_project.project_id"

...which can generally be set, not just for this case. It's similar to the issue you have with S3OptionsFilter JS - if you would use the right widget, then you wouldn't have the problem ;)

And for not adding it, this should check whether you're in the project controller (request.function=="project") and then /not/ add it, instead of adding it when you detect that you are in the task controller.

I tried using the following for filtering activities - 
S3SQLInlineLink("activity",
                                         label = T("Activity"),
                                         field = "activity_id",
                                         multiple = False,
                                         filterby="activity_id:project_activity_project.project_id", 
                                         match="task_id:project_task_project.project_id"
                                         ))

However, it is not filtering, but showing all activities in the list. Because resource._rows in None here(https://github.com/flavour/eden/blob/master/modules/s3/s3forms.py#L3025), it does not filter anything.

Since the crud_form is initialised in the modules and we want to add an element in the controller, the correct way of doing it is having a adder method in S3SQLCustomForm, right? We would not want to manipulate the internals of crud_form outside it's class. Is this correct?

Do you expect you don't need to configure S3OptionsFilter JS just because you use S3SQLInlineLink? :D 
Nah - you still need the S3OptionsFilter JS here, I just said that S3SQLInlineLink supports it (in contrast to S3SQLInlineComponent).

And actually, resource._rows would not be None if you run an update - that's only for create. And in create, indeed, it should show all activities unless you select a project in which case S3OptionsFilter kicks in and filters the activity options.

If it is None during update, then you haven't configured it correctly. I've tested this with IFRC project form and it definitely works for that case.

Sorry, but now this is turning things completely upside down: the project inline-link is added in the project_task model, unconditionally though - while that should be made conditional.

I do absolutely not see the slightest reason why you keep trying to remove or add anything in any controller: just go to the task model, and make that widget conditional, i.e. add it only if current.request.function != "project". That's it, that's all you need.

No adder or remover or any other fancy stuff - just make this one conditional _where it gets first added_.

I am confused. There are 2 problems here - 
1. Not showing the project field from task component view and filtering activities, milestones for the current project for BOTH update and create forms. (To be done by validators/filterby)
2. When not in component view, showing the project field for task (creating, updating, etc). And filter the activities, milestones when the project is changed. (To be done by S3OptionsFilter JS)

The above comment was for Problem #1 here. If filterby cannot filter the activities, milestones on create, then I think it is best to use the validators as I did before.

For Problem #2, we would have to make S3OptionsFilter JS working with whichever widget we want to use.

+1 to this

So, to summarise, 
Problem 1 - 
- Not showing project field - making the widget conditional - (if current.request.function != "project")
- Filtering the activities, milestones for both create, update - (use validators)

Problem 2 - 
- Making S3OptionsFilter JS to work with S3SQLInlineLink and changing projects, activities, milestones to use this
  OR
- Fixing S3OptionsFilter JS to work with S3SQLInlineComponent

It's ok - I'll fix this. This thread takes more time than to do it myself :/

Yup - the whole S3OptionsFilter JS is crap from the top to the bottom. It makes assumptions, tries to be intelligent and doesn't really draw any logical conclusions. I need to rewrite this.
Meanwhile maybe you want to look into more critical things for your project than fancy GUI tricks?

Yes, I am working on setting the subscriptions for tasks, as done in the DRMP template. 
I suppose this wasn't a fancy GUI trick, S3OptionsFilter JS not working made activities, milestones not updatable, affecting the workflow. Anyhow, thanks for the help regarding this :)

I've rewritten the S3OptionsFilter JS so that this case works - but it's far from ready since there are so many other issues in this script. Since I'm going on holiday, it's unlikely that I can get it ready before the weekend - but Monday afternoon should be possible.

Interestingly, there are so many things broken in this script that one can wonder how this could go unnoticed for so long. It's just hacked together fix upon fix upon fix, things wildly duplicated, other things only half-implemented - a big jumble of thousand ideas with no meaningful structure or consistent functional design. It's half-working GUI glitz on the outside, and a hell of a spaghetti syndrome on the inside.

Your case in particular is broken because with current version, inline-component fields can only update the options of fields within the same inline-component, so the project inline-component can not update the activity inline-component. This is actually a known limitation of the S3OptionsFilter script (which I have overcome now), so it has never been working for your case. It just a "want" but no "can".

If you deactivate S3OptionsFilter there for now, then you can at least work with the form, even though it does not filter the activity/milestone options yet. This would buy me enough time to get this right, and I don't currently see any urgency on your side to get this working (though there is urgency in another case that uses the same script, so I can't really drop the ball here now).

The other issue I fixed yesterday, code is in trunk.

Sure, there is no hurry. I will deactivate S3OptionsFilter for now. Thanks :)

@flavour 
I can not ask for admin rights here as the action should be available inside EdenTest before the user logins. The restriction for everyone else except for Admin is checked in main.txt inside EdenTest.

I cannot allow a backdoor into the application to ask for potentially sensitive information unless it is protected for Admin-only.
This function is accessible from outside Edentest so needs securing independently

+1 - the function needs to require admin permissions.

You can use HTTPBasicAuth with the admin credentials (as mentioned in the meeting doc) to login when calling this function. No interactive login required.

i.e. when EdenTest calls get_settings, it must send an HTTP Authorization header with the admin credentials - and the get_settings function _must_ require admin permissions. 

The check for permissions inside EdenTest is not enough - and in fact not needed at all. EdenTest/get_deployment_settings must send admin credentials, and default/get_settings must check these credentials (and raise 403 if they are missing) and require admin permissions (and raise a 401 if not authorized).

Obviously, default/get_settings can logout immediately afterwards - no need for any separate request from EdenTest to do so.

Can I use the requests library to make the request?

Is this a serious question or a todo-note to yourself?

HTTP 404 is "not found", but an invalid or missing argument is a syntax error hence 400

Should always print to sys.stderr, i.e.

```
print >> sys.stderr, "Robot Framework is not installed"
```

Assigning current-references to a module variable is not thread-safe, must do this inside a callable.

Should always use new-style classes, i.e.

```
class Query(object)
```

Also, this is redefining a web2py class - so either rename or at least prefix (like "EdenTestQuery").

Don't see the point in this wrapper - better rename the former.

This doesn't use the self-reference, so could be staticmethod or at least classmethod.

Not using the self-reference, so make static?

Same here...

And here...

Wrong message

Calling a non-existent function?

Duplicating the exception! current.s3db[tablename] already raises this error, so the try/except is totally superfluous.

Err - why override the constructor?

Should be a new-style class.

It is defined in the Query class above.

S3Model object is not callable.

Well, obviously Assertion does not inherit from Query, so you can't do that. You must at least have an abstract interface method if you call it from inside - or you must check for hasattr(self, "row_count").

No, I mean the assignment to a local variable must happen inside a callable - not at the module level.

From the web2py book:

Beware! Given from gluon import current, it is correct to use current.request and any of the other thread local objects but one should never assign them to global variables in the module, such as in

request = current.request # WRONG! DANGER!

nor should one use current to assign class attributes:

class MyClass:
    request = current.request # WRONG! DANGER!

This is because the thread local object must be extracted at runtime. Global variables instead are defined only once when the model is imported for the first time.

You may end up with an error like:

AttributeError: 'thread._local' object has no attribute 's3db'

I created a function in s3db/cr (cr_check_population_availability() ). I need this part of code to show alerts about the housing units too. 
So i didnt want to duplicate code.

I really need help here.
During an evacuee registration we can register him in a shelter using the shelter registration tab.
We think It would be comfortable if we can enroll the evacuee  in a housing unit using the shelter registration tab.
At this time the housing unit drop-down field shows all the housing units defined in the related database table. 

In the shelter registration form we choose the shelter  where the evacuee is going to stay. I would like to choose the housing unit too but I would like to select it in a list containing just the housing units defined in the selected shelter.

Is it possible?

I am working on it. 
I need to select which organisation will take care of evacuues.

Do you think there is any problem?

Typically, we have the name of the organisation in the CSV, not the ID - and in the XSL create an otherwise empty organisation record (empty = no field except the name), then leave it to the importer to match that against any existing organisation.

You /can/ import organisation_id like that, but you should not. That is because organisation_id is a foreign key, and needs to be resolved against an existing organisation record - which is only supported in the reference element.

Please refer to other XSLT stylesheets how to import organisation references (e.g. https://github.com/flavour/eden/blob/master/static/formats/s3csv/org/facility.xsl): create an index, import all orgs with tuids, create reference-elements in the target records.

Consider making this a hierarchical taxonomy, see 
http://eden.sahanafoundation.org/wiki/S3/S3Hierarchy
http://eden.sahanafoundation.org/wiki/S3/S3HierarchyWidget

Example see org_facility_type in s3db/org.py (plus corresponding import in org_facility.xsl)

Consider using the new org_organisation.xsl, which can import any depth of hierarchy in a single file (using "Organisation", "Branch", "SubBranch", "SubSubBranch" etc. fields)

Please uncomment the docstring when activating this class.

Whitespace at the end of the line, should be removed.

Indent?

Whitespace?

Should generally only copy those options where you override the default - not copy the defaults (since they may change).

Whitespace?

Wrong title?

Unnecessary line break, should start behind the opening "("

Where is "os" used in this module? (can't find it)

db = current.db (defined above)

Consider selecting .sum() instead of looping over the rows.

Not nice for translators - especially in languages where the two nouns ("resources") have different genders.
Better to use individual warning messages (though the "Warning:" part can be the same).

Misleading variable names, better use "capacity_night" (CAP = common alerting protocol) and "population_night" (pop = remove last element, an iterable-method).

Misleading variable names, see below

Ouch!
It would be simply db(query_d).count() instead of len(db(query_d).select())

You can combine this into one query, using count() and groupby.

And if current.request.controller is neither "evr" nor "cr" (e.g. "sync")??
You should not use request.args or request.vars in onvalidation - that goes totally wrong during imports, and sync.

Consider making it a computed field if there's no manual update.

Consider making it a computed field if there's no manual update

Make this a computed field if there's no manual update?

Use of list:string is discouraged (very slow queries). Consider moving into a component with link-table.

I can simply delete this function editing the  cr_shelter_registration table but I need help.

In the cr_shelter_registration table I added a drop-down cr_housing_unit_id() field. At this time in the registration form this added field shows all housing units defined in all shelters (This is not really useful), can we show just the housing units defined in the shelter I want to register my evacuees in? 

The problem I met is (You have to consider I refer to the evacuees registration tab in the Evr module, so I have to specify both, shelter and housing unit where I am gong to register the evacuee): shelter_id() field and the housing_unit() field are on the same registration form so I can't filter the housing units because I don't know the chosen shelter_id yet!
Does it makes sense?

Is it possible to edit the shelter registration form adding the housing unit selection field after I specified the shelter? Resuming: step1) I select the shelter step2) the housing unit field appears and it contains only the housing units related to the chosen shelter
My idea is something similar than the "Verify Password" field in the user registration form, It appears after I inserted my password...
How to do this? Or any other idea to filter the housing units?

I modified it. I created a new database table (cr_shelter_environment) and a new simple import template (shelter_environment.csv and xls). Environmental characteristics will be prepopulated

Yes, it is possible to filter the options in a drop-down field by the selection made in another field, using a jQuery script called $.filterOptionsS3. It can be applied in the controller like:

```
# Filter shelter unit options by selected shelter
options = {"trigger": "shelter_id",
                 "target": "shelter_unit_id",
                 "lookupPrefix": "cr",
                 "lookupResource": "shelter_unit",
                 "optional": True,
                  }
s3.jquery_ready_append('''$.filterOptionsS3(%s)''' % json.dumps(options))
```

Note that this requires a "shelter_unit" function in controllers/cr.py that applies s3_rest_controller.

If you need to debug it, the script is defined in static/scripts/s3/S3.js

Ahm - and what it does is whenever the shelter_id field in the form gets changed, it looks up all shelter_units with the selected shelter_id and populates the drop-down for shelter_unit_id with the respective record IDs and names.

The script has recently been reworked and I'm somewhere in the middle of migrating the use-cases to it, so if anything doesn't work as expected, let me know.

Hmm, you may want to set optional=False - it seems you don't allow to not select a unit.

This is not the final CSV file. I don't know if the final version needs the hierarchical taxonomy. At this this time It's ok!

As soon as possible I will delete all useless options (I think next pull request). I am just glancing all available options 

I made a copy of cr_shelter fields!

(see my previous comment in the old commit) - I had this wrong, it's actually priorities here not keys, so you can put this in a meaningful order without disturbing existing databases.

That sort-of calls for a per-template sorting mechanism ;) which could basically just be a list in the deployment settings? Or maybe don't make a science of it and just put it in the right order?

Sorry again - hard to see this with only the diff.

Yes, I have put these in the correct order according to Sunflower, the other contact methods are not used. So, if not for the deployment settings, this order is okay.

Looks strange - why not just use r.component_name? Also, remember that component name and component alias can be different.

Looks even more strange since you don't seem to use the name but just check for whether this is a component request or not - which could just be "if r.component:"

Move this into the prep (return False if r.representation!="s3json"), so that a proper error is raised.

Extend this to:

```
if r.method != "options" or r.representation != "s3json":
```

so that both cases have a proper error response.

This lacks inline-attachments, which are very important for bug reports.

Makes no sense here. If this controller is called, task is the master resource - otherwise it's the project controller that is called.

Or read: your check should be:

 if r.resource.tablename != "project_task"

not checking for component_name == None.

Well, or just r.tablename

You don't seem to use "is_bug" anywhere else than in the next line - do you need this variable?

Instead of the extra is_\* variables, I would suggest a get_vars = r.get_vars at the top to not repeat the dict lookup.

And aren't these elif's rather than separate if's (I mean, they overwrite each other if multiple are true, so they could be exclusive and skip the subsequent checks if the first is already true)

Load the table only when you are certain that you need it? (move behind "if trimmed_task")

Looks right to me, but the commit message says it doesn't work for all cases?

Removed some trailing whitespaces in this file.

It's better to avoid formatting changes outside the code you're working on. If this wasn't deliberate, put the line back so there isn't a diff, which could cause merge conflicts for others.

Same re. format change.

Same re. format change.

Same re. format change.

Is this line in the wrong function's docstring?

Indent looks like it has changed -- check that it's 4 spaces in from the def.

Put the indent back -- Fran likes these indented.

Yup, I'm a stickler for consistency I'm afraid ;)

In general I like the whitespace cleanups, and if there are multiple blank lines then good to remove the redundant ones, but single blank lines are generally good to keep the readability

Recall Dominic said: "Always use self.request or r inside an S3Method, not current.request".  So, you have r already as an argument -- getting it out of self is actually extra time.

Recall Dominic said: "alert_url = r.url(method="", representation="rss")" (only with cap not rss).
(Verify that the method is ok.)
And if you do that you don't need to import re.

Fix indent -- Fran has been putting closing parends in the space after the opening parend, as this is what some editors do by default.

What case actually gets here? If this is an unsupported or unexpected channel, say that.

@ptressel : actually that is needed. I want to get the host as well and then need to add the alert_id before rss. So string formatting will be needed anyways.

What's an example of request_url, and what do you want to transform it into?  The underlying Web2py url formatting is pretty general.

@ptressel what dominic suggested gives me this:
    /eden/cap/alert.cap
what i want is this:
    http://127.0.0.1:8000/eden/cap/alert/2.cap

i need to insert "/alert_id" between "alert" and "cap" .
Also i want the server/host url to be inserted before "/eden/cap/alert/2.cap" like http://demo.sahanafoundation.org or whatever is the server url. That is why i went for that method.

Have a look at the arguments for S3Request.url():
https://github.com/flavour/eden/blob/master/modules/s3/s3rest.py#L1299
It should put in the server that's in the request (r) -- it will default everything from that, so override the parts you want to change.  id is the first argument.

That is well the easiest thing to expose the host-parameter in r.url (done).

The other part is not true:
If the request contains a record ID (e.g. /eden/cap/alert/2/publish) then r.url will retain that URL unless you set id=0. So, if you get /eden/cap/alert.cap, then you did have no record ID in the call - and your method didn't have one either.

In fact, your method handler doesn't check whether r.record != None - so I could call /eden/cap/alert/publish without record ID and it would publish all available alerts, i.e. without record ID (not that I think that this is wrong, just pointing out that there are cases where you do /not/ insert a record ID with the regex either).

The actual reason why I suggest using r.url is that r.method may not come from the current.request URL - it could just be set directly (r.method = "publish") in the prep, or the whole S3Request is handcrafted in a completely different controller/method handler, e.g. if it due to some other workflow indirectly produced a cap alert, and now wishes to chain the publishing workflow by calling your method handler directly.

"r" represents the request you're processing - and that /can/ be current.request, but it could also be handcrafted. Thus, you should avoid to tie things to current.request.

Line those up vertically?

Ambar removed current.request a couple iterations ago.  ;-)
He's getting the id from r.args, no?
If we want to allow "no id" to mean "publish all", then need to allow only the ones that are no longer drafts to be published...  In fact, do we need to check whether the state is draft, and hide the publish button in that case?

No, he did not ;) URL() is still getting the request data (e.g. controller/function) from current.request rather than r.

current.request and URL() are somewhat the same thing.

The publish method could filter for status!=draft, and yes: if you are not supposed to publish this alert, then there shouldn't be a publish-button.

> No, he did not ;) URL() is still getting the request data ... from current.request

Ah!  -and-  D'oh!  :D

I already tried that. Looks better horizontally

Heh.  No, I mean the indent isn't the same on all the lines -- the _class, _id, _value lines are one space more indented.  We've gradually been standardizing on indent to just within the enclosing bracket, like the export_btn above.

Check if this is added whitespace.

Yay!  URL gone!

No need for an OrderedDict here if you use OptionsWidget with sort=True in the form (instead of the SELECT).

Reason: the config.py should not need to provide an OrderedDict (it should not have to deal with Python too much), it is better to have the ordering of the options where it's needed and only there. That's faster and easier for non-coders.

In fact, I think this will become a MultiSelect instead of a simple drop-down so that an alert can be published to multiple channels in one go. And MultiSelect too has a sorting-option.

If you wouldn't hand-craft the form, but use SQLFORM.factory, then the widgets would be inferred from the validators ;) and validation would be included in the process. That way, you wouldn't need this case discrimination, and in fact (see previous comment) I think this isn't an if-else. It should be a MultiSelect allowing multiple channels to be selected simultaneously.

Really - why make the channels configurable, but then raise an error if it is not Pubsubhubbub? Either it's configurable and you serve all possible configurations - or it is not configurable and only pubsubhubbub.

Logging? Where can the user see whether publishing was successful?

Not true: "Publishing scheduled" is what you did. 
Success is not being checked here - nor is it actually logged so that the user could see that.
This needs improvement.

I'm still missing authorization rules here. Does "being able to read the alert" also mean "being permitted to publish the alert"? I don't think so.

This broker list is temporary -- the next step is to come up with a real way to organize brokers.  (Preview:  There are several issues:  a) In a multi-tenant site, each org may have its own list of brokers.  b) Pubsub brokers are gateways -- the "real" way to use them is to have a routing table that says, for each subscriber (recipient in the alert's recipient list), which gateway to hand the message off to.  We don't have a scheme for doing that yet.  And we might decide that's the wrong model -- that this isn't really pubsub, but rather (say) we send to brokers based on properties of the alert itself (e.g. language, type of incident,...).)  However, we could add the multiselect now, if we think we're going to need it anyway.  If the brokers end up in a table, we could populate it from the table instead.

I would think that brokers should be pubsubhubub channels

This is a string. It will give an error when you run it. Please test the code. Use a real comment. Strings as docstrings are a special case.

@ptressel I'll use a normal comment but this doesn't give any error. I have run and tested the code. It is getting published and properly logged.

Generally, .deleted != True or .deleted == False, not == 'F'

But will cleanup after merge.

No idea why this would need eval()?

Why not:

```
table = s3db.table(statement)
count = db(table.deleted != True).count()
```

? Any particular reason?

Shorter version is:

```
table = s3db[statement]
```

I think this does not need eval()

:+1: 

The defaults don't look correct.
port: 7070
server_db: openfire (surely not sahana?)

Same with the defaults for port and server_db here.

yeah. Because by default on the chat server the port used is 7070 for bosh and the database here needed is the openfire database, so not sahana.

port 5432 for postgresql

Every test case should have an assertion. There is no assertion here.

I don't know what L4 is, but if it is a setting in 000_config.py, you can check for it using the edentest library keyword like

```
${settings}=  Get Deployment Settings  l4
${l4}=  Get From Dictionary  ${settings}  l4
```

It is not in the trunk yet but should be when [PR#823](https://github.com/flavour/eden/pull/823) is merged.

This test is still being worked on which is why it didn't have any assert. I'd also like to add checks that the data has been properly added to the database, is this available yet, or is that beyond the scope of this GSoC project?

DB inspection should be available by next week! :) 

Is this a yet to be completed test case?

Any specific reason for using catenate without a separator? If I am not wrong this should work in the same manner.

```
${query}=  Set Variable  select count(*) from survey_section where survey_section.template_id ='${TEMPLATE ID}';
```

No it's a test I use to test my keywords. I feel that I need that because some of them cannot be tested until the code has been added to Eden and I'm still learning how to build the keywords and test cases.

No no. I meant the keyword `List Survey Templates`. It lacks an assertion. 

Having a keyword like `Test Keyword` seems like a very good idea to me.

BTW `Get Deployment Settings` is in trunk now. 

That is used to set up the global variable ${TEMPLATE COUNT} which is used in other tests. I guess that it could be merged with another test but I prefer to keep it separate. 

This makes the different test cases dependent on each other, I think (thus not following the -I- aspect). I would rather put it in the `Suite Setup`.

I didn't want a separator, this is what the two give. I believe for an id, being an integer, either would work but I'd prefer to have no spaces:

select count(_) from survey_section where survey_section.template_id ='1';
select count(_) from survey_section where survey_section.template_id =' 1 ';

Okay but you asked me to remove the Suite Setup ;)

Am I able to create one for this suite and also call the default one or will the default Suite Setup instructions have to be duplicated? 

My point was about using the `Catenate` keyword instead of `Set Variable` keyword. Instead of using `Catenate` without any special delimiter wouldn't simple `Set Keyword` be better? 

Here is my tests code:

```
${query}=  Catenate  SEPARATOR=  select count(*) from survey_section where survey_section.template_id ='  ${TEMPLATE ID}  ';
Log to console  ${query}  
${query}=  Set Variable  select count(*) from survey_section where survey_section.template_id =' ${TEMPLATE ID} ';
Log to console  ${query}  
```

Here is the output:
select count(_) from survey_section where survey_section.template_id ='1';
select count(_) from survey_section where survey_section.template_id =' 1 ';

See the output is different and I don't want those spaces either side of the single quote.

There is no need to put an additional space between single quotes and a RF variable like `' ${TEMPLATE ID} '`. This should work as well `'${TEMPLATE ID}'` and this will not put additional spaces on either side of the single quote.

I meant not having `Start Testing` as the `Suite Setup` as that is now set by default for the parent testsuite i.e the testsuites folder. Every children testsuite can have its own `Suite Setup` as well which will be executed after the setup of the parent is executed. 

2 spaces between arguments

`${TEMPLATE COUNT}` and `${QUESTION COUNT}` are not required here anymore.

2 spaces

But it informs me of the variables that are global for this suite. I like that information to be obvious.

(y)

Is there any reason to not use `Login To Eden If Not Logged In` here and other tests below?

They also do not go to any URL.

I don't really see the tests as being independent it's part of a single workflow. However, I see your point that so long as the data is set up correctly then some tests could be run multiple times; so I can add that.

Do you have a keyword to go to a URL if not already there? Or will I need to make one?

We don't but it will be a good addition. :D 

Something like `Go To URL If Not Already There`.

Also, 2 spaces here also.

:+1: for removing `...`

Check indent

Is it necessary to name the file as project_project.txt? 

Section not needed.

Is there a convention?
If not, can call it project.txt as well

project.txt should do

My repo is ahead right now. Forking yours and sending a PR

silly mistake from previous commit 

-1
"unique" is a DB-level constraint, not a validator. 
This does not auto-migrate (=you can't change this setting in a live DB!), so it can't be a deployment setting. As the todo says: use validators.

CSS classes should use dashes not underscores (i.e. "avatar-img-div"), and they repeating the HTML elements is not needed (i.e. "avatar" is quite enough).

'avatar' alone is too likely to clash with other CSS frameworks, etc
s3_avatar perhaps?

What I understood is that, Deployments would ideally set migrate to False, therefore any changes in "unique" wouldn't be reflected, therefore we need a validator that checks it at the "form" level. ?

migrate=False during normal runs, yes...however when doing a 'pull' to update code then migrate=True to get new DB changes....not normally done when editing deployment_settings, but would be needed for enabling new modules.
Dominic is correct that having this at the validator level is the best strategy....as he has now done :)

No - what I mean is that a unique-constraint can only be set once when the table is created - if you attempt to change the constraint after the first run, it will rightfully cause an integrity error. Therefore, all DB-level constraints can only be constants and not dependent on a deployment setting.

That is why the ToDo said "validator" and not "unique key" - a validator can be changed at any time (although of course you can still not enforce uniqueness in hindsight - that would require a data cleanup).

The validator is required anyway (otherwise invalid data in imports will cause db-level errors, and in postgres we can't skip these as they will halt the transaction on any error).

Besides, we shouldn't make constraints dependent on the assumption that migrate will be set to False after first run - either that is required and happens automatically, or it is an invalid assumption. And development instances do almost never have migrate=False, yet they need to work!

And of course migrations of production instances will also have migrate=True - how else would that work? :D

Now I get it... Thanks :)

No need of if statement here.( for location_names )

forgot to use ' instead of "

That is dangerous - the realm must be a pe_id! So:

```
realm_entity = row.pe_id
```

if at all. But that's the default, anyway.

Indent - comments shall follow the indentation of the code.

Btw, your statement:

```
realm_entity == row.id
```

has no effect, because it uses == instead of =

This seems to just move the project_assignee_represent code into the constructor of the otherwise completely unrelated project_TaskRepresent class, but not to implement an S3Represent for the assignee key.

It is completely unclear how this is supposed to work - or how it would be called. As it is done here, it breaks both the representation of assignees and the representation of tasks. Not acceptable, I'm afraid.

m=user.id is not a valid method (method must be a string or None).

It is wrong anyway, because auth.user.id is auth_user.id not pr_person.id, so you can not use it to construct a URL like /pr/person/[user.id].

But if you have a person_id, you can do it like

```
MM("Edit Profile", c="pr", f="person", args=[person_id], icon="icon-edit")
```

I understand that you took that from the original Sunflower static HTML - but it was wrong there as well ;)

This should be rolled into one class - you can detect whether this is the outermost element by checking item.parent == None.

It seems you're not actually checking whether the item is authorized. 
Unauthorized items may need to be hidden or rendered as disabled - see s3layouts.py how this can be achieved.

There is no need to use a shortcut if you only use 1 instance.
The shortcuts are to improve readability - but ML does not improve readability here as a single-point replacement for S3MenuLogin().

You don't seem to use this - why is it there?

This is a single instance as well - no shortcut needed for that.

Single-instance class does not need a shortcut

better use:

```
BUTTON(...
               data = {"toggle": "collapse", "target": ".nav-collapse"}
               )
```

This should better be done using CSS

Confusing argument name, and not needed. Use:

```
A(..., data = {"toggle": "dropdown"})
```

instead.

Should be "_data-toggle" if done this way - but it shouldn't be done this way anyway. Use the data-argument instead.

Faster if you prepop the list with this instead of inserting afterwards.

The name of the test case is exactly what you you specify in the test case without any conversion. So, it should be something like,  `Updating a Project should be successful`. It is a minor thing but a good practice to incorporate. 

Unnecessary comment 

Unnecessary comment 

This JS is probably not needed - Foundation has a resizable text area integrated.

Better generate this form using a Foundation-formstyle.

Make the telephone number a deployment-setting, rather than hardcoding it here.

Do NOT hardcode this! Otherwise you'll get emails from everywhere and everyone who ever checks out this code and test-runs it ;)

Missing semicolon

Other themes?

What's this for?

Looks complicated. Why not just set sys.stderr=buffer ?

I need the name of the logger in a test -- I am testing for (absence of) a reported error so need to add a handler. The name is not the name of the class. The name is:
applications.[directory].modules.s3log

Because it might be logged to a file, or other.  This is immune to changes elsewhere.  Adding handlers is usual for capturing messages into two places.  Also, I would like to see any messages as they're posted.  Something might be depending on the messages going where they're going now, or might depend on it in the future, so don't want to change that.

Yeah - found it myself, thanks.

True, so maybe this should become a method in current.log then...seems useful for testing (and we wouldn't want to repeat it).

No worries, I'll do this. Stay focussed on what you're working at.

I can change it here if the pull request is open when I wake up...better if I do it than have the pull request stale because there's a merge conflict.

I said: no worries, there will be no merge conflict :) no need for you to action.

unique-constraint should additionally be caught by IS_NOT_IN_DB field validator (otherwise duplicates will halt import transactions on postgresql and cause weird db-level exceptions that are hard to trace)

define_table does not return anything with lazy tables - can't use this

This is too complicated and confusing, better to do this explicit.

empty statement?

this test is superfluous - wouldn't be called in all other cases

Also, there is very little point to make the /model/ introspective of itself - all customizations (such as hiding fields) happens only /after/ the model has been loaded (how else could one access the fields?), and thus wouldn't be introspected at this point.

I think an explicit form definition is much more readable and easier to maintain at this point.

This should really be an S3ResourceQuery, not a query - implicit joins can conflict with query construction.

Pointless variable? (only used in one place)

Not the recommended UUID format - should use URN's instead, e.g. urn:sahana-hospital-type:HOSPITAL.

Commented out despite called for the index at the top?

I'm not sure why there are UUIDs anyway...these aren't universally-agreed types with clear definitions

Quite inefficient - this creates all types per each hospital, importing the same types over and over again. This might be caught by the deduplicator, but it would be better to generate each hospital type only once per source.

Besides - this introspective variant makes the table non-lazy for no reason. Better to keep it lazy.

from s3 import S3ImageCropWidget

please...

And shouldn't that actually be S3ImageCropWidget2 then?

Ah - I see, you made this a conditional fallback. Not needed - just replace.

Trailing comma!

Indent?

Unnecessary line wrap

Can actually be like:

```
var x1 = coords[0],
    x2 = coords[1],
    x3 = ...
```

i.e. not necessary to repeat "var" all the time.

Indent?

Confusing that on the Python side you use a UUID to allow multiple widgets, but then here you use an HTML element ID, of which there can only be one per document.

Ternary op is discouraged, should be a normal "if" for better readability

Excessive indent?

Missing semicolon. I recommend to use jslint to eliminate such minor issues

Every var on a new line pls

Doesn't make much sense to use UUID to distinguish widgets, but HTML node ids inside the widget. Should really be classes instead.

Docstring needed to explain the parameter.

normally, font-sizes and colors and the like should really be per-theme. I understand that this here is intended as fallback, so it's fine. 

So this configures the canvas size - but where can I configure the desired maximum size of the upload image (which could be greater than the canvas), or control mandatory scaling/cropping. This logic is not entirely clear here.

We would (optionally) define a maximum width/height - and it'd be up to the user to decide whether he crops the image to that size, or have it scaled afterwards. But even if we do not define a maximum size, the user should still be able to crop (=select a subsection of the image for upload). 

Remember that different CSS frameworks use different button classes - maybe make that configurable?

What's the parentheses for? It's Python, after all.

Chaining - not re-selecting.

So here's a basic/simple Idea that I am thinking of:
if I pass arguments to S3ImageCropWidget like (500,500), that would mean any image whose size is bigger than that is going to be scaled but if I don't pass anything, the Image is never going to be scaled irrelevant of the method of upload.

:+1: 

I didn't get what you meant by this ? Could you elaborate a bit pls

3x bind to the same selector, should be like: 

```
$('#imagecrop-drag').bind(...).bind(...).bind(...)
```

so that it does not need to repeat the selection. That's called "chaining", and is a lot faster.

Thanks, realized a lot of other selectors can be cached as well ;)

Should we not .lower() in the check rather than including here?
We could make this a tuple too? (slightly better performance and this is currently executed every request...perhaps better even to move this to a module too?)

So will this work in other themes if this is only in the default?

Preferred style:
{"_type": "hidden",
 "_name": "imagecrop-data",
 "_class": "imagecrop-data",
 }

This is counter-productive: person-represent and role-represent should be run in bulk, not per row. Please look at other S3Represent implementations how this can be done.

I don't see any S3SQLInlineComponent here?

SET NULL? What's the point? CASCADE seems more logical to me.

@nursix, counter-productive as in ? running more code than required ? 
Do you want the individual represents to be run in bulk ? 

I looked at the org_SiteRepresent that uses its custom "bulk" function but need some more clarification on the "counter-productive" part.

Not what I mean: you're implementing a custom S3Represent here, and S3Represent does actually provide effective bulk representation out-of-the-box. 

But then inside the row-representation you're calling other S3Represents /per row/ - which effectively neutralizes the bulk-representation effect (therefore "counter-productive").

There is an elegant way to cascade bulk representation, see for example https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L5688

The lookup_rows function there calls the /bulk/ method of the embedded representations (projects in this case), which stores the results in the respective S3Represent instance. That makes the subsequent lookups in represent_row just a dict lookup instead of one DB query per row (or even two like in your implementation).

The magic of S3Represents is that they "remember" all representations, so when you bulk-lookup once, and then subsequently call it for each individual value, it would just deliver from the local dict and not load from the db again.

Aha! So that's why it's Lazy ;), got your point, Thanks

not in widget.css please - some controls will not want this!

there was a reason for this - pls override in template-specific style.css

I made these changes here https://github.com/flavour/eden/pull/892/ but now I realized that it's better to keep pre-line that takes care of new lines as well. Or Do you think it's better to keep it normal here and override in the style.css ?

No - I just saw that it had been introduced only recently, so wanted to avoid that this breaks a deliberate change. Didn't investigate who introduced it - so if you're reverting your own change, and it doesn't have undesirable side-effects across templates, then fine.

Repeated statement

Use resource.delete()? We do not hard-delete normally.

user_id not checked, nor doing any authorization here.

Why have an "action" variable if you use REST? Can use the URL method.

extraneous whitespace

So many queries - why not make it just one query, and use resource.select() to get it all represented in one go?

Repeated T()

Unused variable?

if user_id is None, then interest is TD() - disregarding as_div. Is that intended?

DRY this

DRY this

DRY this

best practice is to set the deleted field = Trues

Which resource.delete() does, in addition to:
- Checking for Permissions
- Moving all FK's into deleted_fks
- Triggering cascade deletions

Correct - you should check that the user has permission to write to that table. Even better is to perhaps use the WebServices to assign the role using the RESTful API - which will do all the checking for you (Note - I've not reviewed all this code - so this will need further investigation - see: http://eden.sahanafoundation.org/wiki/S3/S3REST/URLFormat)

Ah - this is exactly what I was meaning! http://eden.sahanafoundation.org/wiki/S3/S3REST/URLFormat

+1

I think that project_member and project_task_member should be one table - I don't see the reason to split them.
@somayjain I understand you suggested 2 tables - what's the reason for this?

This could default to the person_id of the current user

@michaelhowden : I suggested 2 tables when the requirement included user-defined roles. But, if we are just keeping an interested option, then there is no need for 2 tables.

the Method was "Assign" here, however this was just an additional parameter( could be an argument as well ) in order to inform the method to behave differently.

Nope, but it didn't make any significant difference so I might have overlooked that.

Needed for this => response.s3.theme, maybe unnecessary because the theme would always be "SSF".

I usually try to learn by observing, atleast for coding conventions ;), maybe these need to be DRYed as well ?
https://github.com/flavour/eden/blob/master/modules/s3db/project.py#L6153

No, the principle is to use different methods for different actions - "assign" to assign and "remove" to remove the role. Can both be handled by the same method handler, however - just configure like:

```
s3db.set_method("project", "task", method="assign", action=assign_role)
s3db.set_method("project", "task", method="remove", action=assign_role)
```

and then check for:

```
if r.method == "assign":
    # Code for assignment
elif r.method == "remove":
    # Code to remove assignment
```

Btw - it is not 100% clean to respond to invalid format and invalid method with the same HTTP status code. An invalid format is responded to with a 501, but an unsupported method is actually a 405 - and method should take precedence over format.

No, those are different:

```
if activity:
    activity = TR(TH("%s: " % T("Activity")),
                         activity.name
                         )
else:
    activity = ""
```

No repitition here.

Compare to yours:

```
if record.created_by:
    creator = TR(TH("%s: " % T("Created By")),
                         s3_auth_user_represent(record.created_by),
                         )
else:
    creator = TR(TH("%s: " % T("Created By")),
                         "-"
                         )
```

...which repeats both the T() and the HTML layout.

So it should be:

```
response = current.response
s3 = response.s3
s3db = current.s3db
auth = current.auth
```

no?

That's a different way to look at it, and probably the correct way :+1:

Ahh, it's so hard to notice these things....Thanks, hopefully with time, it will all come naturally.

Ahm, don't see this as you doing something wrong. This is "peer review" for exactly that reason: you can miss these things easily. Happens to me and Fran just as often - which is why we review.
The goal is not that _you_ become perfect - but the code ;)

Not really - the _correct_ way would actually be to require HTTP PUT to assign a role, and HTTP DELETE to remove the assignment. But most browsers do neither support the one nor the other, so you only have HTTP POST - and the Eden way out of this is to send to different sub-resources (=URL "methods") for different actions.

Surely you can qualify the method further by using a query variable - but for consistency reasons, we should use the URL "method" pattern (because we do that elsewhere).

Indeed, you could use the existing web services to create/delete/update the role assignment - without the custom method handler. That requires a bit more thinking, but less code - and delivers the authorization out of the box.

But I know you wanted to do this exercise, and it is good if you learn how custom methods can be build.

NB: There is also a framework way to define method handlers.

You define a function as method handler:

```
def assign_role(r, **attr):
    if r.method == "assign":
        # code for assignment
    elif r.method == "remove":
        # code to remove assignment
```

As an S3Method, it would look like this:

```
class TaskRoleManagement(S3Method):

    def apply_method(self, r, **attr):
        if r.http == "POST":
            if r.method == "assign":
                self.assign_role(r, **attr)
            elif r.method == assign
                self.remove_role(r, **attr)
            r.error(405, current.ERROR.BAD_METHOD)

    def assign_role(self, r, **attr):
         # Code to assign a role

    def remove_role(self, r, **attr):
         # Code to remove a role assignment
```

And then like before:

```
s3db.set_method("project", "task", method="assign", action=TaskRoleManagement)
s3db.set_method("project", "task", method="remove", action=TaskRoleManagement)
```

Of course, that may be a bit too much for this particular case - I'm just outlining it for your learning. The advantage of S3Method is that the base class already implements a lot of the logic for interactive views (e.g. rheader, safe forwarding, crud-strings etc.) in a consistent, generic way. However, this particular case is just Ajax, and doesn't need any of this, so a function is fine here.

NB, you could just write:

```
s3.prep = lambda r: r.method == "options" and r.representation == "s3json"
```

(but only if you want - your variant is totally fine)

;)

I /had/ to use a Custom Method here, couldn't find( maybe I'm not aware of it ?) any such already existing functionality to do what I was planning to do. What I want to do is be able to insert data in a table whose form doesn't exist in the UI....because I don't need the form as I already know the data to insert( i.e, the task opened and the user logged in ), however CRUD operations end up in SQLFORM at the very low level. So I had to make the Method to handle Ajax to accept the data to insert, update or delete it. Any hints to a similar feature already implemented in some form or the other would be helpful ;)

..."Saving" Filterforms caught my attention, may not be useful at all here, but didn't get time to look at it yet.

No - you can use the same CRUD functions without interactive forms, because they actually /are/ RESTful web services. That is as simple as changing the format extension in the URL from .html (=the default) to .xml, .s3json, .s3csv, .kml, ...a variety of formats to choose from.

Then use HTTP GET/PUT/DELETE to manipulate the record.

For example, you can do an HTTP PUT to /eden/project/task/3/role.xml to create a role assignment for that task - using S3XML as data format. Or send an HTTP DELETE to /eden/project/task/3/role/7.s3json in order to delete that record.

For simple CRUD actions, no custom method is required.

That's exactly what I was looking for :). I asked Flavour about that, but I don't think he got my point. Thanks

2 space indentation

2 space indentation

Do you foresee the usage of both `@{SUB URL}` and `@{Name Value}` in other tests in this testsuite? If not, I recommend setting both of these variables inside the test `Create Staff Member` itself.

Michael pointed out that S3ResourceHeader could be used, but I don't think it would be of use here because of the reason I pointed out here https://github.com/flavour/eden/pull/926/

I think S3ResourceHeader could very well be used. The confusion may be that you expect it to be used inside the task_rheader function - but that is not the case. It is actually just an object construction, nothing you need to pass into it.

i.e. you do not need to call the header, just define it.

If you don't know how, then just leave as-is for now. No need to block this feature just for that.

no, I meant the blank after #

Really not necessary to fix it - I can clean this up after merge.

Okay :thumbsup:

I don't think bulk is needed, and it shouldn't be re-implemented without very good reason.

To be efficient, the delegation should happen in lookup_rows - and then bulk is not needed.

the query executed ( in build_set of IS_ONE_OF validator) to retrieve the records that are passed to Bulk takes care of several things such as filterby, accessible query, etc and when we already have all the records before hand, there wouldn't be any need of looking up things again....and wouldn't things be the same if it were in Bulk or lookup_rows in case of efficiency ?

IS_ONE_OF is by far not the only case where bulk is called.

lookup_rows and represent_row are the lazy methods, whereas bulk is always called, even repeatedly. The standard (and the intended method) is to implement the lazy methods in subclasses, not the primary API - only when you have a very good reason to override the default bulk method (e.g. special aggregation), then this is an option. But in this case, all you do in the custom bulk is to delegate - and that, out of all things, should /not/ happen during the bulk call.

You can solve this way more elegantly - I would even argue that the whole class isn't needed at all ;)

Also - and that's actually why your solution isn't valid - rows is an /optional/ parameter. So, apart from the very special IS_ONE_OF case, it wouldn't even work.

.....like S3Represent wasn't elegant enough ;)
Okay, makes sense....this wasn't being used anywhere else though, but I guess it's always better to keep things as general as possible( in case it's used in future )...but I am still thinking of continuing with S3Represent ? :P 

I would then have to take care of all permissions, filtering, etc in the custom_lookup( I don't think I saw any of these in the other lookups ), right ?

No, that is a misunderstanding. Represents don't do any filtering or authorization - they are called with one or more values, and they _must_ return the representations for each of these values (i.e. it can not refuse to represent a value - when it is called for that value, then it must return a representation for it).

representation methods are called by many things - IS_ONE_OF options is only one use-case. Datatables, read forms, pivottable reports, exports in various formats...all these call the represent as well. Some of these call bulk, others call just the represent - and some are lazy (e.g. exports), others require instant response. 

This is not "should be as generic as posssible" - it /has to/ be generic, otherwise it's not valid at all.

I think that this class is not needed - task assignee is a pe_id and we already have a representation method for pe_ids. I think that one can be re-used (it may need some config options, though).

But /if/ you want to continue with a specific class, then pls move the delegation (to the other represents) into lookup_rows, and avoid overriding the standard bulk() method in the subclass.

Interesting...but wouldn't that give an empty list for most people?
Or read: is "My Tasks" not the tasks I am working on (=subscribed to, assigned to me), rather than the tasks I created? Just wondering...

Yes sir i understood :)

I think the idea with yepnope was a different one - it's definitely not a replacement for the pie renderer. This change simply breaks it (which you could have seen if you had tested it).

Please don't make changes if you don't understand what they are about.

Sorry sir..

Not on every page pls - inject as needed.

Comments should start uppercase

Roll this into previous query, and re-use the represent instance?

Risky - address can contain apostrophes. Better pass as data.

...and with a blank, like:

```
// This is a comment
```

Try module pattern, hiding internal vars from global scope?

Hardly - especially not in default. Please move into the theme this concerns.

Err - what?

How can we avoid the join ?

I think this custom lookup_rows is all that is needed, many thanks :)

Bad syntax -- *fields must go last (although Python 2.7 tolerates it).

Do not store a current-object to a module-global variable. The module is only loaded once for all threads, but current is thread-local, so assignments like this can leak data across threads. 

Too much inside try/except - only the statement that throws the exception should be inside it.

Why call it again?

Agreed. But not my implementation. I'll try refactoring. The commit is only for the Todo part

Okay will assign it before try block.

So now shall I make this 
`format = current.deployment_settings.get_L10n_date_format()`

Should we not put 'Albanian' instead of 'Shqip'?
I think that Filipino & Albanian are better-plaved in an EVASS-specific file rather than the main template as few deployments will need these. Am happy for all the rest to be in default as they're more-widely used.

:D I said the opposite: put Shqip instead of Albanian as that's the more commonly used name of the language ;) maybe use "Shqip (Albanian)" for convenience?

Quick survey on other sites gives ~50/50 use if Shqip vs. Albanian. So I guess you can do as you prefer.

ISO says: Language Name = "Albanian", Native Name = "Shqip", code = "sq".

Swedish official registers, libraries and book stores call it "Albanian Shqip". Probably the most convenient variant.

Don't use the bootstrap throbber, use throbber class instead and leave it to the CSS to define the throbber.

Okay

Should not run settings.get_google_anaytics_tracking_id() twice.

Script should be inside CDATA tags if placed directly inside the HTML

Which is done if the extra script tag is removed & re-use the existing one, as it was before

Ok, I found why the code didn't work in existing <script>. If i put analytics code at the beginning of script (i mean before for script in s3.js_global) then everything works as expected. So i moved the code at the beginning of existing script. Now the code is in CDATA. I will commit the file.

I don't understand what you mean. I copied existing if statement and there was also twice.

I wonder if it would be more consistent with conventions to rename the function hrm_cv...

Shall I change the class name instead of the calls.

No - wait to see what the others say. Key thing is that you've highlighted the issue!

hrm_CV is a class, not a function. So this _is_ following the naming conventions.

To explain it: according to conventions (PEP8), class names shall be uppercase. However, since the class is defined in a model, we do need the hrm_ prefix to have it available via s3db. Therefore, it is hrm_CV = hrm_ (model prefix) plus CV (uppercase class name).

No, this was intentionally not setting c here.

This looks like a very ugly modelling, and it contradicts the IFRC use-case.

Even if we would want to implement the factor table, we would certainly not hardcode the fractions. They are not universal, so if at all then this needs to be stored as triples.

Then, of course, the actual table would depend on the organisation and of course on the staff type/level, probably even on the employment contract type (very likely), and in the VNRC case even on merits, education level, awards received etc. - regulations in and within different countries and cultures can vary massively.

So massively that we do not even intend to store the whole table (or table/s/ as it would actually be) and if we would, then we would need to also track all the data required for the lookup, with no generic lookup mechanism possible (nor have you implemented a lookup mechanism yet).

Could it be that the OSU table was given to you as an example and you have just implemented it as-is without first looking at other cases and developing a proper model?

Either you have a deployment setting to control visibility of these fields OR you customize them in the template - but not both. A deployment setting would be checked and applied in the model, whilst the template would just set it - but if you do the entire field customization in the template, then a deployment setting is not needed.

Further the settings lack lookup functions (in S3Config) and default values.

You can /not/ rely on particular record IDs, nor on a particular order.

What exception would this throw?

This again should definitely be in the template - and it is country-dependend. Sweden for example has no L3.

I was not able to find anything other than stable.id, hence i coded it as,  stype = db(query).select(stable.id)  Could you please direct me to an instance where this is done. I'll refer to it and change it as required.

How do I do the change in the template? Should I include hms_hospital.csv in templates/Magnu with the columns that should be displayed?

Oh, this could well be a simple as:

s3db.hms_hospital.location_id.widget = S3LocationSelectorWidget(...)

...in the respective customise_hms_hospital_resource

The problem is that the same ID does not always correspond to the same status.

The recommended method is to indeed link the hms_status record and the gis_marker record directly via a foreign key in the hms_status table. Not only does that make it more robust - it also makes it both CSV- and user-configurable ;)

...and obviously the marker lookup function would become very simple ;)

I have done the changes as requested and will commit soon. Only the hospital marker function change is pending. Is there any documentation/code that I can refer to for the task of addition of gis_marker foreign key to the hms_status table?  

What are these CRUD strings needed for? They only cause unnecessary overheads in the model.

Same here - what for?

Same - what are these needed for?

Why change this?

Can't make a DB-level unique-constraint dependend on settings (because it can't be changed without manual DB migration). 

Must be a validator instead (IS_NOT_IN_DB)

The same deployment setting should also control the field method in the first place

I would not make "visible" a deployment setting - field accessibility is usually controlled via readable/writable in templates, and can vary between use-cases in the same deployment.

So along with filter, the same deployment setting for the start & end date in defination as well?

So a seperate setting for readable and writable?

Meaning: even if there was a deployment setting for that - there are simply too many fields to always remember that there is one for this particular field out of all fields, so people would just apply the usual pattern and set readable/writable as needed (and that is how we describe it throughout all documentation). 

That in turn would lead to a practically ineffective deployment setting - and the intended gain of control would turn into quite the opposite.

Not really ;) I was talking about the Field.Method "year", not the underlying start/end date fields. If that wasn't obvious for you, then it's actually fine to just have the setting control the filter widget.

No - there should be neither the one nor the other in default/widget.css! The whole selector should be removed from that file.

...as that needs to be overridden by almost each and every theme. It's plain wrong to have that in widget.css.

so we have to move that .form-container form textarea  {} to the SSF/style.css ? or the complete form layout styles

At the very least, yes. 

But in general, everything that interferes that gravely with the formstyle should be removed from widget.css.

This particular rule breaks responsiveness of formstyles, and thus must be overridden - and that does actually apply for the SSF theme as well. Responsive themes (=all bootstrap/foundation-based themes) should not impose a fixed width to form widgets, that simply doesn't make any sense whatsoever.

Hence - it should be _fixed_ properly rather than moved.

What's wrong with the error_message? And if you replace it, then why don't you remove the original one?

Is there a reason to remove blank lines? Most of the time they are there to improve readability and structure of the code, so ideally only duplicate blank lines should be removed.

Sorry ! It was by mistake.

Yes - most certainly!

;)

Generally it is a bad habit to start variable names with an underscore without special reason.

Obviously "member_data" would be better than "_data", and "task_exists" better than "_record".

But this isn't a functional issue, just a coding style problem.

Besides, there is a better style for this kind of test:

```
try:
    row = data.rows[0]
except KeyError:
    rheader = ""
else:
    ...build the real rheader...

return rheader
```

Coding convention: except should always have an exception type, don't just catch everything. 

Only Exceptions which are expected should ever be caught - everything that is not expected shall crash.

:+1:

We want this to be label, not title.

Was intentionally removed as per requirements spec.

:+1: 

i.e. the tooltip popups shall not repeat the label as title - that's ugly.

without title, there is no heading in the add_resource called from the create forms. Should i edit it to have both label and title?

No, just leave as-is.

That is because starting with the Alert is an invalid workflow - you can't set up a mission en-passant, and it may even require approval before you can send out alerts. An AddResourceLink at this point is therefore wrong.

I mean, leave your changes in ;) we'll remove as needed.

Not critical, but pointless to allow selection of lookup name in such a custom represent ;)

limitby in DAL is of format (0, x) not just x
(limit in S3Resource is just x)

Means you'd have to override init() too...
No big deal either way, but I would override the init as clearer

@flavour : Line no.256 (I modified the count variable as nursix wanted not to use one extra variable limitby)

Yeah, agree that no extra variable is needed but needs to be limitby = (0, count) not jjust limitby - count

You missed line no. 256 probably?
count = len(values)
...
count = (0, count)
...
limitby = count

Sorry but didnt get you is it wrong?

Yeah I did - the problem with redefining the meaning of a variable.
I don't see a need to do that? Keep count as meaning ;count' & don't reuse as limitby...simply put the result into limitby = (0, count)
This is easier to follow...

:+1: sorry 
Got you!!!

Drat, this starts becoming absurd. Indeed I imagined it to be:

```
db(query).select(..., limitby = (0, count))
```

instead of introducing a local limitby variable - but then I have also said that in no way that is a technical or coding style requirement, just something that crossed my mind when looking at it. Now I feel guilty of having caused unnecessary trouble - maybe should have declared "no action required" more explicitly?

Much more obvious is though that there shouldn't be a fields-variable here to pass the fields, this does indeed go against recommendations (as it is deemed prone to regression issues). Since you do not modify it, the list of fields should be moved into the select statement.

Again, sorry - I can clean this up myself after merge, without all the comms.

hmm, I think that minimising local variables is valuable as it reduces memory consumption (& CPU)
Where there is debug value in intermediate variables, then this can outweigh, but here it adds no value so can be easily removed :)

It can save comms, but part of the purpose is to train :)

prefer the style:
var geti18nSetting = function() {

Better to bring this into scope inside the class once & then just use db - as currently this repeats in the same class

Would be great to have this logic abstracted for use by both users...so that if we need to extend it then we can do so in just 1 place

Normally we use format_date.replace not string.replace(format_date

js_global injects should be kept as small as possible: minimise whitespace, no need for colons (as we have CRs)

I was suggesting this was minimised into S3.min.js (i.e. edit static/scripts/tools/sahana.js.cfg)

I think a more sensible default than 0 would be good here? e.g. I'd have thought that 365 would be the most common. (Currently uncommenting makes 0 difference as it applies the same default)

This was already fixed, btw.

@flavour , hey, do u mean to use this "convert to js format" as a method? If so, In which file should i create the function??

Yes. Seems to me this should be part of the S3DateTime class in s3utils.py

one oft the most frequently re-invented wheels - make sure this doesn't become yet another instance. 

Ukrainian & Croatian seem better in EVASS template too
Arabic/Chinese can stay in global default

Again - I do not see this as an independent function. It is closely tied to the datePicker ui widget (=there is no such thing like a "JavaScript" date format - this is the format for datePicker!), and thus should at least be re-used for the S3DateWidget which currently has it's own conversion mechanism (which is btw. a bit more complete).

-1 to have this in S3DateTime - it's totally unrelated.

Even in this case it is 100% datepicker/S3DateWidget-related - not generic.

This widget is default for s3_date no?

Umh yes - most certainly :D Can be removed here.

Why are you making the start date & end date selectors variables?
If you think this can be reused elsewhere then maybe not HRM-specific?

Yes!! , I'll remove it

Makes the table non-lazy - should be avoided

Can't rely on request args - images are uploaded in many places.

IS_PROCESSED_IMAGE should not be necessary - see previous discussions about the widget.

Not correct - URL is a valid alternative, and file can be NULL in those cases

Yeah got it!

:+1: 

Problematic for location selector: rows which haven't been written yet (e.g. inline rows) don't have an id, yet they provide Lx data that need to be translated. I'd suggest to make this a lazy method which looks up the l10n if not present in self.l10n yet.

For this special case, represent_row can not rely in lookup_rows having been called ;) (specific to this represent, not generally for all represents).

This will always return a hyphen because you don't have any processing to extract the nickname. So what is the point of this?

having to labels for the same item can be confusing. It might be better to stick with nickname or preferred_name, I prefer, er, the latter.

Nickname is extracted by HumanName():
http://nameparser.readthedocs.org/en/latest/usage.html#handling-nicknames
Only if we add it in quotes

@graeme-f : I cant use preferred_name here instead of nickname. name is an object with nickname a key

This new variable preferred_name should be used somewhere. I would suggest that the display of this should be part of this change. Then if you don't have a preferred_name the logic required to extract the preferred_name from fullname should be clear.

preferred_name is returned by name_split() which in turn uses HumanName() for that and splits it accordingly.

Okay I was reading all the commented code not realising that it was commented out. Too long away from looking at code. Do we need to retain the commented code if it has been superseded? Is this function split_name used anywhere else, if not do we really need it?

Well, I think its not needed any more since nameparser does a great job for us. Shall I remove it?

I think commented code can be removed here

@flavour Here https://github.com/flavour/eden/blob/master/modules/s3/s3widgets.py#L5423, a fake row is created, and the widget calls the represent without calling the lookup_rows, so then the l10n and paths I defined in the lookup_rows wouldn't be set here, so I have to define them.

Used here: https://github.com/flavour/eden/blob/master/modules/s3/s3notify.py#L317

Similar to https://github.com/flavour/eden/blob/master/views/msg/notify_email.html#L1

Err...long system name was an explicit requirement! (CRMT)

Make it a deployment_setting?
I think short name should be default, but CRMT can use Long if-preferred...

:+1:

Nah - it's a view-template for a reason! Just needs a template-specific view template if default is changed (maybe it's already there, I don't know).

No such imports needed in regular controllers - s3 is already imported as s3base.

default, default, default...

...default, default, default

Good catch, although one must dig deep to hit the problem ;) 

None of the regular users (and they do use it intensively!) has hit this problem so far - which is simply because they never see that "Add Member" button (as in: they are not normally permitted to add new staff members). 

I guess the button shouldn't be there ;)

definitely the wrong place - nothing to do whatsoever with permissions.

Why move it at all? It is only used in req and nowhere else, so it seems specific. And even if not - it should either go into org (most logical to me) or into AuthS3 (still logical), but certainly not S3Permission.

To be honest, I would leave this in req, and remove the todo. It is only used in the req controller and nowhere else - moving it into a different place will only make debugging harder for no reason.

Yeah didn't made sense to me either but as the Todo suggested. Okay I'll remove Todo.

Not the ideal variant for T() (difficult to parse and extract) - better to separate the fallback.

Also inconsistent - it's "cr_shelter_notification_subject", but not "event_event_notification_subject". Should either both be prefixed, or neither.

Why is this a variable? Should be inside select()

Definitely wrong! MUST not change current.request. Put extension into URL() instead!

No need for this variable

Can use self.table, or otherwise shouldn't assume model loaded.

Extra blank line?

SET NULL is illegal in a link table. Must be CASCADE.

...well - or RESTRICT. But not SET NULL.

Are you talking about the limitby variable ? 

Yes.

@nursix that variable is also been used later. Maybe we would need it ?

No, not needed. You can use:

```
limitby = (0, qty)
```

in the select.

Although I find "qty" not very conclusive a variable name - should be "count" or something like that.

Is it necessary to retain the @todo ?
Does the code change require any other adjustments (I'm think of css or javascript)? I don't know I'm just asking.

yepnope.js has been deprecated, so this might not be the best choice regardless of the todo.
What does yepnope do and does it's functionality replace the line that you have removed?

The idea was not to change the CSS selector, but to change the HTML classes used in these elements and then remove these CSS selectors.

No, yepnope is hardly a replacement for the pieRenderer :D 

Besides, a recent study found that using a JS loader here is actually slower than direct script injection, so the ToDo is actually obsolete and could just be removed.

I don't think this is what is meant by the ToDo...just hiding the permission check isn't valuable.
I think the issue here is that _once Commitments can be made by an Org rather than a Facility_ then is_affiliated can be used to determine whether a user has the ability to commit on behalf of an org or not
The first part is the harder part since the Requests module is currently tied to all Requests/Commitments happening at the Site level...in order to support Inventory/Shipments...but these don't apply as much to Person commitements (people will often travel directly from their homes, even if to a staging area before actual deployment. The staging area is only sometimes their office)

+1 to this for consistency.
Some templates may decide to be explicit about the create links, but it should be consistent either way.
(Personally I like to reduce the 'noise' of redundant information, but this does depend to some extent on the menu styling & structure as to how explicit we need to be here)

Done this in another commit...too small to justify a PR ;)

3x reading the pr_contact table from s3db?
Better to stash a copy:
ctable = s3db.pr_contact
query = (ctable.pe_id == pe_id) & \
etc

This was already useful for db. but even more useful for s3db.

Better to define these 2 lookups once than twice? (DRY)
Generally model is better as this is imported/cached not executed

Any comment to explain this?
(Not just the change but the actual line would usefully have an explanation as to what it's for)

Prefer to have a blank line after docstring...I think this is more readable & is the default for 99% of the existing code

I think the Contact should be an option here (defaulting to Off)

We should still have a line here - to enable the representation of Requester _with_ contact detail

Actually, leave this as the default here (no contact - std person)

So maybe no need for option here - as long as this is only used in the specific context that we want to see it

I prefer to retain this blank line separating the docstring from the @ToDo

Please put this in the alpha-sorted location (eases maintenance)

2015 now ;)

() not [] (minor issue for a single class, but is the std now & eases adding new classes...e.g. other country models

Ah, already defined in the model, so the DRY controller should read from here - pass back in the returned dict here into the controllers' dicts

I don't see Row used in the model?

When defining multiple tables, then better to use:
define_table = self.define_table
define_table(tablename, ...)
NB The indents are a little off right now anyway, so this gives an opportunity to correct them once ;) )

ADD_ASSESSMENT used only once? => remove interim variable

ditto

Why change this? It is deliberate: the description is unused, so no need to waste CPU/RAM on having this in the settings object...however it is useful for the configuration...which is done currently by editing this textfile...hence a comment is appropriate (can uncomment if/when we get WebSetup to allow deployer to select modules via GUI)

2x define_table? => use interim variable

This was readable = False/writable = False in the original, so shouldn't now appear by default in the Custom Form...rather leave it to templates to decide whather to incldue it (or create a deployment_setting defaulting to Off)

Actually, no - Don't add this to the same model as req_req as this table is pointless if Event module disabled...and adds overhead of loading that table if Event enabled, but we don't wish to link. Better to put this in a separate class with just this table (this is the usual practise for optional cross-module linkages). I'd be tempted to put this into the Event module as this already has a lot of these optional linkages.

Please don't remove this blank line

hmm, so if the user has no permission to update these tables, then we don't update those, but we stuill update the request status!? This will lead to inconsistent DB structure!!
This should be an atomic check: All succeeds or All fails.
I think this check should be done at the _record_ level, not just the table level, as permissions here can very much be at the record level.
The check for HTTP GET is incorrect here too as this functionality will currently only ever accessed via GET, so these permission checks will never be done, and the DB status will never be updated in sendtable/tracktable & we will always have inconsistent data...bad, bad, bad.
The fuinctionality is accessed by clicking on this Action Button:
https://github.com/flavour/eden/blob/master/modules/s3db/inv.py#L3600
I suspect the 'Avoid DB modifications from GETs should remain for now as too hard to fix that (NB it wasn't fixed here anyway as the Req status was still getting updated!)

I wouldn't define a crud_form by default here as by default this does nothing.

I wouldn't have these be readable/writable False by default - rather leave the entire use of this table to templates...I can see a temptation to think that it's easier to readable/writable True in a template rather than create a crud_form but as you point out in the crud_form, this can also require changing the label in the crud_form, so actually there is more complexity to enable here, not less.

Move optional link table out to a separate class to avoid having to load the GIS model to access a document, even when no location is required for it.

Sure! thanks :+1: 

Ha ha - of course not the template_id and location_id. That doesn't tell the user anything.

@flavour there is already check being done above that line - https://github.com/flavour/eden/blob/master/modules/s3db/inv.py#L3584, so do I still need to do the same check again ?

Good point that the button to access this is only visible if the inv_send _record_ is updateable.
So, pre-hackers, that should be sufficient.
Unfortunately we do also want to protect from hackers, so the check should be repeated on the new request.
I'm ok for this to be just the inv_send being checked...it certainly should be consistent between the 2 places.
I would also add a comment in each of the 2 locations pointing to the other to ensure that the consistency is maintained if someone decides to change the check.

line limit is 80 characters, not 30 ;)

Either trailing comma plus closing bracket in new line, or closing bracket in the same line...

HTML emails are ugly - where is the "text only" option?

Personally I do 100% prefer text-only - HTML emails isn't nice and always requires a renderer (not readable at CLI, for example).

...and not easily parseable by scripts

limitby=(0,1)

Use json_message instead?

also requires response header to be set (content type = application/json)

Not really limited to this format, is it?

Hahaha

:+1:

It isn't used currently for anything(except for msg), so I thought to mention the reason, but can be omitted, no problem :)

I guess this setting should be set by the user then :)
(btw it looks good in gmail ;), but yeah, I read about why html emails are a problem because of those plenty of email service providers out there...)

Yeah - it is also because I use scripts to parse notifications and route tasks. 

That is simply because Sunflower is by far not my only input line - it's rather one out of many tracks that I (have to) follow. And I simply cannot keep up reading and analysing all the notifications by hand, so I've automated some of it, and text-only is definitely easier to work with.

Even better if there is processing information (e.g. certain text markers) in the notification email.

I'm operating my own email server, so no provider issue here - although sometimes spamassassin takes HTML emails with many links for spam and quarantines them (though that can be overcome by whitelisting the sender domain, so no problem).

Hardcoded application name - not acceptable. Use relative path instead.

Row limit is 80 characters, not 40.

Assignment from current to module-global - incorrect.

I would think that a delete-cascade is more appropriate here (and you do not check for success of the DELETE request).

Funny success-test - success is actually a variable that can be True or False ;)

Better make this an onaccept?

limitby = (0,1)

Merge the first and the third statement?

Relative path ? I am unable to get the import working.

It's actually "status" that's a variable here, that could be "success" or "failure" ;)
But...you might have thought that's a key of the dict, but output is a string(json.dumps) here, so it's a bad check anyways ?

Yeah - I see, you're trying to import from private/..., which is not possible.

But why is the class in controllers anyway - if it's only used in config?

Err...according to the code above, output is a dict with {"item": json_message} - so the condition "success" in output will always fail, no? At least that is how I read this.

Fran told me about the possibility of memory leaks when defining classes in executed code, so he told it's better to keep it in places that are loaded as modules..
https://github.com/hitesh96db/eden/commit/21c8b64722f4e1a8ba27d6b4150c2a327e935017#diff-9c39b6a58ebe22321698bb6806a43b3fR1117

That is you set:

```
result = {"bypass": True}
item = current.xml.json_message(success=True, created=[rows[0].id])
result["output"] = {"item": item}
```

...which makes the REST API bypass the method call - and return result["output"], and that is, to me, a dict.

output will be a dict only when the request is bypassed...otherwise when using RESTful "DELETE" it's a json string.

So, how should I go about this ?

If the user is already a member of the task, then the request will always be bypassed even for a DELETE - so it will be a dict. How is a DELETE supposed to succeed?

Further - why return "created" if you bypassed the request? You didn't create anything.

And then - you look for a record with person_id and task_id - but you do not check whether it's deleted or not. You're lucky of course that both are foreign keys, so they would be set to None - but that's not really clean.

Eventually, this will always be bypassed except for the first PUT. Even if you try to DELETE, it will return a "created". Somehow this is a bit dodgy - maybe don't try tricks?

That is nice, but you still must not hardcode the appname ;)

Besides, the risk for memory leaks is fairly small here - you can very well include a class in config.py (as it is done in various other places) as long as you avoid the **del** method.

The point is that the code to destruct the instance would be inside the exec environment - so the instance can not be destructed after that environment ceased to exist, so it would remain in memory beyond the reach of the outer thread.

But I don't see a **del** method in subscription?

I would say, either move the subscription class into config.py - which I give you my word is safe as long as you don't implement a **del**, or generalize it and move it into the model. 

I wouldn't mind a S3TaskSubscription class in s3notify.py either _if_ it is properly generalized and thus re-usable across use-cases.

I don't think there's a general use-case for it yet, few templates use subscriptions, and the use-cases are different. Subscriptions for Tasks is very specific to SSF for now...so maybe leave it as-is ?

For your understanding what causes the memory leak:

Let your code be this:

```
class Example(object):
    def __del__(self):
        print "deleted"
example = Example()
```

Now, when you run this in regular Python (like: python test.py), it will print "deleted".

But when you run it as web2py script (i.e. inside restricted), you will not see any output - the instance "example" is never destructed.

The reason is quite simple: the destructor method holds a reference to the exec environment, the exec environment holds a reference to the "example" instance, and the "example" instance holds a reference to the destructor method. So you have a perfect circular reference which prevents any of the three objects from being destructed because the interpreter doesn't know in which order.

To break the cycle, you can add:

```
class Example(object):
    def __del__(self):
        print "deleted"
example = Example()
example = None
```

The last statement removes the reference to the "example" instance from the exec environment - thereby breaking the cycle. If you now run this through web2py, it will print "deleted".

When you import a module, the Python interpreter will do this setting to None automatically - which is why this does not happen for imported modules.

However, knowing this, you can avoid the problem - and hence very well put the class inside config.py since you do not have a destructor, or even if you had one, you would know how to break the cycle.

The idea behind the bypass was to take care of the situation where a user comments on a task, and when one does so, one becomes a member of the task and becomes subscribed to it. But the 'Watch' Button in the client-side isn't updated(i.e, it's supposed to be 'Unwatch' because the user is a member now) unless the user refreshes the page. So if he/she then clicks 'Watch', he/she is already a member, so there isn't a need to add the user as a Member again, so just bypass, and take the "already-created" member id of the user and pass it to the client-side(which extracts the id from the created variable).

DELETE doesn't go through project/member but through project/task/[id]/member/[id] 

Leaving as-is is not possible - you must not hardcode the application name in the import statement. No way, sorry.

Sorry, it was RESTful "PUT", I got confused...
But the best way would be to add an onaccept and ondelete, which would make it simpler to understand and less fragile.

No no, it can be moved to config, no issue at all, I was talking about the S3TaskSubscriptions(i.e, it's best to keep template specific subscriptions for now)

:+1: for the explanation

You can actually take my word for this - as long as you avoid the above problem, it is safe to have classes like this in config.py. It isn't recommended - but for very specific reasons, which you can easily get around.

If you don't trust my word, then an alternative could be to break the class up into functions and move those into config.py. It is questionable anyway whether this needs to be a class as you always only call a single function of the instance - but I understand that a class looks nicer and is perceived as easier to maintain.

The ultimate solution for this sort of problems would be to import templates as modules (instead of executing them) - and move them into the module path (modules/templates). But that is truly a major framework change and would require hundreds of hours of work - not to even speak of the retraining of everyone who has ever worked on templates, so it is currently rather wishful thinking, or, as we use to say, something for 2.0 ;) We could equally well think of migrating Eden to django, or cherrypy.

Well, it's up to you whether you want to generalize all the different subscription implementations into a common module with config options - or keep a template-specific one.

But yeah - that's rhetorics, of course ;) sorry if it sounded like a proposal. If you are sane, you will _not_ try to generalize that.

Certainly, that's how I would see it. Apart from that, I would actually _update_ the Button to "Unwatch" ;) Shouldn't be too hard (but not required for this PR).

http://demo.eden.sahanafoundation.org/eden/pr/person/93/contacts
Add emergency contact.

Should probably not be "Open Fire Station", but the name of the particular station - and if at all, then T()

How does that affect other popups? This is by far not the only use-case.
And _if_ then this should not be an inline-style but probably widget.css.

Name of particular station :+1: 

Don't call it person_id if it is a human_resource_id.

You are not checking whether this returns anything - what if the user isn't logged in?

...or not a fire staff member?

Use rows.first() not rows[0] - and make sure you check whether this returns any rows. If the logged-in user is not a fire staff member, then this will crash.

For this if station_id will be None and the link wont be shown according to the if condition in views

Why change this?
Now it needs to be changed in multiple places (both the response.title in the controller, and the title in the view) - which makes it harder to customize. Actually the module_name_nice is a deployment setting, so shouldn't be hardcoded.

Why remove the deployment-setting lookup of the module name? (see the other comment on the view)

But station name will not be None - it will not return a row, and hence crash ;)

:+1: 

Besides: avoid hardcoding the "update" method here - just open the record, so CRUD will decide whether update or read depending on permissions. Not all fire staff members are automatically permitted to update the station record ;)

:+1: ;)

:+1: 

Okay considering that, somehow got confused between two labels ;)

Forgot the .first()?

data.rows is fine

This is a bit too much I'd say - colname for "created_on" is always <tablename>.created_on ;) really no need to introspect it.

No really :D sorry - but now you're getting carried away a bit :P Technically excellent, but completely unnecessary.

|grin|

Is there a need for it ?, I'll be checking for a row existance anyways, so I could just use row[0] without trying to catch an error.

Prior art :), I'll change it...

If you add .first() to the select, then you can just use row instead of row[0] - using row[0] looks a bit cumbersome, and is somewhat inconsistent with the standard way of doing it.

Prior art? Where? :D

https://github.com/flavour/eden/blob/master/modules/s3/s3notify.py#L562

So I'll change that to "~.created_on"

Wants to say: the standard way of doing it is:

```
row = db(query).select(...., limitby=(0, 1)).first()
if row:
    value1 = row.field1
    value2 = row.field2
```

If you do instead:

```
row = db(query).select(..., limitby=(0, 1))
if row:
    value1 = row[0].field1
    value2 = row[0].field2
```

...then you repeat the index lookup, and probably confuse others since "row" doesn't quite suggest that it is a Rows instance and not a Row.

I actually meant you can assume that created_on_colname will always be "<tablename>.created_on", so you do not need to find it by using "~.created_on" as selector. Just define it as:

```
created_on_colname = "%s.created_on" % resource.tablename
```

No? No Introspection required.

But I appreciate that GitHub comments has hidden away the "tablename" :D so you probably misunderstood my comment. I try again Python-style: "%(tablename)s.created_on"

Here you define the created_on_selector, but not the created_on_colname. Yet you could forget the selector since at this point you already know the colname!

```
created_on_colname = "%s.created_on" % resource.tablename
```

No need to find it by scanning the rfields. Instead you can later skip this rfield by checking:

```
if rfield.ftype != "id" and rfield.colname != created_on_colname:
```

;) That's what I meant. A tiny little bit too much introspection trying to find the created_on field by it's selector instead of the (constant) column name.

Will "created_on" be in every table ? I guess the reason it was put there was to consider new records created as well, so only if a "created_on" field is present can we say something about new records...
 That's what I understand from this: https://github.com/flavour/eden/blob/master/modules/s3/s3notify.py#L571

Also: here you loop over the rfields to extract the labels and colnames, and further down you loop over the result again to extract the values from the rows. I don't think you need to do it like that - instead just change the second loop to loop over rfields directly.

Surely you would have the "rfield.colname" lookup inside the inner loop - but then that isn't really slower than the tuple extraction in the "for", and eventually you save a whole loop by not running this extra preparation loop. And you make it a lot less complicated ;) so easier to debug to understand for others.

Just mentioning that - but it's not in the way for a merge, of course.

Generally, striving after the simplest possible way to do something is good (and in Python, the most intuitive way is also often the fastest). 

Complications may not harm functionality - but this is open source code, so it's always good to think of others who may want work with your code later, and make life easier for them.

Also - remember that people could (and will!) copy your style. If you make it complicated, so will others - but then it could lash back against you when you try to debug their code ;) Hence: if you have a choice, then "simpler" is "better".

:+1:

That is true - even if created_on is in the table, it may not be in rfields (and hence not in the rows either), and then you can not distinguish new and updated records. That's a bit the meaning behind this.

But still doesn't create a need to introspect the column name of "created_on". If there is a created_on field, it will always have the column name "%(tablename)s.created_on", so this can be simplified.

Also note that generic code sometimes needs to do a little more introspection so that it can be used for varying use-cases - but in specific use-cases you can make assumptions. I think in this case it's just fine to assume that created_on is in the rfields.

I'd say - leave it as you have it ;) this should not hold up the merge. Technically it's totally fine.

I see that created_on_colname is used as a flag for whether the created_on field is among the rfields, so that this doesn't need to be checked for every row separately. I think this idea is good in general - but it isn't too obvious and has a bit of efficiency side-effects (especially since it loops over all the fields).

You could do it like this instead:

```
created_on_colname = "%s.created_on" % resource.tablename
has_created_on = any(rfield.colname == created_on_colname for rfield in rfields)
```

...and then use:

```
if has_created_on:
```

instead. That makes it a bit more obvious - and it exits early yet provides the flag this needs. Then have the inner loop like:

```
for rfield in rfields:
    if rfield.colname != created_on_colname:
        append_column(rfield.label, row[rfield.colname])
```

But as I said: it's only about style, and whether or not people can easily understand the code. Technically, your solution is totally correct and acceptable.
I also appreciate that you copied this from a generic case - and that this generic case is a bit over the top. So, not your "fault" ;) but of course something you /could/ improve. If you wanted to and had time to waste...

I'll leave this for my next/future PR's ;)

Of course, np.

start_end_date function is used for that disabling some dates. Infact this is used everywhere else why need a seperate widget (when we have a method that already does that).
Please Correct me.

@nursix : More uniform would be making the fieldname of project_activity as 'start_date' (Why keep only the label 'Start Date').
Anyway I still didn't understand why you dont want to call start_end_date similar to this:
https://github.com/flavour/eden/blob/master/controllers/project.py#L246

> Maybe you forgot to add it?

Please explain.

So, this is unrelated to your other work on start/end date selection?

S3.start_end_date is certainly fine here - I just mistook this commit as related to your other work (very similar commit messages and names).

O okay actually you thought it was gauravmittal95's commit(https://github.com/flavour/eden/pull/1013)? So do I need to change anything now? @nursix 

Really sorry - I mixed this up - was just looking at another PR with a very similar commit message (and topic), and got confused over the apparent "change in direction". Collateral damage, really - too many parallel threads, too much chasing.

Your commit is just fine and good to merge.

Okay thanks - well again I am asking this doubt shouldn't the fieldname of project_activity be 'start_date' instead of just 'date' (Anyway label is "Start Date") @nursix ?

The discussion about renaming "date" into "start_date" is not new, but here is what stopped it from happening:

There are /a lot/ of live production data that would need to be migrated, and /a lot/ of related XSLT and other scripts...so this is not "just" to rename the field - it would require a major operation, for very little benefit especially on the user side (where the effect of it is equal to zero).

True that! Okay :+1: 

Hence: heads up when you first create a model. It's a bit like jumping from a skyscraper - after you've jumped, you can not "just" change your mind between the 48th and 47th floor and return to the roof.

HAHA ;). Since you are not on IRC I am troubling you here:
http://127.0.0.1:8000/eden/hrm/staff/summary --> menus -> search by skills
What is this for?
Something's really wrong with this --> It says create skill inside it gives another option for create skills, sometimes after filling the form it gives "record not found", sometimes insert takes place in hrm_competency. @nursix 

Shouldn't "Competency" be made a different menu item and have options to create and search independently?

Post-production field name changes always cause major trouble - and can disrupt critical workflows. 

We had that once in a production system where suddenly the recipient fields in a messages table were all blank - thereby making the whole system completely useless. Luckily we had a backup so we could reconstruct the data, but the service was however down for a whole day.

You really need a better reason than code cosmetics to do that, and even if you have better reasons, it is usually better to introduce a new, independent field and leave the old field in place (e.g. hidden) for some time so that production systems have a chance to migrate without loosing critical data.

And you must adapt a lot of code, and have plenty of fallbacks to handle existing data in the old field (and issue deprecation warnings)...and so forth. A lot of things to take care of, not something you can do en-passant.

Most of the time, that's not worth it - especially since we have the ability to set arbitrary field labels.

Let me check this "search by skills" thing - I get back to you.

:+1: 

Obviously it should say "Search by Competency" not "Search by Skills". It is meant to find a staff member with a certain competency level for a certain skill.

The inner "Create Skill" is to define a skill - the outer "Create Skill" is actually a "Create Competency", i.e. it assigns a competency level to a person for a particular skill.

The "Record not found" error is indeed weird - most likely that is related to a filter inside the controller. Do you want to investigate that or shall I?

Well @nursix : I'll check and get back to you(Hopefully with a PR) :)

This is the problem:
https://github.com/flavour/eden/blob/master/controllers/hrm.py#L565

The "Person" selector allows you to select any kind of person - even if not type==1 (Staff). So you can add a competency record for a person of type==2 or no type at all. Then, after form submission, it would try to redirect to the competency record you just created, but since it is not of type 1 as the controller requires it, it can not be found, hence "Record not found".

Two possible ways to solve that:
1) Do not apply the filter if you have a record ID in the request (r.id)
2) Do not allow the selection of persons who are not type 1

IMHO, both should be done.

Secondly, we do not have pure "Search" pages - almost every "Search" page will also allow you to add a new record (standard). It may be useful to make the "Create" button a bit less prominent at this point (e.g. by moving it to the right, like done in CRMT), so that it is perceived as an additional option, and doesn't cause confusion - but completely removing it is not what we want to do.

Third: no - there should not be a separate competency menu item, because that is actually not a separate workflow. The standard workflow here is to add a competency on the "Skills" tab in the Staff record itself (compare these two forms and you will see the logic in it).

In fact, for this particular case, we may even want to remove the "Create" button from the search page - not because it would be invalid, or for UX reasons, but rather because it isn't the intended workflow. But it is beyond me to make that call - this is something the users should come up with.

I would fix the above two points for now, and then leave it at that.

@nursix : Can I make these changes?

Sure.
I will then put the Create-button in a nicer place. Like this:
![ss22](https://cloud.githubusercontent.com/assets/1257183/5644988/fee53cb2-9669-11e4-9c14-1cad49fd8411.png)

Okay :+1: thanks :)

From the user-perspective, I think this is 'Search by Skill' - more people will understand this than 'Search by Competency'...of course internally where we're filtering a Person list by Skill, we'll do so using the hrm_competency link table.

How about "Search by Skill/Competency"? ;)

Seems noisy to me & an extra string to translate

:+1: okay. So I'll keep "Search by skill" in the menu and competency inside?

Absolutely.

A bit confusing it is to have a "Create Skill"  inside a "Create Skill", however - so how to make clear that in the first case it is the "Skill of a person", and the second case it is "the Skill" in general?

No better idea at this point, though - and neither the time nor the _skills_ to fight with labels :D

Sorry, my comment was in reply to Fran, not your question. (leapfrogging a bit)

Suggest not to change any labels, but just fix the filtering issue for now as discussed.

Well just about to ask that. Okay!

Note: both staff and volunteer module have this search by skill option, 
So now how should I check in pr_search_ac that the query should be filtered according to type==1 or type==2? 
PS: I am trying to display only staff members in staff module and voluteers in vol module in Autocompletewidget @nursix 

E.g. using a different controller (S3PersonAutocompleteWidget takes "controller" as parameter) => "hrm" in the one case, and "vol" in the other. Or you allow S3PersonAutocompleteWidget to take an additional parameter so that it filters by HR type (optional).
I would go for the latter, but the former is very ok too.

Note that using a different controller (and then using that in pr_search_ac to determine what to filter for) may be a lot easier, but way less flexible.

Allowing the specification of URL filters for the Ajax URL would give us the ability to filter by _anything_ we ever need, since pr_search_ac is RESTful and thus processing URL filters - including the ability to change these filters dynamically at the client side ;)

E.g. selecting a driver for a fire engine => only show people who have a driver license... (just making it up, but doesn't look too silly).
If you can't add this to the autocomplete widget, then I would - it's a fairly small change for a BIG effect.

NB if you add a URL filter to the widget, nothing needs to be changed in pr_search_ac ;) URL filters are processed by the REST API before the search_ac is called.

Instead of adding controller to the data, you could add "&~.human_resource.type=1" to the url, and remove the server-side processing of the "cont" option.

Even better would be if you allow the URL filter to be passed in from the widget. Then we are free to define whatever we need, wherever we need it.

@nursix : I'll do as you told. I need to understand filters properly. Thanks a lot for your help.

Well, 

the general flow of RESTful request processing in Eden is:

```
client => controller => S3Request (via s3_rest_controller) => method handler
```

The S3Request interface creates a filtered S3Resource instance for the requested URL, e.g. a request to pr/person generates an instance of the pr_person resource. 

By default, this resource is filtered by accessibility (only the records which are not deleted) and by permissions (only the records the user is permitted to access) - and you can specify additional filters in the request URL, e.g. you could specify:

```
/pr/person?~.first_name=Dominic
```

...to filter only for person records where the first name is "Dominic". Multiple filters are possible, and you can specify filters along any thinkable join axis, e.g. components, link tables, foreign keys.

The filtered resource is then passed on to the method handler. In this case, the method handler is pr_search_ac, and it has the signature:

```
pr_search_ac(r, **attr)
```

The "r" parameter is the S3Request instance, and r.resource is the filtered S3Resource instance generated by this request. When you select from this filtered resource like:

```
data = resource.select(...)
```

...then this select will apply all the filters (accessibility, permissions, URL filters) _plus_ the filter that is set by pr_search_ac itself.

So, if you pass in the additional filter for "human_resource.type" via the URL, there is nothing about that you need to process in pr_search_ac - r.resource already has it when it arrives in pr_search_ac.

If you pass this URL filter to the widget, e.g. by setting:

```
field = s3db.hrm_competency.person_id
field.widget = S3PersonAutocompleteWidget(ajax_filter="~.human_resource.type=1")
```

...and then let S3PersonAutocompleteWidget pass this filter on to the s3.autocomplete.js script, and let the autocomplete script add it to the Ajax URL that calls back to pr_search_ac, then you have a perfect way to specify additional filters for (person-)autocompletes.

Of course, the vol/competency controller would specify a different filter ;)

But with that, you can do more than filtering by "human_resource.type=1", e.g. you can also specify things like "human_resource.organisation_id$root_org=3" (to filter by members of the same organisation as the logged-in user), ...or whatever else you might need.

NB the whole filter form framework works this way - by adding filter queries to Ajax URLs. E.g. when you type something into the filter form in the org/organisation page, then the filter script will add it as a URL filter to the Ajax URL of the datatable, and then just Ajax-refresh that datatable.

The filter form can handle multiple "targets", e.g. in summary pages: you can have a datatable, a map and a pivot table report - and the filter form would update all their Ajax URLs at once, so that you can switch between the different views without loosing your filters.

URL filters work for all URLs in a REST controller - including XML exports - so its a universal framework.

Well thanks a lot @nursix , seriously this encouraged me. Thanks. I will send the changes tomorrow(If you dont mind)

Use r.error(), do not just redirect without any error message.

This will _never_ raise an exception - it could just be None.

except what? No catch-all excepts please.

r.application, simply

Doesn't make sense to me. You can just use r.record here - no need for the extra DB query.

Goodness! Line length limit is 80 characters, not 30!

No - id = "[id]" indeed.

...although - hang on. You are using r.id as translation_id - but bind the method to survey_template? That doesn't quite make sense - r.id would be a survey_template.id, not a survey_translate.id.

Ahm - you bind the method to survey_template, but you are inside the survey_translate model!

This method would never be bound to survey_template (because it loads the survey_template model, not survey_translate)

I think that you should bind this to "survey", "translate" instead - that is what your action button wants.

...but if you bind the method correctly to "survey", "translate" - then it would be a survey_translate.id indeed, but then you would have r.record and no need to re-load it.

:+1: 

Not a valid MIME type, btw - browsers may not have a binding for that. Should use "application/xls" or similar (there is no true standard, but application/xls is very likely to be present in most browsers)

Ahm - ok, I see that this is using contenttype, so strike the above

The web2py implementation is correct.

...uses the official vendor-based "application/vnd.ms-excel"

I missed the contenttype-call, sorry.

Can you explain the difference.

template_id = all hardcocded to that template
"[id]" = use the ID of that row
- this is an action button for a dataTable Row, so each row should have a different ID

Would be good to see a minified version of this file

This is generally not how parameters should be documented.

I'm still not convinced of the value of this deployment setting.

Imagine this setting in a web setup UI! Who is going to configure it? 

I think people will find it like a setting for the standard colour of snow, and isn't it rather so that the validity periods of credentials typically average around a year, with some credentials (not deployments!!) having a longer, and some a shorter standard validity?

IMHO this should be a user-facing widget, where the user selects a start date and then, /instead/ of picking an end date, he selects an interval length from a drop down with one option being to choose a particular end-date. I've described this before.

Really - this setting smells trick question. What would be the incentive to change it? What would be the right value?

I think if at all, then the intervall differs between types of credentials, not between deployments.

@nursix U mean for different Job Titile? So for different Job Title, it should have different days between start and end date?

What I mean is that the user shouldn't see start date and end date, but start date and interval as that are the parameters he normally has at hand.

The "interval" would be a drop down with options "6 months", "1 year", "2 years", "5 years" - plus an additional option "Set End Date" which allows to enter a concrete end date if necessary. There should probably also be an option "permanent" which means "no end date".

I'm saying that because I think that typically, the standard period of validity of credentials does not differ between deployments, but between a) credential types and b) organisations, so that it is actually not possible - or at least futile - to define a useful site-wide standard period.

And yet UX can be significantly improved by a widget calculating the end date from start date and time interval instead of letting the user calculate the end date and then enter it. It's a computer, after all - so it shouldn't delegate computing tasks to the other side of the screen, and this one here can be anticipated.

I think deployment_settings are not always the right solution for certain problems - and this one is IMHO better solved with a widget.

If you will, the actual, primary meaning of the ToDo is to relieve the user of the end date calculation - and to work with the parameters he's typically given.

In my eyes, entering a concrete end-date is an edge-case - yet the form demands it, with or without automatic calculation from a site-wide standard interval. Thus it doesn't really support the user - and to the contrary, the standard process in the user's mind would be to verify the automatic value, hence he would still have to perform the calculation.

If, by contrast, the user can enter the interval instead of the end date _then_ you've really made a difference here.

That again is a common case - there are multiple forms (e.g. projects, activities, deployments, missions...) where we ask the user for start and end date while he more often has a start date and a time interval, so this could very well be generalized.

Why in attr and not explicit?

Globals? Hmm :/ is this really necessary?

Do we really need a field for this? I think client-side widget would be just fine.

@nursix I made this option, so that for some situation when the end-date is required we can change this to false.

I wouldn't hide the clear-button even if the end date is required.

You could action this ToDo, and make the actual intervals (and probably the number of buttons) configurable.

Obviously, the button labels need internationalization.

Beware comma after final member of set: Breaks compile as breaks older IE

Missed the "todo" here? Not "remove this" but "rewrite this"

But the function isnt called anywhere.

Primarily I was trying for the todo but didnt find where was this used.

Can't just drop the field name here.

That's intentional.

This case can indeed be dropped.

+1, I think this can be removed.

I think we want to retain this functionality - but probably as action button.

Why show the Create Organization option then after submitting the popup it goes to this url
http://127.0.0.1:8000/eden/inv/adj_item_new_owner_org_id/options.s3json?field=organisation_id
which indeed is not defined

What is the functionality?

:+1: 

I wonder whether that needs a separate controller-action each and every time? It would be a lot better to place this into the s3_date constructor, and then apply it in the respective model - otherwise we need to repeat this a thousand times.

+1 To the idea will work on that. Will this be merged or I shall close it?

It's writable=False, and should therefore not have any AddResourceLink (set comment=None). But it should still be writable=False.
The URL is wrong due to an invalid caller-setting, which again is caused by this being a read-only field. So, simply remove the AddResourceLink here, but leave the writable=False in place.

Awesome! thanks :)

I would like to stop this here before merging even more of those injections. Better to have a DRY solution in s3_date and apply in the respective model.
Here for example you target pr_identity - but pr_identity is used in multiple places. Shall we really inject this from multiple controllers rather than only once in the model?

Providing an action item to see the candidate matches for the current body.

However, you _must_ retain the field names - these are two different fields, hence need two different field names.

It currently not called because the menu framework has changed.
However, it should not be in the menu anymore - but rather near the record (either as action button, or e.g. as a tab in the record view, or both).

+1 to Model (I thought exactly the same when merging the last one), although this should be as an S3ScriptItem so only gets added only if rendered, not just by running the model...

Okay I'll close this PR and merge the minor form fix in my other PR, @nursix s3_menu_postp should be as is yeah? Will consider that @flavour :)

I'm not saying it "should be as-is" - I'm just saying that we would want to retain the functionality and re-implement it using current functionality and design rather than just removing it. How exactly we do that - that's a separate question. I don't think it should still be in the menu.

@nursix :Yeah ;) I meant specific to this PR. Can you review my other PR if possible?

What is this for?

Do we really want this to NOT be a 'row'? (That has clear meaning in Foundation at least)
Perhaps just add a 2nd class to distinguish in CSS - e.g. .row.home

This is a fix fior something else?

Looks like it's to ensure the list_fields in aadata match interactive.

After this change
.row {
    margin: 0px;
} 
when i opened the index page then the alignments of homepage elements gets distorted . So i added the row-home(according to the foundation css)

SSF template is not using foundation, and row-home is not a foundation class.

But row is a bootstrap class ;)

I wouldn't do that (at least not globally) - better follow bootstrap.

i mean to make the alignment of datatable , forms i changed 
.row {
margin: 0px;
} 
since this made the wrong position of  homepage elements (buttons ,etc) so i changed the row class to row-home as that problem is only occuring in the index page so i changed only in the index file
row-home {
    margin-left: -30px;
} as it is based on the bootstrap.css

but without doing this the alignment of forms and data tables are not in correct order as they should be aligned with the Sunflower logo.
So i used this globally.

The solution I was thinking of was to define SSF specific html files...Since no html files are defined right now, it takes the foundation ones, and hence, the classes are applied in a wrong way.

I understand - but it's still not the right fix.

The problem is rather that this is using the default _list_filter.html, which is a foundation grid layout - and bootstrap doesn't understand the "columns" class (bootstrap is using span-x). 

Hence, the right fix would be to implement a suitable _list_filter.html for bootstrap using span-x classes instead of columns.

Overriding bootstrap in order to deal with a foundation layout brings up the question: why use bootstrap then?

Thanx.. :+1: 
When i changed _list_filter.html for bootstrap using span-x classes , only the data table get aligned.
So i have to do that for others also ?

Not "change" _list_filter.html - you need a custom one in the SSF template.

This one would work:

```
<div class='row'>
 <div class='span-12'>
  {{try:}}{{=H2(title)}}{{except:}}{{pass}}
  {{try:}}{{=s3db.ocr_buttons(r)}}{{except:}}{{pass}}
 </div>
</div>
<div class='row'>
 <div id='rheader' class='span-12'>
  {{try:}}{{=XML(rheader)}}
 </div>
</div>
<div id='component' class='row'>
{{except:}}
 </div>
</div>
<div class='row'>
{{pass}}
 <div class='span-12'>
  <div class='row'>
   <div id='map' class='span-12'></div>
  </div>
  <div class='row'>
   <div class='span-12'>
    <div id='list-btn-add'>
     {{try:}}{{showadd_btn=showadd_btn}}{{except:}}{{showadd_btn=None}}{{pass}}
     {{if showadd_btn:}}{{=showadd_btn}}{{hide_listadd = True}}
     {{else:}}{{try:}}{{=buttons["add_btn"]}}{{except:}}{{pass}}{{hide_listadd = False}}{{pass}}
    </div>
    <div id='list-add'>
     {{try:}}{{=H3(addtitle)}}{{except:}}{{pass}}
     {{try:}}{{=addheader}}{{except:}}{{pass}}
     {{include "key.html"}}
     <div class='form-container'>
      {{try:}}{{=form}}{{except:}}{{pass}}
     </div>
    </div>
   </div>
  </div>
  <div class='row'>
   <div class='span-12'>
    {{try:}}{{if list_filter_form:}}
    <div id='list-filter' class='form-container'>
     {{=list_filter_form}}
    </div>
    {{pass}}
    {{except:}}{{pass}}
   </div>
  </div>
  <div class='row'>
   {{try:}}{{ltype = list_type}}{{except:}}{{ltype = "datatable"}}{{pass}}
   {{try:}}{{items = items}}
   {{if ltype == "datalist":}}
    <div id='dl-container' class='span-12'>
     {{=items}}
    </div>
   {{else:}}
    <div id='table-container' class='span-12'>
     {{=items}}
    </div>
   {{pass}}
   {{except:}}{{pass}}
  </div>
 </div>
</div>
<div class='row'>
 {{if s3.rfooter:}}
 <div id='rfooter' class='span-12'>
  {{=XML(s3.rfooter)}}
 </div>
 {{pass}}
</div>
{{if ltype == "datalist":}}
{{include "dataLists.html"}}
{{else:}}
{{include "dataTables.html"}}
{{pass}}
{{if r.http == "POST" or not hide_listadd:}}
{{script = '''$('#list-add').show()
$('#show-add-btn').hide()'''}}
{{s3.jquery_ready.append(script)}}
{{pass}}
```

But hey...this is a very crude translation of the default _list_filter.html into bootstrap. Rather than that, you may actually want to make one that fits neatly into the Sunflower design ;)

Wait I have done something ;) 

Right what I'm saying @hitesh96db - overriding bootstrap.css in order to make it work with non-bootstrap layouts somehow defeats the original idea of using bootstrap.

But of course, alternatively you can throw out bootstrap and use foundation instead ;)

@flavour I will leave this here for now, so that when @raj454raj does it, he can easily find this and replace it

@raj454raj , I have already done this in my PR (https://github.com/flavour/eden/pull/1042), please remove this as it will cause merge conflicts with mine. And also some other options are needed to be added.

@raj454raj , I have added project_project, project_activity, project_beneficiary in https://github.com/flavour/eden/pull/1042 . Please refer to this PR and remove these, as it can cause merge conflicts. Thanks :)

Okay I'll remove that after review, the idea was to add start_field to ALL the places where the pair occurs so...

Is this over-riding explicit attr["widget"]?

Can we not remove the else = None here?

Why bring this into top-level scope since only used once - just use self.default_interval the one time it is used.

I don't think this has a default_interval at all...Locations change based on local politics

A survey_series is normally a very brief time...default_interval might be 1 month

Does this work with datetimepicker?
That is because the S3DateTimeWidget uses datepicker only if explicitly requested.

I'm not sure that this makes sense everywhere. Looks like you're applying it all over the place without enough information about the requirements - which could actually confuse users rather than helping them.

We also pay (in the sense of "processing time") for the script injection without any actual requirement.

Actually, there is already an option for S3DateTimeWidget to link the fields like this. Your addition does interfer with this, and should actually not be introduced here.

This ^ is how it is done in S3DateTimeWidget. "set_max" and "start_field" do basically the same thing. So, you do not need to introduce a new way to do it.

But as you can easily see - you can well remove the widget = S3DateTimeWidget for this particular case, and use s3_date with start_date (i.e. regular datepicker, not datetimepicker without time). 

Because...this was using S3DateTimeWidget only for the reason that the min/max option did not exist in S3DateWidget, and now that this option exists in S3DateWidget, this is not necessary anymore.

Okay :+1: 

I get that :)

What are the models for which this should be applied? This would be tough to decide. I am not able to understand why is it a problem adding this wherever the pair occurs? @nursix 

I'm suggesting that there isn't necessarily always a problem that requires such a functionality, and that sometimes the problem can not be solved so easily.

This script does not work with inline-forms (or otherwise forms which work with different field names), since you're hardcoding the selectors - and hence applying it indiscriminately everywhere leads to unpredictable side-effects.

It is good to have the option, but I don't think that applying it just _everywhere_ is the right thing to do. In most of these cases, people have either not entered any end-date before the start-date simply because they understood as much by themselves - nor has that had any negative impact so far.

I'd be more careful with this - it's not universally applicable, and users are not generally stupid and destructive.

@raj454raj - the problem is that this option assumes a particular HTML element id. That will work with default forms, but we are increasingly using custom pages with custom forms and custom widgets - so that we often end up with different HTML element ids.

In those cases, the start_end_date will not work properly and can even have side-effects on other page elements, or other scripts that are injected into the page.

So, what I mean is that you need to check very carefully on a case-by-case basis (and across all the different pages in all templates which load that same form) whether it actually works without undesirable side-effects - rather than applying it indiscriminately everywhere.

That applies for _every_ widget application, not just this one - it is a mistake to conclude from one case to another without explicit validation against requirements. 

The fact that this script has been around for so long, yet has only been used in a few occasions doesn't suggest negligence but rather that there hasn't been the requirement to use it more commonly - or, in fact, the script is not as universally applicable as it seems. Since it doesn't easily adapt to form variations (especially due to hardcoded element IDs), I think it indeed isn't so universal and flexible, let alone failsafe.

True! But do we want the developer to add the scripts in every controller wherever the model was used - This was the problem we discussed previously. Checking by case-by-case would be really tedious task to do. So what do you expect from my next PR for revision to this one(If required)? @nursix 

Good question :$ sorry for not being more constructive...

No, we do not want this to be injected in controllers, but rather have this to be a model option - but as it says "option" it means "where suitable" not "everywhere as standard".

What I would expect after what I have said is:
a) that you improve the start_end_date script so it would work both in standard forms as well as in inline-forms without need to alter the setting.
b) that you investigate each case that you identified for whether any template uses a custom form, and if so, then adapt that template so the script does not interfere with that custom form (this will be very little to change, but a lot to investigate indeed).
c) that you include the caveats in the documentation of the feature
d) that you consider how this can generally be introspected rather than having the element IDs hardcoded (that is possible! Just _think_ about it ;) )

Maybe start in reverse order ;)

@nursix : ;) thanks :+1: will look into it.
Sorry for asking you here, can my other PR be merged followed by further refactoring?
 You didnt told me what are the next changes I have to do. I'll be writing unit_tests for this but it will take time. 

I'm sorry - I'm not keeping track of PRs, so I don't know what "your other PR" is.

If something isn't answered yet, then that is simply /because/ you have submitted multiple PR's - and since I can only deal with so and so many parallel threads (sorry, I'm only human), it is very likely I will only look at one at a time. Close one, and I will look at another ;)

Yeah sorry for not providing the link. Actually I didnt wanted to refer it from this. But anyway https://github.com/flavour/eden/pull/1034

@nursix ^

Am I too slow responding? 20 minutes is really very tight to respond to the question "what next", don't you think?

Sorry!

Didnt know how to improve this!!! Any Suggestions?

Unused?

Nah - there is still one use-case. Maybe should be moved into that function.

:+1: 

This looks like it's obscuring the actual error - very bad style.

We do not normally use case-sensitive URL vars, nor does a RESTful method handler actually need method vars. It would be better to bind this method to two separate methods (=2x set_method with the same action, then check r.method inside the handler)

Same here - camel case URL var. Very ugly and fragile (URLs should not be case-sensitive)

Then redirect from that function to survey/series with session.error ?

First of all: naming convention! No camelCase please, but underscore.

Secondly - try to remove any unnecessary local variables, and move them closer to where they are used.

Not our normal style for comments.

No parameter description in docstring

Line limit is 80 characters, not 60

Two S3Method classes like this:

```
class series_ExportSpreadsheet(S3Method):
```

 and 

```
class series_ExportWord(S3Method):
```

:+1:

Yeah ;)

Do we actually need all those different writeToRTF's? Or can this be DRY'd? It seems to me that much of this could be parametrized, and hence a lot of code removed.

Changing names in this module would be my next PR?

Maybe consider switching to easyxf

Repeated lookup of xlwt.Alignment.HORZ_LEFT, consider local var "HORZ_LEFT"

Same - repeated lookup

xlwt.Borders.DOTTED xlwt.Borders.DOTTED xlwt.Borders.DOTTED xlwt.Borders.DOTTED 

A thousand times...

:+1: 

Except without exception class - no catch-all excepts please.

Move these assignments closer to where the variable is defined.

Uses only border styles => move closer to the border definitions

There is truly a nicer way to do this.

I'd recommend to move out the inline-functions. Inline function definitions are useful if the exact definition depends on a condition - but it seems that these functions are constant, even static (no self-use!), so they should be moved out and made staticmethods.

s3_unicode please

"Ouch" (technically) - "Hmm" :S (style-wise) - "OH!" (for the idea to actually parametrize it, even if not done eventually)

Catch-all except - should be avoided. What exactly can go wrong - and is there actually a valid state after that?

Here starts the actual function - which is a few miles away from the def. Very hard to read and debug :/

Avoid "vars" - call it either "get_vars" or "post_vars" or "request_vars" ("vars" is a Python keyword)

Eeek - no!!!

If output.seek(0) raises an AttributeError, then something has gone wrong before. So why make it raise a completely different exception here instead of catching and handling the error where it happens?

This is provoking an exception in order to catch it! We should never get here unless output does have a seek().

It happens here https://github.com/flavour/eden/pull/1034/files#diff-c87b764fac9b35c325082f7c2cc850f4R3714
So do you suggest to redirect from here

Iiirrgh - and that doesn't even return anything :/

I would suggest to move this check out of the subfunction and into apply_method (at the top), and check and raise the error before even attempting to do anything else. Even better would be to also remove the related action buttons (+log a warning).

Here is where you should check for xlwt - because if it's not present, every subsequent action is futile.

If you move the action button definition into a function, you can even hide those if xlwt is not present.

:+1: 

Got You!!!

No, can be the same method handler class - just bound to two different methods ;)

Here's the logic:

```
set_method("my", "table", method="first", action=MyHandler)
set_method("my", "table", method="second", action=MyHandler)
```

That way, it can be called either with /my/table/1/first or /my/table/1/second. When you get into apply_method, you can check which:

```
def apply_method(self, r, **attr):
    if r.method == "first":
        # called with /first
    elif r.method == "second":
        # called with /second
```

Quite simple - no get_vars acrobatics.

It is btw best practice to move the actual method into a subfunction:

```
def apply_method(self, r, **attr):
    if r.method == "first":
        return self.first(r, **attr)
    elif r.method == "second":
        return self.second(r, **attr)

def first(self, r, **attr):
    """ Subfunction for /first """

def second(self, r, **attr):
    """ Subfunction for /second """
```

...and then call commons from there.

In principle, all methods within the same set of functionality would typically be built into the same method handler class - you do not need to create a new method handler class every time (doesn't even make sense DRY-wise).

Maybe consider even to merge in the other two if that has advantages DRY-wise.

Some examples:

Primarily URL-controlled:
https://github.com/flavour/eden/blob/master/modules/s3/s3crud.py

Partially HTTP-controlled:
https://github.com/flavour/eden/blob/master/modules/s3/s3merge.py#L45

Pure REST:
https://github.com/flavour/eden/blob/master/modules/s3/s3hierarchy.py#L52

@nursix : Can you help in this.

+1 to DRY this.

I would rename the base function as "_writeToRTF", and the specific caller functions into "writeQuestionToRTF" etc., rather than overwriting the base method and calling super() every time (yeah - unfortunately Python doesn't support overloading).

The base function _writeToRTF can then probably be staticmethod (so self-access as far as I can see?), which makes it a bit more efficient.

Else - good work.

As I mentioned it before - I think all these configurations should probably be in a subfunction, so that the actual function starts after the docstring ;) otherwise one has to scroll and scroll and scroll until the actual function appears.

@nursix : Couldn't do this https://github.com/flavour/eden/pull/1034#discussion_r23083418 because styleHeader is used here so. There is a bad way to return styleHeader and styleList both from the function. But then this seems to be better than that! What say?

Ahm - styleHeader == style_list["styleHeader"] so where is the problem?

Okay my bad!!!

Consider the following (schematic):

```
class BaseClass(object):
    @staticmethod
    def _complexMethod(param,kwarg1=None,kwarg2=None):
        pass # do something

    def wrapper(self, param):
        """ Wrapper for _complexMethod to simplify the call-pattern """
        return self._complexMethod(param)

class SubClassA(BaseClass):
    # This class uses the standard wrapper (=no subclass-implementation of wrapper required)

class SubClassB(BaseClass)
    def wrapper(self, param):
        """ 
            This class uses more complex call signature of _complexMethod, hence overwriting
            the default wrapper to pass in an instance attribute.
        """
        return self._complexMethod(param, kwarg2=self.attribute)
```

That way, the wrapper method needs to be implemented in the subclass only when it uses a more complex signature of _complexMethod - otherwise the simple default wrapper() of the base class will do.

Generally, of course, the wrapper would only be useful if called from outside the instance (otherwise it would unnecessarily complicate the flow).

...or look at it like this: the wrapper is good to build an abstract interface, where the outside caller doesn't need to distinguish between the subclasses, but calls the instance method with always the same call signature (just "param"). The instance itself would then "know" which other parameters to add before calling the actual _complexMethod.

This is an acceptable reason for a wrapper - otherwise wrappers are problematic.

web2py's DIV class (+subclasses) make a good example for this structure ;)

Okay thanks :), sending changes in some time.

That is not how we normally do it. All callbacks in configure can be lists, e.g.

```
create_onaccept = [custom_project_task_onaccept, create_onaccept]
```

...and will then be executed in list order.

Not that way, no - make the onaccepts a list in configure.

Why test this after the standard prep?

Further - what is the difference between r.get_vars.format == "msg" and r.representation == "msg"? Answer: r.get_vars.format=="msg" will only detect ?format=msg - whereas r.representation=="msg" will detect both .msg extension as well as ?format=msg.

So, this should be:

```
if r.representation in ("msg", "rss"):
```

However, if you intend to return False for all other formats anyway, then you can equally well skip the standard prep.

Stupid questions: Say - Fran creates a new task (he gets subscribed and is made a member). Then, I update the task description to better reflect the problem.
=> Does Fran remain subscribed as the task author?
=> Do I get subscribed as a new member (or as author?)?
=> Is that correct?

Or other funny task actions: say, I update the task status from "closed" to "reopened". Will I become the new "task author"? Will I get subscribed to the task? Will I become a member? Not? Why not? Will I? Why?

Yeah...I know, now I'm becoming a PITA.

@nursix 
Fran creates a new task  - you update it..
Does Fran remain subscribed as the task author?
--- Yes(subscribed to it), but note, there's no author role yet..
Do you get subscribed as a new member (or as author?)? 
--- No, but if you're updating it, that would mean you're interested in the task(?), So.....Click the 'Watch' button :D ?
The idea here was to keep the author subscribed to the task, so that,
- if a user comments, there's someone to answer/reply to that
- if the task is edited, the author knows about it ;)

:+1:

Ok, understood.

What the point with this additional variable?

That's the default

Using append() is faster than +=

@nursix Sorry, i dont understand ... what is default?

These input labels.

@nursix I see, So should i remove the whole label option, or leave it as T("Date") ??

Huh? No - I said these input_labels are default, so they do not need to be specified.

@nursix , Oh sorry, Didnt realise that! That was already there in the code, so i though u were reviewing the part which i changed ... will remove the input_labels

@nursix Done

Still don't get the point with these additional variables - they don't seem necessary?

There is no need to provide a label if the field has a label. In fact, it is often better to stick with the field label.

The might become a bit messy, tbh - there can be multiple budget allocations for a site, and then it'll be hard to see which allocation belongs to which start date, or which end date belongs to which start date. Shouldn't be separate fields - rather have a represent for the allocation.id and only list those as a single field.

Questionable that too - why would we want to filter sites by budget allocation start date? More likely that we would want to filter by sponsoring organisation (=budget owner), or by whether there is budget allocated to the site at all.

@nursix Sorry, i dont understand.... Represent allocation.id as what?

Obviously represent the allocation.id as what it is: a budget allocation. That might include the time interval, the sponsor and the total allocated budget - or it could also be the budget name (although I doubt that makes a lot of sense) plus start/end dates. I don't know.

As I keep stressing: the requirements for this case are incomplete/unclear, we do need input from potential users. Trying to implement anything without proper understanding of the use-case and its requirements makes very little sense (and is a waste of time, tbh).

At the moment, we can do very little here.

As suggested by @flavour 

Shudder...

Surely you can rewrite this in a more readable manner?

Superfluous variable

Not in the model please (lazy tables) - move into the controller where it is needed.

Add a question mark to these ToDos - since the requirements are unclear.

Unspecific except - must have an exception class specified.

R.I.P. ;) =>
1) RECOVERY: Always only catch exceptions for which you have a correct, logical and effective recovery strategy. If there is no point to carry on after an exception (i.e. if you can not produce a useful result due to the exception) - then don't carry on! Log all exceptions where the recovery strategy (and thus the result) seriously deviates from the intended process.

2) INTEGRITY: Never catch exceptions you're not expecting - otherwise you may be hiding/obscuring errors which can have serious side-effects and potentially cause data loss or security leaks, but at least you'll make it seriously harder to find the underlying bugs.

3) PRECISION: Only ever catch exceptions where you are expecting them - do not have any statements inside the try/except that wouldn't throw that exception. Ideally, there should be only one statement inside the try/except, so that you know _precisely_ where the exception occured.

Or short: don't catch things that should not happen, don't recover if you can't produce a plausible result, and always catch one (and only one) condition at a time.

Remember that an exception will roll back invalid database transactions - unless you catch it. So you must be very very certain that you don't put the database at risk by catching an exception. Thus, you should put _every_ try/except in question: is this safe? is this expected? would catching it hide a more serious issue?

In this particular case: what could possibly go wrong? Why could it go wrong? Would this really be an exception - or rather a permanent condition due to a programming mistake that should actually be fixed rather than recovered from?

As far as I can see the only reason for this to fail is if you access fields that you didn't extract before - and if that happens, then you've made a programming error, and hence it would be a permanent condition - the user would only see "Unknown" for each and every row without any indication that this is caused by a programming error.

So:
- this should not throw an exception => don't catch things that should not happen
- you can not produce a plausible result => don't recover if can't produce a plausible result
- you're hiding a programming error preventing it from being detected and hence fixed => don't catch programming errors

So, IMHO there shouldn't be a try/except here.

@nursix Yes, sorry about this. This was just a basic implementation to check the logic .. I still have to refactor it and will make it better.

:+1: 

needed for adding what??

Since this is s3_datetime, it should use the built-in variant start_end_date in S3DateTimeWidget rather than being added manually.

That is, this one should have an S3DateTimeWidget(set_min="cms_post_expiry_datetime") (this needs to be implemented in s3_datetime, though), and then omit the manual injection of the JavaScript that anyway doesn't take care whether the field is visible or not.

"needs implementation" means: s3_datetime needs to pass the "set_min"/"set_max" options to the widget ;) the widget (=S3DateTimeWidget) does already support it, though. The start_end_date script is not needed for S3DateTimeWidget.

That's actually the default label. If you don't set a label, web2py will take the name, capitalize and translate it. So, not needed, actually.

Same here.

Use form_vars not vars (vars is a Python keyword)

Sort options alphabetically - hence "default" before "label"

You just added these tests to the test suite without actually checking whether they are valid?

Same here - are these test cases valid?

Note "overrides" - "implements"! It's an abstract method that is _meant_ to be implemented in test cases.

Can use dict, Storage not needed (generally should try to avoid using Storage unless you really need it)

Not sure what this is for? Better don't mix in unrelated CSS changes - or provide a screenshot for the change.

That is very little to verify the method, isn't it?

A lot of effort for so little Assertion - is that really enough to verify the method?

Not testing failure response in any way, and very little verification. Basically just checking whether it doesn't crash? For that though, you must at least test all possible cases (look at the "if" branches in the target function).

![screenshot from 2015-01-30 00 22 15](https://cloud.githubusercontent.com/assets/6368364/5964042/13ea7190-a817-11e4-8b7f-6615c3f49128.png)

![screenshot from 2015-01-30 00 22 43](https://cloud.githubusercontent.com/assets/6368364/5964069/318bb1dc-a817-11e4-9561-bc16c68d85da.png)

But still there are no tests written here.

Before: Without this  - IndexError is raised

Where?

Ahm...just first_name? You're kidding, right?

Do we really want filters on all tabs? I'm not so sure about this, especially since most of them are just text filters which actually works with the datatable filter already.

Ajax call -> redirects to a ticket

Sorry really forgot to add. Adding in a sec.

Ok - my actual question was: Where in the code is the exception raised?

Reason: if an IndexError is raised, then obviously the function _there_ is wrong and doesn't check whether the element it accesses exists in the list.

...which is wrong and should be fixed (instead of trying to avoid the condition by defining the element here)

Or in short: Do not work around bugs, fix them!

I think that set_min can (should) actually be passed in to s3_datetime rather than the whole widget configuration.

Hopefully this doesn't interfere with end_date_interval?

Is there a reason to change this into date?

Actually it was to pass the start_field, but now that set_min should be passed to s3_datetime, will keep it as datetime. 

No, not that i could see. I tried it on a end_date_interval start_date, and was working as expected

:+1: ... will do that

Let's be reasonable:

```
if item.authorized and (item.enabled or item.enabled is None):
    enabled = visible = True
else:
    enabled = visible = False
```

;)

:D 

That's the default

That too.

That too.

I would recommend to stick with font-awesome.

Foundation icons have only a fraction of what font-awesome provides - and foundation icons are a bit harder to recognize.

Personally, I don't like icons at all but prefer pure text. In my understanding (which comes mostly from medical devices), icons are hieroglyphs and thus the user has to learn a hieroglyph script to navigate the application, instead of just using the language he already speaks fluently. And secondly, there is hardly any consistent let alone standard icon "language" - every application uses its own interpretation, and that makes it rather harder to work with icons than with text.

But if it by all means have to be icons, then font-awesome is still the better choice.

Not making use of any columns-classes? Seems a bit strange.

"large" makes only sense if you have a different "medium" or "small". 

The principle is to design "mobile first", i.e. configure for small and/or medium, and then _add_ an alternative large-setting if necessary - but not have only "large".

I left the deployment pages as it is for now, I was told it has to be redesigned, so I didn't think about modifying it, I just removed the bootstrap classes.

Foundation typically using rem not px - which has advantages with proportional scaling (fixed pixel settings don't scale at all! rem does!)

Should really be rem not px so it scales proportionally with the fonts. px is absolute, rem is relative.

Why are you removing these?

Why is a different modules/templates/SSF/views/layout.html needed? How is this different from modules/templates/default/views/layout.html? Could you remove the SSF layout and allow it to default to the default layout? (This would mean one less file to maintain)

Suitable for default?

Why the different font?

Suitable for default?

Suitable for default?

-1 controlled by base foundation setting in default

Definitely not.

Yes, submit to edenthemes though so that all default-based templates can benefit

Generally, wherever possible, foundation settings should be used for default, instead of extra CSS to override them. However, the higher contrast was intended, so -1 to this change in default.

Although...hang on - this is side-nav not top-nav, so no foundation setting. Sorry, /me confused.

Note that the original side-nav colour was a bit lighter, but then intentionally darkened for better contrast.

Since there is very little point to keep changing colours forth and back, I've decided to put all main colours into the branding package (and also to ensure that they are used consistently throughout). This branding package is a bunch of SCSS variables that a derivate theme can easily change to match its brand colours, basically looking like this:

https://github.com/nursix/edenthemes/blob/master/EVASS/scss/_colors.scss

For the default configuration I've used a colour wheel to determine an optimal yet simple triple of colours - however, the side-nav was set to be too light and should be darker. Then other people come and say make it lighter again...as I say: forth and back and forth and back. No real point with this.

Personally, I would use different shades of green - and I'm convinced I can find a bunch of people who would like it. And some who would find it disgusting. That's how it is, and why it is neutral grey by default.

Should I add this to default/style.css ? 

Can I add new ones to icons.css or should it be specific to SSF ?

New ones? You mean icons which do not exist in font-awesome? Can you give an example?

If you are SCSS-literate, I would prefer to get this as PR for edenthemes, this one in foundation/scss/_widgets.scss.

Otherwise it can be added to style.css, and I will then backport to edenthemes.

https://github.com/nursix/edenthemes

...from there I can propagate it to all default-theme based themes, and also parametrize the background-color so it can be customized easily.

I'd recommend to make use of ICON instead of hardcoding icon classes. This would use an abstract icon name, which can then be configured in config.py.

Example:

Instead of:

```
A(I(" ", _class="fi-eye-open"), ...)
```

you would do:

```
A(ICON("watch"), ...)
```

And then in config.py:

```
settings.ui.custom_icons = {"watch": "fi-eye-open"}
```

Then, if you need to change the icon class (e.g. because you changed the icon set), you adapt this setting rather than the code. E.g. to switch back to font-awesome, you change this into:

```
settings.ui.custom_icons = {"watch": "icon-eye-open"}
```

That makes it easier to maintain and re-use, and you have all icon classes in a central place.

Note that for ICON definitions that are used in core code (i.e. across templates), a default icon class for the abstract name should be configured in modules/s3/s3widgets.py (ICON class).

In templates config.py, you /could/ hardcode icon classes - but that makes it a bit harder to switch (or upgrade) the icon set and to maintain consistency with core code, of course depending on how many icons the template uses.

Using ICON, the base icon set can be switched with a simple setting:

```
settings.ui.icons = "foundation"
```

...with no need to change any icon classes, except those which you have defined in custom_icons.

However, this particular icon doesn't seem to be any helpful - it's not very explanatory, nor familiar, and could easily be misinterpreted as action to open ("view") the item, and since it's not repeated in related contexts, it doesn't really have any purpose whatsoever.

Font-awesome icons are used by writing 'icon-envelope' which is defined in icons.css, right ? How can I access all the font-awesome icons, apart from adding them in icons.css ?

It doesn't ? I thought this icon was the easiest to understand, an "eye" next to "Watch" :D - like how Github uses it for "Subscribe". I noticed that "CRMT" uses it for open/view but I think it makes sense in this context as well.

Is this a serious question?

Replace:

```
../themes/foundation/foundation-icons.css
```

with:

```
bootstrap/font-awesome.css
```

...and then just change all "fi-..." classes into "icon-..." classes. Or even better follow my recommendation and use ICON with abstract icon names instead of any specific classes.

Does the "eye" explain the "Watch", or the "Watch" explain the "eye"?

As I see it, the "eye" does not add any information to the "Watch" label, nor does it give any hint what "Watching" a task actually means. Nor is it repeated in this context anywhere so that it would help to make a connection - so quite obviously it lacks a purpose. It is just decoration, not adding any value whatsoever. 

That does of course equally apply to the GitHub "Watch" button :P

Ah, okay, I was unable to find font-awesome.css, I thought that /only/ needed ones were added to icons.css, and the default/icons.css is the only source.
Yes, ICON is much easier to configure and use.

The CRMT icon for "View" is even worse as it lacks a label.

The open folder icon, the magnifier icon, the arrow-into-document icon - all these are far more familiar for the "view" action than the somewhat exotic "eye" icon.

Anyway - the term "watching" a task is not self-explanatory. What does it mean?

"Subscribing" to task updates seems more self-explanatory (and indeed it gives a hint that this "Watching" is about getting notifications about updates), and so are probably subscribe/unsubscribe icons.

And the "eye" tells nothing about "receiving notifications on updates" whatsoever - not the slightest hint on email notifications, nor about task updates. 

default/icons.css has rather historical reasons - as a method to have theme-specific icons before ICON existed.

It could be deprecated, in favour of icon-set specific CSS (easier to maintain) - and if you include font-awesome.css, you can of course omit default/icons.css.

For the default theme, however, I'd like to migrate to FA4 - but for that I first need to get all I-tags replaced with ICONs, which is still a bit of work "ToDo" ;) (meaning: feel free to join the effort)

But please - feel free to keep the "Watch" and the "eye". That won't be any problem for this PR (it's rather my opinion as an end-user).

My point here was actually about abstract ICONs vs. hardcoded icon classes.

I guess adding a tooltip next to the 'Watch' button would help.

I don't know - as you can see, the GitHub "Watch" button is actually a drop-down menu that explains the different notification options, so this is certainly how I would do it. The icon is still superfluous, though ;)

Uhm - "resource" correct in this context?

In this case you must extend: https://github.com/flavour/eden/blob/master/controllers/cms.py#L157

...so you get a proper default name, and the title readable/writable etc...

:+1: 

@nursix : How is this decided for About and help?
https://github.com/flavour/eden/blob/master/controllers/cms.py#L166

Hmm, find me a website with a reply-option on the About or Help pages...

My gut feeling says these pages are in class with Contact - so False should be just right.

I'm not sure why we would want to relabel "Event Type" as "Type"?

Why hiding it initially?

Why hiding it initially?

Filtering events by name is probably a rare edge-case. I think event type, date and location are the key filters, name is really not so common.

Gives "Name" otherwise. 
http://demo.eden.sahanafoundation.org/eden/event/event

"attachment" not "paper-clip"

"attachment" not "paper-clip"

Hmm, that may not be the idea here - it conflicts with the other "edit" icon on the same card. Should be a "paper-clip" in this case, indeed.

Questionable. "read" would be better.

"delete" not "trash"

"attachment" not "paper-clip" (I won't repeat this for the other cases anymore)

"delete" not "trash"

"icon" for placeholders.

"delete"

For this you must check whether all cases are satisfied - i.e. where is it called, what are the possible values for icon, are all these icons defined?

"delete"

"delete"

just "icon" for placeholders

"delete" (I stop repeating this here)

just "icon" for placeholders (I'll not repeat this again)

Must check all cases

Careful - I con't think map-marker is correct here. It should probably be "link" instead.

Hmm, this used to be icon-truck, and sudden icon-changes aren't really good. But it's ambiguous so we may indeed need to look for a better icon. However, "certificate" is already used in a different context.

Maybe a "tag" ?

What could be a possible icon for "incident". I can't think of an apt one.
...and none of the places calling this configure the icon so far, so it'll always be the default one(i.e, incident) for now.

@nursix ^

I would have thought that this requires a community discussion, at least. Dropping "Eden" goes a bit beyond a simple code change.

And surely I would drop "Sahana" instead of "Eden" ;)

Nah - just kidding... :P

+1 - Will revert and take it to the community

Within the CERT template it can be whatever the users want...it's the default template that needs more consideration

Location filter behind multiple_orgs? Slip or deliberate?
Although multiple locations /might/ mean multiple branches, I'm not sure that's necessarily the case...

All CSS should be in HEAD for faster page loads, so should be injected in the controller into s3.stylesheets

I confess to feeling a pang at losing this prize-winning theme, but things are moving on & it certainly should at least be rebased on the current default theme.

Slip :)

RIP CERT Theme
2011-2015
Winner of RHoK. Promoter of shiny colourful Icons. A standard to follow for better managing Community Emergency Response Team Volunteers.

Was there anything that I culled unnecessarily?
The "Deploy" link was broken - this could be fixed, but would require a bit more work on the event module (some of which I've done - but needs to be merged from my DERA branch). I've added a @ToDo for this - but it's not needed in the current use case for this template.
Removing the theme itself is part of my push to standardize the design and remove duplication. I had a play around with leaving the theme in, but this forced having a dedicated (duplicate) layout.py file.
Sounds like you're OK with these changes however though - just... reminiscent? :)

Your push to standardize the design? Never heard of that.

Can you explain?

Use and improve default theme where possible.

Our actual direction is to provide a larger degree of freedom for GUI design, including framework and tools to implement different designs.

The default theme is intended for RAD (with the D meaning both development and deployment), and therefore flexible, case-neutral and minimalistic. But full-scale development projects may not need to be that, and can thus very well use a different, case-specific design - e.g. to blend in, reduce training efforts, support specific workflows.

A push to standardize the design and use default wherever possible is thus news to me - and I wonder whether that shouldn't be discussed with the wider community first. Looks like an unilateral decision of yours.

And I would be rather reluctant with sudden design changes (regardless whether they are real UX improvements or just fashion), because such changes always mean a learning effort on the user side, and often break existing documentation.

Thus, the default theme is not the ideal place for cutting-edge GUI development - which though seems to be what you are actually looking for. The default theme is rather suitable as final destination for the stable and mature features, at a slow pace and with infrequent fluctuation, and after designs have been successfully field-tested, fully framework-integrated and documented.

I would therefore rather not push for a "standardization" of the default theme, but where possible, realize new design ideas in custom themes first, field-test them, and then cherry-pick, generalize, polish and integrate features back into the default design - which then applies them to the various RAD templates. That way, we don't put stability at risk, and yet can move GUI design forward.

That concept was actually successful - so why should we change it?

My push would be to rebase the CERT theme on the current default theme (as it was based on the default theme before), while retaining its specific features, maybe even improving them in view of responsiveness - rather than removing it.

...and the homepage menu could be improved to use S3Navigation ;)

...yet retaining the original icons...

Why does CERT need it's own theme? Why can't it just use default theme? We don't need a new theme if there's just a couple of custom pages (do we?)
I'm hoping to utilize it more for more deployments - surely that's a good, RAD thing? I'm sure in the process minor incremental iterations (pixel pushing) can be made to the default them to improve it everywhere (there's none of those in this commit)
Homepage menus could certainly be improved to use S3Navigation.
Using font-awesome icons is much more extendable - there's more to choose from as we add more buttons.

I think I've answered most of that already.

Using the default theme for more deployments is not the same as RAD, no - these are totally orthogonal things.

RAD means to be able to quickly knock up an application from pre-built components, and the particular need are emergencies where there are neither time nor resources to develop new components from scratch, let alone to build a new theme - and yet very specific requirements.

However, that does not define any need or desire to maximize quantity - if it is necessary to use RAD components in order to save time and resources, then that is something we support.

But if there is enough time and resources for development of new features (and designs), then that is certainly the preferrable way - especially because it can eventually feed back into the RAD components and thus make new technology available for less well-resourced efforts.

That's what I suggested before: high end development projects with plenty of budget and/or resources develop cutting edge technology and designs, which then get field-tested and generalized through these projects - and eventually made ready and available for RAD.

RAD components need to be mature, stable, thoroughly tested and documented - and should not necessarily be the focus of the development. But RAD projects do neither have the resources nor the incentive to actually develop those components - and _that_ is actually the point. 

So there should actually not be /as many as possible/ RAD deployments, but wherever possible, sufficiently resourced development projects providing new components for RAD deployments - and RAD where necessary.

What file?

What file?

What module?

What is this test for?

As I've said before: we are NOT collecting test cases just for the sake of it.
- If this is a test case for project-specific requirements (e.g. Sunflower), then please move it under that template
- If this is a test case to verify a keyword, then please highlight the keyword you're working on

...otherwise: please remove the test case - it doesn't serve any purpose and will only go out of date as development progresses. We do not have the community resources to maintain generic regression tests.

Same here - please remove this test case unless it is either related to project-specific requirements, or to support the development of the test keyword library (in which case you should highlight the keyword you're working on).

Please do not just write test cases because you can write test cases - there is absolutely NO point doing so. The test cases will only go out of date, it is a mere waste of efforts.

Previous
![screenshot from 2015-01-30 00 22 15](https://cloud.githubusercontent.com/assets/6368364/6112427/f4a355c0-b0b5-11e4-9a4a-e2bffffb7be6.png)

Now
![screenshot from 2015-01-30 00 22 43](https://cloud.githubusercontent.com/assets/6368364/6112447/178467d2-b0b6-11e4-9662-31a84a079ee1.png)

Actually: trailing comma, and closing bracket in the next line ;)

I think that .iframe was intentional here.

Okay I'll keep it, but I don't find any popup calling create() and this url-
http://127.0.0.1:8000/eden/survey/newAssessment.iframe?viewing=survey_series.1 
is empty

I know - but see what the docstring says: obviously there is a requirement for this, so rather than removing the iframe-extension, we should make it work ;)

Well...after investigating and understanding that requirement, of course.

Without this importing completed assessments in xls format and populating to the database wont work. 

Is this a question or just a note to yourself? I mean - that is well obvious ;)

Its a note - because I have referred this PR in the document I will be sending :)

Our style guide says to use " not ' in Python:
http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/CodeConventions

Should specify whether this is get_vars or post_vars
request.get_vars is already brought into scope as 'get_vars'

No need to bring these into scope in a controller as they already are

PEP8 spacing around the + please

PEP8 spacing pls

PEP8

PEP8: space between if and (

Prefer 1 line per member of dict

Can be just 'settings' in a controller which helps keep within the 80 char line width :)

Prefer string subsittuion than concatenation as faster in Python:
url = "%susername=" % geonames_base_url (etc)

I suggested sub-classing this file with the changes rather than making them directly in this file

I'm not sure how to subclass this. This is a Ext.extend object that is called during rendering of the map. Can we subclass objects in js? Furthermore, if we subclass it, how can we make i so that this js file will call the subclassed object as opposed to this object?

Create a new Class: GeoNamesSearchComboS3 which inherits from GeoNamesSearchCombo
Then add in the modifications thwere as overrides
Then use this new class in the core code instead of this one
See OpenLayers.Handler.PointS3 as an example.

Why do we need to download a font for every language? If one of them is the default, why repeat it?

Docstring?

We should not use two libraries for the same purpose (we use urllib2 instead of requests)

Too little information - which font?

Not checking any errors here?

Not checking any errors here?

Not checking any errors here?

We do not normally give write access to static/\* 

URLs can be a lot more complex than that. And what about local files?

Where is this used? Why does it need to be in s3?

This is not what I would call a config setting. How would we configure it?

It does btw. seem to duplicate this function?

Again - sector is not used by default, so making this the default report axis looks wrong.

My plea is to make spectrum:rows the default rather than barchar:rows

I don't quite see why the function gets removed. Filter configuration of such complexity should be in a function (like hrm_human_resource_filters) is.

+1 to that and sectors in Org reports. Sorry I missed them in the review - I blame lambda

a) Only got called in one place
b) Filter configuration uses the same settings checks as report & list_fields configure - so best to do them all together
I could see an argument for a project_project_field_filter_report_form_config func - or _maybe_ framework support to to this automatically...

Ok, fine. But this needs to be cleaned up (PEP8, logical order, append+insert rather than list concatenation with +).

The critical aspect here is that it should be easy to:
- easily see which filters/fields eventually appear in which order (which is much harder with this mix)
- be able to easily add a new filter/field in a template in the right place (which is unsafe if you can't easily see which filters/fields are there in which order)

I think the mix here makes this a lot more difficult and error-prone - unless it goes indeed field by field (i.e. filters corresponding to fields = same rules, same order). This is the most frequently customized CRUD page, so this must become more developer-friendly - while the tiny trade-off through repeated option checks seems irrelevant to me.

Look at project_project_filter - very clean function, base-widgets first, then adding extensions per setting. Makes it easy to see which filter widgets will be active for your configuration and in which order.

Your mix obscures this, and makes it much harder. I am pretty -1 to that, and I can easily accept repeated option checks (which are tiny) to retain this clarity.

So, if we move this inside the model-function, then it should be separated by filters, list fields and report options. Like:

```
config1 = settings.get_bla_bla1()
config2 = settings.get_bla_bla2()

# Filters
filter_widgets = [...base widgets...]
if config1:
    filter_widgets.append(...)
if config2:
    filter_widgets.append(...)

# List fields
list_fields = [...base list fields...]
if config1:
    list_fields.append(...)
if config2:
    list_fields.append(...)

# Report options
report_fields = [...base report fields...]
if config1:
    report_fields.append(...)
```

That way, you can easily see what's going on, and where to insert your custom filter/list field/report field in the template. The repeated "if"s here cause no relevant overheads, as you call the getter only once on top.

Is there /any/ need for the line break here?

or here?

or here?

or here?

All-uppercase for constants?

mode_3w?

Not needed for mode_task.

Trailing comma and closing bracket on the same line - either/or. PEP8=no blanks around keyword assignments.

PEP8=space after colon.

Same here: trailing comma and closing bracket on the same line => either/or

mode_3w?

No check for STAFF role? Doesn't seem right.

PEP8 = no blanks around keyword assignments.

But at least, do it consistently, not one so and another one differently.

Dropped this? (not using it anymore?) Why?

What's the point now with this variable?

inconsistent indent

Trailing comma and closing bracket on the same line => either/or

"Administration" or "Master Data" - but definitely not "Admin" (that's not even a word)

Preferrably "Administration" ("Master Data" is difficult to translate)

"Lookups" is not translatable at all (no corresponding word in any language I know), "Lists" is too generic.

Not used in mode_task/mode_community?

OK - checked out spectrum:rows - couple of issues:
1) They are not represented in the chart options at the top of the chart (pie, bar, per Axis Breakdown)
2) I could only ever get the bar chart at the bottom to show one variable - which seems the wrong visualization tool (especially as it doesn't change size)
3) The interaction doesn't make sense to me... I can see how this might make sense with the breakdown - not sure how to enable that.
4) Not documented on http://eden.sahanafoundation.org/wiki/S3/S3Report
Only 2 & 3 are show stoppers for me adopting this
Do you have another example for me to check out?

Downside - not very DRY
but I've done it _just_ to make you happy :)

No

-        community = settings.get_project_community()
  was a mistake - this setting is only tested once - so no need for variable

OK (although this is a variable)

None

Yes

removed comma

Fixed

Yes - and I stand by this:
1) STAFF isn't a system role (you could have a time tracking template without this role)
2) STAFF isn't the only role to have tasks assigned to them (Vol?)

3W report only in  mode_3w... I _guess_ that makes sense... :)

Is there are better check to make?

Could be - but only if also mode_3w - added that test

This is just the Org report - not ness funding - why have it?

Done

Hmmm... I don't like Administration because it has a different meaning - it's not just the administrator who can look / edit these. But It's the best option, so have adopted it

I have no idea what you're talking about - 1-3 are not true.

Then you've not understood what I mean.

...because it is totally DRY

Actually, the /best/ option would be "reference data" - because that is exactly what it is.

But I suppose you won't like it because it partially exposes the model (i.e. technical term).

Dominic

> 13 mar 2015 kl. 02:32 skrev Michael Howden notifications@github.com:
> 
> In modules/s3menus.py:
> 
> > -                M("Last Week's Work", f="time", m="report",
> > -                  check = mode_task,
> > -                  vars=Storage(rows="person_id",
> > -                               cols="day",
> > -                               fact="sum(hours)",
> > -                               week=1)),
> > -                M("Last Month's Work", f="time", m="report",
> > -                  check = mode_task,
> > -                  vars=Storage(rows="person_id",
> > -                               cols="week",
> > -                               fact="sum(hours)",
> > -                               month=1)),
> > -                M("Project Time Report", f="time", m="report",
> > -                  check = mode_task,),
> > -             ),
> > -             # Is "Admin" the right term? "Master Data"? "Look Ups"? "Lists"? Copy this menu heading to other modules 
> >   Hmmm... I don't like Administration because it has a different meaning - it's not just the administrator who can look / edit these. But It's the best option, so have adopted it
> 
> —
> Reply to this email directly or view it on GitHub.

Should be "settings.org.sectors" no?

This isn't ready yet! Please don't expose yet.

Is there any need for the line break here? Can't this be a tuple? Trailing comma and closing bracket on the same line => either/or

Hmm, programme_project has no "name" => must be programme_id

Not fixed.

Trailing comma and closing bracket on the same line => either/or

Not a text field!

No trailing comma despite closing bracket on the next line :D

No trailing comma and yet closing bracket on the next line ;)

NB That's actually deprecated - supported by S3OptionsFilter directly.

"id" is included automatically, no?

To clarify: 

1) Spectrum is one of the breakdown-options (because it's a two-axis chart), and very well shown in the chart options.

2) Spectrum consists of a half-donut chart showing the distribution along the first axis (=the "spectrum"), and a barchart showing the distribution along the second axis.

Using the drop-down, you can additionally filter the second axis by the individual data points of the first axis. Alternatively, you can just click on the data points in the half-donut.

3) The interaction does absolutely make sense to me. Example:

A "spectrum" of offices by office type (second axis = Organisations):

![ss42](https://cloud.githubusercontent.com/assets/1257183/6634716/be16c2f2-c95c-11e4-9a20-ded29ea0fe08.png)

...shows me the distribution of offices per office type (the half-donut), ...and per organisation (the bars).

Now I can use the drop-down to select one specific office type - which filters the per-organisation bars to that type:

![ss43](https://cloud.githubusercontent.com/assets/1257183/6634733/e7e79f02-c95c-11e4-843b-d4fb42d89592.png)

![ss44](https://cloud.githubusercontent.com/assets/1257183/6634737/ef036aa0-c95c-11e4-8208-d502c218b6e5.png)

Each bar presents me an onhover-tooltip, and clicking on that bar takes me to a list of offices filtered by this office type for this organisation.

![ss45](https://cloud.githubusercontent.com/assets/1257183/6634862/ee71a7f8-c95e-11e4-9934-77079e45173f.png)

The advantage over a standard barchart is that you have this filter in the chart, and can thus easily walk through the data points of the first axis.

Note that "spectrum" means the half-donut, not the bars ;)

Hence when you do spectrum:rows, then the rows will appear as the half-donut, and the cols will be the bars.

For obvious reasons, though, the chart title uses the second axis (because the user would naturally see this as a bar chart that is filtered by the first axis, and not as a half donut that is broken down by the second axis).

However, technically it's the latter - the first axis gives the half-donut, the second axis gives the bars.

Or in other words: that the bars only show one axis (=offices per organisation) is actually the point of it.

Barchart:rows does nothing else (it also shows exactly one axis = offices per organisation). Lets compare that:

![ss46](https://cloud.githubusercontent.com/assets/1257183/6635068/d0ad9d96-c961-11e4-9656-830364141693.png)

The advantage of spectrum over a standard barchart is the option to "focus" a single data point on the other axis, (which is btw something that you suggested as being a useful interaction):

![ss42](https://cloud.githubusercontent.com/assets/1257183/6635080/e11a778a-c961-11e4-99bd-1175438c906f.png)

Apart from that, it's "just" a barchart like barchart:rows.

Another nice example - hours worked per person.

A normal barchart shows me this:
![ss49](https://cloud.githubusercontent.com/assets/1257183/6635188/2f8d27fe-c963-11e4-9fc6-868ff3f147bc.png)

Spectrum shows me the same:
![ss47](https://cloud.githubusercontent.com/assets/1257183/6635196/43c44f04-c963-11e4-96f0-d2a2bad00b5a.png)

...but additionally allows me to focus on a particular project:
![ss48](https://cloud.githubusercontent.com/assets/1257183/6635200/50a28ede-c963-11e4-8bbe-7604983132e3.png)

...of course I could also use the filter form to "focus" on a particular project.

But that wouldn't show the project-context in the chart, and it would require an additional server-side request hence be much slower, and not exactly provide for a walk-through through the individual projects.

And of course you wouldn't see the particular project's total hours put in relationship to the overall hours worked (=the half donut) - but that's just an additional goody.

In the case of offices: if you make the Lx the barchart-axis, then you can see offices per location in the barchart:rows. 

With spectrum:rows you achieve the same, but you can /additionally/ focus on a particular office type - directly inside the chart, without server-side request - which makes totally sense to me.

Of course, you can also produce a chart that shows the offices per location broken down by type, as grouped or stacked bars. That too makes sense.

But I'm not arguing that "spectrum" would be an alternative to "breakdown" - I'm saying it is a better _barchart_.

OK - that clarifies some things for me (this would be much better on the list - do you mind if I move the conversation there?) - couple of things remain:
- I was running into issues because my secondary axis didn't have any meaningful data - I really wanted to chart the primary axis. This is just a simple case of switching the axises (either I will in config or implementation if you think it belongs there)
- I think that it is a bit ambiguous what the spectrum represents - it could benefit from a title
- I think that the chart could work better with 3 separate titles Fact, Primary Axis & Secondary Axis. The "X per Y" is a bit confusing. Also - if fact =count(id) I don't think that a label is needed - it's pretty implicit
- I'm not sure that the Org Type drop down adds value. It repeats the filter functionality of the spectrum - perhaps if it were under the spectrum it would act more like the title I'm seeking?
- The chart labels have multiple 1's , 2's etc - but that's the same with all graphs

I will spend a bit more time investigating this later (while trying to merge code isn't the best time for me to explore new features). Perhaps the biggest point right now is that I think this introduces more complexity into the basic chart. With that comes value - but I think it is better to introduce something very simple to users - and allow them to dig deeper into the complexity (which they can)
Perhaps hiding the spectrum by default and having a simple ability to show it would be a better approach?

NOTE: This isn't a refusal to use it - I just think that this needs to be shared with the community - then made a global default.

OK - but this was controlled by settings....

Yes - thanks!

I would disagree on all points here, and I think that it is NIH that motivates them rather than usability.

> 16 mar 2015 kl. 02:24 skrev Michael Howden notifications@github.com:
> 
> In modules/s3db/org.py:
> 
> > @@ -4132,6 +4150,21 @@ def model(self):
> >                                   ),
> >                  ]
> > -        report_options = Storage(
> > -            rows = report_fields,
> > -            cols = report_fields,
> > -            fact = ["count(id)",
> > -                    "list(name)",
> > -                    ],
> > -            defaults = Storage(rows = lfield, # Lowest-level of hierarchy
> > -                               cols = "office_type_id",
> > -                               fact = "count(id)",
> > -                               totals = True,
> > -                               chart = "barchart:rows",
> >   OK - that clarifies some things for me (this would be much better on the list - do you mind if I move the conversation there?) - couple of things remain:
> 
> I was running into issues because my secondary axis didn't have any meaningful data - I really wanted to chart the primary axis. This is just a simple case of switching the axises (either I will in config or implementation if you think it belongs there)
> I think that it is a bit ambiguous what the spectrum represents - it could benefit from a title
> I think that the chart could work better with 3 separate titles Fact, Primary Axis & Secondary Axis. The "X per Y" is a bit confusing. Also - if fact =count(id) I don't think that a label is needed - it's pretty implicit
> I'm not sure that the Org Type drop down adds value. It repeats the filter functionality of the spectrum - perhaps if it were under the spectrum it would act more like the title I'm seeking?
> The chart labels have multiple 1's , 2's etc - but that's the same with all graphs I will spend a bit more time investigating this. Perhaps the biggest point right now is that I think this introduces more complexity into the basic chart. With that comes value - but I think it is better to introduce something very simple to users - and allow them to dig deeper into the complexity (which they can) Perhaps hiding the spectrum by default and having a simple ability to show it would be a better approach?
> —
> Reply to this email directly or view it on GitHub.

Hmm, it has been shared with the community, and it doesn't make sense as global default.

> 16 mar 2015 kl. 02:37 skrev Michael Howden notifications@github.com:
> 
> In modules/s3db/org.py:
> 
> > @@ -4132,6 +4150,21 @@ def model(self):
> >                                   ),
> >                  ]
> > -        report_options = Storage(
> > -            rows = report_fields,
> > -            cols = report_fields,
> > -            fact = ["count(id)",
> > -                    "list(name)",
> > -                    ],
> > -            defaults = Storage(rows = lfield, # Lowest-level of hierarchy
> > -                               cols = "office_type_id",
> > -                               fact = "count(id)",
> > -                               totals = True,
> > -                               chart = "barchart:rows",
> >   NOTE: This isn't a refusal to use it - I just think that this needs to be shared with the community - then made a global default.
> 
> —
> Reply to this email directly or view it on GitHub.

This needs a trailing comma (otherwise not recognized as tuple)

Same here - must have a trailing comma to be recognized as tuple.

Without trailing comma, this is just a string, so no brackets needed either. 

Mixed style, should be like:

```
field = "sector_id",
),
```

This is not fixed. If you have the closing bracket on a new line, then you are inviting line swaps or insertions, hence there should be a trailing comma after "website".

This lacks a trailing comma /after/ the closing bracket

This should rather be trailing comma plus closing bracket on a new line (since extensible).

Similar here - better to have a trailing comma and the closing bracket on a new line

Similar here - better to have:

```
hidden = True,
)
```

...to allow easy adding of options or line swaps. Ideally, options should be in alphabetical order.

But be sure to NOT have a trailing comma /after/ the closing bracket in append (that'd be a syntax error)

Same here.

Wrong indent, options should be in alphabetical order, ideally a trailing comma after the last option + closing bracket on a new line.

Same here.

...and here

...and here.

and here.

and here (+wrong indent)

There should be a space after the comma:

```
filter_widgets.insert(0, S3TextFilter(...
```

Ideally have a trailing comma here plus closing bracket on a new line.

Or - if you don't expect more fields to be added, then the line break is questionable.

Like this:

```
fact="count(id)",
),
```

Missing space after the comma in the list. Should be:

```
["count(id)", "list(name)"]
```

Mixing method specification and simple field selectors in "fact" is not ideal.

Additionally - specifying a label for each fact is recommended, for two reasons:
a) auto-generated fact labels do not appear in language files (hence not visible for translators)
b) auto-generated fact labels just indicate the aggregation formula, but do not put the fact into the report context, hence not as user-friendly

This can be a tuple

This can be a tuple

This can be a tuple

This can be a tuple

Should have a trailing comma here

vars does not need to be a Storage (Storage is not wrong, but a wee bit slower in construction than a dict)

space after comma

...but only one space after comma, not two.

You say yes - but you don't fix it?

Better have a trailing comma and closing bracket on new line here too.

Still saying org.branches not org.sector

I don't think the setting alone makes the sector suddenly relevant in this view

Same here - the use_sector setting alone doesn't quite make sector relevant in this view

Maybe better the other way around (because more countries than types)?

+1

+1

Hmmm - but the Type is probably more interesting for the chart?
Switch them then do spectrum:cols?

D'oh - thanks

Hmm...insert(2,...) but pop(1)? Is that correct?

Yes, in that order it is correct. Very fragile, though ;)

Hey - not my code! (well at least not in this PR)

In other places, we use something like:

```
filter_widgets = [fw for fw in filter_widgets 
                  if fw.field not in ("organisation_organisation_type.organisation_type_id",
                                      "sector_organisation.sector_id",
                                      )]
s3db.configure(tablename, filter_widgets=filter_widgets)
```

That is certainly more complicated, but much more robust - and more obvious for debugging. Alternatively, the model could skip the insertion of the filters when current.request.controller is "inv" or "asset".

Not inserting the filters when not needed is btw. the preferred variant ;) as always. Most efficient.

Sure - feel free to make that change - I'm not touching that pop in this PR - just adding the (required) conditional

So?

You mean since you didn't write it, it's not your responsibility to check whether it works correctly with the changes you are proposing? Not quite the right attitude, I'm afraid - if you make changes, then you are of course to verify /all/ related functionality as well ;)

I think you should make this more robust as suggested /for/ and through this PR. It's too fragile as it is now.

Minor enhancement (not blocking, just for next time)
text_fields += ["sector.name", "sector.abrv"]

You're deliberately removing this filter?
In general that's good as the core function does some, but does it handle the none/location_filter options?
I certainly doubt the latter...

Why prefer "" to an empty DIV?
Is this just keeping the HTML a little cleaner?
It /might/ cause issues if there are scripts or CSS which expect this to be there, although this isn't too likely....just seems a risk for little gain?

Nope - not sure how that got missed - added back in

I actually thought that was bad practice... 
thanks for not blocking - have added it in with the other change

Cleaner HTML, less nodes, and the styling was causing double borders (or similar weirdness - it was a while ago)

This is a change comment not a code comment...it doesn't make sense to have it in the code

I think you want to keep the tuple format to avoid the extra label no?
(The comment as to why commented is indeed resolved now, so this shoudl work :) )

Why did you move these from the controller to the model?
What is the benefit?
In general, better to push everything unnecessary out of the model since the model is loaded for all CAP requests whereas that controller just for that function...

ok, clear :)

alignment

alignment

I'd rather use settings.get_public_url() here if possible?
Servers are often mis-configured & may have multiple names
(If we really need to do it this way then I'd import socket just in the method so that not every request for any CAP-related function needs to load it)

These should be commented out - they are exampels of instance-specific settings, not defaults...

"Existing Shipments to Receive"?

I am wary of making this change as it means new strings to translate suddenly.
Especially wary just after Honduras Red Cross spent a long time going through this module & tweaking...perhaps this could go into template?

" not ' ;)
And one above too

This can't be merged, sorry.
The default is to let it auto-detect, which works generally as far as I know...is there a case where it fails?

Note I encountered a few crashes with this kind of syntax...something about pickling.
e.g.:
https://github.com/flavour/eden/blob/master/modules/s3db/req.py#L1290

This is perhaps something that can be fixed upstream in Web2Py since I guess this is a Web2Py change which has meant this stopped working...but am wary of merging more of these until we can track down the issue.

hmm, this seems like we're hardcoding somethign which is configurable? Always nasty, but can be mitigated with lots of warnings in code about other locations this is used.

This is certainly something that we'd like to be able to do...before this need to create a generic facility for the destination if we're doing distributions, which is ugly...being able to pick a village is a good idea.
However I do worry about rushing this through - it needs careful validation to make any changes in this area.

Better in static, of course

This should be a deployment_setting.
We have similar already, such as:
https://github.com/flavour/eden/blob/master/modules/s3cfg.py#L2803

I set the default to this now :)

Generally not so good as it needs to create a new location for the street address every time you sent a shipment there - much smarter to indeed create a location-only destination facility, which has a site_id and can be re-used.

This would also make it easier to track all shipments to the same location (e.g. for reporting).

These should be in a Demo/ subfolder as we don't want this in a Prod instance do we?

Shouldn't that be:

```
dict(site=current.deployment_settings.get_inv_facility_label())
```

i.e. call it instead of passing in the function?

What's the reason to start using the newer Font Awesome?
I know it's a good idea generally, as the older release is unsupported, but what is the driver?

This does create a strong layout-/theme-dependency here - shouldn't that be custom?

Anyway - I'm not convinced of location_id in inv_send yet.

It will be useful to use S3Navigation here (not at the moment, perhaps - but in general). Also, ICON() is better than hardcoding i-tags.

Patients?

{{=ICON(menu["icon"])}} maybe?

...is breaking default

Fixed width for foundation? There's a better way to do that which doesn't interfere with the grid

We shouldn't really have all this scss in the fonts folder I don't think

& css should be in the CSS folder not in fonts folder

If you want to switch to FA4, then do switch - not just change the CSS.

Just changing the CSS breaks all ICON tags - you also need to fix that.

@flavour: many more icons available (which in itself is both good and bad), but in any case it has more semantic icons which is why I was wanting to switch to FA4 too.

However, I don't see a need to include all the SCSS sources, we're not going to re-compile FA anyway.

But /if/ we switch, we need to activate FA4 in ICON, and change the default icon set in S3Config - otherwise this change breaks all ICON tags all over the place.

I think the point is for Distributions - where there isn't a Street Address or anything and certainly no Organisation.
This is for Lx, typically Villages...where the Location Selector does work (although should have the widget customised here to NOT include a Street Address/Postcode or a Map...it should just have the Lx dropdowns...or there should be an investment in the LocationSelector to be able to pick existing locations if we do need Street Addresses (NB This was a feature of the original LocationSelector but was de-scoped from the new one)

Yes, this is very hardcoded to a specific theme indeed :/

My understanding was that we could have the 2 co-exist: FA3 for legacy themes & FA4 for newer themes...although if this is a clear superset of FA3 then we can migrate the core ICON & hope there's not too much hard-coded FA3 not wrapped by ICON...which I think is probably too hopeful at this stage?

You can actually inline a facility here - that way the user would perceive this as sending to a location, and yet the same address can be referenced again without creating a new location every time (which you do when you enter a street address).

I would do this via a link table inv_send <=> org_facility, and only expose the location selector of the facility, using the address as name and populating site_id automatically. Next time you need to send to the same address, you can pick it from the facility list (site_id).

Then you can track/report shipments by site_id - which isn't possible when you enter the street address and hence create a new location every time.

Yes, we can have both co-exist, but the default template uses FA3, so changing the CSS without switching the theme to FA4 breaks all ICON instances.

S3Config returns FA3 by default, which must be changed - and ICON does have FA4 icons commented, which needs to be un-commented if we switch /any/ theme to FA4.

Else both sets can easily co-exist. My complaint was merely about changing the css.cfg but not enabling FA4 for the theme and in ICON.

Note that when we make FA4 the default, then all themes which still include FA3 CSS must be explicitly set to FA3 (or have their css.cfg adapted, which is possible if they have no hardcoded i-tags).

There are no hardcoded I-tags in core anymore - only in templates. So, switching is relatively easy - you just need to do the whole job not just half of it.

1) Change default/css.cfg to include FA4 instead of FA3
2) Un-comment the FA4 icons in s3widgets/ICON
3) Change the default for get_ui_icons to FA4 (currently FA3)
4) Make sure that all /templates/ which still have hardcoded FA3 I-tags do define FA3 as their icon set (settings.ui.icons="font-awesome")

Recommend to _not_ introduce any new hardcoded I-tags, but rather use ICON - much easier to switch the ICON theme then.

I get the idea - but then sending to an Lx without street address may work in Nepal, and maybe in Sweden :D but it may be very hard for logistics in places like LA, Berlin or Paris?

Indeed - if the location selector could select existing addresses at the Lx, then that would be a solution, although  you still wouldn't have anything in gis_location to manage the reception - and you are operating outside of Auth with locations.

So, maybe as a deployment option, but not by default?

Locations are not meant to replace Sites, just to supplement them...since not all destinations are Sites

And I wonder whether selecting a location shouldn't enforce "Distribution" - for integrity reasons?

Yeah - I know that this isn't replacement, but an alternative end-point.

And yet, in major cities the same Lx may have multiple distribution end points (=drop-off points), and they may receive more than one shipment each.

Now, I think that a drop-off point is a type of site, not just a naked location - even if it can, in simple cases, just be an Lx without address.

Modelling drop-off points as sites makes things more consistent - and there is then no need to implement site_id/location_id case discriminations for reports and filters (but instead can filter by site type, much easier).

Doesn't mean that this would need to be exposed to the user - but in the interest of consistency and simplicity/robustness of the code I think that all distribution end-points should be modelled as sites as well.

And that could then be one selector (S3SiteSelector), analogous to S3LocationSelector - where you can either choose an existing site, or create a new one inline - which can indeed be both, a named facility, or a location-only drop-off point.

Functionality would be quite similar to S3LocationSelector, except that it has the ability to choose existing drop-off points besides named facilities.

Receipts may then also cite the drop-off site (without though the items being tracked further after that point), which is probably a good idea if we want to track not only whether something has gone out, but also that it has arrived at the intended location.

Tracking drop-off points may btw also be interesting for the public - even if they are not treated as facilities.

You could create distribution end-points as inv_distribution and make that a site-instance (and an OU of the sending organisation). This has obviously advantages for multi-tenancy, where one org doesn't want (or isn't supposed to see) the distribution end points of another (if you now were to re-use existing end points, or report shipments by end point which may be more interesting in this context).

The fundamental point of org_site is a link table between gis_location & org_organisation.
These distribution points do NOT have an org_organisation.
That doesn't completely rule out using Sites but does make them a little odd.
I understand the point of consistency & I don't like the 'Location or Site' "wizard" of a radio button: poor for the user & often very fragile for the devs.
What I'd prefer to see here is the use of Location & have the LocationSelector able to select existing sites...but this is far from trivial & GPF want a solution now.
NB Honduras RC didn't see it as /too/ clumsy to simply create an org_facility for distribution end-points...so this /could/ work here too until we can resource getting a proper solution in-place...I'm certainly very wary about such quick hacks...

Umh, yes - distribution end-points kinda do have an organisation, which is the sending organisation (or the org conducting the distribution).

That may be irrelevant for this deployment, but multi-tenancy deployments may wish to not share their drop-off points, especially when that poses a security risk.

However, that wasn't quite why I proposed the site super-entity, but rather to not complicate the code that is to process the data. If we have a dual location_id in this model (one in inv_send and one in org_site), then it will become much harder to aggregate the data per location (or Lx), e.g. to analyse how much has been delivered to a certain L2. Or to filter shipments by destination Lx.

Such complications, apart from GUI, make the whole thing more fragile, and require a lot more coding around this inconsistency. I see how using org_site is bending the ontology a little bit, but then we also need to think practically. If any end-point is always a site - then there is only one possible link to the destination location_id, and thus accessing it for analysis, aggregation and reporting becomes a whole lot easier.

The destination org is btw separate anyway - so for this particular model the org_site link to organisation isn't relevant anyway. For inv_send, the site_id is primarily a link to a location with a _type_ (encoded as instance-type), and it is the type that distinguishes named facilities and naked drop-off locations as end-points, not the organisation.

> 7 maj 2015 kl. 22:06 skrev Fran Boon notifications@github.com:
> 
> In modules/s3db/inv.py:
> 
> > @@ -1095,6 +1095,8 @@ def model(self):
> >                                                    not_filter_opts = (True,),
> >                                                    )),
> >                             ),
> > -                     self.gis_location_id(label = T("To Location"),
> > -                                          ),
> >   The fundamental point of org_site is a link table between gis_location & org_organisation.
> >   These distribution points do NOT have an org_organisation.
> >   That doesn't completely rule out using Sites but does make them a little odd.
> >   I understand the point of consistency & I don't like the 'Location or Site' "wizard" of a radio button: poor for the user & often very fragile for the devs.
> >   What I'd prefer to see here is the use of Location & have the LocationSelector able to select existing sites...but this is far from trivial & GPF want a solution now.
> >   NB Honduras RC didn't see it as /too/ clumsy to simply create an org_facility for distribution end-points...so this /could/ work here too until we can resource getting a proper solution in-place...I'm certainly very wary about such quick hacks...
> 
> —
> Reply to this email directly or view it on GitHub.

The alternative for unified analysis would be to write location_id back to inv_send onaccept from the site...sure this isn't ideal from an integrity perspective.

What does the user want to see?
- If selecting a village they just want to see the Lx dropdowns and don't want any knowledge of the fact that a site is being created in the background (I prefer supply_distribution_site for this than org_facility with a type since filtering out types is always painful)
- If creating a new facility, they basically want to use the Locationselector & have the site created invisibly in the background (the original LocationSelectorWidget had an extension to do this). The one part that might be visible to them would be a radio or dropdown to select the type: Office, Warehouse, Hospital, etc (would need to be auto-adaptive &/or configurable based on list of enabled site types merged with facility types)
- If selecting an existing site, I'm thinking we'd do this like the AddPersonWidget:
  They have a Name field which does an AC lookup to select existing or 'None of these' to create a new one.
  They /might/ wish to have the list filtered by Lx or Site Type if it's a large list, but this seems to be a future extension to worry about that.

Whilst this feels right longer-term, I think the best short-term option is to simply do what Honduras RC accepted: create an org_facility for each distribution site....slightly clumsy but 100% reliable & working right now.

Sounds right to me :)

+1

Of course not! It's a quick hack. It does appear that the auto-detect is broken however... Will investigate.

Thanks for the review.
I remember considering site_id vs. location_id when I first developed this code - and I must have agreed with your approach then :)
I'm presuming that a S3SiteSelector is no small task?
I'll remove the location_id, but make sure that there is an "Create Facility" link (missing now - is this not a pain for HRC?)

Of Course better in Static - but when playing with ideas fast and rough is better. Given above discussion, this will be removed!

+1

:) 

+1

+1

Although I'm wary about any one template dictating default... Moved to the template for now - but I think that these changes could have generally improved UX with inv

Hmm... appears to be working now...

Removed dict and fixed call

Yes - this is nothing new...
However we were hard coding it wrong - so this has been fixed. 
No time to go through and change all of these now.

Both - thanks for the review :) (And correct - FA4 was needed for new icons)
Dominic - thanks for the guidelines - I will do my best to action this (although not this week).
Some questions:
- Can you confirm - delete FA3?
- Can you give me some examples of Icons in Core?
- I would rather keep all the font awesome files together in the same place (under Fonts), rather than scatter them...
- Is there a way to specific a min.css to use rather than compiling the css into the eden.min.css (the relative file reference breaks when doing this - forcing me to edit the Font Awesome CSS

I know - It's on the list.

+1

What did you have in mind? My aim was to keep the grid - but give a max size... is there a problem with this, or just the method...?

No - completely wrong :/

1) Keep FA3 - FA3 and FA4 can co-exist, and FA3 is still required by many templates!
2) No change in core required, all cases have been migrated to ICON
3) Change default/css.cfg to include FA4 instead of FA3
4) Uncomment FA4 icons in s3widgets.py/ICON.
5) Make S3Config.get_ui_icons default to FA4 instead of FA3
6) Make sure all templates which still use FA3 specify a settings.ui.icons (they may rely on the default of the setting which would break when you change the default)

And as Fran said: CSS should be under css, and fonts under fonts

> 8 maj 2015 kl. 05:32 skrev Michael Howden notifications@github.com:
> 
> In static/fonts/font-awesome/css/font-awesome.css:
> 
> > @@ -0,0 +1,1801 @@
> > +/*!
> > - \*  Font Awesome 4.3.0 by @davegandy - http://fontawesome.io - @fontawesome
> >   Both - thanks for the review :) (And correct - FA4 was needed for new icons)
> >   Dominic - thanks for the guidelines - I will do my best to action this (although not this week).
> >   Some questions:
> 
> Can you confirm - delete FA3?
> Can you give me some examples of Icons in Core?
> I would rather keep all the font awesome files together in the same place (under Fonts), rather than scatter them...
> Is there a way to specific a min.css to use rather than compiling the css into the eden.min.css (the relative file reference breaks when doing this - forcing me to edit the Font Awesome CSS
> —
> Reply to this email directly or view it on GitHub.

This does belong here! The labels vary by config location, so the model must be loaded before you can determine which labels to use. Please remove the comment.

No problem if you do that in your theme's style.css only, not across themes.

Sorry about the complications - but as long as you keep introducing new hardcoded I-tags this is not going to become any easier.

ICON works this way:
- instead of I(_class="fa fa-xyz") you write just ICON("xyz")
- ICON is an HTML helper which will be rendered as `<i class=...>` - you can specify additional attributes with underscore as usual, like ICON("organisation", _class="hide"), it can be used in place of I(). Note that no additional whitespace is required - the horizontal spacing between icon and label is CSS now (at least in the default theme and derivates, as well as IFRC)
- ICON looks up the setting.ui.icons setting, and chooses the corresponding CSS classes for the respective icon set
- ICON has some semantic icon names pre-configured internally (rather than using the descriptive names), e.g. ICON("organisation") rather than I(_class="fa fa-sitemap"). This is recommended, because it allows you to configure icons by /what/ they symbolize rather than by /how/ they look. E.g. there are ICON("edit") and ICON("delete") - rather than "pencil" and "trash".
- In addition to the pre-configured icons, the template can specify custom icons as settings.ui.custom_icons - if you e.g. want to include some icons that are not the default set, like in MCOP which uses both FA3 but also DRMP icons, or when you want to override the default in ICON (e.g. use a different class for "organisation" than what is configured in ICON).
- icon names which are not defined anywhere are used as classes, e.g. ICON("undefined") will give `<i class="fa fa-undefined">` in FA4. That way, you are not forced to configure each and every icon class - only where you want to use semantic icon names you will have to define them somewhere
- it is possible to override the HTML layout of ICON, although FA3, FA4 or FI currently all have the same layout
- provided you are only using ICON and no hardcoded I-tags, you can switch a template to a different icon set by just changing settings.ui.icons and including a different CSS. All core code (s3 and s3db) is completely migrated to ICON and will thus follow the setting - only some older templates are still using hardcoded I-tags. However, just changing the included CSS without changing the setting will break it ;)
- the theme must of course include all corresponding CSS for the icon classes. It is generally possible to include multiple (e.g. MCOP), but remember that where they use the same selectors, the order of inclusion matters!
- of course, if you are using JS or CSS in your template that relies on specific icon CSS classes, then you can not easily switch the icon set. That is why this is discouraged at least for all core JS and CSS - only the icon CSS itself should refer to icon classes

ICON is used throughout the core - in data list layouts, profile pages, and some form widgets. Since this code is used across many templates, no hardcoded I-tags should be introduced in core anymore.

Changing a theme's icon set is easy - but changing the _default_ requires more care. The majority of templates currently uses FA3 - but implicitly, relying on the default. Where there are hardcoded I-tags in the template, they can not easily be "switched" to FA4. However, if you don't have the time to migrate all hardcoded I-tags, you can just configure these templates to continue using FA3 for now - via setting.ui.icons. Obviously, you can then not "remove" FA3 just yet.

Bit odd however that you change CERT/style.css while it is not used for the Nepal template - and odd also to set a fixed width again while we're struggling to much with fixed widths. Generally, I'm very sceptical - and don't quite see what this would improve.

Also note that the PR retains the default/eden.min.css even though you removed the changes in its source now. Should remove the minified file as well.

1) Nepal & CERT Homepages use the same css: https://github.com/flavour/eden/blob/master/modules/templates/Nepal/controllers.py#L19
2) +1. Although planning to change Default to use FA4 - any complaints?

"Although planning to change Default to use FA4 - any complaints?"
Just read our comment:
"Changing a theme's icon set is easy - but changing the default requires more care. The majority of templates currently uses FA3 - but implicitly, relying on the default. Where there are hardcoded I-tags in the template, they can not easily be "switched" to FA4. However, if you don't have the time to migrate all hardcoded I-tags, you can just configure these templates to continue using FA3 for now - via setting.ui.icons."
There should be no need to switch default to FA4 (yet), just switch setting.ui.icons = to FA4 in Nepal... I'll dig into that... 

I'm -1 to introducing this - we already have a (much better) method to customize the home page controller, and this introduces double standards, which is confusing.

But I can see why you did this - you wanted to have access to the IM layout definition.

However, that's not necessary - templates are now just normal modules, so you can move everything into the right place:
- move the IM layout into layouts.py
- move the inv index controller into controllers.py

...and import:
- import IM into controllers.py like: from layouts import IM
- import the inv index controller into config.py like: from controllers import customise_inv_homepage

Alternatively, you can keep the customise_inv_homepage in config.py, and import the IM layout there.

You can even import across templates, e.g. a layout like: from templates.Nepal.layouts import IM

...so there is less need to duplicate code across templates.

I see that you changed/added some keys here. If you do that, please make sure the same keys are available in every icon set - or, if that is not possible, move the additional keys into settings.ui.custom_icons (same dict structure).

All icon sets should have a consistent set of default icons.

Really? A cross-model dependency just for a CRUD string? That looks ugly to me.

I think it's better to replicate this CRUD string here - the implications of loading another model in a model are too heavy, especially if that happens unconditionally.

I mean - it's not technically wrong, but it is totally disproportionate for just one CRUD string. It's not worth it.

Wrong syntax (trailing comma)

Absolute font-size? Maybe you missed that - the others you used rem for (which is appropriate)

Hmmm... (pondering)
I was expecting some debate around this - and generally I'm OK with this approach!
Some comments:
- One main reason to move it into config.py is to avoid restarting web2py for every change!
- We already have double standards with the "customise_home" setting... should that have been introduced?
- I actually see a strong reason for putting more in controllers.py than config.py so that it can be reused between templates - eg, let's say that the customise_org_organization_controller needed to be reused in multiple templates... is this right? (Not something I'm planning to do right away)

OK

Thanks for the import pointers - took <5min to change :)

Moved to settings.ui.custom_icons

Changes

Clear -1 to this - this should definitely not be enforced in the codec, and especially not without any option to turn it off. Exporting comments is not a general requirement for every deployment, and not for every resource either.

Why would you remove these settings?

NB PEP8 recommends CamelCase for word separation, but Lay and Out are not two words ;) such fanciness is a source for bugs and should be avoided.

måndagen den 1 juni 2015 14.50.34 skrev  Michael Howden:

> > @@ -63,8 +63,13 @@ def register_validation(form):
> >  #
> >  ========================================================================
> >  =====> 
> >  def index():
> > 
> > ## \-    """ Main Home Page """
> > -    """ Customized Main Home Page (in modules/<TEMPLATE>/config.py) """
> 
> Hmmm... (pondering)
> I was expecting some debate around this - and generally I'm OK with this
> approach! Some comments:
> - One main reason to move it into config.py is to avoid restarting web2py
>   for every change! 
>   This is out-of-date information.

All of the template is now imported, so it doesn't make any difference whether 
it's config.py or controllers.py. As long as you have module tracking enabled 
(debug mode), there's no need to restart web2py.

However, note that git repository dates may be older than your .pyc's so that 
applying changes with git (e.g. switching branches) may however require a 
web2py restart.

Also, Eclipse does sometimes not follow these re-imports - even if web2py does 
(that's hearsay, though - I'm not using Eclipse).

Generally, one should be more relaxed about having to restart web2py - if run 
from the command line, it's just two key strokes away, and not really 
disruptive for the flow. We can not seriously make code design decisions 
dependend on such.

No need to bring settings into scope if just using ionce: this just adds memory usage

No need for the intermediate variable public_url since only used once...better to simply use direct

I would move all these CAP settigns _much_ lower in the file.
Pretty much all deployments will want to change email settings yet perhaps less than 1% will use CAP, so the Email ones should be much higher in the file...

Try to keep within 80 char page width - the ----- is a visual guide for this.
Can have a line break after the comma

I'd still move lower: what is more likely?
Restrict to an individual countrey? (most deployments) or CAP (very few)

This seems wrong: "fa" class is for font-awesome 4, but "icon-bullhorn" is font-awesome 3. We also try to avoid hardcoding icon classes, and instead use the ICON helper with abstract names that indicate the meaning rather than the look.

This should probably be on the index page only, not in the layout frame - because that way it would appear on /every/ page, while no other dynamic contents (like CRUD forms, Admin dialogs, tables etc) would ever be shown.

This is not responsive design in any way - you're overriding foundation's dynamic positioning and grid sizes, but what's the point with a responsive CSS framework then?

Hardcoded widths, floats, positions can not adapt to screen size. Suggest that you instead utilize the grid provided by Foundation (fluid grid), which is controlled by HTML classes rather than styles.

You're including a lot of CSS for no obvious reason - should only include what you really need for your layout.

I would avoid such whitespace changes - the existing style was the one used in all the other code

If these are right after one another then slightly more efficient to do the 2 together:
output = dict(map=map)

We normally prefer to just import from the main s3 module (this may have been wrong in the code you copy/pasted)

Note that in the code you're copying from, these are both just types of cms_post, yet in SAMBRO an alert should be a cap_alert, no?
Does SAMBRO need Events at all?

If you're going to tweak all this whitespace then please sort indents

If all you need is a little extra CSS for the homepage then moving to a full theme probably isn't required (a lot more maintenance effort).
I would suggest just inserting the extra CSS into the homepage.
(via s3.stylesheets)

Better to do this via s3.stylesheets, as I explained

This should be a for item in list_of_items: etc no?

I don't think this is responsive is it?

This is responsive. I am using "row" and "column" in the html. The css above is for formatting only, adding some paddings and margin, doesn't have to do with layout.

margins and paddings are fine, although Foundation recommends to use rem instead of px as that would make them adapt to font scaling ;)

rem is recommended as it allows scaling (mobile devices often do auto-scaling of fonts)

from s3 import S3CRUD (probably copy/pasted, I know)

Empty? So better to remove?

ok... thanks.

indent

indent: you still have tabs here which need to all be removed & replaced with spaces!

requires here is the same as the default isn't it? So better not to copy here.
Seems the only thing you are doing is making this mandatory which can be achieved by adding empty = False (since this is an S3ResuableField which will strip off the IS_EMPTY_OR in the default validator)

If this is to be accessed via UI, then you will need a represent in the validator too

For CSV Importers we generally replace things like priority_rank with the more human "Priority Rank"

In Python, string substition is faster than appending so better to do:
"%s-%s" % (sheet_name, count)

I'm not clear where the indent should be here but if thiss is correct then the comment should also be indented?

would prefer to align indents so that the s of subheading was under the r of the 1st rowCnt

Is this likely to become a list again?
If not then no need for a loop of 1...just itable.category.required = False

I don't think required = True is needed here?
requires = IS_IN_SET already achieves this

No need to include the fields argument if it's the default

default = ?
Shouldn't this be requires = ?

& what is different about this requires to the default one?

indent (Tabs again!)

This also needs changing in the Import.xsl (I am doinjg this atm as I need this for my work)

Would prefer each field on separate line, as per current code

Why iterate over a single row here? Surely more efficient to just build the row_dict directly?

Why no label for these fields?
No label => no ability to localise

What is different about this requires to the default one? (I asked this before but got no answer)

@flavour this could be multiple rows...so I iterate

Ah, a bad variable name then! row => 1 & rows => multiple
So yes we need to iterate, but pls change the variable name accordingly

still missing a label on this field

The reason this was indented less before was to keep within the 80 char page width - I guess this exceeds if you indent to the full like this?

The order of queries matters here since they will stop after the 1st failure.
The first is simplest & hence correct to have first, but then the 2nd simplest is currently last, so I would move that 2nd.

auth_group can always be loaded straight from db.auth_group

Can there not be multiple?

Yes there can, so misleading comment

I would rewrite this to avoid the loop of DB queries - more efficient to have a single DB query with a .belongs() in (which we could further optimise by using == if we only have a single approver)

@flavour I am creating the list of person ids from user ids here

Yes. That doesn't answer my point in any way. I am saying how you can do that _better_

Why check for permission to create alerts here?

I don't think we want a default here do we? I think it does nothing since the field is writable=False, but may as well remove for cleaner code (& probably faster if ou look at what this does in the reusable field)

Again, why this multiple permissionc heck?
Why check that you can create alerts & then update this one?
Doesn't make sense to me...

This isn't a query.
The query is (agtable.role == "Alert Approver")

This is a rows....please use variable names which aren't misleading

If you only need tho use the .id field then better to limit to just this in the select() as less data to read from the DB

This is dangerous as it allows arbitrary script injection - should not be accepted into trunk.

An acceptable method would be to parse the "css" contents, and then inject the CSS rules one by one explicitly.

Fixed

This entire function is already contained in the etree.parse() method - parse() does accept URLs directly, so it's unnecessary to re-implement that.

If you really need to read the URL yourself, then it would be as simple as:

```
with urllib2.urlopen(url) as source:
        tree = etree.parse(source)
```

The whole rest with read() and stuff is superfluous, and re-inventing the wheel.

Also - such a function (if at all necessary) should be placed in s3utils - it's not codec-related in any way.

Not protocol-safe.

```
if not auth.s3_logged_in():
    auth.permission.fail()
```

Should add:

```
and not r.record
```

It's a lot of processing here which is only needed if you look at multiple records.

Should use sys.exc_info instead - str(e) is not reliable.

Same here - sys.exc_info is the standard

Why is that block separate from the other methods? Is it actually misplaced and doesn't belong into that function?

Not safe - the page URL can (and often does) contain a query part.

This doesn't make any sense to me. Why fetch from a local XML instead of retrieving directly from the function that uses it? This does also circumvent authorization - in fact, that local request is not authorized at all, let alone with a subscriber-specific authentication.

A much better variant would be to implement that "send XML by FTP" as a method handler for the subscription URL, so that the request to that URL would send the data right away.

@nursix The representation in url may contain other than XML file (pdf, xls)

Right, I think this should be in the
for method in methods:
    if method == "FTP":
       ....
    else:
       ... old code here

etree.parse() will work for XML URLs, yes good...am sure that can be worked in, but we do also need (in future) to be able to handle non-XML representations like XLS/PDF

Ah yes, missed that ;)

Yup, True

Yes, better

I'm not sure where the query comes from (the filter?), but I guess it can be removed completely if we are accessing the resource_id directly

Although I agree with Dominic that it can come directly from the API rather than going back via a URL.
For XML formats: https://github.com/flavour/eden/blob/master/modules/s3/s3rest.py#L763
For4 PDF/XLS:
https://github.com/flavour/eden/blob/master/modules/s3/s3crud.py#L753

I had actually mentioned the authorisation issue (in depth) on an earlier commit, but then forgot it again when reviewing for the nth time and this hadn't been addressed :/
Anyway this is not required if using trhe API call instead :)

@biplovbhandari : that speaks even more for a sync adapter rather than this fetch-push combo.

XLS/PDF will not work with etree.from_string anyway, so hardly an argument?

An interesting idea...if using the current Channel implementation, this would be something like:
/eden/module/resourcename/resource_id.representation/send_via_ftp/channel_id

This would still require us to handle the authorisation though (both for access to the resource & for access to the FTP Channel)

The advantage of this method though is that we don't need to have an if method == "xxx" to call direct from the back-end API.
The disadvantage (other than the need for authorisation handling) is that we'll get the request overheads for every FTP send

If it's about /any/ web contents to be fetched, then indeed fetch() should be your method of choice. In that case it is not necessary to implement any new function here.

Not necessarily - the method handler can easily queue this and the queue can be handled async.

But all that is actually /included/ in Sync ;)

...or yes, right - notify does work asynchronously. But sync reduces the request overheads to one per target repository, which is a lot less than one request per record.

The interesting question is where the resource ID comes from? What do people subscribe to?

I would imagine that they want to subscribe to an alert area, not any particular alert - right? But the exported resource would not be the area, but the alerts for that area - so in this case, you wouldn't have a resource ID, but an area_id or location_id as filter.

Therefore I think that just removing the filter and replacing it by an ID isn't quite the whole story.

Could of course be that I'm wrong, and people do indeed subscribe to particular alerts...dunno. What's the concept here?

Unfortunately, notifications do impersonate rather than really login, otherwise you could work around the authorization problem here by adding the session cookie to the request. 

Direct API calls will however be properly authorised even with impersonate, and actually this is the only way from here.

People will filter by event_type_id & potentially by Location, yes
However ultimately this becomes a list of Alert resource_ids doesn't it?

I would avoid the leading space inside the T(), have that as a separate line if it is required (easier, more reusable l10n)

That how it is done here for the "FTP" method - in order to export every record as a separate file.

However, that's not standard - and a more than questionable generalization of a specific case.

True that XLS or PDF would work differently, as would other XML variants typically- for these we would expect a single file for all matching records

Note the way how it's done here - despite having the rows, a get_id() is run against the resource which runs a new db query. 

Instead, something like [row[resource._id] for row in rows] could be used.

But either way - URL filters will, in the majority of cases, be present in the page_url as that is the whole point about the page_url (see what notify() does to produce it). So, at least they need to be removed before doing simple string-operations with the URL.

Controller-Function ACLs (not "Functional-ACLs") ;)

FS is good enough (on s3base needed for FS)

Now that confuses me completely: 
You want to filter alerts by info.expires, but you implement a filter widget for info.id, and run a db query for info.id based on info.expires?? Why don't you implement a date filter for info.expires and set current.request.utcnow as default (=no db query)? What's useful about the info.id filter widget? Aren't you hiding from the user what you actually filter by?

Sorry, this doesn't make any sense to me.

It's still the same - and still not making sense. Recent alerts, according to the specs, are alerts which are still active, not those which have expired yesterday. This s3.filter excludes all unexpired alerts - how can this be correct?

How does this filter make sense?

I was thinking like this:

```
def customise_cap_alert_controller(**attr):

        now = current.request.utcnow()
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        from s3 import s3_set_default_filter
        s3_set_default_filter("info.expires",
                                         {"ge": today_start},
                                         tablename = "cap_alert",
                                         )
```

And then have a filter widget like S3DateFilter("info.expires").

NB If you would implement an S3DateFilter for info.expires instead, then you could perhaps see this default as generic, hence instead of calling set_default_filter in the template, you could pass the default filter as "default" parameter to the widget directly (in the model), similar to:

```
S3DateFilter("info.expires",
                     default = {"ge": current.request.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)},
                     )
```

That may make things a whole lot easier.

isn't "ge" and "le" input labels? How do use default here?

ge is an operator...which can link to a label or a default.

Have you tried this?

S3DateFilter("info.expires",
                         default = {"ge": current.request.utcnow.replace(hour=0, minute=0, second=0, microsecond=0)},
                         ),

This is not working for me?

Too little information: "is not working for me"

This may work if you change "ge" into "info.expires__ge", like:

```
S3DateFilter("info.expires"
                {"info.expires__ge": current.request.utcnow.replace(hour=0, minute=0, second=0, microsecond=0)},
               )
```

Generally useful to know what exactly it does or does not - rather than "is not working for me".

I am sorry Dominic...had to go out...
The commit link is https://github.com/biplovbhandari/eden/commit/3ebb7bcf7a97816abba7bd19b8ad125b42391498 as you have suggested.
I wipe the database and start again. This is how it looks: http://i.imgur.com/D4gjrAx.png 
when I add the date then it looks like this: http://i.imgur.com/BLdOKyr.png
Should not the second one by default? 

Whilst Dominic is leaning towards this view (which I understand) I actually prefer the alternate approach of making this simpler for users by simply having a radio button to select between 'Expired', 'Unexpired' and 'All', defaulting to 'Unexpired'

NB I would label this filter as 'Expiry Date' as if I didn't see the code then I would assume this was 'Date Created' or "Date Published' (Ideally the same date!)

That would be even better @flavour :) no real reason for the user having to fumble with the expiry date, the actual intent is pretty clear.

...was just following the spec in the document as I thought that was what Biplov was looking at

@biplovbhandari No, if you only set a default for the "ge" operator, then that would only be for the "from" field, while the "to" field (which is "le") remains empty. 

If you want both, then you must set a default for both (it's a dict!) - but I didn't yet see that requirement?

Admittedly, this translation of "has not expired yet" into "expiry date is greater or equal than today" can be a bit of a brain twister because "expiry" itself suggests an end date hence you spontaneously conclude the filter to be "until" not "from" (which is already reflected in the requirements spec).

Since that error seems common and hence would also affect the user and leave them confused, Fran's proposed simplification doesn't just seem better, but even necessary.

You could consider to replace this by:

```
deduplicate = S3Duplicate(primary=("area_id", "language"))
```

...and remove this function.

Nice new option :)
Will merge and let that enhancement come later

This used to be the "human_resource" controller, which is still defined in this file but commented. Maybe just uncomment+rename, or remove the commented version and replace with this one?

@nursix : Done :+1: 

Fine by me, good to merge.

Please use r.next, do not redirect from here.

Please use r.error, do not redirect from here.

I'm not sure that this button is really required now that unapproved records are visible for reviewers in regular CRUD. It seems a bit overcrowded with buttons in this view.

Approve should be a POST, not a GET (REST standard = GET must not change db status)

This doesn't even check whether there is an r.id - but that must be checked. You can not assume that.

Ideally you follow the pattern for "review" and hold those two things together.

Correction: self.next not r.next

This is incorrect - must be s3db.resource(self.resource), and must apply URL filters.

Ideally, you follow the standard for next as it is implemented in other methods (e.g. UPDATE).

@nursix Overcrowded, yes but looks okey rather than having to enter the url...The _next helps to come to the previous view rather than again having to type in the url...The label in the button is clear and does not confuse approver ?

-1 to renaming this. It's unnecessary and "S3ResourceLink" says nothing, it's confusing - please revert it. The main use-case is to _add_ a new record.

Using the same layout for an update-link is well possible - and if for that edge-case the name seems wrong, then do something like "from s3layouts import S3AddResourceLink as S3UpdateResourceLink".

Note that this does not properly authorize the particular record!
It will be better to check permission for the user_repository_id first - and only then add the update_link

Actually not - shall even be run if user_id is None.

Repeating the title is not quite the point with a tooltip ;)

Working around authorization and construction your own?

Err? No - this is PULL

this is FATAL not ERROR - because you can't even try to push.

This should go into login()

This should go into login

Implement what exactly?
(If you don't have a spec, then remove this alternative for now)

Why would you return a JSON message? Standard is just the error message.

I don't understand the ~ here - you do want just this record, not exclude this record, or?

Just:
    from s3query import S3URLQuery, FS

You can store the FTP object in self - S3Sync will always use the same connector instance it has logged in with.

output is just the message, not json_message

You could DRY this a little bit, and have just one log.write at the end. This is easier to read and maintain

You're not supposed to write to resource.muntil here - use a local variable (mtime).

I know you copy/pasted it, but ideally - remove this.
We should not use any local _debug anymore - but always current.log.debug where it makes sense.

I think I've said that before: our standard is:

```
except ftplib.all_errors:
    message = sys.exc_info()[1]
```

Same - we should use sys.exc_info in Sahana.

Maybe you shouldn't repeat "current.db" - but bring it into scope at an appropriate point outside of the loop (maybe even outside of the "if"s if multiple of them can apply).

Note that we do normally _not_ delete.
You should remove the task using S3Resource.delete(), and rely on the cascade.

Same here - better use S3Resource.delete and rely on the cascade.

That is not how we should do it. Use S3Resource.delete

Really?

I mean: really hardcoding it?

Updated alerts wouldn't get synchronized? Ok...

Again - should use S3Resource.delete.

Note: when using S3Resource.delete, deletion of the scheduler_task entries should go last.

Safer (and faster) to use the scheduler_task_id from the respective sync_jobs.

I think this is unnecessarily complicated.

? this needs a comment

This entire block is very difficult to understand - what does it do? Can you add comments so that it becomes clear what it is good for? There may be people after you trying to maintain this - please explain it to them.

Parameter description?

I think it's worth keeping this but commented out...

Do you have an alternative idea?
It comes from needing to have the UX for the sync be the same as subscription

Alert updates are always done as extra info elements

Hardcoding?

Yeah, obviously:

```
properties["sync_task_id"] = sync_task_id
```

Worth a comment to code maintainers?

A ToDo should be a wee bit more specific than that, that's what I mean.

+1 to commenting the branch, though.

Hardcoding the sync interval.

I highly doubt that new alerts would be created every 5 minutes - if that is really the case, then the recipients would be overwhelmed anyway. Who could possibly respond at that rate?

The actual idea may be to get new alerts out with a maximum delay of 5 minutes - but: wouldn't it make a lot more sense to trigger synchronize() onaccept of a new alert rather than running on a fixed schedule?

...yes, you can trigger synchronize for a repository directly:

```
task_id = s3task.async("sync_synchronize",
                       args = [repository.id],
                       vars = {"user_id": auth.user.id, "manual": True},
                       )
```

Had no idea you meant the interval! ;)
Yes should be sent ASAP...this is fundamentally notify & here we're talking about alerts...

...although it might be better to implement a new task that can synchronize multiple repositories, so that you don't need to schedule one task per repo (seems unnecessary). That task could start immediately onaccept, and update all CAP target repos.

That way, as long as there is no new alert, nothing will happen at all.

I would be tempted to add ftplib as self.ftplib after importing during login
I'm not sure if this really makes any difference though ;)

I'm sure it will be CRUD not URL ;)

Remember that Dominic already said that if title == label, means don't bother with title definition

Superfluous log message, really.

DRY DRY DRY - log one message per push, not many.

If you need debug information, write to current.log.debug - in the sync log, this is irrelevant.

Not needed - S3Sync will write a log entry if there was an error, otherwise we do not log the login-action separately.

Just return the error message if there was an error, otherwise none.

That's not needed either - if there was an error, S3Sync will log it. If there was no error, we don't log anything.

If you need debug info, use current.log.debug.

No it doesn't. Faster to read names from module than from self.

Way too much logging.

We want 1 log entry per push, not many - just to see whether the push was successful or not, and if not then why. Not logging every step in the process - that's what you can use current.log.debug for.

This is actually not necessary - owned_by_user will automatically be the user who created the record.

Wrong query.

Use an S3ResourceQuery here:

```
query = (FS("owned_by_user") == current.auth.user.id) & (FS("repository_id") == properties["repository_id"])
```

deleted != True is not needed with S3Resource - it will never contain deleted records unless you ask for it explicitly.

In principle, you would have to call update_super, set_record_owner and onaccept when you insert records in a table. 

However, there is currently no onaccept and no super-entity - so it's just set_record_owner you need to call.

Better use FS("owned_by_user") == user_id

Not calling set_record_owner here nor onaccept here :/

Not calling set_record_owner nor onaccept - but there is an onaccept to be called!

Specify the fields you want to select

"for" has no "else"

blanks around operators

parsing the JSON twice?? Why?

"filter" is a reserved Python keyword - use something else

Try with:

```
if row.repository_id != selected_repository_id:
```

There is no reason to have a pass under "if", and then an else-branch

Try to negate the condition?

There is no reason to have a pass under "if" (but then have an else-branch).

This is quite funny, isn't it?

In the try you set self.x, just to then bring it back into scope here. Why not:

```
try:
    ftp_connection = ftplib.FTP(url)
except ftplib.all_errors:
    ....
    ftp_connection = None
else:
    ....

self.remote_ftp_connection = ftp_connection
```

Bit easier to grasp...

pass? Forgot to remove?

consistent blanks around = if multi-line.

Simpler:

```
resource = s3db.resource("sync_resource_filter", id=removed_filter_ids)
```

In Python, you don't need outer brackets around conditions.

I would still want to have a comment here explaining what this block does (=splitting the belongs-filter into a series of = queries), and why (yeah: why? what is this good for?)

Why still the hassle with sync_job and scheduler_task?

Why not call repository.synchronize directly from a separate async task for the relevant repositories?

It is not required to have a sync_job for a repository - it's merely an /option/ if you want to run synchronizations with regular time intervals. But you don't want to sync with regular time intervals - you only want to sync when a new alert gets approved - so best to call an async task here onapprove.

Yup, exactly what I said :)

Why not just async a task to push all relevant repositories once onapprove - it doesn't quite make sense to me to create a schedule if you don't need a schedule.

The point with scheduled tasks is that they are repeated automatically after a certain amount of time - but you don't want it to be repeated automatically. You want the FTP repositories to be updated exactly once when an alter gets approved.

So - write a task function cap_ftp_sync in models/tasks.py, which finds the relevant repositories and calls repository.synchronize() for each of them. Then call this function like current.s3task.async("cap_ftp_sync", ...)

And remove all the sync_job and scheduler_task stuff.

No?

repository_id is an S3ReusableField - it does not have a "comment" attribute. 

You set such an attribute here, just to read it again when you create the form row a few lines further down - but for that you do not need "repository_id" /at all/. You can just make this a local variable "repository_comment".

There is no other purpose of bringing repository_id into scope here, so that's completely unnecessary.

...and wrong, actually. You're manipulating a nonexistent attribute of a template object, both of which isn't really allowed as it can lead to terrible regressions. This must be fixed.

(you are overwriting the original job query - always careful when re-using variables ;) )

Tip:

represent = S3Represent(options=dvr_status_opts),

Saves the innermost loop when representing many rows ;)

Just the error, no JSON message.

Hmm, include_deleted=True would only make sense if you would indeed delete remote records when they have been deleted locally - but you're not doing that.

Additionally, you would have to follow task.strategy. Only if it contains "delete", then you are allowed to delete remote records. Same for "create" and "update" strategies.

Right now, you export all records (both deleted and not deleted), and you push all records which have been modified (any of created, deleted or updated) regardless of task.strategy. In SAMBRO, where you set msince manually, this might work. But for a generic adapter, this is wrong of course.

Fine with a ToDo for now, though. But re-consider include_deleted.

No cascade=True please!

cascade=True is to indicate recursion (of resource.delete itself!), so that it can rollback this part of the cascade in case another part of the cascade fails. But there is no such exit in this function, and you do write the new filters unconditionally, so no point to keep this transaction open.

Actually - no: you can not just make it a ToDo. You /must/ follow strategy.

SAMBRO specifies task.strategy=["create"] which means:

1) Only if strategy contains "update" or "delete" then you can use modified_on > mtime. If strategy is only "create", you must use created_on > mtime.
2) include_deleted must be False unless task.strategy includes "delete" _and_ you have the capability to delete remote records.

So, this must be fixed - not just ToDo.

Here: must use created_on if strategy is only "create". Only if strategy includes "update" or "delete" you may use modified_on.

This is important even with manual mtime, because otherwise you create a race-condition. Records could be updated before the async task goes out, and then you end up with old records whilst you only want to send new ones (=violates the strategy).

Btw - in Python, we usually write:

```
return output, mtime
```

...but at least a blank between the "return" and the value (return is not a function)

Hmm - still not following task.strategy :/

I was thinking of something like:

```
if msince:
    strategy = task.stragegy
    updated = "update" in strategy
    created = "create" in stratgegy
    if udpated and created:
        mtime_filter = table.modified_on > msince
    elif created:
        mtime_filter = table.created_on > msince
    elif updated:
        mtime_filter = (table.created_on <= msince) & (table.modified_on > msince)
    else:
        mtime_filter = None
    if mtime_filter:
        resource.add_filter(mtime_filter)
```

...but of course you write a nicer one.

This is the default ;) Better try a useful comment:

```
resource = current.s3db.resource(resource_name,
                                 # FTP remote deletion not supported yet
                                 #include_deleted = True
                                 )
```

Note that this is specific for this adapter as FTP has no update strategy, so the export must take care of it (normally, the importer would).

New to me :)
Many, many examples that could be improved this way then - ideal beginner volunteer task I guess

No big win performance-wise, but a lot easier to type ;)

This is confusing as it looks like you are conflating id with layer_id - since the id is from gis_layer_entity they are in fact the same as there is no id field...I would prefer this to be more explicit & actually use the layer_id field directly

Bring this outside the loop
(I would bring it outside the top if: )

Again, bring this outside the loop

Why does this need to be Ordered?

row.style is getopt many times...I would bring this into scope up here

I'm still worried by this not using IS_JSONS3 validator
SQLite & PostgreSQL behave differently with the style field since it just uses a text field in SQLite but a real JSON field in PostgreSQL.

Comment no longer valid of course ;)

Can even be moved below the if rows:

I'll merge this as it's a step fwd, but you did you get the UX enhancement suggestions I made for this?
i.e. the fact that there needs to be a login channel
Hence I would filter the login channel from this view & provide a dedicated link to the login channel (we can create this in prepop, even with the entries blank)

Deprecated - pls use S3PopupLink instead (drop-in replacement)

and not used in this file anyway

In general, I think this kind of thing is better done by adding/removing classes...the actual CSS is in the stylesheet.
Won't hold-up merge though...just a future @ToDo (not urgent)

I still think there is a bug here.
Surely we don't want u'fou' converted to 'fo' which I think this would do
What we want is 'fou'

That looks safer :)

Makes no difference with S3Represent if you call other represents per-row.

Blank line after docstring please.

Separate logical code blocks by blank line => easier to read and follow the flow

You should call the bulk-method of the same (!) represent instances once during lookup_rows for /all/ values.

That will store the representations in the instance, so that when you call them per-row in represent_row, they wouldn't be looked up again.

Typically, use self.table in lookup_rows

This constructor does basically nothing - so should be removed.

Repeated lookups of self.table - should be brought into scope.

I don't think date.represent has a bulk-method?

Repeated lookup of str(self.table.date) inside the loop - should be done once outside the loop (it's constant)

Same - repeated lookup of str(self.table.organisation_id) inside the loop. Should be done once outside the loop.

Here too - same repeated lookup of a constant value inside the loop.

Blanks between """ and the text pls.

You should test this - site_id.represent may return a link (unless you suppress it explicitly), and then this string construction is actually not ok, or is it?

Same here - organisation_id.represent may return a link (unless you set show_link=False), which may not work with this type of string construction.

Subject to testing, of course - I'm not certain it really does.

Critically, this lookup does not include table.id - but that is mandatory. All rows must contain the record ID, otherwise S3Represent won't work.

(How else could we identify which representation belongs to which id?)

This not being here tells me that you did not test it!

Why is this a separate controller?
Makes more sense to me as an S3Method

So we'd have cap/alert/[alert_id]/publish

F

no i18n?

should be moved inside the branch which uses it

@flavour I am a bit confused here. As Dominic was saying earlier, the original concept was 'approve' being that the record could come into the database and 'publish' being record sent out. But in SAMBRO, we trust the user so every alert created comes into the database and 'approve' simply gets it out to the general public. So I think if we stick to workflow ATM, the approve should be implemented as I have done here, or otherwise we need to modify the workflow, which would involve two steps -> Create Alert -> Send for Approval -> Approved -> Send for Publish -> Published -> Record to general public.

Since I think we agreed to have this simple as Approved being record sent to general public, the approve method works for now? What are your thoughts?

I think Fran's point is that it should not be a separate controller, but rather an S3Method, so that it's called via cap/alert/5/publish instead of cap/publish?cap_alert.id=5.

It's not about the workflow, I don't think.

Here I am simply approving the record so that it appears in the datatable, name is different though

Dominic is right...I am NOT trying to complicate/alter the workflow
I am merely saying that the functionality should be at cap/alert/5/publish instead of cap/publish?cap_alert.id=5

Hmm - yesterday Fran said he wanted this to become an S3Method of cap_alert.

Now you merely renamed the controller - what am I missing here?

Was exactly my comment earlier

This was done as separate function as in others also as here:https://github.com/flavour/eden/blob/master/controllers/vulnerability.py#L1535
Besides, S3crud always outputs view https://github.com/flavour/eden/blob/master/modules/s3/s3crud.py#L790? This is just action? What am I missing here?

> This was done as separate function as in others also as here: https://github.com/flavour/eden/blob/master/controllers/vulnerability.py#L1535

This is a custom function highly tied to the Vulnerability model, whereas I see nothing CAP-specific about the one you created. (Also the function was created by a developer who wasn't aware of the S3Method-based approach)

> S3crud always outputs view https://github.com/flavour/eden/blob/master/modules/s3/s3crud.py#L790? This is just action?

Typically yes, but I don't see that as a complete requirement.

I wouldn't get rid of the Text Label - just add the RSS icon too...
Also I think you can be more DRY here:
{{if current.auth.s3_logged_in(): fn = "alert" else fn = "public"}}
<a href='/{{=appname}}/cap/{{=fn}}.rss' target='_blank'><i class='icon-rss'></i></a>

This violates our naming conventions - function names are all-lowercase (CamelCase), and underscores as word separator.

And in th controller, you do not need the cap_ prefix.

This is a very poor docstring, not the slightest explaining why you need such a hyper-complex procedure just to change the message status!

The truth is that this function is cloning an alert, including all its components - which is not exactly what "changing status" means to me. Why not call it "clone" and say that in the docstring - if that is what it does?

You do not need to re-select the new row, it is good enough if you add the new record id to the dict, and then pass that dict.

Moreover, the function name and the docstring tell two different stories, and the actual function yet another one. Somehow this should be sorted out.

Why is it necessary to clone the entire alert?

Such changes are evil (because they do not auto-migrate, and hence require each and every existing Sahana system to be manually migrated).

Please explain why you're doing this, why you suddenly need to allow (in fact: deliberately produce) duplicates (clones), and how you want to deduplicate alerts.

@nursix Sorry my bad...will fix that

@nursix Sorry again...I forget to update the docstring :(

You are aware that this function is open for everyone, hence even anonymous users can clone alerts. Is that correct? Wouldn't it be better to make this an S3Method and call it via the alert() controller?

You are not validating this - you just trust the URL variable??

You are not checking whether alert_row actually exists - just trusting it?

Not quite correct - onaccept takes the form vars, i.e.:

```
location_row_clone["id"] = new_location_id
s3db.onaccept(location_table, location_row_clone)
```

Same here: update the form vars with the "id" (not "resource_id"!) and pass them into onaccept.

Same here - it's "id" not "tag_id", and you should pass the entire dict, not just the id (onaccept callbacks expect /all/ form vars, may otherwise not do anything)

Same here - "id" not "area_id", and pass the entire dict, not just the id.

Same here - not "info_id" but "id", and pass the entire dict.

You're not calling update_super, but cap_resource is a doc_entity instance, so you must call update_super after insert. Otherwise you can not attach documents to this resource.

This is not good enough - you must not copy the doc_id (or any super-keys) either.

You are not validating this - can set whatever I want

You are not validating this - I can pick whatever alert I want, and don't even need any permissions. Even anonymous can clone an alert

It is, again, wrong to alter the database state with a GET request. This entire function should:

1) be an S3Method, called as /cap/alert/[id]/clone
2) be properly authorized, checking both READ permission on the record, and CREATE permission on all tables that are being written to
3) respond to POST (or PUT), but report an error for GET
4) call audit!
5) validate all inputs, especially the "caller" (which is actually: "msgtype")
6) make sure that super-keys are not duplicated, but instead update_super is called properly for new records
7) Make sure that for gis_locations, onvalidation is called (location_onvalidation is one of the few form validators that alters the data, so you must call it)

Sorry, I know - quite a lot of work before this can be merged :S

@nursix Can you point me to the example how do we make call and then alter using POST request in eden, so that I can get started?

I think the safest variant is to make these Ajax buttons, and attach a script that produces the POST request - and if the request succeeds, then opens the new record.

An Ajax-button is like an action button, except that it has a "_ajaxurl" property instead of "url". You can set a "_class" property to attach the script (e.g. "action-btn cap-clone-update").

The script would send an Ajax-request to cap/alert/[id]/clone - and the S3Method would respond to it by cloning the record (if permitted) and, if successful, returning the new record ID to the script. Then the script would open the new record in a regular cap/alert/[id]/update view (i.e. client-side forwarding rather than server-side redirect).

Examples for S3Methods are easy to find, e.g.:
https://github.com/flavour/eden/blob/master/modules/s3db/work.py#L466 
This example is also a method handler responding to POST requests (in this case: POST work/job/[id]/signup.json and POST work/job/[id]/cancel.json). It responds with a simple JSON message, and you can put the new record ID into that JSON message by just adding it as another keyword argument.

This method handler is bound to the respective resource (work/job) here:
https://github.com/flavour/eden/blob/master/modules/s3db/work.py#L257

The corresponding button script is here:
https://github.com/flavour/eden/blob/master/static/scripts/S3/s3.work.js#L25
Of course the lookup of the record ID is a bit different because it works from a data list not data table. However, in data tables it's all the easier because you have a "db_id" attribute in the action-button that holds the record ID.

This example is still a bit incomplete (WIP) - lacks the audit-part. But you can find that in CRUD Forms:
https://github.com/flavour/eden/blob/master/modules/s3/s3forms.py#L648

So, when you have created the clone, then you should call current.audit("create", ...).

Obviously, if you use db().select, then you must check permissions manually (using current.auth.s3_accessible_query). If you use S3Resource.select instead, then you do not need to do that - the permission check would be included.

For the insert, however, you must check create-permission on the respective table (using current.auth.s3_has_permission) - there is no way to automate that.

Note that if you make this an S3Method of the cap_alert, then read-permission on the master-record is checked before the S3Method is even reached - as is the permission to access the cap/alert controller. This is one of the arguments /for/ using an S3Method.

(the other argument for making this a REST method is that it would call s3.prep (so you can configure method-specific resource settings), and can be customised in templates (using settings.customise_cap_alert_controller))

This conflict needs resolving before it can be merged

And this one

I deliberately added this one to test out x-org functionality in Volunteer Requests - I think it is useful to keep.
I changed the passwords to eden since all other templates have that as the default password for non-Admin

Since these are just used once, no need to bring into scope - just use them inline

This term isn't fitting with the rest of the system (only CRMT template uses this term).
Better to respect the deployment_setting:
label=settings.get_org_site_label()
- this defaults to Facility

Not sure why you moved, but not a problem, will merge :)

Won't hold up merge, but 'uncomment' won't be an easy option...either this needs to be in a template fragment (once we have cascading templates) or else a deployment_setting

I won't hold up merge, but I don 't see any need for this extra var?
Why not just:
if msg_error_btn:

Slightly DRYer if the .rss is not part of the fn variable (also matches the meaning of 'fn' better!)

I said that using any of the buttons msg_*_btn can lead to regression if you remove one of them.

But I also said that the condition itself can be assigned to a boolean variable, not to create a separate one.

Sorry but...

...your previous solution was more regression-safe.

If in subsequent versions, or under certain conditions, the "Error" button would be removed, renamed or whatever, then you will now have to fix a lot of code - whilst with the separate boolean, you can do with particular buttons whatever you want without having to worry about regression.

I would revert to the boolean. Much better style.

Should it really be "/.rss" - not just ".rss" ?

@nursix Oops sorry...

Apart from that it is technically not defined what a truthy value of an HTML object is, so correctly it would have to be: "if msg_error_btn is not None".

We normally use the shortcut 'settings'

No need to check for ADMIN role here as ADMIN will get True for all roles

Indent

Easy enough to move these to else

indent

Same as earlier - no need for ADMIN check

This is quite complex - I wonder if you can't use owned_by_group instead?
Seems to make for much simpler queries.
(You may well need to set the owned_by_group)

indent

indent

generally prefer to end last line with comma & have closing parenthesis on next line
(allows easier adding/commenting entries)

So Admins can't susbcribe via FTP?
I think this is OK...requirements I've seen didn't suggest otherwise but good to make this very explicit in the docs

avoid get_opt in nested loop:
define_resource = s3db.resource outside of outer loop

Again, avoid repeated getopt by bringing update_admin_subscription into scope outside loop

current_user_id = auth.user.id is simpler

We generally use the shortcut define_resource for this...to distinguish from an instantiation:
resource = define_resource(...)

Not yet actioned ;)

I see auth.user.id read earlier too, so can be brought into scope up there

We probably won't have too many user_ids in the list but still better to bring the s3_user_pe_id into scope outside the list

Again, s3_get_user_id can be brought into scope outside the loop

So ensure the in scope outside loop also works for this one

I think you can limit the fields you wish to read? I only see id & filter_id used

& again...

Why have these 2 options which do exactly the same thing?

I don't think we need to set the group differently per role doing it...this is over-complicated.
I would just use the ALERT_EDITOR group no matter which of the 3 updates the subscription?

@flavour The alert editor can also have own subscriptions...However they need to add the FTP through url...This one is for that check

This is no longer actually used anywhere

I still don't understand this if/elif?
Both branches are the same

Seems to me that it will be more efficient to collect the IDs to delete in the loop & then do a single resource.delete() outside the loop?

You bring get_user_id into scope outside the loop, but then don't actually use it inside ;)

In general if such a wrapper doesn't have a bulk option, then you may be more efficient not using it, but rather doing your own bulk method (or adding a bulk method to core)

Likewise, I suspect a bulk conversion would be much faster than doing it 1 by 1 through the wrapper

Again, I would collate the IDs to delete inside the loop & then delete them all together outside the loop

We only expect a single group_id don't we?
row = ...limitby(0,1)
owned_by_group == group_id

As above

No need for the explicit check for ADMIN

group_row only defined in this branch, so would crash outside it...hmm, this fn only gets called if the users are set already? So why check again?

Since this is a wrapper called multiple times in a loop, try to minimise the work done inside it.
Here we lookup a group_id every time!
At the minimum, cache the result with cache=s3db.cache in the select(), but I think here we can easily avoid it by doing the lookup outside & passing group_id into the fn

@flavour THis one is for self subscription for alert editor. He can subscribe and remove himself, but sees the admin subscription page. FOr FTP configure, need to go through url? 

I was suggesting doing this using a bulk lookup rather than this wrapper which is ineffecient when done inside a loop

In fact you're not using this at all anyway?

I suggested doing this using a bulk lookup fn instead of this wrapper, which is inefficient when done in a loop (it's not complex what it does, so very easy to write a bulk version...which would be usefully added to s3aaa.py)

You can make this more efficient by having a base_query outside the loop:
base_query = (stable.owned_by_group == group_row.id) & (stable.deleted != True)
for pe_id in pe_ids:
    query = base_query & (stable.pe_id == pe_id)

@flavour Any examples on bulk lookup?

indent

Again, completely unused (if it was should be using the bulk version, but seems can just be removed)

base_query outside loop can be used here (less useful than the 2 element version above, but still useful)

current_pe_id is defined earlier...admittedly ina  branch...but why not define along with current_user_id for reuse?

All Admin Subscriptions are held in a single record?

@flavour They are same in each record, isn't it?

This seems odd. I would have thought that different Subscriptions would be done for different Groups?

As I explained before, the fn doesn't exist yet, but if you look at what this fn does then it should be pretty easy to write a bulk equivalent

@flavour How to have groups, add members to group? As S3OptionsFilter?

Groups could be the answer, but we wouldn't want to create auth_group for these...pr_group would be used...which also has a pe_id in it already - so the subscriptions work directly with that rather than having to convert user_id <> pe_id.
Obviously if we're using pr_group for this then we'll need to give Admins a menu entry to manage them

NB Check with Nuwan whether he wants Groups...as I understood it, the norm was to subscribe individuals...i.e. most groups would contain 1 mmber which means that the groups concept is unnecessarily clumsy.
But each user should have separate subscriptions, right? Your query always does a limitby=(0,1) for the subscriptions table based purely on owned_by_group...which seems wrong...it should also be restricted to the relevant pe_id.
So fotr each pe_id (Person in this case) we can have 2 subscriptions: 1 which is user-controlled (owned_by_group=None) & 1 which is Admin-controlled (owned_by_group="ALERT_EDITOR") [id, not name of course ;)]

Why do this as 2 separate queries instead of a join? Join is generally more efficient for this

The query looks correct here - not just owned_by & deleted, but also pe_id

@flavour Actually this function is only called for admin subscriptions as <a href="https://github.com/biplovbhandari/eden/blob/master/modules/templates/SAMBRO/controllers.py#L373">here</a>

So here is where you call the fn which returns a single Admin Subscription.
But this is not what we need - an Admin should be able to set subscriptions for each user individually, shouldn't they?

This is how it appears to Alert Editors. They selects user and the assign the filter that is used for all selected users. Ofcourse, there is no group in here
![123](https://cloud.githubusercontent.com/assets/4207677/10997506/3ae11d2c-84c0-11e5-986f-20b02fe80f63.PNG)

So how do they have different users for different subscriptions?
e.g. User 1 for Area 1 & User 2 for Area 2

@flavour So we need group?

As I said before: Group is 1 option, however I think it's unnecessarily complex for this usecase where most groups would have 1 member.
& anyway that wouldn't ultimately change anything to use groups here instead of users - you still have just a single subscription option for all Admins for all Users

@flavour Sorry  for this, but when you say bulk version, what kinda fn do you mean? Also are there any examples of bulk lookup in the trunk?

bulk = not 1 by 1
So instead of:
for x in y:
row = db(table.id==x.id).select()

do:

rows = db(table.id.belongs([x.id for x in y])).select()

Better to avoid the multiple double get_opt:
subscription_id = request.get_vars.get("subscription_id")
if subscription_id:
...

used 3 times => bring into scope

used 2 times => bring into scope

Surely better to do these 2 queries in bulk?
i.e. using .belongs()
Remember: Python loops are a lot cheaper than multiple DB calls

Same multiple double get_opt:
subscription_id = request.get_vars.get("subscription_id")
if subscription_id:
...

Again, better to this uising a single bulk query outside the loop: .belongs()

& again: multiple double get_opt

Again, better to do this in bulk outside the loop

This too can be done in bulk outside the loop

multiple double getopt can be removed

Seems rather odd to me to have these be in the personal menu for Admins?
Admin menu would seem more suitable?
Or within the main CAP module...

@flavour How to write this in bulk outside loop?

essentially using .belongs() instead of ==

@flavour This is the S3 function. Should I rewrite the query using belongs?

@flavour What is operator for != in query like belongs for ==?

I think I have said this a few times already: YES
Idewally this could be a reusable bulk function added to S3AAA

There is no != which needs converting : both of these are checking None
Only the == pe_id needs converting to a .belongs()
(I checked this before adding the original comment)

Could be:

```
represent = S3Represent(options = pr_literacy_opts)
```

Good enough for now, can come with next push.

Why the intermediate variable?

There should be some kind opf documentation...even if just a comment to explain that we're using the Alert Editor role as the owned_by_group to distinguish Admin-controlled subscriptions

I don't understand this comment?

Ah: "Both Individuals & Groups selected"

I don't see the value of this intermediate variable.
auth.user, however would be useful to bring into scope as used twice.

Groups plural?

How about "Manage Recipient Groups"

could bring s3_has_role into scope before the if

I still don't like this being the location for these options.
This is a Personal menu...not a menu for Admin tasks.
I suggest moving these to either the CAP module or Admin.
I think the CAP module menu makes most sense to me...it already has many Admin functions in

Subscriptions ;)

Useful to add a comment explaining this (whilst we still remember!)

Why not just define output here?
Seems very odd to define empty at the start & then update here?
(This pattern is useful where there are several updates, some of which at least are optional)

Why did you change this to extend here?
append is likely to be more efficient when adding just 1 entry

You're not using the has_role shortcut here yet

Recipients?

Post-merge: "Filter to just Admin-controlled subscriptions"

You don't need to send nor check the password with the POST vars.

If you send an HTTP BasicAuth header with the request, this will happen automatically, so you can simply check whether current.auth.user is not None (i.e. the BasicAuth was successful), and then user current.auth.user to obtain the user info.

This here is all re-inventing the wheel - and in a rather unsafe and non-standard way. I gave you the exact code structure, why don't you just follow it?

Do any users not have this right?

Do any users with Update not have Delete?
This seems a little overly-generic to me, but perhaps you do need it?

What value does a dict add over a simple list?
Seems to just add bloat to me...

keys here are still overly long for my tastes...why not use just single letters?

Why are first_name/last_name needed? What are they used for?

Why is organisation name needed? What is this used for?
If there is a field in the form which gets filled from this, then why not do that server-side rather than passing back to client & thence back to server...

What do these permissions tell you which the roles don't?
Seems overkill to me for such a use-case specific client/function.

Building a generic toolkit sounds great, but then that would need to not just query 1 table, but all tables and would therefore carry far more information than you want...and it wouldn't live in SAMBRO/controllers.py but somewhere else.
So either build a generic toolkit or a SAMBRO-specific client, but don't do half-and-half.
My understanding is that this is SAMBRO-specific hence it living here & hence can be simplified to just saying whether the user is:
- Just Authenticated (i.e. we get a 200 here)
- Has Alert Editor or Publisher

so Potentially we could just have 4 possible responses:
- 401 (Authentication Required)
- 200 but empty (User is Authenticated but has no special rights in the system...so can just read Alerts (if this is even in-scope for the mobile app))
- 200 with an 'e' returned (User is an Alert Editor)
- 200 with an 'a' returned (User is an Alert Approver)

Sure, if there really are more things that are required back to the client then send them by all means, but start with the very simplest data structure & work up from there on an as-needed basis.

& do we really need all Roles?
Seems to me that Authenticated isn't useful to pass back, nor is Administrator (as no Admin tasks are done by the mobile client?)
The only roles I am aware of as useful are Alert Editor & Approver (assuming approval is in-scope for the mobile client, which I'm not sure of)
I would have thought that a top-level single letter key with a boolean 0/1 for whether they have the role would be plenty sufficient here...

I've only seen this syntax before for left joins, which isn't required in this case.
Simpler to just put in the query:
query = (mtable.deleted != True) & \
             (mtable.group_id == gtable.id) & \
             (mtable.user_id == user["id"])

NB Note also that I am checking for the deleted memberships here not roles (I can't see roles being deleted & not an issue anyway as we filter these later...but deleted memberships on the other hand are critical)

@ToDo: enhance this by as well as True, being able to specify a specific Twitter channel to tweet on (True => use default channel)

Still have this unnecessary intermediate variable

No @ToDo: on handling the multi-message nicely? ;)

@flavour If False, is there a deployment setting to assign the channel id?
for tweet, can we do send_tweet(self, text="", recipient=None, channel_id=None) to  send_tweet(self, text="", recipient=None, channel_id=None) or is there other way? 

Options:
False = No tweeting
True = tweet using default channel
<name of channel>

Currently msg.send_tweet doesn't support that option, so if we get to that requirement then we would need to add it there too (easy to add, just like is already there for msg.poll_twitter)

As I say, this is an @ToDo anyway

Since this is primarily shown on an action button, it should remain "Öffnen" - the double translation is very confusing.

Uppercase should be uppercase.

Uppercase should be uppercase.

we should alter the english title for the button "Open" into "Edit" - and
use the translation Offen for Open, cause the status "Open" is used in many
other cases ;-)

2016-02-07 18:36 GMT+01:00 Dominic König notifications@github.com:

> In languages/de.py
> https://github.com/flavour/eden/pull/1215#discussion_r52120957:
> 
> > @@ -2875,7 +2917,7 @@
> >  'Opacity': 'Opazität (Undurchsichtigkeit)',
> >  'Open area': 'Offener Bereich',
> >  'Open recent': 'Kürzlich Bearbeitetes öffnen',
> > -'Open': 'Öffnen',
> > +'Open': 'Offen/Öffnen',
> 
> Since this is primarily shown on an action button, it should remain
> "Öffnen" - the double translation is very confusing.
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1215/files#r52120957.

söndagen den 7 februari 2016 09.41.49 skrev  Armin Retterath:

> we should alter the english title for the button "Open" into "Edit" - and
> use the translation Offen for Open, cause the status "Open" is used in many
> other cases

Easier said than done: "Open" is used as generalization for both READ and EDIT 
actions, so it can't just be changed into "EDIT" as it could also mean "READ".

More generally speaking, any differentiation between "to open" and "being open" 
is not easy to do in English - both meanings are needed in various places, 
with "to open" being the primary meaning.

And also, the fact that the English language requires context interpretation 
to understand a word while other languages use different words, is not limited 
to "open" - there are many other examples.

To make things worse, German has more than 30 different translations for the 
various meanings of "open" ;)

http://www.dict.cc/?s=open

So - however you do it, you can't do it right.

However, in Sahana the primary meaning of "open" is "to open", so we should 
not double-translate the word, and ideally use a different term in other 
contexts where possible - for example, in the shelter context, you could use 
something like "operating", "in service", "available", ...whilst there are no 
real alternatives to "to open" a record.

Dominic

Read: better to not OPEN that can of worms ;)

Ok - 'in service' seems to be a good idea ;-)
Am 07.02.2016 19:22 schrieb "Dominic König" notifications@github.com:

> In languages/de.py
> https://github.com/flavour/eden/pull/1215#discussion_r52121574:
> 
> > @@ -2875,7 +2917,7 @@
> >  'Opacity': 'Opazität (Undurchsichtigkeit)',
> >  'Open area': 'Offener Bereich',
> >  'Open recent': 'Kürzlich Bearbeitetes öffnen',
> > -'Open': 'Öffnen',
> > +'Open': 'Offen/Öffnen',
> 
> söndagen den 7 februari 2016 09.41.49 skrev Armin Retterath:
> we should alter the english title for the button "Open" into "Edit" - and
> use the translation Offen for Open, cause the status "Open" is used in many
> other cases
> Easier said than done: "Open" is used as generalization for both READ and
> EDIT actions, so it can't just be changed into "EDIT" as it could also mean
> "READ". More generally speaking, any differentiation between "to open" and
> "being open" is not easy to do in English - both meanings are needed in
> various places, with "to open" being the primary meaning. And also, the
> fact that the English language requires context interpretation to
> understand a word while other languages use different words, is not limited
> to "open" - there are many other examples. To make things worse, German has
> more than 30 different translations for the various meanings of "open" ;)
> http://www.dict.cc/?s=open So - however you do it, you can't do it right.
> However, in Sahana the primary meaning of "open" is "to open", so we should
> not double-translate the word, and ideally use a different term in other
> contexts where possible - for example, in the shelter context, you could
> use something like "operating", "in service", "available", ...whilst there
> are no real alternatives to "to open" a record. Dominic
> 
> —
> Reply to this email directly or view it on GitHub
> https://github.com/flavour/eden/pull/1215/files#r52121574.

A better way to do this (which doesn't end up with a trailing space):
" ".join(info.response_type)

auth = current.auth worth bringing into scope above has_role =

This is all still commented-out?

I guess that's OK because S3LocationSelectorWidget doesn't support Circles (yet or ever)
Then we should have appropriate comments on this: "Enable this if adding Circle tool support to S3LocationSelectorWidget"

I think the CIRCULARSTRING support should be line-commented too with another comment above that section & also a comment in the commented-out helper function

& the CIRCULAR STRING

& then this comment can be updated for S3LocationSelector & s3.ui.locationselector.js
Here & the other location(s): always take the opportunity to housekeep to help the next person...who may very well be ourselves in a few months' time! ;)

Sorry - you had a bad example to copy from here: cll these args="xxx" should actually be m="xxx".

I'll cleanup after merge, so go ahead @flavour 

My comment remains unanswered here

# @ToDo: Make the filter update timestamp on refresh in the client side

Why is this being done in postp & not onaccept?

I guess we should filter out deleted segments here too?

This is not localisable, so seems a very poor way to do this!
I think you can add msg_no_match here:
https://github.com/flavour/eden/blob/master/modules/s3db/cap.py#L562

This might be best done in the custom controller as the message is specific to this usecase. NB Might also be best to say T("No Current Alerts match these filters") or something...as there may well be current alerts which we choose to filter out...the 'No Current Alerts' is the filter which is hardcoded & not user-visible/selectable

This now should be 'Modify Open button' of course (won't delay merge)

Nothing CAP-specific about this is there?
Wouldn't it make more sense in gis.css?

space ;)

I wonder if we shouldn't enhance this by also checking that the user didn't just press return & set their org_oid to the country_oid...which I assume would be bad?

resource_table.insert can be brought into scope outside the loop

onvalidation can be brought into scope outside the loop

location_row.clone.update(alert_id = new_alert_id,
                                           area_id = new_area_id)

outside outer loop

location_table.insert can be brought into scope outside outer loop

Are these ever going to be different?
I think that we can use business-knowledge to avoid such multiple tests.
In the real world a user will either have create access to both or Neither

& I think both the same as the outer check (has_permission("create", area_table))
I think both of these are redundant

Again, I don't think we need yet another check: Real world users have all or None

Country root oid. The oid for the organisation includes this base with an additional suffix

@ToDo: Add validation to ensure user doesn't just accept this root as this would not be acceptable

I'm actually a little uncomfortable with this. WIll ALL orgs defined in the system be Alerting Orgs?
I would suspect that some (many?) might not - they might just be responding Orgs

This should just be one, not multiple?
So limitby=(0,1)).first() & no loop within the rows later

Can reuse the has_permission brought into scope earlier?

gtable can be brought into scope outside outer loop

resource_table is not an instance of a super entity, is it?
So this isn't required

@flavour But it has reference to super entity https://github.com/flavour/eden/blob/master/modules/s3db/cap.py#L1004. This case requires update_super, yes?

A reference wouldn't need this, no.
However this is partially an instance of a super entity (missing this: https://github.com/flavour/eden/blob/master/modules/s3db/doc.py#L75)
This is for the document component, which is being used...although oddly it has an image field directly embedded instead of using the image component...I guess due to widget limitations? (This is commented in the crud_form, but could also be usefully added as a comment in the model)
So then yes, it should haave update_super here, so bring into scope outside outer loop.
Also fix the missing entry in doc.py

Used only once now we removed the loop? So no need to bring into scope

area_table.insert can be brought into scope outside loop

This is still inside the outer loop

I don't see the value in the if here...can go straight to the loop (even if loop is empty)

Seems daft to me - can just "is_template" to primary, no? That way you can still deduplicate templates.

What if is_template is True? Shouldn't a template be deduplicated against an existing template with the same name?

To me: S3Duplicate(primary=("area_id", "location_id", "is_template"))

That way, if the item is not a template, it won't match a template - but if it is a template, then it will only match templates. Makes sense?

@nursix "is_template" field is in master table cap_area. This is component table cap_area_location.

Yeah, I picked the wrong line here. See below.

My point is that you're preventing deduplication of template<=>template here too, which doesn't seem to make sense. 

Shouldn't that be so that templates match templates, and non-templates match non-templates (i.e. is_template is equal between item and row), or do you really want to never deduplicate templates?

@nursix I didnt looked the template area because some demo data that were collected from previous training have some data with same name but different location_id. 

Meaning: you should prevent deduplication of template<=>non-template as well as non-template<=>template. But template<=>template seems just as desirable as non-template<=>non-template. How else would you be able to update templates via import?

You change here prevents deduplication completely if the import item is a template - and that seems to throw the baby out with the bath water. If that's deliberate, then fine of course.

@nursix Thanks for heads up! I checked data and those were differing in some parts (as those were hand drawn). Will add this check too.

Just out of curiosity: is "is_template" actually relevant, or does alert_id==None just equally qualify the record as a template?

I'm just wondering that because is_template!=True does not catch is_template==None, which should of course never happen due to the default, but since there is no notnull contraint for that field, it could be broken.

There is no "unbreakable code" requirement here, so you don't need to fix anything. It's more for my understanding when reviewing this.

alert_id is for sync

Put the atable.id, limitby=(0,1) inside the select...otherwise we are pulling back all fields and searching through all records, rather than stopping on first match

prefer alpha-sort: deletable before editable

As above

This doesn't make sense to me?
"If the 1st cap_area record has an info_id then show this column in list_fields otherwise don't?"
This doesn't seem related to the areas which are part of this alert or anything.
It's a little expensive to do a DB query test here...why not just include it always if you want it sometimes?

As above

if you are using event_type_id to say 'this is a template' then why bother with the additional is_template check?

If template !=True then we absolutely should have an alert_id right?
We don't ever want to match on alert_id is None?
In which case the is_templayte is redundant & we should check we have an alert_id before bothering with the query?

@flavour I think we need this for xml import where we have info_id and not alert_id

hmmm, a little dangerous to rely on multiple foreign XML imports to all use unique area names.
If we don't  have an alert_id in the data, then we assume this is an XML import...and thus we have an info_id? So we can use the info_id to lookup the alert_id?

This still doesn't make sense to me. Please see my previous comments

As above

Perhaps better to move this comment to the field which doesn't work...what happens currently? It is ignored? Perhaps better to comment out the problem field(s)?

Since used so many times, better to move this into scope: fvget = form_vars.get

Why bring these 2 into scope outside of a branch which may end up not using them?

A comment explaining this would be useful:
e.g. 
'# This must be a template

Comment: CAP XML Import

Comment: Real Alert, not Termplate

Comment: Nothing we can use

Why do this query outside a branch & hence it might not be used?

(Same for the 2 bring into scopes)

I don't think these make sense in SAMBRO/config.py since we have multiple sites sharing the same template.
Instead create separate templates for each of the SAMBRO deployments which have these deployment-specific things in.
We have cascading templates, so in 000_config.py can set: settings.base.template = ("locations.MM", "SAMBRO"))
Can also add a "SAMBRO.MM" at the end if there are SAMBRO-specific things to change, but generic ones like the timezone should be in core locations.

used in else also

So this is deliberately not localised?

This query is still outside a branch - so it might be run for no reason (still useful, but less-critical for the 2x bring into scope above, but a DAL query is always relatively expesnive so more important to optimise)

itable was already brought into scope earlier

I prefer:
''Show predefined areas tab if we have some defined for this event_type"

@flavour that is because there is else branch that is also using it

ok, yes, looked at whole file - big function!

When is row True but not row.id?
I don't believe such a case exists? (I see this twice & it seems an unnecessary check to me)

This seems out of place - no event_type_id in this table, and no deduplicator will be reached if you have a unique key among the fields.

unique=True must me supplemented with an IS_NOT_ONE_OF validator, otherwise violations of the constraints during imports can break the entire import.

Also note that adding a unique-constraint will require a manual DB migration (can't just add the constraint)

This is not enough - validator must also catch the notnull/unique constraints (PostgreSQL will stop the entire transaction on violations, not just the current query, so this would break imports).

@nursix I would love to document these tips by you... Do we have a particular wiki page for this?

Nothing Sahana-specific here, just common knowledge/logic:

Adding a unique-constraint to a legacy database will fail if there are non-unique values in the field. That is why it does not auto-migrate - and you will have to sort this out by hand.

PostgreSQL doesn't do nested transactions, so if one command fails, no further commands can be added to the same transaction. Hence you must validate data against all constraints /before/ sending the command.

I don't think that documenting that on the Sahana wiki would add a lot of value - developers usually know that.

...and if they don't know it, they wouldn't search the wiki for it.

The problem is that people always need a reason to search the wiki for information - and for these two things there is no such reason unless they are aware of these things. But if you already are aware, then there's no reason to search either ;) as the question is already the answer.

No need for current here: T is in scope

five priority names

This assumes that all feature Layers are CAP ones.
This is only true within the SAMBRO template, not all possible Sahana deployments which enable CAP

I suggest querying the gis_layer_feature table instead & filtering for c==cap
This covers both private & public Alerts
Could consider filtering to f==public or alert but I think that we can assume that no other cap resources are going to be put on the map

Should this not crash the system?
I am very wary of hiding this error here...

I would generally say:
if group_ids:

This is both simpler and catches the case where the input is None.

(Can be fixed post-merge)

if request.get_vars["option"] == "manage_recipient" is being checked twice (actually 3 times since once outside the postp) So better to check once & then cache the result.
NB To pass into the postp requires a trick:
def custom_postp(r, output, manage_recipient=manage_recipient)

if rows:
simpler

if rows:
simpler

What is this needed for?

Ideally, there should be no independent controller here - or at least it must be restricted to exactly what it is needed for.

Wouldn't this be better expressed as class? Node ids can easily clash.

You did not get my point when I explained this: the reason to pre-render the records in Python is because it is easier to debug than a view template. 

Yet you're doing it exactly the other way around, moving the rendering of the rows into the view template.

What's the reason for that?

Now that doesn't make sense to me.

All of `if group_ids` or `if len(group_ids)` or `if len(group_ids) > 0` have a point, but comparing a list against 0 seems wrong.

"field" not defined if permission check fails

This entire nested loop over queries can be done in a much better way - this is complicated, fragile and inefficient. 

And why is it repeated, for Groups/Persons separately? DRY

Bit pointless to construct with %(number)s here - it'll be exactly 1 according to the condition.

This is not valid - all anchors have the same node ID. Node IDs must be unique in the document.

Inconsistent indentation - makes it hard to read. Why have 2 queries here? Should be just one.

No point passing in "option" - is in scope anyway.

{"prefix": "sync"}

Shouldn't use the dict constructor if all parameters are constants anyway (less efficient)

This is a really strange string construction - what's the point here?

Why have a local variable at all if single-use?

r.record.msg_type? Do you really need an additional query here?

"" is not a valid response for a popup link.

Like this:

```
s3.prep = lambda r: r.representation == "s3json" and r.method == "options"
```

Ok, though I actually think that this function isn't needed. The case can be better solved with a join.

In fact - where is this used?

As much as I can see you're iterating through the subscriptions and compare the pe_id of the subscriber to the group_ids - but why not select just those subscriptions belonging to the respective groups/users in the first place? This can be solved via a join, and then you do not need either of the bulk lookup functions.

Besides, an intelligent join will remove the deep nesting in the function, making it more readable and less fragile.

There is really no common case for this function, and no plausible one can be constructed. I'd recommend to either move this into SAMBRO, or (much better) solve this with an intelligent join that doesn't require loop+compare.

So Relay can now be used by all users, even within same Org, right?
I'll assume a deliberate change...

So yes this is really where we should be using realms now, but I won't hold up the merge for it.
Users would need an ANY read & a write just for their realms...then can check for write access ('update') to show these buttons

@flavour No I just defined this here as this is used more than once

Nice to add the 'for SMS' here
(Won't hold up merge)

@flavour Thats why I asked you...This seems to solve the case for now...Shall we move to realm when it is needed as you mentioned in your email earlier?

Should have PEP8 spacing:
etable.id == event_type_id
(Won't hold up merge)

No need for the > 0 here...easier to read without.
(Won't hold up merge)

As above

As above

Slight optimisation:
bring the pr_subscription element of row into scope as used twice
(Won't hold up merge)

If this is a list I'd prefer the variable name to reflect that:
user_ids

Ah no, it's a single due to the [0]

This seems rather inefficient?
We iterate over group_pe_ids within an iteration of that same var!?
Why not do this for the outer loop?:
for pe_id, group_id in group_pe_ids.iteritems():

Again the slight optimisation  of bringing row.pr_subscription into scope as used twice
(& this is within a loop so will matter more)

I see a common pattern here of:
    if` x:
       for row in rows:
            # Lots of lines
    else:
        # Something small

I think I'd find it a lot easier to read with the negative:
    if not x:
        # something small
    else:
          # Add a comment referring back to the if
          for row in rows:
              # Lots of lines

Very funny construction - does nothing else than `group_id = group_pe_ids[pe_id]` :D

Sorry, what I actually wanted to say is that dict.iteritems() is deprecated, should be just dict.items():

```
for pe_id, group_id in group_pe_ids.items():
```

It's not wrong to use iteritems, though - e.g. if you want to break out of the loop prematurely like you do here (so you can continue using it if you think you need to). However, this isn't any faster or more readable than:

```
for pe_id in group_pe_ids:
    group_id = group_pe_ids[pe_id]
```

...which still allows you to break out of the loop before the end of the sequence.

(In fact, in Python 2.7 this variant is the faster than either of items() and iteritems(), so this is what I recommend)

@flavour I added this here because the generic SAMBRO has other two language along this. The settings.L10n.languages["dv"] = "ދިވެހި" would just update the same and hence all four languages are visible for SAMBRO.MV

NB in settings.langauges, US is just 'en' (CAP languages is different)
I don't think that the default SAMBRO template should have any setting for languages any more...not the right place for it in an application template. Instead this should be the job of the Locations template(s) &/or any Deployment Template

No - pls do as I suggested here

This is not needed for the Deployment template.
The location template should give exactly the same result if the app template doesn't interfere

See my comment in other commit:
Why have multiple separate controlelrs each to look up 1-2 settings?
far more efficient to do a single lookup for all settings.

You didn't answer why you added Opacity separately at the layer level when it is already in the style?

Still no indication of how these should be formatted

@flavour I changed at the layer level but that didn't worked as I expected...so I changed it at the layer level

@flavour I have `settings.base.template = ("SAMBRO", "locations.PH", "SAMBRO.PH")` in models/000_config.py

The SAMBRO instance that we have here at AIT is not country specific ( I plan to use `settings.base.template = "SAMBRO"` ,ie all the four languages). In this case, do you think we should remove the language setting in the default SAMBRO template?

Read what you wrote: it makes no sense

Perhaps say what you are tryign to achieve exactly?
The Features already have a transparency, correct? (it's in the style)
You want it to be more transparent?

@flavour sorry :( 
I meant it didn't worked as expected when I changed the opacity in the style

I do think that the SAMBRO template shouldn't have languages in it.
Perhaps what you need is a SAMBRO.Demo template for this?
(or just use 000_config.py)

Generally the order to apply should be:
("locations.PH", "SAMBRO", "SAMBRO.PH")
Although hopefully the application should never over-ride location settings

& what was expected? & what happened?

@flavour if you look at here: http://sambro.geoinfo.ait.ac.th/eden/cap/public/64/profile
The layer should be transparent. I changed the style opacity to 0.25 and this is the result. But if I change the layer opacity to 0.25 it works as expected.
See the mail for the login details

I don't need login details for public ;)
Page took ages to load as in debug mode...but OK, I see the issue:
This is the default style since none of the style elements are being matched (since we have no priority).
The simple option is to remove the fillOpacity from the style elements & just have it at the layer level  (either 0.4 or 0.25 whatever is desired).
The option with more control is to specify an element in the style list with a "fallback" attribute (the value is the title for this option, so 'No priority' or something here)

This should probably be removed from here too?
Perhaps the Demo SAMBRO template should have a gis_config to define the SITE_DEFAULT
On the Demo server you could set
settings.template += (Locations/MM, Locations/MV, Locations/PH, SAMBRO, SAMBRO/Demo)

ok, will merge even with this major issue unresolved! ;)
We should probably have a list of all the places which need handling for this.
I thought we already had this usecase in our 1st deployment countries or is that not the case?

I don't think this needs a ToDo actually...was more for your info

"-" comes from current.messages["NONE"] right?
better to have that in this check so that if that value changes then this code won't need updating

This doesn't look right - the onaccept expects an area_id not id. Maybe pass the entire ldata:

```
ldata["id"] = lid
s3db.onaccept(ltable, ldata)
```

?

It's not custom if it is in the standard model. If it is meant to be custom, move it into the template. Otherwise remove the "Custom" here.

+1

PEP8: increase indent if it's a continued line

docstring missing

docstring missing

docstring missing

Although actually I would comment this anyway as it wouldn't be needed in this case
(can keep commented in case that changes)

Actually: name of the tag - right? Easier to understand.

docstring

Personally I don't see that every onaccept needs a docstring - we know what onaccepts are so something like "Post DB processing for x table" is pretty tautological.
I prefer the "what it does" to be within the code itself as it can often do several things & even if just 1 it makes more sense to me to have within the code as easier to read.
What is the argument to have a docstring here?

Well, we call this 'Key' normally...just that that's a reserved word in SQL so we need to use the fieldname 'tag' & hence the table gets that too.
Some UI usecases expose 'Tag' to the user too, although Key is more' common'
Here I think 'Name of the code' is fine

I was thinking "Name of the tag" as opposed to "Value of the Tag". Name of the code is a bit cryptic.

However, I just commented for reason of completeness - my actual point was about the onaccept.

http://eden.sahanafoundation.org/wiki/DeveloperGuidelines/CodeConventions#CommentsandDocstrings

Of course, something like "post-DB processing" is just nonsense ;) however, I prefer having a bullet point list with the actions done onaccept rather than having to study the function (comments in the function may explain "how" but a summary of what would be nice in the docstring - a nice practice introduced by @flavour).

This function, in any case, has neither the one nor the other.

Good examples:
https://github.com/sahana/eden/blob/master/modules/s3db/hrm.py#L1026
https://github.com/sahana/eden/blob/master/modules/s3db/gis.py#L2210
https://github.com/sahana/eden/blob/master/modules/s3db/gis.py#L2742
...and many more.

Unfortunately, "name of the code" doesn't quite give a hint that the "code" is stored as location tag :/ I can see it now within the context of this PR - but I (or another developer studying SAMBRO) may not be able to remember that in a year or two. At least there should be a hint that this has to do with gis_location_tags. Just a hint. Please?

I would comment this line as does nothing here (but commented is a reminder to uncomment if the fn changes) Can be done post-merge

hmm, why remove this?
This is a useful feature as some feeds require a username/password.
If you wish to simplify the UI for a single usecase which doesn't require it then this should be done using a deployment_setting

probably not wanted for the core template!?

Whilst it is possible to do a full override like this, I wonder if this would add too much to maintenance?
For adding a single entry it is more DRY to do something like:
menu = super(S3OptionsMenu, self).cap()
menu[1] = M()

It may need some playing with...e.g. here super is the core s3menus version, not any SAMBRO version that exists, so that may need tweaking.

I'm not too objecting to a completely different menu here...just worth trying to be DRY if we're just adding 1 entry

trailing comma is probably not desired (do you want a tuple here?)

Model methods should have a prefix to avoid clashes

Should not this & the above one be run?
i.e. don't you want:
row_clone["expires"] = s3db.cap_expiry_date()
row_clone["sender_name"] = s3db.cap_sender_name()

I don't think this is correct.
Like this we can bypass security just by providing a pe_id which isn't related to a person.
This needs more thought

Do we really want to send such a message if there are no new notifications?
Personally I'd prefer to receive nothing.
I can see that potentially some people might disagree & prefer to receive such a message daily whether or not there are any new notifications...so perhaps add a deployment_setting to allow this option & then T() the message that it sends.
Ideally the normal case, where we don't want to send empty notifications, would be caught earlier

No! Templates want to customize that as well. And it is not internationalized anyway, so plain and simply: no.

> caught earlier

i.e. Why submit a POST request needlessly?
This adds a whole request overhead cycle to the system...

hmm, this seems to break the main security model!

ok, I see you put in a custom check here
But the cap/public also needs access - since this is used for all other representations.
Can the 'msg' representation not be set to use the public controller for anonymous requests?

Just checking:
approved_on gets set in both workflow options, right?
If 'approval is not needed' then the Editor auto-approves under the hood?

This was added because for HTML emails empty emails ( no body only subject) were received

Actually I think this is correct, though it can be simplified by removing the logged-in check completely.

If the lookup request comes in anonymously, then we apply ANONYMOUS permissions in the data lookup (resource.select below) - which allows us to subscribe other PE's than persons. 

Hence, the subscriber does not have to be logged-in - the only thing that is important at this point is that we do have a valid subscriber (pe_id!=None).

@biplovbhandari: Doesn't make sense - send() exits with a JSON message when no rows were found, and doesn't send a message. 
https://github.com/sahana/eden/blob/master/modules/s3/s3notify.py#L302

@flavour: To see whether there are updates which are accessible by the subscriber (and hence to be notified), you need to impersonate the subscriber and go through the resource's controller (including custom prep/postp and other customizations of the template), which is what the POST request is for.

This can't be done during notify() - hence the POST request is always required.

...but it's just a local request, so overheads are small - and notify isn't time-critical anyway.

@biplovbhandari : What you may want to do is to add:

```
if not message:
    continue
```

before this block:

https://github.com/sahana/eden/blob/master/modules/s3/s3notify.py#L424

That way, if the message template returns empty, no message would be sent.

@flavour both workflow options means? approved_on is set here: https://github.com/sahana/eden/blob/master/modules/s3db/cap.py#L1678

Not for imported but for system alert. Anyway we have to either Relay Alert for the imported alert.

@nursix But for html emails, although the body is empty, the message is not empty as it has at least `<html>` and `<body>` tags, no?

Err - that is entirely up to your message template.

If that template adds tags even if there is no contents, then yes - but there is nothing that says the template must add tags. It could render empty if there is nothing to render.

At the same time, there is nothing that says the template must not add contents even if there are no updates. It could render an info like the one you want to hardcode here.

Entirely your choice - which to leave is exactly why I'm insisting on this to be passed to the template and not hardcoded here.

Here is where these tags get added:
https://github.com/sahana/eden/blob/master/modules/templates/SAMBRO/views/msg/notify_email_html.html

...so you can easily prevent that.

Btw, there is yet another problem here that forbids this change: the data extraction method is completely customizable (settings.get_msg_notify_renderer), and if it doesn't return a dict with "upd" and "new", then this check will just crash.

But the whole point about having this customizable is that you can implement any kind of custom rendering, there is nothing that says it must have a "upd" or "new" - it could also render complete HTML elements or text sections, and hence a different dict structure.

So, this change is simply a no-go - the only acceptable alternative is to check whether the message template renders empty and in such cases not sending the message.

...and I did recommend before to move your complex rendering from the message template into a renderer function (so that it can be debugged - which is difficult with view templates), and have the template just be `{{=contents}}`.

That way, you can easily render empty by returning `contents=""` from the renderer ;)

And here you did:
https://github.com/sahana/eden/blob/master/modules/templates/SAMBRO/config.py#L528

Now, your renderer returns a dict structure with "upd" and "new" - but it doesn't have to. The renderer can be tailored to the template and vice versa - the dict structure is only between these two.

And to leave it at that, we can not and we must not inspect the renderer output in send() - but rather check whether the template produces any message at all from that (which seems legitimate as we don't really want to send completely empty messages).

You haven't corrected this ;)

This hasn't yet been modified.
We don't need the DB call to lookup the instance type.
We just need pe_id != None

Is there really no way to avoid this?

Both workflow options are:
- Approval Required (i.e. 2 steps with 2 roles: Editor & Approver)
- Approval not Required (i.e. 1 step with 1 role: Editor)
  or did this change? (so hard to remember all details)
  Do we now always have the 2 steps?
  Just that some deployments allow the Editors to be self-approvers (i.e. they are given Approver role) & some deployments have this be a separate role

Remember that lines with just python {{}} still give a blank line in the output.
More optimised output is obtained using:
{{if new is not None:}}<html>
</html>{{pass}}

@flavour currently its 2 steps...I will leave comment to remind when we have option 2 also

I'm not sure why you changed this? What you had was correct: the dropdown should be the list of cap languages not UI languages.
The suggestions I had were:
- Hide filter completely if only 1x CAP language
- Default the filter to the user's language for user-controlled subscriptions if there is a match (here was where en<>en_US needed tackling)

@flavour How do you default value in S3OptionsFilter? This does not seem to work

That is exactly how to do it - specify a "default" value. Are you sure this is executed, and the default is in the selectable options?

And what do you mean by "does not seem to work"? How are you testing it?

Ah ok - I see. This "filter form" doesn't actually filter anything - and if it does not filter, filter defaults can not be applied. So setting a filter default here is pointless.

For what you seem trying to do, you must send the default values in the get_vars when calling S3FilterForm.fields in manage_subscriptions (that is, when it isn't an update of an existing subscription).

That is here:
https://github.com/biplovbhandari/eden/blob/master/modules/templates/SAMBRO/controllers.py#L445

The filter widgets get their current values from the get_vars.

If you want to set a default selection for those widgets, you must pass those defaults through the get_vars (unless it's an update). 

That seems relatively simple to do because you are generating the get_vars here:
https://github.com/biplovbhandari/eden/blob/master/modules/templates/SAMBRO/controllers.py#L949
https://github.com/biplovbhandari/eden/blob/master/modules/templates/SAMBRO/controllers.py#L1008

Simply don't leave them empty if there is no subscription row, but set your defaults.

Please note that a filter default is not the same as pre-selecting an option in a CRUD form widget - because a filter default does actually mean to /filter/ the target resource by default. That does obviously only work if the filter widget is actually attached to a resource /and/ that resource is the target of the current request - otherwise it would claim to be filtering while it can not.

Since you're re-purposing the filter widgets into CRUD widgets here, the filter default option is indeed not the way to pre-select values. In this case you must treat the filter widgets like CRUD widgets, and hence pass in the default value as the current value when rendering the widget.

In normal CRUD widgets, this happens via the "value" parameter - in filter widgets, this is done through the "get_vars" parameter (which is passed on from the filter form to individual widgets).

This modifies the field type rather than the label.

An internationalized label looks like this:

```
Field("name",
      label = T("Name"), # <= internationalized label, a T-instance
      ),
```

The field type "text" is not correct here, btw - name is of type "string", which is the default type and therefore not specified explicitly.

Same for the other fields.

No, this is not correct. Must be lookupResource here, can't rely on ~

What is the problem that made you change this?

lookupResource is used for the controller, which isn't always the resource
e.g. cap/template (which is a filtered version of cap/alert)
What cases are lookupResource != ~ ?
(assumign lookupResource really is the resource & not just the controller)

The lookupResource is != ~ when the lookupPrefix specifies a parent (e.g. "pr/person/1/address").

I do remember that this was deliberately changed from "~" into "lookupResource" due to a bug report, so I don't think it can't just be changed back.

ok, so then we do need the lookupController option adding
(it can default to lookupResource if not specified)

Ahm, actually I don't think so. The change with lookupResource predates the introduction of the ~ shortcut, so it can't have been related to that.

Try using ~ - this should cover all current cases, and if a problem comes up we can look over this again.

We can still use lookupURL if we really wanted to add a parent (this is the existing option to override the URL construction with a custom URL, and I don't think we need another one)

So you're saying that this change can stay as-is, right?

Avoid duplicate r.table: bring into scope

Avoid duplicate r.table: bring into scope

slightly less HTML to send back to browser if you substitute the app name server-side instead of client-side (can be cleaned up post merge)

Should these be ORs not ANDs?

Is this small enough to include in modules/ along with the other 3rd-party modules there?

Seems it is to me

No error if not?
I'd have thought a try/except (faster for the usual case where this is configured) with the except giving a current.log.error

Only used once so no need to bring into scope

Why move this under the queries? Those aren't used for this & seems clearer to me to start with this...as it was...

Why do you need the LIKE here?
It should be exactly "GCM", no?

I don't think you need this special case here?
Just need:
for pe_id in pe_ids:
This is DRYer and should perform a little better

Minor tweak: can bring utcnow into scope outside loop

Minor tweak: can bring subject/message into scope outside loop

is this not the case already?

It depends on the usecase...the current usecases for tagging are very specific to each resource & hence make sense to be restricted to each resource...a global tag table would be poor there.
A generic tagging table would meet other usecases (although I'm surprised this comes up for CAP!?).

I think list_orderby falls back to orderby, so if they are the same, then no need to specify both

default name, so no need to specify

default name, so no need to specify

default name, so no need to specify

I see label = T() ?

I would create a new class for all the History tables
- there are few (if any!) usecases which require loading both tables together...so keep performance trim by loading only what is required: Working tables OR Historic tables

This seems like the wrong place to do this?
No need to wrap in prep & in fact better to do within customise_resource?

Same as above

In fact even better is to simply modify this in the usecases in the CAP module
So where you have:
self.event_type_id()
Replace with:
self.event_type_id(ondelete = "SET NULL")
This puts it directly into the core model

This is a little confusing...it appears to be a REST operator, but I don't think it is.
(The REST operator would be ~.approved_by__ne=None)
Is this doing a filter or just configuring these options?

@flavour This is for filter to show the approved alerts `eden/cap/alert?~.approved_by!=None` and I am configuring list_fields according to this URL (Menu item)?

I see the menu item, but I don't see the filtering.
If you want to filter then you should use the REST operator:
approved_by__ne=None

approved_by!=None may look like it would do this, but I don't believe that it does.

@flavour not sure if this works correctly.

I have 22 approved alerts in my local db.
- `eden/cap/alert?~.approved_by__ne=None` gives me 10 records
  ![image](https://cloud.githubusercontent.com/assets/4207677/15471860/6a1fdfca-2122-11e6-8223-8a55eda944a7.png)
- `eden/cap/alert?~.approved_by!=None` gives 22 records
  ![image](https://cloud.githubusercontent.com/assets/4207677/15471897/93857262-2122-11e6-8080-78359c97b4d9.png)

Is there something I am missing here?

Ahm - question: two consecutive assignments to the same variable - what's the point here? The second would override the first. Should perhaps better use resource.add_filter (since you're already in the prep, there is no need for s3.filter).

Besides: FS is global, no need for s3base.

Same: second assignment overriding the first - what's the point? Should use add_filter, I suppose.

Why are you hardcoding a non-standard date representation? The current date format is a global setting which can be customized in the template (or in the controller if needs be), yet this one case doesn't apply the setting.

required = True or IS_NOT_EMPTY? That's two different things: 
- required=True means the field must be specified in _every_ write command to the DB (i.e. both create and update), but it can be set to None (!)
- IS_NOT_EMPTY means that it can not be set to None - but it doesn't have to be specified in every write command (since there's a default for create, and update can just keep the value without having to read it first)

I highly suspect that you want IS_NOT_EMPTY rather than required=True.

No need for 'response' in the controller context: s3 already in-scope (as you use on the previous line)

Seems odd to have this controller for something which would pretty much always get used in component context?
Anyway I won't block on it

But explaining the usecase in the docstring would be useful

Can just use get_vars in the controller context :)

Did you try using msg.compose() ?

I don't think you gain value from separating these files within a single theme
- the point of the separation is to allow multiple themes

I'm not sure why CAP needs a separate Compose function & View?
What is different about the CAP one?

Sure there are some permission checks etc as a wrapper to the compose form, but the form itself should be standard & hence best DRY?

better:
if representation in ("html", "aadata"):

Useful to note this dependency in optional_requirements.txt

Seems an odd limitation?
Might we not want to have different Orgs having diff accounts for diff billing/reporting?

Why is this cap_gcm & not msg_gcm?
This seems to be msg_ to me...

Nope, this is wrong - no ids required at this point, and even if they were required, this is the wrong way to determine them.

If you need all ids, you must specify getids=True in the select.

What's your point with this change? Maybe should fix the select instead.

This seems wrong too (and doesn't pass tests) - request library is already an optional requirement (for posting to facebook), and specified as >=2.3.0 there.

@nursix this was for /eden/msg/compose which does not get the person auto complete suggestion because ids are not available for pr/pentity/search_ac.json

It's the wrong approach, however.

> 6 juni 2016 kl. 02:48 skrev Biplov Bhandari notifications@github.com:
> 
> In modules/s3/s3resource.py:
> 
> > @@ -5252,6 +5252,8 @@ def **init**(self,
> >                          # Limited master query without count/getids
> >                          # (=rows is the subset, only need page IDs)
> >                          page = self.getids(rows, pkey)
> > -                        if not ids:
> > -                            ids = self.getids(rows, pkey)
> >   @nursix this was for /eden/msg/compose which does not get the person auto complete suggestion because ids are not available for pr/search
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.

Besides: what is pr/search?

If you meant pr/person_seach, then this is using pr_search_ac, and pr_search_ac is not using ids anywhere.

So can you please specify the problem more precisely?

Dominic

> 6 juni 2016 kl. 02:48 skrev Biplov Bhandari notifications@github.com:
> 
> @nursix this was for /eden/msg/compose which does not get the person auto complete suggestion because ids are not available for pr/search

I guess (!) you mean pe_search_ac ;)

Well, I'm afraid that is a wrong implementation in the pe_search_ac function. It uses data.ids, but it doesn't request ids. And even if it did, it would be a wrong assumption that ids[i] belongs to rows[i] - because by definition, data.ids holds all record ids even outside of the requested page.

In pe_search_ac, the record ID must be added to the requested fields, and then read from the row - using data.ids is wrong in this way (bug).

I can try fixing it, if you give me a little time - and back out this change in S3ResourceData.

Dominic

> 6 juni 2016 kl. 02:48 skrev Biplov Bhandari notifications@github.com:
> 
> In modules/s3/s3resource.py:
> 
> > @@ -5252,6 +5252,8 @@ def **init**(self,
> >                          # Limited master query without count/getids
> >                          # (=rows is the subset, only need page IDs)
> >                          page = self.getids(rows, pkey)
> > -                        if not ids:
> > -                            ids = self.getids(rows, pkey)
> >   @nursix this was for /eden/msg/compose which does not get the person auto complete suggestion because ids are not available for pr/search
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub, or mute the thread.

@nursix I meant for /eden/msg/compose which does not get the person auto complete suggestion because ids are not available for pr/pentity/search_ac.json
I have back out the change in S3Resource

Yup, I figured that it was about pe_search_ac rather than pr/search.

The use of S3ResourceData.ids in that function is not valid - and actually unnecessary. 

The point with using data.ids was that the "pe_id" field was represented as name, and could thus not be used as option value - but the solution to that is as simple as to use the raw data, like here:
https://github.com/nursix/eden/commit/deb9373b1f12a279c54053f1f660413f724a4bcf

With this, msg/compose should work as expected - testing+feedback appreciated, of course.

This seems to always repeat what was done in lines 215-216

'headline' alone risks clashes...the namespaced version of cap-headline is safer

I thought the representation would always use the complete list, no?

Looks like a copy/paste bug ;)

I still think the users are going to want to have a fixed list in a dropdown to select from rather than having to enter data in freetext, which is error-prone.
An Alert Hub configuration can have this set to the complete list if-required...and perhaps the requires can be modified between the 2 usecases in a prep in config.py

I think these should be translatable, so:
("ar", T("Arabic")),
etc

I also think this should be a complete list which isn't configurable & can be used in other cases to CAP (this representation of language codes has much wider applicability).
modules/s3/s3translate.py would seem to be the best place to put this
Then in CAP, can from s3.s3translate import languages

Copy/paste fragment ;)
(I don't think FB messages are size limited...)

"Posting Alert to Facebook failed:

Should this be current.messages["NONE"] in case that changes?

~.external__ne=True

Would be nice to include a note as to why this is subclassed - what is different vs the std one?
(I know this is the separate RSS channels, since I hunted, but making this more explicit is nice)

But remember that there is already a Sahana standard for that:
https://github.com/sahana/eden/blob/master/modules/s3/s3validators.py#L3325

which uses a complete list:
https://github.com/sahana/eden/blob/master/modules/s3/s3validators.py#L3360

I wonder whether this really needs a re-implementation.

Used like this:

```
represent = IS_ISO639_2_LANGUAGE_CODE.represent_local
```

IMHO that does exactly the same, doesn't it?

Example: https://github.com/sahana/eden/blob/master/modules/s3db/dvr.py#L551

Can still specify settings.get_cap_languages() as subset ("select" parameter). The good part is that it would limit the selection, but still be able to represent codes which are not in the subset.

I don't think there is a need for either the representation function nor a custom IS_IN_SET construct here - but maybe I'm missing something here.

No this is perfect - I knew we should have a global one instead of a local one...forgot we already had one & so no need to make it :)

Shouldn't this be:

```
requires = IS_EMPTY_OR(IS_ISO639_2_LANGUAGE_CODE(select=represent_languages, translate=True))
```

?

(I also thought that you wanted a configurable subset as settings.cap.languages?)

If you have an external-flag, then you don't need to set it onaccept (nor to check the MCI).

Just let it default to True, and in the interactive prep, set the default to False.

If you let this default to True instead, and in the interactive prep change the default to False, then you do not need to update it onaccept, or by mci, because it would always only be False for interactively (=locally) created alerts, while all imported alert would have external=True by default.

Btw, I don't get the IS_EMPTY_OR - why would you allow the language to be set to empty deliberately in the GUI?

According to the standard, a null value shall be understood as en-US, which already is your default. Hence, if empty and en-US are equivalent, then IMHO allowing empty makes no sense. It's either en-US, or it is another language - but it is never "no language".

This shouldn't be necessary - should disallow empty for all cases.

json.loads, not eval

Btw, you can check for resource.error - which may be easier than parsing the response locally.

len(resource.import_created)

len(resource.import_updated)

resource.import_updated[0]

resource.import_created[0]

I don't quite see a need to parse the JSON message - since it's local context, you can just pick the information from the resource.

Ideally, "record_id" not "_id". And according to PEP8, trailing underscore rather than leading underscore (to avoid confusion with semi-private variables)

Better to use an S3 filter expression: FS("type") == "cap" (because the framework can not introspect web2py queries). That may not be required here, but better to make that a general habit: if you can FS, then better do FS.

Better to override-replace than to update (relying on the _class attribute is prone to regression):

```
s3.actions = S3CRUD.action_buttons(...)
```

This would also check permissions and hide buttons if action is not permitted.

Superfluous continue - where else would it go?

Not checking permissions?

If that is the assumption, then you should break out of the loop here, right?

...out of both loops actually.

Why this line break? Short enough to have that in a single line.

Indentation (PEP8)! Even after a line break.

dict members should follow regular name rules, i.e. all lowercase and underscore for word separation. And better to use the dict literal than the constructor:

```
{"scope": s3_str(row["cap_alert.scope"],
 "status": s3_str(row["cap_alert.status"]),
}
```

What a string template! Have you tried making bodies an array, and use "\n\n".join(bodies)?

If it is an array, then it should be an array:

```
body = []
body.append(...)
body.append(...)
body.append(...)

body = "\n\n".join(body)
```

(meaning: indices in variable names indicate that this should actually be a list, but the programmer didn't know how to make a list in Python. Does that apply for you?)

Missing semicolon

Missing semicolon

What is the reason for indices in the variable names here. Those "fn" don't seem generic, they have a specific purpose, like: details_widget, info_widget, qualifier_widget - so why not indicate that clearly in the names. Should those functions be defined inline in the controller, or should those be decorated functions in the model?

Is there a reason for (or even a point with) the training blank in the text node of the SPAN? HTML would ignore it anyway. And is the double colon just personal style or does that have a reason (it looks odd tbh).

Inserting into a DIV isn't quite efficient - and a bit fragile in refactoring. It may be better to create the sub-DIVs as a sequence, and define the outer DIV with that sequence of components at the end of the function. Then you can append to the sequence, or even use "" for the empty components and avoid append/insert altogether.

There is also a lot (!) you could DRY here - this repeated DIV(SPAN(something, _class="cap-label"), SPAN(something_else, _class="cap-value")) is really unnecessary and makes the code hard to read.

@nursix I created a div as:

```
                        detail_div = DIV(SPAN("%(heading)s",
                                              _class = "%(hclass)s"
                                              ),
                                         SPAN("%(value)s",
                                              _class = "%(vclass)s"
                                              ))
```

Is there a way I can dynamically replace heading, hclass, value and vclass later so I dont have to redefine the DIV again and DRY

@biplovbhandari : serious question?

Try Python:

```
def form_row(label, value, lclass="cap-label", vclass="cap-value"):

    return DIV(SPAN(label, _class=lclass),
               SPAN(value, _class=vclass),
               )
```

@biplovbhandari : How about the following variant:

```
                widget = s3db.cap_AlertProfileWidget
                component = widget.component

                @widget(None)
                def alert_widget(r, **attr):
                    return (
                      component("Headline", info.headline,
                                uppercase = True,
                                hide_empty = True,
                                ),
                      component("Description",
                                info.description,
                                uppercase = True,
                                hide_empty = True,
                                ),
                      component("Response Type",
                                " ".join(info.response_type),
                                uppercase = True,
                                hide_empty = True,
                                ),
                      component("Instructions",
                                info.instruction,
                                uppercase = True,
                                hide_empty = True,
                                ),
                    )

                @widget("Information",
                        label = "Event",
                        value = itable.event_type_id.represent(info.event_type_id),
                        )
                def info_widget(r, **attr):

                    if len(parameters):
                        params = ", ".join("%s: %s" % (p.name, p.value)
                                           for p in parameters)
                    else:
                        params = None

                    return (
                        component("Language",
                                  info.language,
                                  represent = itable.language.represent,
                                  ),
                        component("Category",
                                  info.category,
                                  represent = itable.category.represent,
                                  hide_empty = True,
                                  ),
                        component("Urgency",
                                  info.urgency,
                                  represent = itable.urgency.represent,
                                  ),
                        component("Severity",
                                  info.severity,
                                  represent = itable.severity.represent,
                                  ),
                        component("Certainty",
                                  info.certainty,
                                  represent = itable.certainty.represent,
                                  ),
                        component("Audience",
                                  info.audience,
                                  hide_empty=True,
                                  ),
                        component("Effective Date",
                                  info.effective,
                                  represent = itable.effective.represent,
                                  ),
                        component("Onset Date",
                                  info.onset,
                                  represent = itable.onset.represent,
                                  ),
                        component("Expiry Date",
                                  info.expires,
                                  represent = itable.expires.represent,
                                  ),
                        component("Information URL",
                                  info.web,
                                  ),
                        component("Sender",
                                  info.sender_name,
                                  hide_empty=True,
                                  ),
                        component("Contact Info",
                                  info.contact,
                                  ),
                        component("Parameters",
                                  parameters,
                                  hide_empty=True,
                                  ),
                    )

                @widget("Alert Qualifiers")
                def qualifiers_widget(r, **attr):

                    return (
                        component("Sender ID",
                                  record.sender,
                                  ),
                        component("Sent Date/Time",
                                  record.sent,
                                  represent = table.sent.represent,
                                  ),
                        component("Message Status",
                                  record.status,
                                  represent = table.status.represent,
                                  ),
                        component("Message Type",
                                  record.msg_type,
                                  ),
                        component("Handling Code",
                                  record.codes,
                                  represent = table.codes.represent,
                                  hide_empty = True,
                                  ),
                        component("Scope",
                                  record.scope,
                                  ),
                        component("Note",
                                  record.note,
                                  ),
                        component("Reference ID",
                                  record.reference,
                                  ),
                        component("Incident IDs",
                                  record.incidents,
                                  represent = table.incidents.represent,
                                  ),
                    )

                s3db.configure(tablename,
                               profile_header = profile_header,
                               profile_layers = (layer,),
                               profile_widgets = ({"type": "custom",
                                                   "fn": alert_widget,
                                                   },
                                                  map_widget,
                                                  {"type": "custom",
                                                   "fn": info_widget,
                                                   },
                                                  {"type": "custom",
                                                   "fn": qualifiers_widget,
                                                   },
                                                  ),
                               )
```

Does this look ok?

Here is the DRY part of it (in modules/s3db/cap.py then):

```
class cap_AlertProfileWidget(object):
    """ Custom profile widget builder """

    def __init__(self, title, label=None, value=None):

        self.title = title
        self.label = label
        self.value = value

    # -------------------------------------------------------------------------
    def __call__(self, f):
        """ Widget builder """

        def widget(r, **attr):
            components = f(r, **attr)
            components = [c for c in components if c is not None]
            title = self.title
            if title:
                label = self.label
                value = self.value
                if label and value:
                    title_ = DIV(SPAN("%s " % T(title),
                                      _class="cap-value upper"
                                      ),
                                 SPAN("%s: " % T(label),
                                      _class="cap-label upper"
                                      ),
                                 SPAN(value,
                                      _class="cap-strong"
                                      ),
                                 )
                else:
                    title_ = DIV(SPAN(T(title)))

                header = TAG[""](title_,
                                 DIV(_class="underline"),
                                 )
                output = DIV(header, *components)
            else:
                output = DIV(components)
            return output

        return widget

    # -------------------------------------------------------------------------
    @staticmethod
    def component(label, value,
                  represent = None,
                  uppercase = False,
                  strong = False,
                  hide_empty = False):
        """ Component builder """

        if not value and hide_empty:
            return None
        else:
            if represent:
                value = represent(value)
            label_class = "cap-label"
            if uppercase:
                label_class = "%s upper" % label_class
            value_class = "cap-strong" if strong else "cap-value"
            output = DIV(SPAN("%s: " % T(label), _class=label_class),
                            SPAN(value, _class=value_class),
                            )
            return output
```

Clean separation of logic and layout, readable code.

Yeah, of course - just quickly hacked together. Lacks proper docstrings, and some details may need to be adjusted, but it illustrates the idea.

With this widget configuration pattern, you can quickly add/extend/refactor the profile widgets - and even make this customisable (both contents and layout) - and the component order doesn't break when you add, move or remove components (much more robust than insert).

And I think, there's also potential for generalisation of the pattern so it can be re-used in other profiles - but ok, that might go too far right now ;)

You can't let go of the index in the variable name, can you? 

body1, body2, body3...why not just "item" and re-use that, or why have a local variable at all?

Could just make this a list (rather than appending):

(Example to illustrate the pattern - don't use verbatim):

```
    body = [
        T("%(scope)s %(status)s Alert") % \
            {"scope": s3_str(row["cap_alert.scope"]),
             "status": s3_str(row["cap_alert.status"]),
             },
        T((s3_str(row["cap_info.headline"]))),
        T("ID: %(identifier)s") % \
            {"identifier": s3_str(row["cap_alert.identifier"]),
             },
        T("""%(priority)s message %(message_type)s in effect for %(area_description)s""") % \
            {"priority": s3_str(priority),
             "message_type": s3_str(row["cap_alert.msg_type"]),
             "area_description": s3_str(row["cap_area.name"]),
             },
        T("This %(severity)s %(event_type)s is %(urgency)s and is %(certainty)s") % \
            {"severity": s3_str(row["cap_info.severity"]),
             "event_type": s3_str(event_type),
             "urgency": s3_str(row["cap_info.urgency"]),
             "certainty": s3_str(row["cap_info.certainty"]),
             },

        T("""Message %(identifier)s: %(event_type)s (%(category)s) issued by %(sender_name)s sent at %(date)s from %(source)s""") % \
            {"identifier": s3_str(row["cap_alert.identifier"]),
             "event_type": s3_str(event_type),
             "category": s3_str(category),
             "sender_name": s3_str(row["cap_info.sender_name"]),
             "date": s3_str(row["cap_alert.sent"]),
             "source": s3_str(row["cap_alert.source"]),
             },
        # and so forth...
    ]

    # str.join not working with T's
    body = "\n\n".join(s3_str(item) for item in body)
```

Nice to add a comment explaining why this default & pointing to the setting of True in interactive
(It looks odd seeing it here naked)

This isn't i18n like this (i.e. Strings will always be English, not translated)
I see that you can't use the validator as-is since you need the extra option for en-US.
I would propose adding an option to the validator to pass in extra options & then use that as-is

This comment doesn't match the core model definition.
If the requires is modified to a subset for interactive records in the controller then this label should be added there too (which also improves performance a fraction ;) )

At least (missing space)

As-above

semantically this should be cap-title

No, this isn't what I was suggesting to make configurable...it was the following of links at all.
This is what seems usecase-specific.
That is what should either be a deployment_setting (but then I'm not sure what the consistent pattern should be for handling such returned data?) or else left to the parser (seems more correct to me)

Currently this is the same as the default model setting, just without translate=True
I'd have thought you defintiely wanted translate=True here.
Maybe the model should remove the 'select' parameter? (Otherwise the comment is valid there too)

I don't think the username needs to be readable False?

Seems that we could use some stdisation of this...other settings are inconsistent here.
I think readable=False is probably correct and also enhanced with:
widget = S3PasswordWidget()

This does nothing any more?

Ah, well used here but is there any point?
When would a SAMBRO deployment not want this option?
The Parser is already template-specific

Why was this removed?
has the CAP std changed?
Internally Sahana GIS uses m, my understanding was that CAP used km, hence the need to multiply by 1000

As-above

Should this be OR not AND?

Why do a separate select here? Why not just add this field to the 1st one?

Is this true for all Alerts or do we need to distinguish?

Same question

Good, but you'll need to do a lot more, no?
All the cap_incident_type_opts justunder this refer to T which will no longer be available...these will need moving into a class or better just a function to minimise need for loading table models unnecessarily.

Much nicer...although I would suggest using s3_fullname...this supports Middle Names too & adjusts word order based on locale

Or, you simply remove the T's in these option dicts, and instead add translate=True to the respective S3Represent instances.

Also used in S3OptionsFilter options

Ah...doesn't really hurt to add a translate-option to the S3OptionsFilter with fixed options dicts as well, does it? Maybe I should do that...

Calling a function twice that delivers an invariant result? Probably better to call it once and assign to a local variable.

NB slight violation of naming convention (camel case) - maybe take the opportunity to fix that?

Now that translate=True doesn't make sense as you have T's in the options dict. Either T there or translate here.

Changing the iterable inside the loop => this can crash. Safer to build a new list, or skip here and add an iterator into the join().

Should also update the docstring with the represent-option.

I was imagining a single fn rather than all these => called 1/model => less overheads

Although with the new enhancement Dominic added to S3OptionsFilter, then no need for fns...can do the T() inside the Represent & Filter instead...so can define plain strings at the module level

Yikes, you even call the fn twice ;)

The case which doesn't have a translate=True option is requires=IS_IN_SET
But can do the T() part before that inside the model (then may as well re-use for the S3Represent/S3OptionsFIlter)

messages["NONE"](not the same thing)

No need to run this if cap_use_ack is False

if cap_use_ack is False then do this once outside the loop

distinguish from?

In general better to avoid double-negatives like non_system=False, system=True would seem more intuitive...but I don't understand the 2 use-cases yet

from the first responders email. because row coming from .msg is already represented and formatted if it is a list.

Looks a bit odd as quote, better to leave it as normal text, but replace the exclamation mark with a colon.

For consistency, this should also be a list item, and the sentence above end with a colon.

Cool! One more here (drop the link to the next line and make it a list item like the others).

Then squash all commits into one and push again, after that it can be merged.

Ahm, no - not hardcoding this here.

Same - can't hardcode this here (base is generic)

Should retain a fallback for the case that the iso_datetime has a Z (which can happen if so configured)

Nope - don't remove that, there was a point to it. 
If you need an exception, then implement an exception based on resource_name - but don't change all other cases.

Also - not really a good idea to un-DRY this, the <item> wrapper should be retained in base.

Required for all other resource types - pls don't remove this. If you need an exception, implement a xsl:choose.

This way of putting the username & password in isn't as good as the previous method as it means that the username/password get recorded in more proxy logs etc

The previous method already handled this...so there may be sites which will break due to this now

This shouldn't need to be done inside the parser as it happens here:
https://github.com/sahana/eden/blob/master/modules/s3/s3msg.py#L266

What is different about this parser that that doesn't already do the job?

@flavour Some of them are not saved because of rollback if there is any error during the xml import

All the code here is highly copied from s3msg.py - would be muich better to make a helper function there & then reuse that here?
DRY => Easier maintenance

This can be S3Msg.feed_parser

Why not have the bozo handline inside the helper function as well? Again it is duplicated verbatim

Again, why is this stuff in common not moved inside the helper function?

Again, this part is in common with the core...something smells wrong here to duplicate it.
Why are we downloading RSS inside a parser?
My understanding of program flow is:
Scheduler -> Poll RSS -> RSS populates msg_message instance -> Parser invoked -> Parser then does whatever

Why would we invoke RSS download when a URL cannot be fetched?

Why do these errors come in? This still feels very wrong to workaround an issue like this...seems better to catch & isolate the issue instead

Why do we need this match to follow links?

In general I think that following links & handling them might be best done via a callback function...I haven't thought through exactly how that would work here but then I'm still confused by the whole flow...I don't know why you're polling an RSS feed inside a Parser at all!

Why have this only in the except clause?
Seems better to me to have:
if username/password:
 # Try download using authentication
  try:
    import base64
else:
  # Try download without authentication
   try:
     fetch

I still don't understand why we're looking at the parser status inside a parser?
All of that should be handled externally - we should never enter this function for a message if is_parsed is True

Related is why are you looking for multiple records here? Any individual message_id should only have a single record in the parser status table, yet you are assuming multiple & bombing out if any are done.
This seems to be why you're touching this table inside the parser as you are not trusting the external routine....so Why are there multiple records in the parser status table for a single message_id?

@flavour This is the case for Philippines Public Alerts http://publicalert.pagasa.dost.gov.ph/feeds/

With feedparser parsing, for a single entry, we get the value of entry['link'] as http://publicalert.pagasa.dost.gov.ph/feeds/a159aa44-96fc-4f8f-8b75-8a771b69e7dc which is not a valid cap feed but if I look at entry['links'] as <type 'list'>: [{'href': u'http://publicalert.pagasa.dost.gov.ph/output/gfa/a159aa44-96fc-4f8f-8b75-8a771b69e7dc.cap', 'type': u'application/cap+xml', 'rel': u'alternate'}], the href inside links containing the proper cap feed.

I told PH group about this, but they don't seem to care about this.

Actually these errors are for the feeds from SAMBRO at country where event type id are not there or the draft alerts. These feeds are before I made changes to them.

@flavour so as I explained above the entry['link'] will be http://publicalert.pagasa.dost.gov.ph/feeds/a159aa44-96fc-4f8f-8b75-8a771b69e7dc and the record.from_address is the url for that message_id. This is just to avoid duplicate looping

I have looked at the full file & it still makes no sense to me.
We have downloaded all the entries from the RSS feed in the Scheduled Poll
If we don't yet have a record in the CAP table then we assume that there must be an embedded link. (Aren't such links _always_ embedded? Why mention that in the else clause?) and so we download the whole feed again to extract it!?
This seems mightily inefficient.

Sorry, still not clear.
Are there still errors?
If so, can we isolate them to prevent touching parser status inside the parser?

@flavour How do we isolate the broken alerts to prevent touching parser status table?

ok, so the key problem here is this.
The usual case for RSS is that the link tag inside an entry would point to that item alone...in an unspecified format...could be HTML/RSS/CAP
The parser needs to be generic (does it? Or can we have separate ones in each sub-template?)
We want to look for the CAP.
For some sources this is the link (correct?) & for some it is the links entry.
The links entry is currently not parsed by the main poll, which is why you download the feed again to extract it.
I can't find any note on 'links' as a standard tag in RSS, however the right place to parse it seems to be in the core (to avoid having to parse feeds twice). What I do see is that it is perfectly legal to have multiple 'link' entries, though.
I think we should create a msg_rss_link table to store the multiple links in (component of msg_rss)
I don't think we need a deployment_setting for use_links since it's no faster to check that than simple to check for entry.links...so here the core will extract the links & the parser can simply read them to find the one which is 'type': u'application/cap+xml
How does that sound?
(@ToDo: Later we can reuse the same mechanism to handle multiple <link entries)

Avoid the 3rd loop ;)
All will go away if we do no RSS downloading in the parser...only the CAP

I need to understand exactly where it crashes & why

@flavour If we try to import this alert http://www.dmhwarning.gov.mm/eden/cap/alert/804.cap, there is no event_type_id (required) field in the xml, so it gives out the error from here: https://github.com/sahana/eden/blob/master/modules/s3/s3import.py#L2109

The error arise from here: https://github.com/sahana/eden/blob/master/modules/s3/s3resource.py#L2816 and the database rollback happens here: https://github.com/sahana/eden/blob/master/modules/s3/s3resource.py#L2839

Not sure if this is helpful to isolate the broken alerts preventing to touch parser status table?

Please review https://github.com/biplovbhandari/eden/commit/9ce0dca65da80975848e92b5141eb3ef6e055b21

Biplov--

not sure whether this helps, but you can prevent rollbacks on validation errors by adding ignore_errors=True to the import_xml. This will then walk through the entire tree, import all correct records but skip the invalid ones. You can still see all errors in resource.error and resource.error_tree.

Dominic

> 10 sep. 2016 kl. 18:49 skrev Biplov Bhandari notifications@github.com:
> 
> In modules/templates/SAMBRO/parser.py:
> 
> > ```
> >                                          current.log.error("Getting content from link failed: %s" % e)
> > ```
> > -                                    except urllib2.URLError, e:
> > -                                        current.log.error("Getting content from link failed: %s" % e)
> > -                                        else:
> > -                                            File = StringIO(file)
> >   +
> > -                                            # Import via XSLT
> > -                                            resource = s3db.resource("cap_alert")
> > -                                            stylesheet = os.path.join(current.request.folder, "static", "formats", "cap", "import.xsl")
> > -                                            success = resource.import_xml(File, stylesheet=stylesheet)
> > -                                            # Any error on database hook causes to rollback, so ensure this
> >   @flavour If we try to import this alert http://www.dmhwarning.gov.mm/eden/cap/alert/804.cap, there is no event_type_id (required) field in the xml, so it gives out the error from here: https://github.com/sahana/eden/blob/master/modules/s3/s3import.py#L2109
> 
> Not sure if this is helpful to isolate the broken alerts preventing to touch parser status table?
> 
> Please review biplovbhandari@9ce0dca
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub, or mute the thread.

Select inside loop - this should better be moved out

Empty update?

Besides - "set" is a reserved keyword, should not be used as variable name. Use "dbset" instead.

This is confusing: firstly, resource.import_xml does not return "success", but a JSON response - and secondly, you're not doing anything with "success" here anyway. If you don't intend to do anything with the return value, you shouldn't assign it. If you however do, then don't use a misleading variable name, use something like "result" or "json_output" instead.

Should you really repeat os.path.join inside the loop? Or s3db.resource, for that matter?

Should this be repeated inside the loop? (username/password don't seem to change)

Are unsolicited Auth headers really required? Seems wrong to me to unsolicitedly send the same username/password to multiple URLs. Wouldn't a 401 handler (opener) be more appropriate? And wouldn't different URLs require different credentials?

NB if the linked URLs are external sites, then you're giving away the user's credentials to sites which shouldn't see them. Are you sure this is safe operation in the context of the deployment?

Maybe this should have a separate username/password configuration per link then.

Hide this behind an 'if links' as this is a real edge case to have this field populated & we don't want to slow down the common cases any more than necessary

These too could be behind the 'if links'

How do we know that we should use the same username/password for the links?
Can we check that the links are on the same domain? & only then use the same username/password?

Within the MM template, do we need these commented entries?

Same as for MM

Same as for MM

Since this is the SAMBRO template, a 'For SAMBRO' comment seems superfluous?

links are for individual entry

eh?
I am suggesting moving these 2 lines underneath L2126
They are only ever needed 'if links' so better moved there, no?

I'm not sure what the value of storing these in the table are?
We have 3 different usecases:
(1) Main feed has no username/password & so we have nothing to try the links with (no other way we will populate these are there?)
(2) Main feed has a username/password & the links have the same domain & so we want to try the same username/password (since we can get these from the main channel, no need to store again here?
(3) Main feed has a username/password & the links have a different domain & so we don't wish to assume the same username/password ( we don't wish to send these off to random 3rd-party sites which could intercept them) - again we have no way to put in different usernames/password, do we?

So overall I would remove the usrl_domain parsing from the core poll_rss & move that to the parser:
Parser decides what to do with the links & there does the check for link_domain == channel_domain & then can reuse the channel's username/password if so

Yes but if links is in loop for entry in entries. So isn't better to define once outside loop?

Ah right, ok, couldn't see that in the diff..OK thanks for the other change, merging :)

This should really be done via an index (see Education Levels), not per-row.

I wonder whether this is not better in the custom theme?

It's a very rare edge case to impose a load on every interactive request for all other templates.

A similar process is done here: https://github.com/sahana/eden/blob/master/modules/s3layouts.py#L148

Indeed...changing the Logo without needing to build a custom theme is a process we expect to be very common...with websetup this would be configurable via web with ability to upload the new logo...this enhances accessibility a lot.
However the case you have here I envisage to be extremely uncommon & you already have a custom theme that you are maintaining

Err...there is no need for this really.

You can easily override the whole title_area in the custom menus.py if you with to link it to somewhere else, and I don't like the idea of having two ways of doing the same thing.

In the menus.py of the template, just add the HTML for the title area as in:

```
main_menu = MM(title_area = DIV(...))(
```

For an edge-case, this should be convenient enough.

I don't link this, really - if you need to go that far that you want to change even the URL of the logo, then you can as well override the entire title_area (see a few rows above) with an A() instance.

"title_area" is an option to the MM() class, so you can easily apply that to the main_menu in your template's menus.py.

Here:
https://github.com/sahana/eden/blob/master/modules/templates/SAMBRO/menus.py#L46

You can easily override the title area of the main menu with your own thing, e.g.:

```
    logo = IMG(_src=settings.get_ui_menu_logo(), 
            _alt=settings.get_system_name_short(),
            _class="logo",
            )
    url = URL(c="what", f="ever")

    main_menu = MM(title_area=A(logo, _href=url))(
```

You can go as fancy here as you like (as long as the CSS covers it)...and sure enough, this can apply different URLs per template if required.

If it's only the logo, then the setting would do - if it's more than the logo, then override the entire title area.

At the same time, from the discussion on the mailing list it seems that you want to permanently replace the homepage for this template with a custom page - so I wonder why you don't do exactly that (we have the option to override default/index per template), but instead try fumbling around with the link?

Define a custom index controller (class index) in controllers.py, and let it set whatever view you like default/index to be.

If you never need the inherited default/index in this template, then why wouldn't you just override it?

...and remember that you can just import classes from another template (in case you want to re-use a certain function in the parent template's controllers.py):

```
from ..controllers import something

class index(something):
    pass
```

...and it would inherit the 'something' function from the parent template, and set it as index-page for this template.

Not complicated at all.

Ok, more concrete:

in modules/templates/SAMBRO/MM/controllers.py:

```
from templates.SAMBRO.controllers import alert_hub_cop

class index(alert_hub_cop):
    pass
```

That should be enough to make alert_hub_cop the default/index controller for the MM template.

One very important point about that vs. the messing with the home-link is that many redirections go to default/index (e.g. after login!), so changing this link in the menu really isn't a solution.

But replacing the default/index controller with the function you want (while leaving the default/index link intact), that should do what you need.

...and also spares you the redirection in the web server, btw.

Actually, it is even more silly than that :D I just tested this as modules/templates/SAMBRO/MM/controllers.py:

```
# -*- coding: utf-8 -*-

from templates.SAMBRO.controllers import alert_hub_cop as index, subscriptions, user_info
```

Seriously...that does it already ;)

...although it would spoil your "Alert Hub" menu entry, so maybe you need:

```
# -*- coding: utf-8 -*-

from templates.SAMBRO.controllers import alert_hub_cop as index, subscriptions, user_info

class alert_hub_cop(index):
    pass
```

after all.

I think as long as the dependency of the parent template is given anyway, there is very little that would forbid importing and subclassing from it. Nothing is going to be DRYer than that.

...or more efficient, really.

All in all, I think the ability to override the default/index controller just like that makes it even less necessary (or useful) to be able to override the home-link in a setting - especially when there are so many things that would redirect directly to default/index.

It's simply so that default/index is assumed to be a safe constant throughout the system -  that it can be hard-coded without risk, that's where the system can go if all else fails, that's where it goes when it goes home. 

I see very little point in being able to override that - especially with such an inconsistent option. Hence I would ask for that option to be removed.

Are there multiple of these per Authority?

Are there multiple of these per Authority?

UTF-8 not ANSI

There can be like Kenya Met Service and Republic Hydromet. service of Replublic of Srpska have multiple

Not fully correct - must use the uploadfolder of the field. Besides, upload fields have a method to extract the file.

See here:
https://github.com/sahana/eden/blob/master/modules/s3/s3xml.py#L1250

And...having a Field method to get at the file properties, I'm not sure we need another wrapper function in doc.py.

Normally do imports at the module level, especially for a module like this which will inevitably be loaded anyway

Do this check outside the loop
if file_field.custom_retrieve_file_properties:
    retrieve_file_properties = file_field.custom_retrieve_file_properties
else:
    retrieve_file_properties =field_field.retrieve_file_properties

loop:
    prop = retrieve_file_properties (file)

Why plural? Seems misleading to me as it just creates a single one so best as:
def _create_attachment(alert_id)

No, you should never need to manually create records in the super entity.
You shopudl create records in the instane & then use s3db.update_super() to create/update the super-entity

Since alert_id is an integer then can just use normal str()

doc_document is NOT an instance of the doc_entity super entity
In this case it's cap_resource
doc_document is a component of the super-entity...

@flavour some question.
1. DO I need to update_super? Because I am creating records in the component (doc_document) and not in instance (cap_resource). The documentation talks about the instance table record creation/manipulation/deletion <a href="http://eden.sahanafoundation.org/wiki/S3/S3Model/SuperEntities#UpdatingaSuper-Entity" target="_blank">here</a>
2. when I update_super, does that mean a new record in super entity referencing the instance table is created?

1) If all you are doing is creating component records then no need to update_super.
However to make it a component then you will need to read the doc_id of the parent & insert that into the component.
2) update_super will create/update records in the super-entity table & then add the superkey to the instance table

To answer your questions:
1) doc_document is not an SE instance table, so calling update_super is not required. However, calling it will certainly not harm - _if_ you call it correctly. Here though you call it for the cap_resource table, but you pass a doc_document record ID, and that is clearly wrong (you must call it for the table the record belongs to!)

2) update_super does what it says - it updates all super-entity records for the instance records (copying all shared fields). Where no SE entry yet exists, it will create one. It is mandatory for all SE instance tables. Now, doc_document is no SE instance, so you could omit it (however, it doesn't harm to call it anyway)

Regarding your procedure here:

The way you do it, you're not attaching the document record to anything? Entries in doc_document can be unattached, of course - but the normal way is to attach document to some master record, and in this case it seems it should be attached to the alert at least.

If you want to create a document record for the alert, then you need to:
- extract the doc_id of the alert record, and add it to the document record
- create a new doc_document record
- run the usual update_super (on the right table!!), set_record_owner, onaccept etc

```
    # Get the alert's doc_id
    atable = s3db.cap_alert
    row = db(atable.id==alert_id).select(atable.doc_id, limitby=(0, 1)).first()

    # Create a new doc_document record
    dtable = s3db.doc_document
    record = {"doc_id": row.doc_id, "file": file}
    record_id = dtable.insert(**record)
    record["id"] = record_id

    # Update super
    s3db.update_super(dtable, record)

    # Record owner
    auth = current.auth
    auth.s3_set_record_owner(dtable, record_id)
    auth.s3_make_session_owner(dtable, record_id)

    # Execute onaccept
    s3db.onaccept("doc_document", record, method="create")
```

Of course, if it's not an SE instance (like in this case), then update_super may not be required. And if there is no onaccept defined, then calling onaccept may not be required either.

But neither call will fail (or do anything) if not required - and if anything changes in future or in a template (e.g. an onaccept being added), then calling them in any case you will be on the safe side.

Record ownership may be relevant in any case, and certainly the doc should be attached to the alert

You /can/ have this shorter:

```
    data = {"doc_id": row.doc_id, "file": file}
    dresource = s3db.resource("doc_document")
    record_id = dresource.insert(**data)
```

This will do all of the above as required. However, it will also check permissions to create a new record - and if the current user doesn't have permissions to create doc_documents, then this will raise an S3PermissionError. You could override it, of course.

---

Now, I wonder though why you want to store the XML as a doc_document - it's the alert XML, right? Why keep it? For just sending it, it'd be good enough to create a temp file, attach it to the message(s), and remove the file again after send.

I see little point in creating a new doc_document record with the alert XML every time you send the alert - it'll be the same XML over and over again, and it wouldn't be anything that is not already in the alert record or its components - so it seems to me that you are replicating data here? Why?

Why does the task have a file_path?

Should be inside the branch which uses it

generally I prefer arg names which imply their meaning
document_id suggests single...if multiple, then perhaps 'documents'

& the docstring should explain the args

The attachments should be per-message not per Task

One should never create a document_id within message sending anyway, no need to mention that I don't think.
I am really puzzled by this....why have both a file_path & a URL in the same branch?
file_path should be if we have a file
URL if we want to download a URL & send the results...seems a bit of an edge case but handy when wanted so I guess am happy to support within core messaging.

So I see 3 args required for send_by_pe_id:
documents=None (list of document_ids)
files = None (list of file_paths)
urls = None (list of URLs to download & attach results)

For this to work then msg_attachment needs to have 3 corresponding fields:
document_id (for when the attachment is a doc_document)
file (for when the attachment is a file)
url (for when the attachment is downloaded, results attached & then file discarded)

I generally don't like the 3rd option, I have to say, as the URL can give different results on different days...not a great history of what is sent, however I do see that it saves storage space in the msg_attachment table.

However for this usecase, contrary to what Dominic says, I personally see no big deal with storing the CAP XML for an Alert with the Alert if you need to send this with some of ther subscriptions.
I certainly agree with him that you shouldn't generate this multiple times, that seems ludicrous...the solution, to me, would be to store this in doc_document & then the subscriptions create msg_attachment pointing to document_id...this seems to be less of a CPU hog then creating the XML for each attachment separately...and CPU is far more of a bottleneck concern to me than diskspace.

So...whilst I see some value to add support to core messaging for attachments which are files & attachments which are URLs, personally I would prefer to just stick to using doc_document as this:
- Ensures we have a proper history of what is sent
- We should be able to avoid storing multiple copies of the same file
- We should be able to avoid the overheads of generating/downloading multiple copies of the same file

A run of process_outbox has to be able to support attachments in multiple formats

Why did you remove the try/except here?

Why this new table?
If you want documents to be a component of Alerts then make cap_alert a doc_entity instance.
Although currently cap_resource already is...so could that be used instead?

dtable is not an instance of a super entity...this is the wrong table to update_super on.
(Yes it won't hurt but it is wrong/unnecessary)

The key thing here is to add the doc_id of the doc_entity that you wish this to be a component of...but currently you're not using that since you've added a cap_attachment table instead, but that should be removed

This should be looking for the doc_document which has cap_alert.doc_id == doc_document.doc_id

No! As-before the doc_entity record is created by update_super.
In this case the doc_entity should already be created by the cap_resource

doc_id or document_id?
I think it's document_id

if cap_resource definitely exists already, then we can (hopefully!) assume that update_super was run as part of that record's creation, so we should just read the doc_id from that

Create the cap_resource record

NB This needs to happen before the doc_document is created, so that we can read the doc_id

+1: I like this :)

s3db.update_super(rtable, record) creates new record in doc_entity but how do I read the doc_id? This function returns boolean

https://github.com/sahana/eden/blob/master/modules/s3/s3msg.py#L394

Read the comment above the line you changed & see that you break that
Just

   from s3 import IS_ISO639_2_LANGUAGE_CODE

I think that should be "document_ids" instead of "documents_id"? (so it indicates multiple ids rather than a single id)
Not quite true - it's supposed to return a function that produces an array of document IDs (multiple)
Would attachment_fnc always be defined?
I think there should be an if attachment_fnc here
Good to add the args that the fnc needs to support here
typo ;)
Is this different to the below 'incident_tags' ?
Why are we returning to lots of hardcoded dummy data here?
This seems a step backwards when the previous version had live data in?
I'm not keen to replace a working system with a hardcoded set of dummy data...sure we can work on the styling of the working system, but I think that should happen outside of a Pull Request. NB For the Tags system our options may be limited as we're using a plugin to handle the Tags...we can investigate alternate plugins or even try rolling our own, but this then starts to get a lot more time-consuming
Currently this is a dummy form isn't it?
If you're happy to move to a jQueryUI popup, then I think best not to include this in the Pull Request...just the button which should invoke it...I will then add a default update form which we can then subsequently try to style like this - basically this would be a formstyle like for the filter widgets.
Again you're replacing working live code with dummy flat stuff...I really am reluctant to do this in a Pull Request
Just a note that if we're using Offsite fonts then that means that we cannot operate the system offline. This may not be an issue for WACOP but in general Incident Management systems need to be able to operate offline...this was a very key issue for our work with LAEMD for instance.
If you remove these then all the other default Sahana-style pages will likely break.
As per conversation with Devin, these will be used for all the Admin stuff like taxonomy changes
So you've removed all this CSS, but I don't see you've put it anywhere else?
So this will then break the Incident Browse page...perhaps some of the rest of the code in this file is also needed for that page...did you check it at all?
from s3 import s3_auth_user_represent
output["modified_by"] = s3_auth_user_represent(record.modified_by)
This looks like a mistake in your version of the code.
Default strings in code should always be en_US - so Organizations
Organisations is an en_GB translation
OK, I see this is a bug in current code, will fix
Done: https://github.com/sahana/eden/commit/50f2abbb03f845ab291fc17d68249e28acd01413
This shouldn't be necessary.
The controller now uses the create_post_button variable here (since this is now a button not a form):
https://github.com/dhornbein/eden/blob/90a5049898e61c9e8add64e7dc98ecd2925238c7/modules/templates/WACOP/controllers.py#L901

Looks like I updated the incident_profile.html view but not the dashboard view, so the correct solution is to update the dashboard view like the incident_profile already has been:
https://github.com/sahana/eden/blob/master/modules/templates/WACOP/views/incident_profile.html#L112

No need for the if...it is "" if not present
Wow, a lot of diff showing on GitHub to look throughy but seems just this added twice ;)
Ah well, I guess nothing we can do to make that easier
should this not be 'columns' not just 'column'? (& yes ' not " pls)
Generally T() will work better for translators like this:
XML("<b>%(label)s:</b> %(instruction)s" %
{'label': T("Instructions"),

etc
 
Nope - indeed none (parameter of this function), and not None.
Keep the HTML formatting outside of T:
XML("<b>%(label)s</b>:
{"label": T("ID"),
I know this is part of old code, not the change, but we would never expect to see multiple rows here would we? In which case a limitby=(0,1) will improve performance noticeably.
locations are only imported if we set polygons to be imported
The DB call here is only required if polygon not in location_default...so move it inside that branch to improve performance for the cases where polygon is in location_default
The DB call here is only required if geocode in location_default...so move it inside that branch to improve performance for the cases where geocode is not in location_default
👍 
👍 
👍 
Would be good to add a comment on why here
More importantly, should this not run when polygon not in location_default but row.external is False?
Again, is this final else in the correct place?
Comments would be useful to explain the logic here again...
typo: refers
Not so critical, but I would DRY these last 2 by having a return after the .delete()
& then having the .update() outside of the if (no need for any else)
I still think we're doing an unnecessary DB check here in some branches.
I would do:
if "geocode" in current.deployment_settings.get_cap_area_default():
    import_location = True 
else:
    # check for internal
@flavour but this "geocode" check is only while importing the alerts from external feeds (i.e. external alerts). Plus if there is no tag or same_code, we don't need to import as well.
> this "geocode" check is only while importing the alerts from external feeds (i.e. external alerts)

Yes, however if geocode is in the setting (quick lookup) then no need to check for internal/external...we always import_location=true (according to this logic anyway)

> if there is no tag or same_code, we don't need to import as well.

That is already covered by the 1st import_location = False

PEP8 space
PEP8 space after comma
Do we really need triple exclamation marks? 1 is plenty sufficient I think?
Makes sense since Resources are default as well. But could it go last in the menu?
I've tried to follow the same order as with the actual records using the types. Currently there are *Offices* - *Facilities* - *Resources* in that order, so *Office Types* - *Facility Types* - *Resource Types* made sense. But sure, I can move it to the end.
Actually, there is a better strategy here - see my comment in your other commit.
https://github.com/trendspotter/eden/commit/6523bba4d502a16951d83876a58925a5bac4c78d#diff-33fc0b179125dd7a80339eede2995c49R3131

Sorry, wasn't quick enough
My point there is that we don't actually want to extend the setting with the [item], but the [item] with the setting ;)

That way, we always know that it is mutable, and we spare us the explicit conversion to a list and the extra assignment of a dict property.

And then, implementations can do what they want - mutable or immutable doesn't matter. You can basically revert the cap.py changes: it's okay to set a tuple.
(And under the hood: instantiating tuples is a lot faster ;) - so cap.py setting tuples is a good thing, and performance in CRUD isn't worse with .extend than it would be with .insert)
No, that's actually meant to be NONE not None ;) However, this may be missing:

    NONE = current.messages["NONE"]
So, maybe replace ```NONE``` with ```current.messages["NONE"]``` here.
This format looks nice, however it isn't i18n, of course.
Nor is it a scaleable S3Represent
Are you able to enhance in these 2 ways?

> it isn't i18n

True, however [this one](https://github.com/sahana/eden/blob/8386145559fa8e4aad4208487d419b2d36c8ded0/modules/s3db/dvi.py#L153) wasn't either. I guess wrapping in it `T()` should do the trick in both cases.

> Nor is it a scaleable S3Represent

I've just copied and adjusted `morgue_represent()` method, so I take it that it's not a proper one either. Will try to modify both, if I figure out how :)
```
S3Represent(lookup = "dvi_recreq", 
            fields = ["marker", "date", "bodies_found"], 
            labels = T("[%(marker)s] %(date)s: %(bodies_found)s bodies"),
            )
```

Something like that.

...solves both, i18n and S3Represent.

Morgue_represent is even simpler:
```
S3Represent(lookup="dvi_morgue")
```
...the rest is default anyway.
Oh, forgot to say - S3Represent is configured during the table definition, like:
```
Field("some_field", represent = S3Represent(...))
```

...so no functions required here at all.
I'm not sure if this is correct, but when I put `T()` into `requires`, it doesn't show the string in dropdown at all and when I put `T()` to `S3Represent`'s `labels`, it gets ignored and builds the label from `fields` instead.
This is fine, but you should use the /same/ S3Represent in both requires and represent. Like this:

```
represent = S3Represent(...)
...requires = IS_EMPTY_OR(IS_ONE_OF(db, "dvi_recreq.id", represent))
...represent = represent
```

(Obviously, I can fix S3Represent to accept T for labels - but that will take a moment)
Done:
https://github.com/nursix/eden/commit/c972e9ca296562ceda25f319d1d1a4056b89ef91

Now you should be able to omit the s3_str() and just pass the T() for a label template. However, still, you should use S3Represent in both IS_ONE_OF and requires.
Example:
https://github.com/nursix/eden/blob/master/modules/s3db/dvr.py#L555
We should keep this to trigger sspag requests only every 4th page instead of every page
If it's supposed to be every 4th page, then I'd reintroduce
```
limit = 2 * display_length
```

because the pagination itself already doubles the amount of shown records in its request (ie. when I set 25 records per page, i get `limit=50` in GET). Witchcraft again :)
Nope. My bad. I'm trying to push the adjusted values to too many places.
But yes, it does :)

Even when I simplify this whole commit to 
```diff
-    display_start = int(get_vars.displayStart) if get_vars.displayStart else 0
-    display_length = int(get_vars.pageLength) if get_vars.pageLength else 10
+    display_start = int(get_vars.start) if get_vars.start else 0
+    display_length = int(get_vars.limit) if get_vars.limit else 10
```

After first 4 pages, the `limit` variable gets set to double the amount of items per page.
That was a misunderstanding - it is correct that the pipeline script retrieves 2x as many records as the user wants to see per page. That wasn't the point here.

This doubling doesn't happen for the 1st request - because it doesn't come from the pipeline script, and for that initial page request it should retrieve 4x as many records as in the initial page length setting, so that no pagination request is triggered unless the user browses past the 4th page (or changes the page length so something bigger than that).

So, the intended fetch length is 4x (initial request) - 2x (after the 4th page) - 2x (after the 6th) - 2x (etc...)

I think this one is good enough - does anything speak against just leaving it at that?
Debug code left in
I'm not sure this is a good enough reason to remove it completely?
Surely site_id & organisation_id don't need logging anyway, as these are now back to the original for the asset?
I would add a little note:
Read method set in prep
Lovely :)
Should this not check whether itable.id != form.id? (otherwise updates would always be rejected this way, right?)
Shouldn't this better be
```
elif len(irows) > 1
```

...otherwise 3 info segments would allow adding more again.
Same here - better check >1 than ==2?
Wondering about this...isn't ```if len(irows) < 2``` exactly the same condition? Would be one len() less.
Above you're checking for ```if row``` - but here you just access row.event_type_id without checking. Is that correct?
...and if you check ```if len(irows) < 2``` then this can be ```else``` instead of ```elif```. So saving yet another len().
That is, there is no case where len(irows) would be <0 ;)
👍 
Yes. `event_type_id` is a required field. The `if alert` makes sure of `row.event_type_id`. But now I am thinking `row` will never be `None`, so I can avoid that `if row` check? 
Should be added as an optional dependency to requirements.txt
Better to do as:
try:
    import
except Import Error
    pass
else:
    try:
        url = ...
& ideally 2nd except would be more specific...why would it fail? Network issues?
Sam try/except/else
the exception is ```requests.exceptions.ReadTimeout```. Just do not want to import requests, which would be unused. I would make changes with the structure you mentioned
